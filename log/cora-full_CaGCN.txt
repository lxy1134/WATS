/usr/local/lib/python3.11/dist-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning(
Dataset: cora-full | #Nodes: 18800 | #Edges: 144170 | #Classes: 70 |#Features: 8710
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2466 | Acc(train) 0.0218 | Acc(val) 0.1691 |*
Epoch 00002 | Loss(train) 4.2081 | Acc(train) 0.1056 | Acc(val) 0.1766 |*
Epoch 00003 | Loss(train) 4.1599 | Acc(train) 0.1519 | Acc(val) 0.1952 |*
Epoch 00004 | Loss(train) 4.0930 | Acc(train) 0.1588 | Acc(val) 0.2085 |*
Epoch 00005 | Loss(train) 4.0136 | Acc(train) 0.1689 | Acc(val) 0.2229 |*
Epoch 00006 | Loss(train) 3.9304 | Acc(train) 0.1824 | Acc(val) 0.2330 |*
Epoch 00007 | Loss(train) 3.8705 | Acc(train) 0.1705 | Acc(val) 0.2319 |
Epoch 00008 | Loss(train) 3.8183 | Acc(train) 0.1809 | Acc(val) 0.2138 |
Epoch 00009 | Loss(train) 3.7433 | Acc(train) 0.1819 | Acc(val) 0.1835 |
Epoch 00010 | Loss(train) 3.6972 | Acc(train) 0.1715 | Acc(val) 0.1809 |
Epoch 00011 | Loss(train) 3.6336 | Acc(train) 0.1729 | Acc(val) 0.1904 |
Epoch 00012 | Loss(train) 3.5753 | Acc(train) 0.1806 | Acc(val) 0.2213 |
Epoch 00013 | Loss(train) 3.4961 | Acc(train) 0.2093 | Acc(val) 0.2654 |*
Epoch 00014 | Loss(train) 3.4386 | Acc(train) 0.2428 | Acc(val) 0.3170 |*
Epoch 00015 | Loss(train) 3.3629 | Acc(train) 0.2694 | Acc(val) 0.3606 |*
Epoch 00016 | Loss(train) 3.3020 | Acc(train) 0.2856 | Acc(val) 0.3883 |*
Epoch 00017 | Loss(train) 3.2659 | Acc(train) 0.2926 | Acc(val) 0.4144 |*
Epoch 00018 | Loss(train) 3.2039 | Acc(train) 0.3154 | Acc(val) 0.4229 |*
Epoch 00019 | Loss(train) 3.1635 | Acc(train) 0.3104 | Acc(val) 0.4218 |
Epoch 00020 | Loss(train) 3.0873 | Acc(train) 0.3149 | Acc(val) 0.4197 |
Epoch 00021 | Loss(train) 3.0942 | Acc(train) 0.3048 | Acc(val) 0.4223 |
Epoch 00022 | Loss(train) 3.0266 | Acc(train) 0.3098 | Acc(val) 0.4250 |*
Epoch 00023 | Loss(train) 3.0136 | Acc(train) 0.3149 | Acc(val) 0.4245 |
Epoch 00024 | Loss(train) 2.9573 | Acc(train) 0.3181 | Acc(val) 0.4303 |*
Epoch 00025 | Loss(train) 2.9315 | Acc(train) 0.3269 | Acc(val) 0.4388 |*
Epoch 00026 | Loss(train) 2.8956 | Acc(train) 0.3322 | Acc(val) 0.4537 |*
Epoch 00027 | Loss(train) 2.8673 | Acc(train) 0.3391 | Acc(val) 0.4691 |*
Epoch 00028 | Loss(train) 2.8555 | Acc(train) 0.3471 | Acc(val) 0.4819 |*
Epoch 00029 | Loss(train) 2.8266 | Acc(train) 0.3484 | Acc(val) 0.4915 |*
Epoch 00030 | Loss(train) 2.7952 | Acc(train) 0.3561 | Acc(val) 0.4984 |*
Epoch 00031 | Loss(train) 2.8051 | Acc(train) 0.3561 | Acc(val) 0.5005 |*
Epoch 00032 | Loss(train) 2.7919 | Acc(train) 0.3644 | Acc(val) 0.5090 |*
Epoch 00033 | Loss(train) 2.7233 | Acc(train) 0.3721 | Acc(val) 0.5064 |
Epoch 00034 | Loss(train) 2.7351 | Acc(train) 0.3713 | Acc(val) 0.5096 |*
Epoch 00035 | Loss(train) 2.7476 | Acc(train) 0.3630 | Acc(val) 0.5043 |
Epoch 00036 | Loss(train) 2.7206 | Acc(train) 0.3809 | Acc(val) 0.5032 |
Epoch 00037 | Loss(train) 2.6946 | Acc(train) 0.3801 | Acc(val) 0.4989 |
Epoch 00038 | Loss(train) 2.6814 | Acc(train) 0.3848 | Acc(val) 0.4995 |
Epoch 00039 | Loss(train) 2.7035 | Acc(train) 0.3793 | Acc(val) 0.5032 |
Epoch 00040 | Loss(train) 2.6561 | Acc(train) 0.3883 | Acc(val) 0.5069 |
Epoch 00041 | Loss(train) 2.6783 | Acc(train) 0.3827 | Acc(val) 0.5112 |*
Epoch 00042 | Loss(train) 2.6451 | Acc(train) 0.3896 | Acc(val) 0.5191 |*
Epoch 00043 | Loss(train) 2.6533 | Acc(train) 0.3819 | Acc(val) 0.5298 |*
Epoch 00044 | Loss(train) 2.6572 | Acc(train) 0.3931 | Acc(val) 0.5367 |*
Epoch 00045 | Loss(train) 2.6399 | Acc(train) 0.3923 | Acc(val) 0.5399 |*
Epoch 00046 | Loss(train) 2.6243 | Acc(train) 0.3846 | Acc(val) 0.5410 |*
Epoch 00047 | Loss(train) 2.6333 | Acc(train) 0.3984 | Acc(val) 0.5420 |*
Epoch 00048 | Loss(train) 2.5903 | Acc(train) 0.3979 | Acc(val) 0.5420 |
Epoch 00049 | Loss(train) 2.6267 | Acc(train) 0.4051 | Acc(val) 0.5426 |*
Epoch 00050 | Loss(train) 2.6046 | Acc(train) 0.4106 | Acc(val) 0.5489 |*
Epoch 00051 | Loss(train) 2.6229 | Acc(train) 0.3926 | Acc(val) 0.5473 |
Epoch 00052 | Loss(train) 2.5720 | Acc(train) 0.4082 | Acc(val) 0.5447 |
Epoch 00053 | Loss(train) 2.6056 | Acc(train) 0.3963 | Acc(val) 0.5431 |
Epoch 00054 | Loss(train) 2.5552 | Acc(train) 0.4106 | Acc(val) 0.5420 |
Epoch 00055 | Loss(train) 2.5768 | Acc(train) 0.4138 | Acc(val) 0.5426 |
Epoch 00056 | Loss(train) 2.5895 | Acc(train) 0.3936 | Acc(val) 0.5436 |
Epoch 00057 | Loss(train) 2.5501 | Acc(train) 0.4085 | Acc(val) 0.5447 |
Epoch 00058 | Loss(train) 2.5564 | Acc(train) 0.4170 | Acc(val) 0.5457 |
Epoch 00059 | Loss(train) 2.5459 | Acc(train) 0.4037 | Acc(val) 0.5489 |
Epoch 00060 | Loss(train) 2.5413 | Acc(train) 0.4136 | Acc(val) 0.5479 |
Epoch 00061 | Loss(train) 2.5660 | Acc(train) 0.4104 | Acc(val) 0.5505 |*
Epoch 00062 | Loss(train) 2.5690 | Acc(train) 0.4120 | Acc(val) 0.5532 |*
Epoch 00063 | Loss(train) 2.5566 | Acc(train) 0.4186 | Acc(val) 0.5585 |*
Epoch 00064 | Loss(train) 2.5530 | Acc(train) 0.4136 | Acc(val) 0.5622 |*
Epoch 00065 | Loss(train) 2.5235 | Acc(train) 0.4263 | Acc(val) 0.5612 |
Epoch 00066 | Loss(train) 2.5405 | Acc(train) 0.4152 | Acc(val) 0.5633 |*
Epoch 00067 | Loss(train) 2.5129 | Acc(train) 0.4266 | Acc(val) 0.5638 |*
Epoch 00068 | Loss(train) 2.5236 | Acc(train) 0.4176 | Acc(val) 0.5617 |
Epoch 00069 | Loss(train) 2.5157 | Acc(train) 0.4122 | Acc(val) 0.5606 |
Epoch 00070 | Loss(train) 2.5401 | Acc(train) 0.4237 | Acc(val) 0.5564 |
Epoch 00071 | Loss(train) 2.5516 | Acc(train) 0.4197 | Acc(val) 0.5527 |
Epoch 00072 | Loss(train) 2.4962 | Acc(train) 0.4162 | Acc(val) 0.5537 |
Epoch 00073 | Loss(train) 2.5241 | Acc(train) 0.4226 | Acc(val) 0.5559 |
Epoch 00074 | Loss(train) 2.5428 | Acc(train) 0.4168 | Acc(val) 0.5580 |
Epoch 00075 | Loss(train) 2.5096 | Acc(train) 0.4295 | Acc(val) 0.5596 |
Epoch 00076 | Loss(train) 2.5595 | Acc(train) 0.4048 | Acc(val) 0.5596 |
Epoch 00077 | Loss(train) 2.5201 | Acc(train) 0.4176 | Acc(val) 0.5612 |
Epoch 00078 | Loss(train) 2.5238 | Acc(train) 0.4205 | Acc(val) 0.5596 |
Epoch 00079 | Loss(train) 2.5069 | Acc(train) 0.4229 | Acc(val) 0.5596 |
Epoch 00080 | Loss(train) 2.5240 | Acc(train) 0.4141 | Acc(val) 0.5606 |
Epoch 00081 | Loss(train) 2.5381 | Acc(train) 0.4152 | Acc(val) 0.5585 |
Epoch 00082 | Loss(train) 2.4934 | Acc(train) 0.4266 | Acc(val) 0.5628 |
Epoch 00083 | Loss(train) 2.5429 | Acc(train) 0.4128 | Acc(val) 0.5676 |*
Epoch 00084 | Loss(train) 2.5694 | Acc(train) 0.4130 | Acc(val) 0.5707 |*
Epoch 00085 | Loss(train) 2.5087 | Acc(train) 0.4194 | Acc(val) 0.5723 |*
Epoch 00086 | Loss(train) 2.5321 | Acc(train) 0.4160 | Acc(val) 0.5702 |
Epoch 00087 | Loss(train) 2.4645 | Acc(train) 0.4295 | Acc(val) 0.5702 |
Epoch 00088 | Loss(train) 2.5485 | Acc(train) 0.4011 | Acc(val) 0.5686 |
Epoch 00089 | Loss(train) 2.5272 | Acc(train) 0.4181 | Acc(val) 0.5681 |
Epoch 00090 | Loss(train) 2.5020 | Acc(train) 0.4255 | Acc(val) 0.5676 |
Epoch 00091 | Loss(train) 2.5318 | Acc(train) 0.4120 | Acc(val) 0.5665 |
Epoch 00092 | Loss(train) 2.5217 | Acc(train) 0.4098 | Acc(val) 0.5665 |
Epoch 00093 | Loss(train) 2.5195 | Acc(train) 0.4173 | Acc(val) 0.5649 |
Epoch 00094 | Loss(train) 2.5192 | Acc(train) 0.4245 | Acc(val) 0.5633 |
Epoch 00095 | Loss(train) 2.4978 | Acc(train) 0.4274 | Acc(val) 0.5644 |
Epoch 00096 | Loss(train) 2.5141 | Acc(train) 0.4229 | Acc(val) 0.5606 |
Epoch 00097 | Loss(train) 2.5020 | Acc(train) 0.4199 | Acc(val) 0.5617 |
Epoch 00098 | Loss(train) 2.5129 | Acc(train) 0.4199 | Acc(val) 0.5670 |
Epoch 00099 | Loss(train) 2.5327 | Acc(train) 0.4098 | Acc(val) 0.5702 |
Epoch 00100 | Loss(train) 2.5016 | Acc(train) 0.4303 | Acc(val) 0.5691 |
Epoch 00101 | Loss(train) 2.5120 | Acc(train) 0.4231 | Acc(val) 0.5665 |
Epoch 00102 | Loss(train) 2.5079 | Acc(train) 0.4136 | Acc(val) 0.5670 |
Epoch 00103 | Loss(train) 2.5277 | Acc(train) 0.4160 | Acc(val) 0.5601 |
Epoch 00104 | Loss(train) 2.5364 | Acc(train) 0.4138 | Acc(val) 0.5585 |
Epoch 00105 | Loss(train) 2.4959 | Acc(train) 0.4226 | Acc(val) 0.5585 |
Epoch 00106 | Loss(train) 2.5161 | Acc(train) 0.4157 | Acc(val) 0.5580 |
Epoch 00107 | Loss(train) 2.4981 | Acc(train) 0.4170 | Acc(val) 0.5574 |
Epoch 00108 | Loss(train) 2.5013 | Acc(train) 0.4178 | Acc(val) 0.5612 |
Epoch 00109 | Loss(train) 2.5106 | Acc(train) 0.4237 | Acc(val) 0.5633 |
Epoch 00110 | Loss(train) 2.5130 | Acc(train) 0.4181 | Acc(val) 0.5649 |
Epoch 00111 | Loss(train) 2.5232 | Acc(train) 0.4237 | Acc(val) 0.5633 |
Epoch 00112 | Loss(train) 2.5116 | Acc(train) 0.4165 | Acc(val) 0.5644 |
Epoch 00113 | Loss(train) 2.5246 | Acc(train) 0.4186 | Acc(val) 0.5633 |
Epoch 00114 | Loss(train) 2.5133 | Acc(train) 0.4245 | Acc(val) 0.5660 |
Epoch 00115 | Loss(train) 2.5312 | Acc(train) 0.4157 | Acc(val) 0.5702 |
Epoch 00116 | Loss(train) 2.5034 | Acc(train) 0.4205 | Acc(val) 0.5697 |
Epoch 00117 | Loss(train) 2.5008 | Acc(train) 0.4247 | Acc(val) 0.5713 |
Epoch 00118 | Loss(train) 2.4831 | Acc(train) 0.4372 | Acc(val) 0.5681 |
Epoch 00119 | Loss(train) 2.5180 | Acc(train) 0.4221 | Acc(val) 0.5665 |
Epoch 00120 | Loss(train) 2.5014 | Acc(train) 0.4231 | Acc(val) 0.5633 |
Epoch 00121 | Loss(train) 2.5067 | Acc(train) 0.4250 | Acc(val) 0.5660 |
Epoch 00122 | Loss(train) 2.4919 | Acc(train) 0.4274 | Acc(val) 0.5665 |
Epoch 00123 | Loss(train) 2.5232 | Acc(train) 0.4205 | Acc(val) 0.5612 |
Epoch 00124 | Loss(train) 2.5801 | Acc(train) 0.4072 | Acc(val) 0.5569 |
Epoch 00125 | Loss(train) 2.4986 | Acc(train) 0.4229 | Acc(val) 0.5564 |
Epoch 00126 | Loss(train) 2.5277 | Acc(train) 0.4133 | Acc(val) 0.5574 |
Epoch 00127 | Loss(train) 2.4836 | Acc(train) 0.4285 | Acc(val) 0.5574 |
Epoch 00128 | Loss(train) 2.5175 | Acc(train) 0.4207 | Acc(val) 0.5601 |
Epoch 00129 | Loss(train) 2.5069 | Acc(train) 0.4269 | Acc(val) 0.5686 |
Epoch 00130 | Loss(train) 2.4985 | Acc(train) 0.4266 | Acc(val) 0.5723 |
Epoch 00131 | Loss(train) 2.5189 | Acc(train) 0.4210 | Acc(val) 0.5793 |*
Epoch 00132 | Loss(train) 2.4957 | Acc(train) 0.4370 | Acc(val) 0.5793 |
Epoch 00133 | Loss(train) 2.5341 | Acc(train) 0.4191 | Acc(val) 0.5750 |
Epoch 00134 | Loss(train) 2.5025 | Acc(train) 0.4335 | Acc(val) 0.5707 |
Epoch 00135 | Loss(train) 2.5222 | Acc(train) 0.4255 | Acc(val) 0.5681 |
Epoch 00136 | Loss(train) 2.4880 | Acc(train) 0.4386 | Acc(val) 0.5660 |
Epoch 00137 | Loss(train) 2.5273 | Acc(train) 0.4178 | Acc(val) 0.5670 |
Epoch 00138 | Loss(train) 2.4742 | Acc(train) 0.4309 | Acc(val) 0.5665 |
Epoch 00139 | Loss(train) 2.5208 | Acc(train) 0.4255 | Acc(val) 0.5660 |
Epoch 00140 | Loss(train) 2.5105 | Acc(train) 0.4189 | Acc(val) 0.5697 |
Epoch 00141 | Loss(train) 2.4731 | Acc(train) 0.4327 | Acc(val) 0.5697 |
Epoch 00142 | Loss(train) 2.5265 | Acc(train) 0.4311 | Acc(val) 0.5729 |
Epoch 00143 | Loss(train) 2.5225 | Acc(train) 0.4242 | Acc(val) 0.5697 |
Epoch 00144 | Loss(train) 2.5020 | Acc(train) 0.4277 | Acc(val) 0.5718 |
Epoch 00145 | Loss(train) 2.4903 | Acc(train) 0.4293 | Acc(val) 0.5723 |
Epoch 00146 | Loss(train) 2.4911 | Acc(train) 0.4340 | Acc(val) 0.5761 |
Epoch 00147 | Loss(train) 2.5052 | Acc(train) 0.4229 | Acc(val) 0.5729 |
Epoch 00148 | Loss(train) 2.4934 | Acc(train) 0.4247 | Acc(val) 0.5707 |
Epoch 00149 | Loss(train) 2.5314 | Acc(train) 0.4117 | Acc(val) 0.5713 |
Epoch 00150 | Loss(train) 2.5144 | Acc(train) 0.4162 | Acc(val) 0.5745 |
Epoch 00151 | Loss(train) 2.5017 | Acc(train) 0.4253 | Acc(val) 0.5777 |
Epoch 00152 | Loss(train) 2.4992 | Acc(train) 0.4266 | Acc(val) 0.5809 |*
Epoch 00153 | Loss(train) 2.5046 | Acc(train) 0.4293 | Acc(val) 0.5803 |
Epoch 00154 | Loss(train) 2.5009 | Acc(train) 0.4261 | Acc(val) 0.5761 |
Epoch 00155 | Loss(train) 2.5053 | Acc(train) 0.4231 | Acc(val) 0.5707 |
Epoch 00156 | Loss(train) 2.4796 | Acc(train) 0.4213 | Acc(val) 0.5702 |
Epoch 00157 | Loss(train) 2.4575 | Acc(train) 0.4332 | Acc(val) 0.5697 |
Epoch 00158 | Loss(train) 2.5369 | Acc(train) 0.4104 | Acc(val) 0.5654 |
Epoch 00159 | Loss(train) 2.4720 | Acc(train) 0.4309 | Acc(val) 0.5670 |
Epoch 00160 | Loss(train) 2.4961 | Acc(train) 0.4218 | Acc(val) 0.5750 |
Epoch 00161 | Loss(train) 2.5088 | Acc(train) 0.4250 | Acc(val) 0.5798 |
Epoch 00162 | Loss(train) 2.4826 | Acc(train) 0.4404 | Acc(val) 0.5840 |*
Epoch 00163 | Loss(train) 2.5053 | Acc(train) 0.4253 | Acc(val) 0.5872 |*
Epoch 00164 | Loss(train) 2.5087 | Acc(train) 0.4316 | Acc(val) 0.5846 |
Epoch 00165 | Loss(train) 2.4875 | Acc(train) 0.4301 | Acc(val) 0.5798 |
Epoch 00166 | Loss(train) 2.4771 | Acc(train) 0.4359 | Acc(val) 0.5734 |
Epoch 00167 | Loss(train) 2.4919 | Acc(train) 0.4309 | Acc(val) 0.5702 |
Epoch 00168 | Loss(train) 2.5105 | Acc(train) 0.4253 | Acc(val) 0.5697 |
Epoch 00169 | Loss(train) 2.4709 | Acc(train) 0.4346 | Acc(val) 0.5686 |
Epoch 00170 | Loss(train) 2.5044 | Acc(train) 0.4247 | Acc(val) 0.5697 |
Epoch 00171 | Loss(train) 2.5260 | Acc(train) 0.4130 | Acc(val) 0.5670 |
Epoch 00172 | Loss(train) 2.4691 | Acc(train) 0.4263 | Acc(val) 0.5734 |
Epoch 00173 | Loss(train) 2.5042 | Acc(train) 0.4269 | Acc(val) 0.5745 |
Epoch 00174 | Loss(train) 2.4979 | Acc(train) 0.4293 | Acc(val) 0.5729 |
Epoch 00175 | Loss(train) 2.4472 | Acc(train) 0.4436 | Acc(val) 0.5750 |
Epoch 00176 | Loss(train) 2.4772 | Acc(train) 0.4290 | Acc(val) 0.5777 |
Epoch 00177 | Loss(train) 2.4847 | Acc(train) 0.4293 | Acc(val) 0.5824 |
Epoch 00178 | Loss(train) 2.4831 | Acc(train) 0.4367 | Acc(val) 0.5803 |
Epoch 00179 | Loss(train) 2.4965 | Acc(train) 0.4274 | Acc(val) 0.5745 |
Epoch 00180 | Loss(train) 2.5058 | Acc(train) 0.4293 | Acc(val) 0.5707 |
Epoch 00181 | Loss(train) 2.5272 | Acc(train) 0.4152 | Acc(val) 0.5681 |
Epoch 00182 | Loss(train) 2.5057 | Acc(train) 0.4197 | Acc(val) 0.5660 |
Epoch 00183 | Loss(train) 2.5063 | Acc(train) 0.4199 | Acc(val) 0.5612 |
Epoch 00184 | Loss(train) 2.5067 | Acc(train) 0.4239 | Acc(val) 0.5649 |
Epoch 00185 | Loss(train) 2.4989 | Acc(train) 0.4229 | Acc(val) 0.5707 |
Epoch 00186 | Loss(train) 2.5061 | Acc(train) 0.4191 | Acc(val) 0.5707 |
Epoch 00187 | Loss(train) 2.5164 | Acc(train) 0.4221 | Acc(val) 0.5707 |
Epoch 00188 | Loss(train) 2.5019 | Acc(train) 0.4229 | Acc(val) 0.5644 |
Epoch 00189 | Loss(train) 2.4781 | Acc(train) 0.4205 | Acc(val) 0.5654 |
Epoch 00190 | Loss(train) 2.5110 | Acc(train) 0.4269 | Acc(val) 0.5649 |
Epoch 00191 | Loss(train) 2.4960 | Acc(train) 0.4197 | Acc(val) 0.5654 |
Epoch 00192 | Loss(train) 2.5094 | Acc(train) 0.4186 | Acc(val) 0.5628 |
Epoch 00193 | Loss(train) 2.4944 | Acc(train) 0.4258 | Acc(val) 0.5633 |
Epoch 00194 | Loss(train) 2.4508 | Acc(train) 0.4449 | Acc(val) 0.5665 |
Epoch 00195 | Loss(train) 2.4949 | Acc(train) 0.4202 | Acc(val) 0.5702 |
Epoch 00196 | Loss(train) 2.5079 | Acc(train) 0.4218 | Acc(val) 0.5734 |
Epoch 00197 | Loss(train) 2.4839 | Acc(train) 0.4335 | Acc(val) 0.5739 |
Epoch 00198 | Loss(train) 2.4916 | Acc(train) 0.4258 | Acc(val) 0.5686 |
Epoch 00199 | Loss(train) 2.4771 | Acc(train) 0.4346 | Acc(val) 0.5660 |
Epoch 00200 | Loss(train) 2.4940 | Acc(train) 0.4176 | Acc(val) 0.5638 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 713.53 MB
GPU Memory Reserved: 2060.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2510 | Acc(train) 0.0133 | Acc(val) 0.0989 |*
Epoch 00002 | Loss(train) 4.2087 | Acc(train) 0.0952 | Acc(val) 0.1676 |*
Epoch 00003 | Loss(train) 4.1553 | Acc(train) 0.1620 | Acc(val) 0.1941 |*
Epoch 00004 | Loss(train) 4.0845 | Acc(train) 0.1665 | Acc(val) 0.1819 |
Epoch 00005 | Loss(train) 4.0020 | Acc(train) 0.1654 | Acc(val) 0.1606 |
Epoch 00006 | Loss(train) 3.9153 | Acc(train) 0.1572 | Acc(val) 0.1521 |
Epoch 00007 | Loss(train) 3.8656 | Acc(train) 0.1436 | Acc(val) 0.1410 |
Epoch 00008 | Loss(train) 3.7960 | Acc(train) 0.1457 | Acc(val) 0.1463 |
Epoch 00009 | Loss(train) 3.7368 | Acc(train) 0.1492 | Acc(val) 0.1569 |
Epoch 00010 | Loss(train) 3.6919 | Acc(train) 0.1489 | Acc(val) 0.1830 |
Epoch 00011 | Loss(train) 3.6247 | Acc(train) 0.1758 | Acc(val) 0.2197 |*
Epoch 00012 | Loss(train) 3.5527 | Acc(train) 0.2016 | Acc(val) 0.2660 |*
Epoch 00013 | Loss(train) 3.4794 | Acc(train) 0.2380 | Acc(val) 0.3181 |*
Epoch 00014 | Loss(train) 3.4144 | Acc(train) 0.2614 | Acc(val) 0.3596 |*
Epoch 00015 | Loss(train) 3.3776 | Acc(train) 0.2707 | Acc(val) 0.3941 |*
Epoch 00016 | Loss(train) 3.3287 | Acc(train) 0.2944 | Acc(val) 0.4213 |*
Epoch 00017 | Loss(train) 3.2443 | Acc(train) 0.3117 | Acc(val) 0.4293 |*
Epoch 00018 | Loss(train) 3.2016 | Acc(train) 0.3152 | Acc(val) 0.4282 |
Epoch 00019 | Loss(train) 3.1443 | Acc(train) 0.3269 | Acc(val) 0.4266 |
Epoch 00020 | Loss(train) 3.0938 | Acc(train) 0.3247 | Acc(val) 0.4213 |
Epoch 00021 | Loss(train) 3.0598 | Acc(train) 0.3133 | Acc(val) 0.4197 |
Epoch 00022 | Loss(train) 3.0315 | Acc(train) 0.3162 | Acc(val) 0.4213 |
Epoch 00023 | Loss(train) 2.9771 | Acc(train) 0.3128 | Acc(val) 0.4266 |
Epoch 00024 | Loss(train) 2.9675 | Acc(train) 0.3290 | Acc(val) 0.4324 |*
Epoch 00025 | Loss(train) 2.9204 | Acc(train) 0.3263 | Acc(val) 0.4436 |*
Epoch 00026 | Loss(train) 2.9045 | Acc(train) 0.3356 | Acc(val) 0.4606 |*
Epoch 00027 | Loss(train) 2.8839 | Acc(train) 0.3335 | Acc(val) 0.4809 |*
Epoch 00028 | Loss(train) 2.8787 | Acc(train) 0.3372 | Acc(val) 0.4920 |*
Epoch 00029 | Loss(train) 2.8352 | Acc(train) 0.3529 | Acc(val) 0.5048 |*
Epoch 00030 | Loss(train) 2.8032 | Acc(train) 0.3620 | Acc(val) 0.5170 |*
Epoch 00031 | Loss(train) 2.7941 | Acc(train) 0.3649 | Acc(val) 0.5181 |*
Epoch 00032 | Loss(train) 2.7984 | Acc(train) 0.3707 | Acc(val) 0.5207 |*
Epoch 00033 | Loss(train) 2.7870 | Acc(train) 0.3614 | Acc(val) 0.5202 |
Epoch 00034 | Loss(train) 2.7335 | Acc(train) 0.3769 | Acc(val) 0.5144 |
Epoch 00035 | Loss(train) 2.7697 | Acc(train) 0.3636 | Acc(val) 0.5106 |
Epoch 00036 | Loss(train) 2.7675 | Acc(train) 0.3625 | Acc(val) 0.5101 |
Epoch 00037 | Loss(train) 2.7246 | Acc(train) 0.3734 | Acc(val) 0.5080 |
Epoch 00038 | Loss(train) 2.7040 | Acc(train) 0.3723 | Acc(val) 0.5101 |
Epoch 00039 | Loss(train) 2.7125 | Acc(train) 0.3753 | Acc(val) 0.5101 |
Epoch 00040 | Loss(train) 2.6903 | Acc(train) 0.3737 | Acc(val) 0.5122 |
Epoch 00041 | Loss(train) 2.6894 | Acc(train) 0.3798 | Acc(val) 0.5191 |
Epoch 00042 | Loss(train) 2.6855 | Acc(train) 0.3737 | Acc(val) 0.5255 |*
Epoch 00043 | Loss(train) 2.6965 | Acc(train) 0.3763 | Acc(val) 0.5293 |*
Epoch 00044 | Loss(train) 2.6729 | Acc(train) 0.3838 | Acc(val) 0.5378 |*
Epoch 00045 | Loss(train) 2.6317 | Acc(train) 0.3870 | Acc(val) 0.5399 |*
Epoch 00046 | Loss(train) 2.6488 | Acc(train) 0.3910 | Acc(val) 0.5420 |*
Epoch 00047 | Loss(train) 2.6296 | Acc(train) 0.4080 | Acc(val) 0.5431 |*
Epoch 00048 | Loss(train) 2.6009 | Acc(train) 0.4035 | Acc(val) 0.5436 |*
Epoch 00049 | Loss(train) 2.6180 | Acc(train) 0.4013 | Acc(val) 0.5415 |
Epoch 00050 | Loss(train) 2.6013 | Acc(train) 0.4032 | Acc(val) 0.5410 |
Epoch 00051 | Loss(train) 2.6100 | Acc(train) 0.3899 | Acc(val) 0.5340 |
Epoch 00052 | Loss(train) 2.5804 | Acc(train) 0.4053 | Acc(val) 0.5324 |
Epoch 00053 | Loss(train) 2.5451 | Acc(train) 0.4082 | Acc(val) 0.5346 |
Epoch 00054 | Loss(train) 2.6011 | Acc(train) 0.4013 | Acc(val) 0.5415 |
Epoch 00055 | Loss(train) 2.5579 | Acc(train) 0.4093 | Acc(val) 0.5457 |*
Epoch 00056 | Loss(train) 2.5597 | Acc(train) 0.4021 | Acc(val) 0.5500 |*
Epoch 00057 | Loss(train) 2.5628 | Acc(train) 0.4056 | Acc(val) 0.5484 |
Epoch 00058 | Loss(train) 2.5617 | Acc(train) 0.4093 | Acc(val) 0.5521 |*
Epoch 00059 | Loss(train) 2.5541 | Acc(train) 0.4178 | Acc(val) 0.5574 |*
Epoch 00060 | Loss(train) 2.5643 | Acc(train) 0.4173 | Acc(val) 0.5574 |
Epoch 00061 | Loss(train) 2.5726 | Acc(train) 0.4082 | Acc(val) 0.5612 |*
Epoch 00062 | Loss(train) 2.5579 | Acc(train) 0.4024 | Acc(val) 0.5559 |
Epoch 00063 | Loss(train) 2.5514 | Acc(train) 0.4199 | Acc(val) 0.5553 |
Epoch 00064 | Loss(train) 2.5705 | Acc(train) 0.4101 | Acc(val) 0.5516 |
Epoch 00065 | Loss(train) 2.5336 | Acc(train) 0.4197 | Acc(val) 0.5495 |
Epoch 00066 | Loss(train) 2.5400 | Acc(train) 0.4229 | Acc(val) 0.5479 |
Epoch 00067 | Loss(train) 2.5620 | Acc(train) 0.4021 | Acc(val) 0.5511 |
Epoch 00068 | Loss(train) 2.5715 | Acc(train) 0.4085 | Acc(val) 0.5521 |
Epoch 00069 | Loss(train) 2.5306 | Acc(train) 0.4117 | Acc(val) 0.5537 |
Epoch 00070 | Loss(train) 2.5750 | Acc(train) 0.4000 | Acc(val) 0.5559 |
Epoch 00071 | Loss(train) 2.5126 | Acc(train) 0.4141 | Acc(val) 0.5574 |
Epoch 00072 | Loss(train) 2.5247 | Acc(train) 0.4258 | Acc(val) 0.5596 |
Epoch 00073 | Loss(train) 2.5462 | Acc(train) 0.4104 | Acc(val) 0.5612 |
Epoch 00074 | Loss(train) 2.5428 | Acc(train) 0.4157 | Acc(val) 0.5574 |
Epoch 00075 | Loss(train) 2.5256 | Acc(train) 0.4223 | Acc(val) 0.5553 |
Epoch 00076 | Loss(train) 2.5476 | Acc(train) 0.4072 | Acc(val) 0.5543 |
Epoch 00077 | Loss(train) 2.5429 | Acc(train) 0.4178 | Acc(val) 0.5521 |
Epoch 00078 | Loss(train) 2.4952 | Acc(train) 0.4112 | Acc(val) 0.5511 |
Epoch 00079 | Loss(train) 2.5027 | Acc(train) 0.4080 | Acc(val) 0.5468 |
Epoch 00080 | Loss(train) 2.5453 | Acc(train) 0.4069 | Acc(val) 0.5479 |
Epoch 00081 | Loss(train) 2.5269 | Acc(train) 0.4168 | Acc(val) 0.5495 |
Epoch 00082 | Loss(train) 2.5131 | Acc(train) 0.4098 | Acc(val) 0.5553 |
Epoch 00083 | Loss(train) 2.5022 | Acc(train) 0.4205 | Acc(val) 0.5596 |
Epoch 00084 | Loss(train) 2.5814 | Acc(train) 0.4040 | Acc(val) 0.5633 |*
Epoch 00085 | Loss(train) 2.5210 | Acc(train) 0.4162 | Acc(val) 0.5628 |
Epoch 00086 | Loss(train) 2.5281 | Acc(train) 0.4202 | Acc(val) 0.5649 |*
Epoch 00087 | Loss(train) 2.5407 | Acc(train) 0.4098 | Acc(val) 0.5644 |
Epoch 00088 | Loss(train) 2.5051 | Acc(train) 0.4202 | Acc(val) 0.5649 |
Epoch 00089 | Loss(train) 2.5350 | Acc(train) 0.4213 | Acc(val) 0.5670 |*
Epoch 00090 | Loss(train) 2.5223 | Acc(train) 0.4168 | Acc(val) 0.5665 |
Epoch 00091 | Loss(train) 2.5098 | Acc(train) 0.4234 | Acc(val) 0.5654 |
Epoch 00092 | Loss(train) 2.5220 | Acc(train) 0.4191 | Acc(val) 0.5649 |
Epoch 00093 | Loss(train) 2.4845 | Acc(train) 0.4295 | Acc(val) 0.5628 |
Epoch 00094 | Loss(train) 2.4963 | Acc(train) 0.4215 | Acc(val) 0.5622 |
Epoch 00095 | Loss(train) 2.5038 | Acc(train) 0.4255 | Acc(val) 0.5612 |
Epoch 00096 | Loss(train) 2.5239 | Acc(train) 0.4215 | Acc(val) 0.5628 |
Epoch 00097 | Loss(train) 2.5069 | Acc(train) 0.4207 | Acc(val) 0.5638 |
Epoch 00098 | Loss(train) 2.5080 | Acc(train) 0.4261 | Acc(val) 0.5649 |
Epoch 00099 | Loss(train) 2.5493 | Acc(train) 0.4080 | Acc(val) 0.5628 |
Epoch 00100 | Loss(train) 2.5441 | Acc(train) 0.4213 | Acc(val) 0.5612 |
Epoch 00101 | Loss(train) 2.5367 | Acc(train) 0.4168 | Acc(val) 0.5617 |
Epoch 00102 | Loss(train) 2.5212 | Acc(train) 0.4181 | Acc(val) 0.5612 |
Epoch 00103 | Loss(train) 2.5272 | Acc(train) 0.4226 | Acc(val) 0.5601 |
Epoch 00104 | Loss(train) 2.5106 | Acc(train) 0.4274 | Acc(val) 0.5617 |
Epoch 00105 | Loss(train) 2.4746 | Acc(train) 0.4383 | Acc(val) 0.5596 |
Epoch 00106 | Loss(train) 2.4968 | Acc(train) 0.4263 | Acc(val) 0.5622 |
Epoch 00107 | Loss(train) 2.5415 | Acc(train) 0.4059 | Acc(val) 0.5617 |
Epoch 00108 | Loss(train) 2.5322 | Acc(train) 0.4181 | Acc(val) 0.5628 |
Epoch 00109 | Loss(train) 2.5301 | Acc(train) 0.4144 | Acc(val) 0.5617 |
Epoch 00110 | Loss(train) 2.5104 | Acc(train) 0.4173 | Acc(val) 0.5606 |
Epoch 00111 | Loss(train) 2.4917 | Acc(train) 0.4378 | Acc(val) 0.5601 |
Epoch 00112 | Loss(train) 2.5235 | Acc(train) 0.4176 | Acc(val) 0.5612 |
Epoch 00113 | Loss(train) 2.5278 | Acc(train) 0.4136 | Acc(val) 0.5665 |
Epoch 00114 | Loss(train) 2.5299 | Acc(train) 0.4221 | Acc(val) 0.5638 |
Epoch 00115 | Loss(train) 2.5092 | Acc(train) 0.4207 | Acc(val) 0.5670 |
Epoch 00116 | Loss(train) 2.5610 | Acc(train) 0.4199 | Acc(val) 0.5654 |
Epoch 00117 | Loss(train) 2.5354 | Acc(train) 0.4279 | Acc(val) 0.5670 |
Epoch 00118 | Loss(train) 2.5147 | Acc(train) 0.4160 | Acc(val) 0.5622 |
Epoch 00119 | Loss(train) 2.4749 | Acc(train) 0.4271 | Acc(val) 0.5622 |
Epoch 00120 | Loss(train) 2.4890 | Acc(train) 0.4234 | Acc(val) 0.5649 |
Epoch 00121 | Loss(train) 2.4691 | Acc(train) 0.4324 | Acc(val) 0.5644 |
Epoch 00122 | Loss(train) 2.5231 | Acc(train) 0.4199 | Acc(val) 0.5713 |*
Epoch 00123 | Loss(train) 2.5122 | Acc(train) 0.4287 | Acc(val) 0.5707 |
Epoch 00124 | Loss(train) 2.4881 | Acc(train) 0.4332 | Acc(val) 0.5649 |
Epoch 00125 | Loss(train) 2.5195 | Acc(train) 0.4255 | Acc(val) 0.5644 |
Epoch 00126 | Loss(train) 2.4978 | Acc(train) 0.4362 | Acc(val) 0.5665 |
Epoch 00127 | Loss(train) 2.4935 | Acc(train) 0.4314 | Acc(val) 0.5660 |
Epoch 00128 | Loss(train) 2.5093 | Acc(train) 0.4231 | Acc(val) 0.5665 |
Epoch 00129 | Loss(train) 2.5021 | Acc(train) 0.4229 | Acc(val) 0.5622 |
Epoch 00130 | Loss(train) 2.4988 | Acc(train) 0.4354 | Acc(val) 0.5654 |
Epoch 00131 | Loss(train) 2.5075 | Acc(train) 0.4191 | Acc(val) 0.5676 |
Epoch 00132 | Loss(train) 2.4832 | Acc(train) 0.4295 | Acc(val) 0.5676 |
Epoch 00133 | Loss(train) 2.5227 | Acc(train) 0.4189 | Acc(val) 0.5681 |
Epoch 00134 | Loss(train) 2.4900 | Acc(train) 0.4221 | Acc(val) 0.5723 |*
Epoch 00135 | Loss(train) 2.4734 | Acc(train) 0.4364 | Acc(val) 0.5686 |
Epoch 00136 | Loss(train) 2.4516 | Acc(train) 0.4327 | Acc(val) 0.5665 |
Epoch 00137 | Loss(train) 2.4930 | Acc(train) 0.4309 | Acc(val) 0.5622 |
Epoch 00138 | Loss(train) 2.4913 | Acc(train) 0.4205 | Acc(val) 0.5638 |
Epoch 00139 | Loss(train) 2.5069 | Acc(train) 0.4189 | Acc(val) 0.5649 |
Epoch 00140 | Loss(train) 2.5214 | Acc(train) 0.4199 | Acc(val) 0.5670 |
Epoch 00141 | Loss(train) 2.4902 | Acc(train) 0.4316 | Acc(val) 0.5660 |
Epoch 00142 | Loss(train) 2.4984 | Acc(train) 0.4186 | Acc(val) 0.5670 |
Epoch 00143 | Loss(train) 2.4777 | Acc(train) 0.4285 | Acc(val) 0.5633 |
Epoch 00144 | Loss(train) 2.5078 | Acc(train) 0.4266 | Acc(val) 0.5638 |
Epoch 00145 | Loss(train) 2.4934 | Acc(train) 0.4202 | Acc(val) 0.5628 |
Epoch 00146 | Loss(train) 2.5102 | Acc(train) 0.4234 | Acc(val) 0.5638 |
Epoch 00147 | Loss(train) 2.5332 | Acc(train) 0.4239 | Acc(val) 0.5633 |
Epoch 00148 | Loss(train) 2.4930 | Acc(train) 0.4229 | Acc(val) 0.5622 |
Epoch 00149 | Loss(train) 2.5145 | Acc(train) 0.4213 | Acc(val) 0.5617 |
Epoch 00150 | Loss(train) 2.5339 | Acc(train) 0.4149 | Acc(val) 0.5649 |
Epoch 00151 | Loss(train) 2.5010 | Acc(train) 0.4269 | Acc(val) 0.5633 |
Epoch 00152 | Loss(train) 2.5162 | Acc(train) 0.4231 | Acc(val) 0.5654 |
Epoch 00153 | Loss(train) 2.5131 | Acc(train) 0.4293 | Acc(val) 0.5681 |
Epoch 00154 | Loss(train) 2.5084 | Acc(train) 0.4229 | Acc(val) 0.5723 |
Epoch 00155 | Loss(train) 2.4879 | Acc(train) 0.4301 | Acc(val) 0.5734 |*
Epoch 00156 | Loss(train) 2.5455 | Acc(train) 0.4059 | Acc(val) 0.5729 |
Epoch 00157 | Loss(train) 2.4850 | Acc(train) 0.4285 | Acc(val) 0.5745 |*
Epoch 00158 | Loss(train) 2.4979 | Acc(train) 0.4210 | Acc(val) 0.5739 |
Epoch 00159 | Loss(train) 2.4900 | Acc(train) 0.4274 | Acc(val) 0.5691 |
Epoch 00160 | Loss(train) 2.4789 | Acc(train) 0.4279 | Acc(val) 0.5707 |
Epoch 00161 | Loss(train) 2.4965 | Acc(train) 0.4234 | Acc(val) 0.5750 |*
Epoch 00162 | Loss(train) 2.5173 | Acc(train) 0.4303 | Acc(val) 0.5691 |
Epoch 00163 | Loss(train) 2.4769 | Acc(train) 0.4290 | Acc(val) 0.5707 |
Epoch 00164 | Loss(train) 2.5135 | Acc(train) 0.4229 | Acc(val) 0.5697 |
Epoch 00165 | Loss(train) 2.4869 | Acc(train) 0.4271 | Acc(val) 0.5686 |
Epoch 00166 | Loss(train) 2.4893 | Acc(train) 0.4274 | Acc(val) 0.5649 |
Epoch 00167 | Loss(train) 2.4875 | Acc(train) 0.4285 | Acc(val) 0.5676 |
Epoch 00168 | Loss(train) 2.4456 | Acc(train) 0.4293 | Acc(val) 0.5686 |
Epoch 00169 | Loss(train) 2.5261 | Acc(train) 0.4239 | Acc(val) 0.5697 |
Epoch 00170 | Loss(train) 2.5249 | Acc(train) 0.4136 | Acc(val) 0.5761 |*
Epoch 00171 | Loss(train) 2.4651 | Acc(train) 0.4285 | Acc(val) 0.5750 |
Epoch 00172 | Loss(train) 2.4789 | Acc(train) 0.4298 | Acc(val) 0.5771 |*
Epoch 00173 | Loss(train) 2.5248 | Acc(train) 0.4245 | Acc(val) 0.5755 |
Epoch 00174 | Loss(train) 2.4982 | Acc(train) 0.4189 | Acc(val) 0.5750 |
Epoch 00175 | Loss(train) 2.5039 | Acc(train) 0.4237 | Acc(val) 0.5681 |
Epoch 00176 | Loss(train) 2.4428 | Acc(train) 0.4348 | Acc(val) 0.5596 |
Epoch 00177 | Loss(train) 2.4892 | Acc(train) 0.4290 | Acc(val) 0.5580 |
Epoch 00178 | Loss(train) 2.5180 | Acc(train) 0.4231 | Acc(val) 0.5527 |
Epoch 00179 | Loss(train) 2.5166 | Acc(train) 0.4197 | Acc(val) 0.5564 |
Epoch 00180 | Loss(train) 2.5141 | Acc(train) 0.4154 | Acc(val) 0.5628 |
Epoch 00181 | Loss(train) 2.4823 | Acc(train) 0.4279 | Acc(val) 0.5686 |
Epoch 00182 | Loss(train) 2.5137 | Acc(train) 0.4117 | Acc(val) 0.5734 |
Epoch 00183 | Loss(train) 2.5042 | Acc(train) 0.4335 | Acc(val) 0.5766 |
Epoch 00184 | Loss(train) 2.5142 | Acc(train) 0.4226 | Acc(val) 0.5771 |
Epoch 00185 | Loss(train) 2.4668 | Acc(train) 0.4473 | Acc(val) 0.5750 |
Epoch 00186 | Loss(train) 2.4629 | Acc(train) 0.4362 | Acc(val) 0.5702 |
Epoch 00187 | Loss(train) 2.4985 | Acc(train) 0.4322 | Acc(val) 0.5670 |
Epoch 00188 | Loss(train) 2.4546 | Acc(train) 0.4359 | Acc(val) 0.5633 |
Epoch 00189 | Loss(train) 2.4847 | Acc(train) 0.4213 | Acc(val) 0.5617 |
Epoch 00190 | Loss(train) 2.4931 | Acc(train) 0.4221 | Acc(val) 0.5622 |
Epoch 00191 | Loss(train) 2.5398 | Acc(train) 0.4136 | Acc(val) 0.5660 |
Epoch 00192 | Loss(train) 2.5051 | Acc(train) 0.4237 | Acc(val) 0.5702 |
Epoch 00193 | Loss(train) 2.4819 | Acc(train) 0.4314 | Acc(val) 0.5755 |
Epoch 00194 | Loss(train) 2.4851 | Acc(train) 0.4213 | Acc(val) 0.5782 |*
Epoch 00195 | Loss(train) 2.5239 | Acc(train) 0.4194 | Acc(val) 0.5745 |
Epoch 00196 | Loss(train) 2.5094 | Acc(train) 0.4279 | Acc(val) 0.5686 |
Epoch 00197 | Loss(train) 2.4828 | Acc(train) 0.4309 | Acc(val) 0.5638 |
Epoch 00198 | Loss(train) 2.5127 | Acc(train) 0.4277 | Acc(val) 0.5590 |
Epoch 00199 | Loss(train) 2.4962 | Acc(train) 0.4197 | Acc(val) 0.5628 |
Epoch 00200 | Loss(train) 2.4903 | Acc(train) 0.4343 | Acc(val) 0.5660 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 714.21 MB
GPU Memory Reserved: 2060.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2601 | Acc(train) 0.0080 | Acc(val) 0.0957 |*
Epoch 00002 | Loss(train) 4.2181 | Acc(train) 0.0912 | Acc(val) 0.1707 |*
Epoch 00003 | Loss(train) 4.1662 | Acc(train) 0.1543 | Acc(val) 0.1404 |
Epoch 00004 | Loss(train) 4.0949 | Acc(train) 0.1500 | Acc(val) 0.1383 |
Epoch 00005 | Loss(train) 4.0162 | Acc(train) 0.1468 | Acc(val) 0.1335 |
Epoch 00006 | Loss(train) 3.9272 | Acc(train) 0.1532 | Acc(val) 0.1298 |
Epoch 00007 | Loss(train) 3.8601 | Acc(train) 0.1463 | Acc(val) 0.1271 |
Epoch 00008 | Loss(train) 3.8066 | Acc(train) 0.1407 | Acc(val) 0.1362 |
Epoch 00009 | Loss(train) 3.7563 | Acc(train) 0.1537 | Acc(val) 0.1665 |
Epoch 00010 | Loss(train) 3.7090 | Acc(train) 0.1596 | Acc(val) 0.1941 |*
Epoch 00011 | Loss(train) 3.6316 | Acc(train) 0.1838 | Acc(val) 0.2266 |*
Epoch 00012 | Loss(train) 3.5696 | Acc(train) 0.2035 | Acc(val) 0.2617 |*
Epoch 00013 | Loss(train) 3.5051 | Acc(train) 0.2324 | Acc(val) 0.3122 |*
Epoch 00014 | Loss(train) 3.4205 | Acc(train) 0.2633 | Acc(val) 0.3569 |*
Epoch 00015 | Loss(train) 3.3612 | Acc(train) 0.2785 | Acc(val) 0.3915 |*
Epoch 00016 | Loss(train) 3.2993 | Acc(train) 0.3069 | Acc(val) 0.4106 |*
Epoch 00017 | Loss(train) 3.2541 | Acc(train) 0.2952 | Acc(val) 0.4186 |*
Epoch 00018 | Loss(train) 3.1892 | Acc(train) 0.3178 | Acc(val) 0.4186 |
Epoch 00019 | Loss(train) 3.1722 | Acc(train) 0.3024 | Acc(val) 0.4176 |
Epoch 00020 | Loss(train) 3.0891 | Acc(train) 0.3178 | Acc(val) 0.4170 |
Epoch 00021 | Loss(train) 3.0471 | Acc(train) 0.3082 | Acc(val) 0.4144 |
Epoch 00022 | Loss(train) 3.0019 | Acc(train) 0.3120 | Acc(val) 0.4186 |
Epoch 00023 | Loss(train) 2.9926 | Acc(train) 0.3170 | Acc(val) 0.4234 |*
Epoch 00024 | Loss(train) 2.9657 | Acc(train) 0.3181 | Acc(val) 0.4346 |*
Epoch 00025 | Loss(train) 2.9398 | Acc(train) 0.3199 | Acc(val) 0.4410 |*
Epoch 00026 | Loss(train) 2.8939 | Acc(train) 0.3359 | Acc(val) 0.4569 |*
Epoch 00027 | Loss(train) 2.8392 | Acc(train) 0.3511 | Acc(val) 0.4691 |*
Epoch 00028 | Loss(train) 2.8635 | Acc(train) 0.3441 | Acc(val) 0.4798 |*
Epoch 00029 | Loss(train) 2.8201 | Acc(train) 0.3492 | Acc(val) 0.4851 |*
Epoch 00030 | Loss(train) 2.8332 | Acc(train) 0.3489 | Acc(val) 0.4926 |*
Epoch 00031 | Loss(train) 2.8268 | Acc(train) 0.3473 | Acc(val) 0.4973 |*
Epoch 00032 | Loss(train) 2.7709 | Acc(train) 0.3694 | Acc(val) 0.5016 |*
Epoch 00033 | Loss(train) 2.7693 | Acc(train) 0.3644 | Acc(val) 0.4979 |
Epoch 00034 | Loss(train) 2.7619 | Acc(train) 0.3625 | Acc(val) 0.4989 |
Epoch 00035 | Loss(train) 2.7500 | Acc(train) 0.3641 | Acc(val) 0.5005 |
Epoch 00036 | Loss(train) 2.7671 | Acc(train) 0.3710 | Acc(val) 0.5032 |*
Epoch 00037 | Loss(train) 2.7328 | Acc(train) 0.3673 | Acc(val) 0.5043 |*
Epoch 00038 | Loss(train) 2.7199 | Acc(train) 0.3694 | Acc(val) 0.5085 |*
Epoch 00039 | Loss(train) 2.7228 | Acc(train) 0.3620 | Acc(val) 0.5074 |
Epoch 00040 | Loss(train) 2.6865 | Acc(train) 0.3872 | Acc(val) 0.5122 |*
Epoch 00041 | Loss(train) 2.6754 | Acc(train) 0.3867 | Acc(val) 0.5234 |*
Epoch 00042 | Loss(train) 2.6700 | Acc(train) 0.3902 | Acc(val) 0.5309 |*
Epoch 00043 | Loss(train) 2.6731 | Acc(train) 0.3984 | Acc(val) 0.5340 |*
Epoch 00044 | Loss(train) 2.6422 | Acc(train) 0.3992 | Acc(val) 0.5367 |*
Epoch 00045 | Loss(train) 2.6398 | Acc(train) 0.3891 | Acc(val) 0.5431 |*
Epoch 00046 | Loss(train) 2.6110 | Acc(train) 0.3971 | Acc(val) 0.5415 |
Epoch 00047 | Loss(train) 2.6504 | Acc(train) 0.3952 | Acc(val) 0.5410 |
Epoch 00048 | Loss(train) 2.5917 | Acc(train) 0.4059 | Acc(val) 0.5415 |
Epoch 00049 | Loss(train) 2.6448 | Acc(train) 0.3928 | Acc(val) 0.5404 |
Epoch 00050 | Loss(train) 2.6040 | Acc(train) 0.4056 | Acc(val) 0.5410 |
Epoch 00051 | Loss(train) 2.6132 | Acc(train) 0.4035 | Acc(val) 0.5388 |
Epoch 00052 | Loss(train) 2.6078 | Acc(train) 0.3955 | Acc(val) 0.5399 |
Epoch 00053 | Loss(train) 2.5420 | Acc(train) 0.4051 | Acc(val) 0.5431 |
Epoch 00054 | Loss(train) 2.6060 | Acc(train) 0.3973 | Acc(val) 0.5431 |
Epoch 00055 | Loss(train) 2.5671 | Acc(train) 0.4029 | Acc(val) 0.5447 |*
Epoch 00056 | Loss(train) 2.5758 | Acc(train) 0.3981 | Acc(val) 0.5479 |*
Epoch 00057 | Loss(train) 2.5719 | Acc(train) 0.4104 | Acc(val) 0.5516 |*
Epoch 00058 | Loss(train) 2.5440 | Acc(train) 0.4165 | Acc(val) 0.5500 |
Epoch 00059 | Loss(train) 2.5709 | Acc(train) 0.4024 | Acc(val) 0.5532 |*
Epoch 00060 | Loss(train) 2.5638 | Acc(train) 0.4168 | Acc(val) 0.5548 |*
Epoch 00061 | Loss(train) 2.5384 | Acc(train) 0.4176 | Acc(val) 0.5548 |
Epoch 00062 | Loss(train) 2.5762 | Acc(train) 0.4077 | Acc(val) 0.5527 |
Epoch 00063 | Loss(train) 2.5839 | Acc(train) 0.4021 | Acc(val) 0.5511 |
Epoch 00064 | Loss(train) 2.5486 | Acc(train) 0.4125 | Acc(val) 0.5489 |
Epoch 00065 | Loss(train) 2.5118 | Acc(train) 0.4165 | Acc(val) 0.5436 |
Epoch 00066 | Loss(train) 2.5431 | Acc(train) 0.4085 | Acc(val) 0.5452 |
Epoch 00067 | Loss(train) 2.5056 | Acc(train) 0.4207 | Acc(val) 0.5463 |
Epoch 00068 | Loss(train) 2.5522 | Acc(train) 0.4122 | Acc(val) 0.5500 |
Epoch 00069 | Loss(train) 2.5241 | Acc(train) 0.4197 | Acc(val) 0.5527 |
Epoch 00070 | Loss(train) 2.5479 | Acc(train) 0.4074 | Acc(val) 0.5564 |*
Epoch 00071 | Loss(train) 2.5443 | Acc(train) 0.4138 | Acc(val) 0.5612 |*
Epoch 00072 | Loss(train) 2.5434 | Acc(train) 0.4189 | Acc(val) 0.5574 |
Epoch 00073 | Loss(train) 2.5102 | Acc(train) 0.4207 | Acc(val) 0.5585 |
Epoch 00074 | Loss(train) 2.5218 | Acc(train) 0.4223 | Acc(val) 0.5617 |*
Epoch 00075 | Loss(train) 2.5044 | Acc(train) 0.4202 | Acc(val) 0.5606 |
Epoch 00076 | Loss(train) 2.5144 | Acc(train) 0.4261 | Acc(val) 0.5596 |
Epoch 00077 | Loss(train) 2.5441 | Acc(train) 0.4181 | Acc(val) 0.5612 |
Epoch 00078 | Loss(train) 2.5046 | Acc(train) 0.4247 | Acc(val) 0.5628 |*
Epoch 00079 | Loss(train) 2.5537 | Acc(train) 0.4157 | Acc(val) 0.5649 |*
Epoch 00080 | Loss(train) 2.5601 | Acc(train) 0.4157 | Acc(val) 0.5628 |
Epoch 00081 | Loss(train) 2.4997 | Acc(train) 0.4301 | Acc(val) 0.5644 |
Epoch 00082 | Loss(train) 2.5086 | Acc(train) 0.4146 | Acc(val) 0.5644 |
Epoch 00083 | Loss(train) 2.5569 | Acc(train) 0.4133 | Acc(val) 0.5638 |
Epoch 00084 | Loss(train) 2.5388 | Acc(train) 0.4176 | Acc(val) 0.5638 |
Epoch 00085 | Loss(train) 2.5419 | Acc(train) 0.4221 | Acc(val) 0.5649 |
Epoch 00086 | Loss(train) 2.5148 | Acc(train) 0.4184 | Acc(val) 0.5676 |*
Epoch 00087 | Loss(train) 2.5608 | Acc(train) 0.3952 | Acc(val) 0.5670 |
Epoch 00088 | Loss(train) 2.5227 | Acc(train) 0.4242 | Acc(val) 0.5665 |
Epoch 00089 | Loss(train) 2.5408 | Acc(train) 0.4072 | Acc(val) 0.5676 |
Epoch 00090 | Loss(train) 2.5177 | Acc(train) 0.4255 | Acc(val) 0.5638 |
Epoch 00091 | Loss(train) 2.5212 | Acc(train) 0.4109 | Acc(val) 0.5601 |
Epoch 00092 | Loss(train) 2.5073 | Acc(train) 0.4197 | Acc(val) 0.5590 |
Epoch 00093 | Loss(train) 2.5235 | Acc(train) 0.4122 | Acc(val) 0.5574 |
Epoch 00094 | Loss(train) 2.5116 | Acc(train) 0.4226 | Acc(val) 0.5617 |
Epoch 00095 | Loss(train) 2.5287 | Acc(train) 0.4117 | Acc(val) 0.5628 |
Epoch 00096 | Loss(train) 2.4796 | Acc(train) 0.4231 | Acc(val) 0.5622 |
Epoch 00097 | Loss(train) 2.4914 | Acc(train) 0.4293 | Acc(val) 0.5628 |
Epoch 00098 | Loss(train) 2.5304 | Acc(train) 0.4157 | Acc(val) 0.5601 |
Epoch 00099 | Loss(train) 2.5332 | Acc(train) 0.4223 | Acc(val) 0.5606 |
Epoch 00100 | Loss(train) 2.4755 | Acc(train) 0.4319 | Acc(val) 0.5612 |
Epoch 00101 | Loss(train) 2.4940 | Acc(train) 0.4266 | Acc(val) 0.5665 |
Epoch 00102 | Loss(train) 2.5187 | Acc(train) 0.4197 | Acc(val) 0.5713 |*
Epoch 00103 | Loss(train) 2.5294 | Acc(train) 0.4239 | Acc(val) 0.5713 |
Epoch 00104 | Loss(train) 2.5045 | Acc(train) 0.4194 | Acc(val) 0.5697 |
Epoch 00105 | Loss(train) 2.5072 | Acc(train) 0.4258 | Acc(val) 0.5660 |
Epoch 00106 | Loss(train) 2.5171 | Acc(train) 0.4133 | Acc(val) 0.5617 |
Epoch 00107 | Loss(train) 2.5407 | Acc(train) 0.4090 | Acc(val) 0.5628 |
Epoch 00108 | Loss(train) 2.5032 | Acc(train) 0.4215 | Acc(val) 0.5612 |
Epoch 00109 | Loss(train) 2.5105 | Acc(train) 0.4255 | Acc(val) 0.5628 |
Epoch 00110 | Loss(train) 2.5147 | Acc(train) 0.4221 | Acc(val) 0.5691 |
Epoch 00111 | Loss(train) 2.5255 | Acc(train) 0.4149 | Acc(val) 0.5729 |*
Epoch 00112 | Loss(train) 2.5067 | Acc(train) 0.4245 | Acc(val) 0.5676 |
Epoch 00113 | Loss(train) 2.5205 | Acc(train) 0.4215 | Acc(val) 0.5697 |
Epoch 00114 | Loss(train) 2.5051 | Acc(train) 0.4173 | Acc(val) 0.5665 |
Epoch 00115 | Loss(train) 2.4814 | Acc(train) 0.4237 | Acc(val) 0.5660 |
Epoch 00116 | Loss(train) 2.4738 | Acc(train) 0.4239 | Acc(val) 0.5681 |
Epoch 00117 | Loss(train) 2.5170 | Acc(train) 0.4184 | Acc(val) 0.5649 |
Epoch 00118 | Loss(train) 2.4969 | Acc(train) 0.4207 | Acc(val) 0.5638 |
Epoch 00119 | Loss(train) 2.5257 | Acc(train) 0.4170 | Acc(val) 0.5665 |
Epoch 00120 | Loss(train) 2.5123 | Acc(train) 0.4287 | Acc(val) 0.5649 |
Epoch 00121 | Loss(train) 2.4708 | Acc(train) 0.4311 | Acc(val) 0.5617 |
Epoch 00122 | Loss(train) 2.5180 | Acc(train) 0.4218 | Acc(val) 0.5638 |
Epoch 00123 | Loss(train) 2.4880 | Acc(train) 0.4258 | Acc(val) 0.5638 |
Epoch 00124 | Loss(train) 2.4798 | Acc(train) 0.4348 | Acc(val) 0.5686 |
Epoch 00125 | Loss(train) 2.4966 | Acc(train) 0.4242 | Acc(val) 0.5734 |*
Epoch 00126 | Loss(train) 2.4987 | Acc(train) 0.4269 | Acc(val) 0.5729 |
Epoch 00127 | Loss(train) 2.4689 | Acc(train) 0.4370 | Acc(val) 0.5739 |*
Epoch 00128 | Loss(train) 2.5247 | Acc(train) 0.4178 | Acc(val) 0.5718 |
Epoch 00129 | Loss(train) 2.5531 | Acc(train) 0.4088 | Acc(val) 0.5739 |
Epoch 00130 | Loss(train) 2.4772 | Acc(train) 0.4324 | Acc(val) 0.5676 |
Epoch 00131 | Loss(train) 2.5014 | Acc(train) 0.4213 | Acc(val) 0.5660 |
Epoch 00132 | Loss(train) 2.5099 | Acc(train) 0.4189 | Acc(val) 0.5633 |
Epoch 00133 | Loss(train) 2.4790 | Acc(train) 0.4322 | Acc(val) 0.5617 |
Epoch 00134 | Loss(train) 2.4871 | Acc(train) 0.4343 | Acc(val) 0.5612 |
Epoch 00135 | Loss(train) 2.5117 | Acc(train) 0.4207 | Acc(val) 0.5617 |
Epoch 00136 | Loss(train) 2.4598 | Acc(train) 0.4372 | Acc(val) 0.5622 |
Epoch 00137 | Loss(train) 2.4746 | Acc(train) 0.4380 | Acc(val) 0.5638 |
Epoch 00138 | Loss(train) 2.4896 | Acc(train) 0.4199 | Acc(val) 0.5638 |
Epoch 00139 | Loss(train) 2.4820 | Acc(train) 0.4293 | Acc(val) 0.5649 |
Epoch 00140 | Loss(train) 2.4905 | Acc(train) 0.4258 | Acc(val) 0.5676 |
Epoch 00141 | Loss(train) 2.4847 | Acc(train) 0.4346 | Acc(val) 0.5686 |
Epoch 00142 | Loss(train) 2.5085 | Acc(train) 0.4271 | Acc(val) 0.5665 |
Epoch 00143 | Loss(train) 2.4928 | Acc(train) 0.4298 | Acc(val) 0.5649 |
Epoch 00144 | Loss(train) 2.5411 | Acc(train) 0.4117 | Acc(val) 0.5638 |
Epoch 00145 | Loss(train) 2.4564 | Acc(train) 0.4330 | Acc(val) 0.5644 |
Epoch 00146 | Loss(train) 2.5105 | Acc(train) 0.4234 | Acc(val) 0.5681 |
Epoch 00147 | Loss(train) 2.4632 | Acc(train) 0.4404 | Acc(val) 0.5649 |
Epoch 00148 | Loss(train) 2.5050 | Acc(train) 0.4279 | Acc(val) 0.5660 |
Epoch 00149 | Loss(train) 2.4948 | Acc(train) 0.4380 | Acc(val) 0.5707 |
Epoch 00150 | Loss(train) 2.4842 | Acc(train) 0.4378 | Acc(val) 0.5750 |*
Epoch 00151 | Loss(train) 2.5058 | Acc(train) 0.4231 | Acc(val) 0.5766 |*
Epoch 00152 | Loss(train) 2.4892 | Acc(train) 0.4380 | Acc(val) 0.5729 |
Epoch 00153 | Loss(train) 2.5231 | Acc(train) 0.4226 | Acc(val) 0.5723 |
Epoch 00154 | Loss(train) 2.5224 | Acc(train) 0.4165 | Acc(val) 0.5681 |
Epoch 00155 | Loss(train) 2.4584 | Acc(train) 0.4343 | Acc(val) 0.5612 |
Epoch 00156 | Loss(train) 2.4783 | Acc(train) 0.4237 | Acc(val) 0.5601 |
Epoch 00157 | Loss(train) 2.4670 | Acc(train) 0.4239 | Acc(val) 0.5628 |
Epoch 00158 | Loss(train) 2.4962 | Acc(train) 0.4199 | Acc(val) 0.5739 |
Epoch 00159 | Loss(train) 2.4989 | Acc(train) 0.4253 | Acc(val) 0.5761 |
Epoch 00160 | Loss(train) 2.5466 | Acc(train) 0.4146 | Acc(val) 0.5745 |
Epoch 00161 | Loss(train) 2.4904 | Acc(train) 0.4290 | Acc(val) 0.5755 |
Epoch 00162 | Loss(train) 2.4820 | Acc(train) 0.4332 | Acc(val) 0.5702 |
Epoch 00163 | Loss(train) 2.5277 | Acc(train) 0.4239 | Acc(val) 0.5617 |
Epoch 00164 | Loss(train) 2.4788 | Acc(train) 0.4295 | Acc(val) 0.5543 |
Epoch 00165 | Loss(train) 2.5045 | Acc(train) 0.4168 | Acc(val) 0.5564 |
Epoch 00166 | Loss(train) 2.4908 | Acc(train) 0.4263 | Acc(val) 0.5585 |
Epoch 00167 | Loss(train) 2.5057 | Acc(train) 0.4237 | Acc(val) 0.5649 |
Epoch 00168 | Loss(train) 2.5185 | Acc(train) 0.4146 | Acc(val) 0.5691 |
Epoch 00169 | Loss(train) 2.4783 | Acc(train) 0.4234 | Acc(val) 0.5702 |
Epoch 00170 | Loss(train) 2.5090 | Acc(train) 0.4364 | Acc(val) 0.5713 |
Epoch 00171 | Loss(train) 2.5079 | Acc(train) 0.4157 | Acc(val) 0.5755 |
Epoch 00172 | Loss(train) 2.5044 | Acc(train) 0.4210 | Acc(val) 0.5697 |
Epoch 00173 | Loss(train) 2.4727 | Acc(train) 0.4311 | Acc(val) 0.5697 |
Epoch 00174 | Loss(train) 2.4845 | Acc(train) 0.4322 | Acc(val) 0.5681 |
Epoch 00175 | Loss(train) 2.4746 | Acc(train) 0.4231 | Acc(val) 0.5644 |
Epoch 00176 | Loss(train) 2.5129 | Acc(train) 0.4255 | Acc(val) 0.5617 |
Epoch 00177 | Loss(train) 2.4981 | Acc(train) 0.4221 | Acc(val) 0.5617 |
Epoch 00178 | Loss(train) 2.4783 | Acc(train) 0.4309 | Acc(val) 0.5654 |
Epoch 00179 | Loss(train) 2.4670 | Acc(train) 0.4324 | Acc(val) 0.5676 |
Epoch 00180 | Loss(train) 2.4904 | Acc(train) 0.4332 | Acc(val) 0.5702 |
Epoch 00181 | Loss(train) 2.5178 | Acc(train) 0.4253 | Acc(val) 0.5734 |
Epoch 00182 | Loss(train) 2.4683 | Acc(train) 0.4396 | Acc(val) 0.5739 |
Epoch 00183 | Loss(train) 2.4959 | Acc(train) 0.4298 | Acc(val) 0.5713 |
Epoch 00184 | Loss(train) 2.4717 | Acc(train) 0.4335 | Acc(val) 0.5691 |
Epoch 00185 | Loss(train) 2.5036 | Acc(train) 0.4303 | Acc(val) 0.5633 |
Epoch 00186 | Loss(train) 2.4503 | Acc(train) 0.4346 | Acc(val) 0.5644 |
Epoch 00187 | Loss(train) 2.4676 | Acc(train) 0.4418 | Acc(val) 0.5628 |
Epoch 00188 | Loss(train) 2.5096 | Acc(train) 0.4239 | Acc(val) 0.5644 |
Epoch 00189 | Loss(train) 2.4862 | Acc(train) 0.4298 | Acc(val) 0.5702 |
Epoch 00190 | Loss(train) 2.4901 | Acc(train) 0.4293 | Acc(val) 0.5707 |
Epoch 00191 | Loss(train) 2.4535 | Acc(train) 0.4346 | Acc(val) 0.5713 |
Epoch 00192 | Loss(train) 2.4999 | Acc(train) 0.4226 | Acc(val) 0.5707 |
Epoch 00193 | Loss(train) 2.4565 | Acc(train) 0.4370 | Acc(val) 0.5691 |
Epoch 00194 | Loss(train) 2.4686 | Acc(train) 0.4354 | Acc(val) 0.5686 |
Epoch 00195 | Loss(train) 2.4853 | Acc(train) 0.4285 | Acc(val) 0.5665 |
Epoch 00196 | Loss(train) 2.4591 | Acc(train) 0.4316 | Acc(val) 0.5622 |
Epoch 00197 | Loss(train) 2.4954 | Acc(train) 0.4282 | Acc(val) 0.5633 |
Epoch 00198 | Loss(train) 2.4883 | Acc(train) 0.4311 | Acc(val) 0.5713 |
Epoch 00199 | Loss(train) 2.4762 | Acc(train) 0.4378 | Acc(val) 0.5755 |
Epoch 00200 | Loss(train) 2.4915 | Acc(train) 0.4314 | Acc(val) 0.5718 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 713.53 MB
GPU Memory Reserved: 2060.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2473 | Acc(train) 0.0104 | Acc(val) 0.1261 |*
Epoch 00002 | Loss(train) 4.2075 | Acc(train) 0.1066 | Acc(val) 0.2090 |*
Epoch 00003 | Loss(train) 4.1583 | Acc(train) 0.1601 | Acc(val) 0.2266 |*
Epoch 00004 | Loss(train) 4.0926 | Acc(train) 0.1721 | Acc(val) 0.2250 |
Epoch 00005 | Loss(train) 4.0116 | Acc(train) 0.1798 | Acc(val) 0.2160 |
Epoch 00006 | Loss(train) 3.9323 | Acc(train) 0.1697 | Acc(val) 0.2106 |
Epoch 00007 | Loss(train) 3.8581 | Acc(train) 0.1739 | Acc(val) 0.1989 |
Epoch 00008 | Loss(train) 3.8012 | Acc(train) 0.1689 | Acc(val) 0.1899 |
Epoch 00009 | Loss(train) 3.7488 | Acc(train) 0.1694 | Acc(val) 0.1862 |
Epoch 00010 | Loss(train) 3.6858 | Acc(train) 0.1630 | Acc(val) 0.1926 |
Epoch 00011 | Loss(train) 3.6191 | Acc(train) 0.1801 | Acc(val) 0.2112 |
Epoch 00012 | Loss(train) 3.5519 | Acc(train) 0.1931 | Acc(val) 0.2399 |*
Epoch 00013 | Loss(train) 3.4699 | Acc(train) 0.2215 | Acc(val) 0.2803 |*
Epoch 00014 | Loss(train) 3.3813 | Acc(train) 0.2676 | Acc(val) 0.3340 |*
Epoch 00015 | Loss(train) 3.3819 | Acc(train) 0.2585 | Acc(val) 0.3777 |*
Epoch 00016 | Loss(train) 3.2886 | Acc(train) 0.2941 | Acc(val) 0.4090 |*
Epoch 00017 | Loss(train) 3.2632 | Acc(train) 0.2957 | Acc(val) 0.4277 |*
Epoch 00018 | Loss(train) 3.1900 | Acc(train) 0.3194 | Acc(val) 0.4351 |*
Epoch 00019 | Loss(train) 3.1486 | Acc(train) 0.3181 | Acc(val) 0.4383 |*
Epoch 00020 | Loss(train) 3.0968 | Acc(train) 0.3197 | Acc(val) 0.4372 |
Epoch 00021 | Loss(train) 3.0656 | Acc(train) 0.3093 | Acc(val) 0.4351 |
Epoch 00022 | Loss(train) 3.0025 | Acc(train) 0.3295 | Acc(val) 0.4324 |
Epoch 00023 | Loss(train) 2.9935 | Acc(train) 0.3117 | Acc(val) 0.4309 |
Epoch 00024 | Loss(train) 2.9567 | Acc(train) 0.3242 | Acc(val) 0.4330 |
Epoch 00025 | Loss(train) 2.9366 | Acc(train) 0.3178 | Acc(val) 0.4367 |
Epoch 00026 | Loss(train) 2.9000 | Acc(train) 0.3309 | Acc(val) 0.4463 |*
Epoch 00027 | Loss(train) 2.8804 | Acc(train) 0.3338 | Acc(val) 0.4574 |*
Epoch 00028 | Loss(train) 2.8217 | Acc(train) 0.3545 | Acc(val) 0.4713 |*
Epoch 00029 | Loss(train) 2.8429 | Acc(train) 0.3479 | Acc(val) 0.4835 |*
Epoch 00030 | Loss(train) 2.8290 | Acc(train) 0.3622 | Acc(val) 0.4947 |*
Epoch 00031 | Loss(train) 2.7919 | Acc(train) 0.3548 | Acc(val) 0.5011 |*
Epoch 00032 | Loss(train) 2.7872 | Acc(train) 0.3551 | Acc(val) 0.5080 |*
Epoch 00033 | Loss(train) 2.7799 | Acc(train) 0.3670 | Acc(val) 0.5090 |*
Epoch 00034 | Loss(train) 2.7688 | Acc(train) 0.3564 | Acc(val) 0.5074 |
Epoch 00035 | Loss(train) 2.7209 | Acc(train) 0.3763 | Acc(val) 0.5059 |
Epoch 00036 | Loss(train) 2.7078 | Acc(train) 0.3697 | Acc(val) 0.5069 |
Epoch 00037 | Loss(train) 2.6751 | Acc(train) 0.3862 | Acc(val) 0.5064 |
Epoch 00038 | Loss(train) 2.7352 | Acc(train) 0.3676 | Acc(val) 0.5085 |
Epoch 00039 | Loss(train) 2.6852 | Acc(train) 0.3684 | Acc(val) 0.5085 |
Epoch 00040 | Loss(train) 2.6744 | Acc(train) 0.3886 | Acc(val) 0.5133 |*
Epoch 00041 | Loss(train) 2.6503 | Acc(train) 0.3779 | Acc(val) 0.5213 |*
Epoch 00042 | Loss(train) 2.6692 | Acc(train) 0.3867 | Acc(val) 0.5239 |*
Epoch 00043 | Loss(train) 2.6586 | Acc(train) 0.3779 | Acc(val) 0.5319 |*
Epoch 00044 | Loss(train) 2.6734 | Acc(train) 0.3840 | Acc(val) 0.5388 |*
Epoch 00045 | Loss(train) 2.6169 | Acc(train) 0.4019 | Acc(val) 0.5441 |*
Epoch 00046 | Loss(train) 2.6390 | Acc(train) 0.3939 | Acc(val) 0.5452 |*
Epoch 00047 | Loss(train) 2.6203 | Acc(train) 0.3997 | Acc(val) 0.5463 |*
Epoch 00048 | Loss(train) 2.6228 | Acc(train) 0.4027 | Acc(val) 0.5489 |*
Epoch 00049 | Loss(train) 2.5949 | Acc(train) 0.4019 | Acc(val) 0.5516 |*
Epoch 00050 | Loss(train) 2.6031 | Acc(train) 0.4027 | Acc(val) 0.5521 |*
Epoch 00051 | Loss(train) 2.5870 | Acc(train) 0.3947 | Acc(val) 0.5521 |
Epoch 00052 | Loss(train) 2.6191 | Acc(train) 0.4024 | Acc(val) 0.5495 |
Epoch 00053 | Loss(train) 2.5783 | Acc(train) 0.4035 | Acc(val) 0.5527 |*
Epoch 00054 | Loss(train) 2.6014 | Acc(train) 0.4051 | Acc(val) 0.5559 |*
Epoch 00055 | Loss(train) 2.5706 | Acc(train) 0.4120 | Acc(val) 0.5580 |*
Epoch 00056 | Loss(train) 2.5817 | Acc(train) 0.4069 | Acc(val) 0.5511 |
Epoch 00057 | Loss(train) 2.5445 | Acc(train) 0.4170 | Acc(val) 0.5473 |
Epoch 00058 | Loss(train) 2.5430 | Acc(train) 0.4178 | Acc(val) 0.5473 |
Epoch 00059 | Loss(train) 2.5336 | Acc(train) 0.4096 | Acc(val) 0.5473 |
Epoch 00060 | Loss(train) 2.5605 | Acc(train) 0.4125 | Acc(val) 0.5532 |
Epoch 00061 | Loss(train) 2.5911 | Acc(train) 0.4074 | Acc(val) 0.5495 |
Epoch 00062 | Loss(train) 2.5881 | Acc(train) 0.4048 | Acc(val) 0.5516 |
Epoch 00063 | Loss(train) 2.5771 | Acc(train) 0.4043 | Acc(val) 0.5489 |
Epoch 00064 | Loss(train) 2.5001 | Acc(train) 0.4226 | Acc(val) 0.5495 |
Epoch 00065 | Loss(train) 2.5493 | Acc(train) 0.4109 | Acc(val) 0.5521 |
Epoch 00066 | Loss(train) 2.5254 | Acc(train) 0.4189 | Acc(val) 0.5543 |
Epoch 00067 | Loss(train) 2.5704 | Acc(train) 0.4080 | Acc(val) 0.5559 |
Epoch 00068 | Loss(train) 2.5361 | Acc(train) 0.4080 | Acc(val) 0.5585 |*
Epoch 00069 | Loss(train) 2.5737 | Acc(train) 0.4080 | Acc(val) 0.5580 |
Epoch 00070 | Loss(train) 2.5115 | Acc(train) 0.4263 | Acc(val) 0.5628 |*
Epoch 00071 | Loss(train) 2.5418 | Acc(train) 0.4096 | Acc(val) 0.5649 |*
Epoch 00072 | Loss(train) 2.5360 | Acc(train) 0.4176 | Acc(val) 0.5644 |
Epoch 00073 | Loss(train) 2.5260 | Acc(train) 0.4138 | Acc(val) 0.5622 |
Epoch 00074 | Loss(train) 2.5626 | Acc(train) 0.4082 | Acc(val) 0.5617 |
Epoch 00075 | Loss(train) 2.5241 | Acc(train) 0.4173 | Acc(val) 0.5590 |
Epoch 00076 | Loss(train) 2.5192 | Acc(train) 0.4199 | Acc(val) 0.5564 |
Epoch 00077 | Loss(train) 2.5239 | Acc(train) 0.4189 | Acc(val) 0.5553 |
Epoch 00078 | Loss(train) 2.5479 | Acc(train) 0.4090 | Acc(val) 0.5569 |
Epoch 00079 | Loss(train) 2.5230 | Acc(train) 0.4234 | Acc(val) 0.5622 |
Epoch 00080 | Loss(train) 2.5325 | Acc(train) 0.4170 | Acc(val) 0.5665 |*
Epoch 00081 | Loss(train) 2.5000 | Acc(train) 0.4197 | Acc(val) 0.5681 |*
Epoch 00082 | Loss(train) 2.5546 | Acc(train) 0.4059 | Acc(val) 0.5691 |*
Epoch 00083 | Loss(train) 2.5058 | Acc(train) 0.4202 | Acc(val) 0.5691 |
Epoch 00084 | Loss(train) 2.5088 | Acc(train) 0.4199 | Acc(val) 0.5707 |*
Epoch 00085 | Loss(train) 2.5522 | Acc(train) 0.4088 | Acc(val) 0.5707 |
Epoch 00086 | Loss(train) 2.4912 | Acc(train) 0.4237 | Acc(val) 0.5665 |
Epoch 00087 | Loss(train) 2.5049 | Acc(train) 0.4231 | Acc(val) 0.5644 |
Epoch 00088 | Loss(train) 2.5346 | Acc(train) 0.4122 | Acc(val) 0.5574 |
Epoch 00089 | Loss(train) 2.5605 | Acc(train) 0.4120 | Acc(val) 0.5532 |
Epoch 00090 | Loss(train) 2.4874 | Acc(train) 0.4266 | Acc(val) 0.5532 |
Epoch 00091 | Loss(train) 2.5327 | Acc(train) 0.4199 | Acc(val) 0.5532 |
Epoch 00092 | Loss(train) 2.5252 | Acc(train) 0.4197 | Acc(val) 0.5521 |
Epoch 00093 | Loss(train) 2.5353 | Acc(train) 0.4043 | Acc(val) 0.5468 |
Epoch 00094 | Loss(train) 2.4568 | Acc(train) 0.4359 | Acc(val) 0.5511 |
Epoch 00095 | Loss(train) 2.5579 | Acc(train) 0.4096 | Acc(val) 0.5543 |
Epoch 00096 | Loss(train) 2.5130 | Acc(train) 0.4176 | Acc(val) 0.5585 |
Epoch 00097 | Loss(train) 2.5186 | Acc(train) 0.4199 | Acc(val) 0.5596 |
Epoch 00098 | Loss(train) 2.5127 | Acc(train) 0.4239 | Acc(val) 0.5622 |
Epoch 00099 | Loss(train) 2.5091 | Acc(train) 0.4231 | Acc(val) 0.5622 |
Epoch 00100 | Loss(train) 2.5193 | Acc(train) 0.4184 | Acc(val) 0.5660 |
Epoch 00101 | Loss(train) 2.4912 | Acc(train) 0.4338 | Acc(val) 0.5638 |
Epoch 00102 | Loss(train) 2.5379 | Acc(train) 0.4133 | Acc(val) 0.5617 |
Epoch 00103 | Loss(train) 2.4917 | Acc(train) 0.4364 | Acc(val) 0.5628 |
Epoch 00104 | Loss(train) 2.5176 | Acc(train) 0.4237 | Acc(val) 0.5606 |
Epoch 00105 | Loss(train) 2.5134 | Acc(train) 0.4237 | Acc(val) 0.5596 |
Epoch 00106 | Loss(train) 2.5654 | Acc(train) 0.4088 | Acc(val) 0.5564 |
Epoch 00107 | Loss(train) 2.5029 | Acc(train) 0.4223 | Acc(val) 0.5590 |
Epoch 00108 | Loss(train) 2.5457 | Acc(train) 0.4226 | Acc(val) 0.5596 |
Epoch 00109 | Loss(train) 2.5546 | Acc(train) 0.4253 | Acc(val) 0.5644 |
Epoch 00110 | Loss(train) 2.5095 | Acc(train) 0.4279 | Acc(val) 0.5691 |
Epoch 00111 | Loss(train) 2.5058 | Acc(train) 0.4234 | Acc(val) 0.5691 |
Epoch 00112 | Loss(train) 2.5044 | Acc(train) 0.4258 | Acc(val) 0.5713 |*
Epoch 00113 | Loss(train) 2.5440 | Acc(train) 0.4261 | Acc(val) 0.5676 |
Epoch 00114 | Loss(train) 2.5042 | Acc(train) 0.4404 | Acc(val) 0.5681 |
Epoch 00115 | Loss(train) 2.4805 | Acc(train) 0.4250 | Acc(val) 0.5654 |
Epoch 00116 | Loss(train) 2.5015 | Acc(train) 0.4160 | Acc(val) 0.5612 |
Epoch 00117 | Loss(train) 2.4961 | Acc(train) 0.4173 | Acc(val) 0.5649 |
Epoch 00118 | Loss(train) 2.5081 | Acc(train) 0.4205 | Acc(val) 0.5697 |
Epoch 00119 | Loss(train) 2.5173 | Acc(train) 0.4191 | Acc(val) 0.5723 |*
Epoch 00120 | Loss(train) 2.5210 | Acc(train) 0.4242 | Acc(val) 0.5739 |*
Epoch 00121 | Loss(train) 2.5151 | Acc(train) 0.4149 | Acc(val) 0.5697 |
Epoch 00122 | Loss(train) 2.5186 | Acc(train) 0.4191 | Acc(val) 0.5718 |
Epoch 00123 | Loss(train) 2.4973 | Acc(train) 0.4207 | Acc(val) 0.5713 |
Epoch 00124 | Loss(train) 2.5060 | Acc(train) 0.4181 | Acc(val) 0.5638 |
Epoch 00125 | Loss(train) 2.5032 | Acc(train) 0.4199 | Acc(val) 0.5681 |
Epoch 00126 | Loss(train) 2.5051 | Acc(train) 0.4168 | Acc(val) 0.5686 |
Epoch 00127 | Loss(train) 2.4769 | Acc(train) 0.4303 | Acc(val) 0.5729 |
Epoch 00128 | Loss(train) 2.4903 | Acc(train) 0.4277 | Acc(val) 0.5707 |
Epoch 00129 | Loss(train) 2.5097 | Acc(train) 0.4247 | Acc(val) 0.5739 |
Epoch 00130 | Loss(train) 2.4997 | Acc(train) 0.4295 | Acc(val) 0.5718 |
Epoch 00131 | Loss(train) 2.5141 | Acc(train) 0.4319 | Acc(val) 0.5702 |
Epoch 00132 | Loss(train) 2.4994 | Acc(train) 0.4301 | Acc(val) 0.5707 |
Epoch 00133 | Loss(train) 2.4802 | Acc(train) 0.4282 | Acc(val) 0.5686 |
Epoch 00134 | Loss(train) 2.5081 | Acc(train) 0.4199 | Acc(val) 0.5633 |
Epoch 00135 | Loss(train) 2.4847 | Acc(train) 0.4332 | Acc(val) 0.5601 |
Epoch 00136 | Loss(train) 2.4969 | Acc(train) 0.4205 | Acc(val) 0.5622 |
Epoch 00137 | Loss(train) 2.4910 | Acc(train) 0.4253 | Acc(val) 0.5622 |
Epoch 00138 | Loss(train) 2.4964 | Acc(train) 0.4295 | Acc(val) 0.5649 |
Epoch 00139 | Loss(train) 2.5054 | Acc(train) 0.4218 | Acc(val) 0.5691 |
Epoch 00140 | Loss(train) 2.4736 | Acc(train) 0.4372 | Acc(val) 0.5676 |
Epoch 00141 | Loss(train) 2.4724 | Acc(train) 0.4271 | Acc(val) 0.5665 |
Epoch 00142 | Loss(train) 2.4825 | Acc(train) 0.4346 | Acc(val) 0.5649 |
Epoch 00143 | Loss(train) 2.5079 | Acc(train) 0.4274 | Acc(val) 0.5606 |
Epoch 00144 | Loss(train) 2.4931 | Acc(train) 0.4242 | Acc(val) 0.5548 |
Epoch 00145 | Loss(train) 2.5020 | Acc(train) 0.4202 | Acc(val) 0.5585 |
Epoch 00146 | Loss(train) 2.5007 | Acc(train) 0.4191 | Acc(val) 0.5585 |
Epoch 00147 | Loss(train) 2.5179 | Acc(train) 0.4184 | Acc(val) 0.5617 |
Epoch 00148 | Loss(train) 2.5021 | Acc(train) 0.4258 | Acc(val) 0.5644 |
Epoch 00149 | Loss(train) 2.5045 | Acc(train) 0.4199 | Acc(val) 0.5697 |
Epoch 00150 | Loss(train) 2.5097 | Acc(train) 0.4229 | Acc(val) 0.5702 |
Epoch 00151 | Loss(train) 2.5055 | Acc(train) 0.4215 | Acc(val) 0.5745 |*
Epoch 00152 | Loss(train) 2.4563 | Acc(train) 0.4282 | Acc(val) 0.5750 |*
Epoch 00153 | Loss(train) 2.4736 | Acc(train) 0.4226 | Acc(val) 0.5702 |
Epoch 00154 | Loss(train) 2.5192 | Acc(train) 0.4213 | Acc(val) 0.5681 |
Epoch 00155 | Loss(train) 2.5124 | Acc(train) 0.4221 | Acc(val) 0.5670 |
Epoch 00156 | Loss(train) 2.4611 | Acc(train) 0.4402 | Acc(val) 0.5670 |
Epoch 00157 | Loss(train) 2.4660 | Acc(train) 0.4324 | Acc(val) 0.5612 |
Epoch 00158 | Loss(train) 2.5316 | Acc(train) 0.4152 | Acc(val) 0.5654 |
Epoch 00159 | Loss(train) 2.4749 | Acc(train) 0.4226 | Acc(val) 0.5654 |
Epoch 00160 | Loss(train) 2.5075 | Acc(train) 0.4269 | Acc(val) 0.5654 |
Epoch 00161 | Loss(train) 2.4838 | Acc(train) 0.4375 | Acc(val) 0.5660 |
Epoch 00162 | Loss(train) 2.5044 | Acc(train) 0.4271 | Acc(val) 0.5665 |
Epoch 00163 | Loss(train) 2.4906 | Acc(train) 0.4255 | Acc(val) 0.5633 |
Epoch 00164 | Loss(train) 2.4881 | Acc(train) 0.4311 | Acc(val) 0.5638 |
Epoch 00165 | Loss(train) 2.4716 | Acc(train) 0.4269 | Acc(val) 0.5638 |
Epoch 00166 | Loss(train) 2.4740 | Acc(train) 0.4327 | Acc(val) 0.5638 |
Epoch 00167 | Loss(train) 2.5185 | Acc(train) 0.4205 | Acc(val) 0.5681 |
Epoch 00168 | Loss(train) 2.4869 | Acc(train) 0.4319 | Acc(val) 0.5676 |
Epoch 00169 | Loss(train) 2.4883 | Acc(train) 0.4197 | Acc(val) 0.5686 |
Epoch 00170 | Loss(train) 2.5280 | Acc(train) 0.4226 | Acc(val) 0.5702 |
Epoch 00171 | Loss(train) 2.4877 | Acc(train) 0.4253 | Acc(val) 0.5702 |
Epoch 00172 | Loss(train) 2.5301 | Acc(train) 0.4149 | Acc(val) 0.5686 |
Epoch 00173 | Loss(train) 2.4809 | Acc(train) 0.4221 | Acc(val) 0.5665 |
Epoch 00174 | Loss(train) 2.4819 | Acc(train) 0.4346 | Acc(val) 0.5686 |
Epoch 00175 | Loss(train) 2.4656 | Acc(train) 0.4407 | Acc(val) 0.5638 |
Epoch 00176 | Loss(train) 2.4988 | Acc(train) 0.4258 | Acc(val) 0.5681 |
Epoch 00177 | Loss(train) 2.4878 | Acc(train) 0.4266 | Acc(val) 0.5697 |
Epoch 00178 | Loss(train) 2.4908 | Acc(train) 0.4255 | Acc(val) 0.5707 |
Epoch 00179 | Loss(train) 2.4876 | Acc(train) 0.4322 | Acc(val) 0.5713 |
Epoch 00180 | Loss(train) 2.5046 | Acc(train) 0.4287 | Acc(val) 0.5707 |
Epoch 00181 | Loss(train) 2.5151 | Acc(train) 0.4181 | Acc(val) 0.5660 |
Epoch 00182 | Loss(train) 2.5217 | Acc(train) 0.4255 | Acc(val) 0.5681 |
Epoch 00183 | Loss(train) 2.4896 | Acc(train) 0.4311 | Acc(val) 0.5676 |
Epoch 00184 | Loss(train) 2.4641 | Acc(train) 0.4285 | Acc(val) 0.5628 |
Epoch 00185 | Loss(train) 2.5038 | Acc(train) 0.4245 | Acc(val) 0.5612 |
Epoch 00186 | Loss(train) 2.4825 | Acc(train) 0.4247 | Acc(val) 0.5644 |
Epoch 00187 | Loss(train) 2.4986 | Acc(train) 0.4173 | Acc(val) 0.5665 |
Epoch 00188 | Loss(train) 2.4966 | Acc(train) 0.4247 | Acc(val) 0.5713 |
Epoch 00189 | Loss(train) 2.4519 | Acc(train) 0.4407 | Acc(val) 0.5723 |
Epoch 00190 | Loss(train) 2.5240 | Acc(train) 0.4202 | Acc(val) 0.5723 |
Epoch 00191 | Loss(train) 2.4903 | Acc(train) 0.4274 | Acc(val) 0.5729 |
Epoch 00192 | Loss(train) 2.4629 | Acc(train) 0.4420 | Acc(val) 0.5654 |
Epoch 00193 | Loss(train) 2.4815 | Acc(train) 0.4293 | Acc(val) 0.5670 |
Epoch 00194 | Loss(train) 2.4835 | Acc(train) 0.4293 | Acc(val) 0.5654 |
Epoch 00195 | Loss(train) 2.4765 | Acc(train) 0.4378 | Acc(val) 0.5681 |
Epoch 00196 | Loss(train) 2.5272 | Acc(train) 0.4221 | Acc(val) 0.5718 |
Epoch 00197 | Loss(train) 2.5020 | Acc(train) 0.4311 | Acc(val) 0.5729 |
Epoch 00198 | Loss(train) 2.5235 | Acc(train) 0.4221 | Acc(val) 0.5761 |*
Epoch 00199 | Loss(train) 2.5151 | Acc(train) 0.4277 | Acc(val) 0.5782 |*
Epoch 00200 | Loss(train) 2.5185 | Acc(train) 0.4285 | Acc(val) 0.5761 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 714.98 MB
GPU Memory Reserved: 2060.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2494 | Acc(train) 0.0138 | Acc(val) 0.0606 |*
Epoch 00002 | Loss(train) 4.2063 | Acc(train) 0.0971 | Acc(val) 0.0894 |*
Epoch 00003 | Loss(train) 4.1510 | Acc(train) 0.1199 | Acc(val) 0.1128 |*
Epoch 00004 | Loss(train) 4.0830 | Acc(train) 0.1215 | Acc(val) 0.1277 |*
Epoch 00005 | Loss(train) 4.0024 | Acc(train) 0.1223 | Acc(val) 0.1324 |*
Epoch 00006 | Loss(train) 3.9218 | Acc(train) 0.1242 | Acc(val) 0.1346 |*
Epoch 00007 | Loss(train) 3.8575 | Acc(train) 0.1218 | Acc(val) 0.1367 |*
Epoch 00008 | Loss(train) 3.8134 | Acc(train) 0.1319 | Acc(val) 0.1426 |*
Epoch 00009 | Loss(train) 3.7441 | Acc(train) 0.1391 | Acc(val) 0.1580 |*
Epoch 00010 | Loss(train) 3.6940 | Acc(train) 0.1521 | Acc(val) 0.1851 |*
Epoch 00011 | Loss(train) 3.6276 | Acc(train) 0.1785 | Acc(val) 0.2154 |*
Epoch 00012 | Loss(train) 3.5630 | Acc(train) 0.2074 | Acc(val) 0.2665 |*
Epoch 00013 | Loss(train) 3.4849 | Acc(train) 0.2354 | Acc(val) 0.3191 |*
Epoch 00014 | Loss(train) 3.4226 | Acc(train) 0.2638 | Acc(val) 0.3580 |*
Epoch 00015 | Loss(train) 3.3799 | Acc(train) 0.2856 | Acc(val) 0.3872 |*
Epoch 00016 | Loss(train) 3.3113 | Acc(train) 0.3008 | Acc(val) 0.4090 |*
Epoch 00017 | Loss(train) 3.2573 | Acc(train) 0.2992 | Acc(val) 0.4191 |*
Epoch 00018 | Loss(train) 3.1662 | Acc(train) 0.3184 | Acc(val) 0.4160 |
Epoch 00019 | Loss(train) 3.1340 | Acc(train) 0.3176 | Acc(val) 0.4149 |
Epoch 00020 | Loss(train) 3.0845 | Acc(train) 0.3202 | Acc(val) 0.4138 |
Epoch 00021 | Loss(train) 3.0570 | Acc(train) 0.3165 | Acc(val) 0.4101 |
Epoch 00022 | Loss(train) 3.0295 | Acc(train) 0.3122 | Acc(val) 0.4138 |
Epoch 00023 | Loss(train) 2.9759 | Acc(train) 0.3221 | Acc(val) 0.4239 |*
Epoch 00024 | Loss(train) 2.9743 | Acc(train) 0.3149 | Acc(val) 0.4340 |*
Epoch 00025 | Loss(train) 2.9378 | Acc(train) 0.3162 | Acc(val) 0.4436 |*
Epoch 00026 | Loss(train) 2.9341 | Acc(train) 0.3231 | Acc(val) 0.4537 |*
Epoch 00027 | Loss(train) 2.8947 | Acc(train) 0.3370 | Acc(val) 0.4723 |*
Epoch 00028 | Loss(train) 2.8190 | Acc(train) 0.3511 | Acc(val) 0.4904 |*
Epoch 00029 | Loss(train) 2.8277 | Acc(train) 0.3457 | Acc(val) 0.5021 |*
Epoch 00030 | Loss(train) 2.8322 | Acc(train) 0.3590 | Acc(val) 0.5096 |*
Epoch 00031 | Loss(train) 2.8075 | Acc(train) 0.3582 | Acc(val) 0.5096 |
Epoch 00032 | Loss(train) 2.7724 | Acc(train) 0.3705 | Acc(val) 0.5090 |
Epoch 00033 | Loss(train) 2.7659 | Acc(train) 0.3694 | Acc(val) 0.5096 |
Epoch 00034 | Loss(train) 2.7608 | Acc(train) 0.3596 | Acc(val) 0.5048 |
Epoch 00035 | Loss(train) 2.7100 | Acc(train) 0.3660 | Acc(val) 0.5000 |
Epoch 00036 | Loss(train) 2.7278 | Acc(train) 0.3774 | Acc(val) 0.4973 |
Epoch 00037 | Loss(train) 2.7094 | Acc(train) 0.3713 | Acc(val) 0.5005 |
Epoch 00038 | Loss(train) 2.6891 | Acc(train) 0.3785 | Acc(val) 0.5096 |
Epoch 00039 | Loss(train) 2.6718 | Acc(train) 0.3864 | Acc(val) 0.5170 |*
Epoch 00040 | Loss(train) 2.6983 | Acc(train) 0.3745 | Acc(val) 0.5250 |*
Epoch 00041 | Loss(train) 2.6629 | Acc(train) 0.3880 | Acc(val) 0.5309 |*
Epoch 00042 | Loss(train) 2.6562 | Acc(train) 0.3907 | Acc(val) 0.5351 |*
Epoch 00043 | Loss(train) 2.6412 | Acc(train) 0.3851 | Acc(val) 0.5426 |*
Epoch 00044 | Loss(train) 2.6464 | Acc(train) 0.3939 | Acc(val) 0.5431 |*
Epoch 00045 | Loss(train) 2.6272 | Acc(train) 0.3886 | Acc(val) 0.5426 |
Epoch 00046 | Loss(train) 2.6386 | Acc(train) 0.3920 | Acc(val) 0.5367 |
Epoch 00047 | Loss(train) 2.6248 | Acc(train) 0.4029 | Acc(val) 0.5351 |
Epoch 00048 | Loss(train) 2.6079 | Acc(train) 0.3968 | Acc(val) 0.5362 |
Epoch 00049 | Loss(train) 2.6216 | Acc(train) 0.4048 | Acc(val) 0.5399 |
Epoch 00050 | Loss(train) 2.5736 | Acc(train) 0.3960 | Acc(val) 0.5404 |
Epoch 00051 | Loss(train) 2.6210 | Acc(train) 0.3941 | Acc(val) 0.5420 |
Epoch 00052 | Loss(train) 2.5786 | Acc(train) 0.4037 | Acc(val) 0.5431 |
Epoch 00053 | Loss(train) 2.6232 | Acc(train) 0.4013 | Acc(val) 0.5457 |*
Epoch 00054 | Loss(train) 2.5667 | Acc(train) 0.4005 | Acc(val) 0.5484 |*
Epoch 00055 | Loss(train) 2.5446 | Acc(train) 0.4146 | Acc(val) 0.5505 |*
Epoch 00056 | Loss(train) 2.5898 | Acc(train) 0.3976 | Acc(val) 0.5468 |
Epoch 00057 | Loss(train) 2.5377 | Acc(train) 0.4205 | Acc(val) 0.5484 |
Epoch 00058 | Loss(train) 2.5502 | Acc(train) 0.4152 | Acc(val) 0.5527 |*
Epoch 00059 | Loss(train) 2.5757 | Acc(train) 0.4056 | Acc(val) 0.5548 |*
Epoch 00060 | Loss(train) 2.5449 | Acc(train) 0.4160 | Acc(val) 0.5585 |*
Epoch 00061 | Loss(train) 2.5619 | Acc(train) 0.4181 | Acc(val) 0.5580 |
Epoch 00062 | Loss(train) 2.5568 | Acc(train) 0.4008 | Acc(val) 0.5596 |*
Epoch 00063 | Loss(train) 2.5585 | Acc(train) 0.4043 | Acc(val) 0.5596 |
Epoch 00064 | Loss(train) 2.5700 | Acc(train) 0.4059 | Acc(val) 0.5580 |
Epoch 00065 | Loss(train) 2.5271 | Acc(train) 0.4120 | Acc(val) 0.5596 |
Epoch 00066 | Loss(train) 2.5636 | Acc(train) 0.4112 | Acc(val) 0.5569 |
Epoch 00067 | Loss(train) 2.5689 | Acc(train) 0.4005 | Acc(val) 0.5564 |
Epoch 00068 | Loss(train) 2.5181 | Acc(train) 0.4301 | Acc(val) 0.5548 |
Epoch 00069 | Loss(train) 2.5240 | Acc(train) 0.4098 | Acc(val) 0.5553 |
Epoch 00070 | Loss(train) 2.5649 | Acc(train) 0.4136 | Acc(val) 0.5543 |
Epoch 00071 | Loss(train) 2.5314 | Acc(train) 0.4173 | Acc(val) 0.5590 |
Epoch 00072 | Loss(train) 2.5558 | Acc(train) 0.4141 | Acc(val) 0.5612 |*
Epoch 00073 | Loss(train) 2.5185 | Acc(train) 0.4226 | Acc(val) 0.5633 |*
Epoch 00074 | Loss(train) 2.5755 | Acc(train) 0.4130 | Acc(val) 0.5638 |*
Epoch 00075 | Loss(train) 2.5340 | Acc(train) 0.4157 | Acc(val) 0.5622 |
Epoch 00076 | Loss(train) 2.5270 | Acc(train) 0.4242 | Acc(val) 0.5574 |
Epoch 00077 | Loss(train) 2.4894 | Acc(train) 0.4277 | Acc(val) 0.5532 |
Epoch 00078 | Loss(train) 2.5529 | Acc(train) 0.4120 | Acc(val) 0.5532 |
Epoch 00079 | Loss(train) 2.5033 | Acc(train) 0.4234 | Acc(val) 0.5537 |
Epoch 00080 | Loss(train) 2.5081 | Acc(train) 0.4170 | Acc(val) 0.5511 |
Epoch 00081 | Loss(train) 2.5117 | Acc(train) 0.4152 | Acc(val) 0.5569 |
Epoch 00082 | Loss(train) 2.5213 | Acc(train) 0.4263 | Acc(val) 0.5628 |
Epoch 00083 | Loss(train) 2.5563 | Acc(train) 0.4120 | Acc(val) 0.5676 |*
Epoch 00084 | Loss(train) 2.5416 | Acc(train) 0.4106 | Acc(val) 0.5638 |
Epoch 00085 | Loss(train) 2.4871 | Acc(train) 0.4269 | Acc(val) 0.5644 |
Epoch 00086 | Loss(train) 2.4874 | Acc(train) 0.4346 | Acc(val) 0.5654 |
Epoch 00087 | Loss(train) 2.5278 | Acc(train) 0.4186 | Acc(val) 0.5628 |
Epoch 00088 | Loss(train) 2.5127 | Acc(train) 0.4189 | Acc(val) 0.5622 |
Epoch 00089 | Loss(train) 2.5466 | Acc(train) 0.4160 | Acc(val) 0.5633 |
Epoch 00090 | Loss(train) 2.5098 | Acc(train) 0.4242 | Acc(val) 0.5649 |
Epoch 00091 | Loss(train) 2.5549 | Acc(train) 0.4154 | Acc(val) 0.5665 |
Epoch 00092 | Loss(train) 2.5170 | Acc(train) 0.4226 | Acc(val) 0.5649 |
Epoch 00093 | Loss(train) 2.5320 | Acc(train) 0.4189 | Acc(val) 0.5649 |
Epoch 00094 | Loss(train) 2.5254 | Acc(train) 0.4109 | Acc(val) 0.5633 |
Epoch 00095 | Loss(train) 2.5299 | Acc(train) 0.4101 | Acc(val) 0.5628 |
Epoch 00096 | Loss(train) 2.5266 | Acc(train) 0.4154 | Acc(val) 0.5612 |
Epoch 00097 | Loss(train) 2.5243 | Acc(train) 0.4114 | Acc(val) 0.5633 |
Epoch 00098 | Loss(train) 2.5193 | Acc(train) 0.4210 | Acc(val) 0.5649 |
Epoch 00099 | Loss(train) 2.5397 | Acc(train) 0.4173 | Acc(val) 0.5649 |
Epoch 00100 | Loss(train) 2.5244 | Acc(train) 0.4191 | Acc(val) 0.5638 |
Epoch 00101 | Loss(train) 2.5455 | Acc(train) 0.4149 | Acc(val) 0.5606 |
Epoch 00102 | Loss(train) 2.5174 | Acc(train) 0.4152 | Acc(val) 0.5543 |
Epoch 00103 | Loss(train) 2.5496 | Acc(train) 0.4168 | Acc(val) 0.5527 |
Epoch 00104 | Loss(train) 2.5279 | Acc(train) 0.4181 | Acc(val) 0.5564 |
Epoch 00105 | Loss(train) 2.5380 | Acc(train) 0.4191 | Acc(val) 0.5649 |
Epoch 00106 | Loss(train) 2.4881 | Acc(train) 0.4229 | Acc(val) 0.5681 |*
Epoch 00107 | Loss(train) 2.5257 | Acc(train) 0.4250 | Acc(val) 0.5691 |*
Epoch 00108 | Loss(train) 2.4914 | Acc(train) 0.4338 | Acc(val) 0.5665 |
Epoch 00109 | Loss(train) 2.5066 | Acc(train) 0.4327 | Acc(val) 0.5628 |
Epoch 00110 | Loss(train) 2.5141 | Acc(train) 0.4239 | Acc(val) 0.5622 |
Epoch 00111 | Loss(train) 2.4876 | Acc(train) 0.4380 | Acc(val) 0.5633 |
Epoch 00112 | Loss(train) 2.5060 | Acc(train) 0.4250 | Acc(val) 0.5644 |
Epoch 00113 | Loss(train) 2.5464 | Acc(train) 0.4199 | Acc(val) 0.5654 |
Epoch 00114 | Loss(train) 2.5158 | Acc(train) 0.4231 | Acc(val) 0.5691 |
Epoch 00115 | Loss(train) 2.5240 | Acc(train) 0.4202 | Acc(val) 0.5676 |
Epoch 00116 | Loss(train) 2.4676 | Acc(train) 0.4415 | Acc(val) 0.5660 |
Epoch 00117 | Loss(train) 2.4870 | Acc(train) 0.4314 | Acc(val) 0.5617 |
Epoch 00118 | Loss(train) 2.4869 | Acc(train) 0.4271 | Acc(val) 0.5596 |
Epoch 00119 | Loss(train) 2.4897 | Acc(train) 0.4306 | Acc(val) 0.5580 |
Epoch 00120 | Loss(train) 2.5279 | Acc(train) 0.4120 | Acc(val) 0.5596 |
Epoch 00121 | Loss(train) 2.4778 | Acc(train) 0.4306 | Acc(val) 0.5601 |
Epoch 00122 | Loss(train) 2.5185 | Acc(train) 0.4223 | Acc(val) 0.5644 |
Epoch 00123 | Loss(train) 2.5268 | Acc(train) 0.4096 | Acc(val) 0.5649 |
Epoch 00124 | Loss(train) 2.5402 | Acc(train) 0.4210 | Acc(val) 0.5660 |
Epoch 00125 | Loss(train) 2.4937 | Acc(train) 0.4338 | Acc(val) 0.5702 |*
Epoch 00126 | Loss(train) 2.5023 | Acc(train) 0.4306 | Acc(val) 0.5686 |
Epoch 00127 | Loss(train) 2.5024 | Acc(train) 0.4144 | Acc(val) 0.5707 |*
Epoch 00128 | Loss(train) 2.5024 | Acc(train) 0.4261 | Acc(val) 0.5681 |
Epoch 00129 | Loss(train) 2.4952 | Acc(train) 0.4311 | Acc(val) 0.5628 |
Epoch 00130 | Loss(train) 2.4870 | Acc(train) 0.4274 | Acc(val) 0.5596 |
Epoch 00131 | Loss(train) 2.4538 | Acc(train) 0.4378 | Acc(val) 0.5580 |
Epoch 00132 | Loss(train) 2.4678 | Acc(train) 0.4399 | Acc(val) 0.5633 |
Epoch 00133 | Loss(train) 2.5213 | Acc(train) 0.4130 | Acc(val) 0.5665 |
Epoch 00134 | Loss(train) 2.5019 | Acc(train) 0.4184 | Acc(val) 0.5697 |
Epoch 00135 | Loss(train) 2.4687 | Acc(train) 0.4319 | Acc(val) 0.5739 |*
Epoch 00136 | Loss(train) 2.5354 | Acc(train) 0.4218 | Acc(val) 0.5723 |
Epoch 00137 | Loss(train) 2.4660 | Acc(train) 0.4375 | Acc(val) 0.5707 |
Epoch 00138 | Loss(train) 2.4726 | Acc(train) 0.4311 | Acc(val) 0.5702 |
Epoch 00139 | Loss(train) 2.4846 | Acc(train) 0.4245 | Acc(val) 0.5691 |
Epoch 00140 | Loss(train) 2.5022 | Acc(train) 0.4197 | Acc(val) 0.5649 |
Epoch 00141 | Loss(train) 2.5369 | Acc(train) 0.4152 | Acc(val) 0.5681 |
Epoch 00142 | Loss(train) 2.5256 | Acc(train) 0.4165 | Acc(val) 0.5654 |
Epoch 00143 | Loss(train) 2.4817 | Acc(train) 0.4306 | Acc(val) 0.5686 |
Epoch 00144 | Loss(train) 2.5185 | Acc(train) 0.4199 | Acc(val) 0.5649 |
Epoch 00145 | Loss(train) 2.5027 | Acc(train) 0.4215 | Acc(val) 0.5617 |
Epoch 00146 | Loss(train) 2.5151 | Acc(train) 0.4261 | Acc(val) 0.5633 |
Epoch 00147 | Loss(train) 2.4969 | Acc(train) 0.4263 | Acc(val) 0.5686 |
Epoch 00148 | Loss(train) 2.5169 | Acc(train) 0.4255 | Acc(val) 0.5660 |
Epoch 00149 | Loss(train) 2.4486 | Acc(train) 0.4399 | Acc(val) 0.5633 |
Epoch 00150 | Loss(train) 2.5455 | Acc(train) 0.4133 | Acc(val) 0.5596 |
Epoch 00151 | Loss(train) 2.4652 | Acc(train) 0.4261 | Acc(val) 0.5585 |
Epoch 00152 | Loss(train) 2.4872 | Acc(train) 0.4205 | Acc(val) 0.5569 |
Epoch 00153 | Loss(train) 2.4904 | Acc(train) 0.4282 | Acc(val) 0.5569 |
Epoch 00154 | Loss(train) 2.4978 | Acc(train) 0.4234 | Acc(val) 0.5638 |
Epoch 00155 | Loss(train) 2.4865 | Acc(train) 0.4184 | Acc(val) 0.5676 |
Epoch 00156 | Loss(train) 2.5080 | Acc(train) 0.4194 | Acc(val) 0.5697 |
Epoch 00157 | Loss(train) 2.4572 | Acc(train) 0.4434 | Acc(val) 0.5707 |
Epoch 00158 | Loss(train) 2.4755 | Acc(train) 0.4396 | Acc(val) 0.5707 |
Epoch 00159 | Loss(train) 2.4912 | Acc(train) 0.4226 | Acc(val) 0.5660 |
Epoch 00160 | Loss(train) 2.4709 | Acc(train) 0.4439 | Acc(val) 0.5649 |
Epoch 00161 | Loss(train) 2.4968 | Acc(train) 0.4298 | Acc(val) 0.5649 |
Epoch 00162 | Loss(train) 2.5107 | Acc(train) 0.4274 | Acc(val) 0.5633 |
Epoch 00163 | Loss(train) 2.5186 | Acc(train) 0.4093 | Acc(val) 0.5606 |
Epoch 00164 | Loss(train) 2.5257 | Acc(train) 0.4205 | Acc(val) 0.5622 |
Epoch 00165 | Loss(train) 2.4980 | Acc(train) 0.4263 | Acc(val) 0.5670 |
Epoch 00166 | Loss(train) 2.4621 | Acc(train) 0.4356 | Acc(val) 0.5691 |
Epoch 00167 | Loss(train) 2.4550 | Acc(train) 0.4375 | Acc(val) 0.5739 |
Epoch 00168 | Loss(train) 2.4847 | Acc(train) 0.4250 | Acc(val) 0.5729 |
Epoch 00169 | Loss(train) 2.4862 | Acc(train) 0.4311 | Acc(val) 0.5702 |
Epoch 00170 | Loss(train) 2.4548 | Acc(train) 0.4378 | Acc(val) 0.5713 |
Epoch 00171 | Loss(train) 2.4796 | Acc(train) 0.4191 | Acc(val) 0.5707 |
Epoch 00172 | Loss(train) 2.4970 | Acc(train) 0.4271 | Acc(val) 0.5723 |
Epoch 00173 | Loss(train) 2.4937 | Acc(train) 0.4239 | Acc(val) 0.5713 |
Epoch 00174 | Loss(train) 2.4776 | Acc(train) 0.4364 | Acc(val) 0.5729 |
Epoch 00175 | Loss(train) 2.5161 | Acc(train) 0.4231 | Acc(val) 0.5676 |
Epoch 00176 | Loss(train) 2.5029 | Acc(train) 0.4282 | Acc(val) 0.5617 |
Epoch 00177 | Loss(train) 2.4861 | Acc(train) 0.4301 | Acc(val) 0.5596 |
Epoch 00178 | Loss(train) 2.4845 | Acc(train) 0.4277 | Acc(val) 0.5590 |
Epoch 00179 | Loss(train) 2.4981 | Acc(train) 0.4258 | Acc(val) 0.5622 |
Epoch 00180 | Loss(train) 2.4761 | Acc(train) 0.4285 | Acc(val) 0.5654 |
Epoch 00181 | Loss(train) 2.4954 | Acc(train) 0.4247 | Acc(val) 0.5702 |
Epoch 00182 | Loss(train) 2.4764 | Acc(train) 0.4418 | Acc(val) 0.5665 |
Epoch 00183 | Loss(train) 2.4748 | Acc(train) 0.4277 | Acc(val) 0.5654 |
Epoch 00184 | Loss(train) 2.4710 | Acc(train) 0.4298 | Acc(val) 0.5633 |
Early stopping at epoch 184
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 713.53 MB
GPU Memory Reserved: 2060.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2526 | Acc(train) 0.0160 | Acc(val) 0.1335 |*
Epoch 00002 | Loss(train) 4.2105 | Acc(train) 0.0987 | Acc(val) 0.1229 |
Epoch 00003 | Loss(train) 4.1554 | Acc(train) 0.1293 | Acc(val) 0.1207 |
Epoch 00004 | Loss(train) 4.0862 | Acc(train) 0.1309 | Acc(val) 0.1181 |
Epoch 00005 | Loss(train) 4.0093 | Acc(train) 0.1303 | Acc(val) 0.1101 |
Epoch 00006 | Loss(train) 3.9207 | Acc(train) 0.1253 | Acc(val) 0.1074 |
Epoch 00007 | Loss(train) 3.8594 | Acc(train) 0.1245 | Acc(val) 0.1122 |
Epoch 00008 | Loss(train) 3.8071 | Acc(train) 0.1170 | Acc(val) 0.1271 |
Epoch 00009 | Loss(train) 3.7422 | Acc(train) 0.1396 | Acc(val) 0.1564 |*
Epoch 00010 | Loss(train) 3.6852 | Acc(train) 0.1495 | Acc(val) 0.1798 |*
Epoch 00011 | Loss(train) 3.6221 | Acc(train) 0.1684 | Acc(val) 0.2011 |*
Epoch 00012 | Loss(train) 3.5454 | Acc(train) 0.2043 | Acc(val) 0.2351 |*
Epoch 00013 | Loss(train) 3.4816 | Acc(train) 0.2293 | Acc(val) 0.2782 |*
Epoch 00014 | Loss(train) 3.4381 | Acc(train) 0.2452 | Acc(val) 0.3277 |*
Epoch 00015 | Loss(train) 3.3602 | Acc(train) 0.2702 | Acc(val) 0.3686 |*
Epoch 00016 | Loss(train) 3.3029 | Acc(train) 0.2960 | Acc(val) 0.3920 |*
Epoch 00017 | Loss(train) 3.2351 | Acc(train) 0.2918 | Acc(val) 0.4096 |*
Epoch 00018 | Loss(train) 3.2032 | Acc(train) 0.3189 | Acc(val) 0.4176 |*
Epoch 00019 | Loss(train) 3.1467 | Acc(train) 0.3112 | Acc(val) 0.4186 |*
Epoch 00020 | Loss(train) 3.1047 | Acc(train) 0.3090 | Acc(val) 0.4160 |
Epoch 00021 | Loss(train) 3.0813 | Acc(train) 0.3019 | Acc(val) 0.4160 |
Epoch 00022 | Loss(train) 3.0365 | Acc(train) 0.3059 | Acc(val) 0.4170 |
Epoch 00023 | Loss(train) 3.0041 | Acc(train) 0.3077 | Acc(val) 0.4191 |*
Epoch 00024 | Loss(train) 2.9900 | Acc(train) 0.3056 | Acc(val) 0.4271 |*
Epoch 00025 | Loss(train) 2.9313 | Acc(train) 0.3114 | Acc(val) 0.4399 |*
Epoch 00026 | Loss(train) 2.9625 | Acc(train) 0.3136 | Acc(val) 0.4511 |*
Epoch 00027 | Loss(train) 2.9086 | Acc(train) 0.3170 | Acc(val) 0.4681 |*
Epoch 00028 | Loss(train) 2.8191 | Acc(train) 0.3548 | Acc(val) 0.4819 |*
Epoch 00029 | Loss(train) 2.8621 | Acc(train) 0.3460 | Acc(val) 0.4947 |*
Epoch 00030 | Loss(train) 2.8234 | Acc(train) 0.3540 | Acc(val) 0.5016 |*
Epoch 00031 | Loss(train) 2.8391 | Acc(train) 0.3370 | Acc(val) 0.5090 |*
Epoch 00032 | Loss(train) 2.7938 | Acc(train) 0.3590 | Acc(val) 0.5096 |*
Epoch 00033 | Loss(train) 2.7533 | Acc(train) 0.3689 | Acc(val) 0.5106 |*
Epoch 00034 | Loss(train) 2.7522 | Acc(train) 0.3668 | Acc(val) 0.5080 |
Epoch 00035 | Loss(train) 2.7564 | Acc(train) 0.3620 | Acc(val) 0.5074 |
Epoch 00036 | Loss(train) 2.7357 | Acc(train) 0.3662 | Acc(val) 0.4995 |
Epoch 00037 | Loss(train) 2.7086 | Acc(train) 0.3684 | Acc(val) 0.4995 |
Epoch 00038 | Loss(train) 2.7138 | Acc(train) 0.3662 | Acc(val) 0.4995 |
Epoch 00039 | Loss(train) 2.7141 | Acc(train) 0.3660 | Acc(val) 0.4989 |
Epoch 00040 | Loss(train) 2.7040 | Acc(train) 0.3691 | Acc(val) 0.5037 |
Epoch 00041 | Loss(train) 2.6951 | Acc(train) 0.3798 | Acc(val) 0.5064 |
Epoch 00042 | Loss(train) 2.6772 | Acc(train) 0.3809 | Acc(val) 0.5138 |*
Epoch 00043 | Loss(train) 2.6477 | Acc(train) 0.3830 | Acc(val) 0.5154 |*
Epoch 00044 | Loss(train) 2.6815 | Acc(train) 0.3763 | Acc(val) 0.5250 |*
Epoch 00045 | Loss(train) 2.6234 | Acc(train) 0.3886 | Acc(val) 0.5309 |*
Epoch 00046 | Loss(train) 2.6514 | Acc(train) 0.3891 | Acc(val) 0.5340 |*
Epoch 00047 | Loss(train) 2.6197 | Acc(train) 0.4064 | Acc(val) 0.5351 |*
Epoch 00048 | Loss(train) 2.6380 | Acc(train) 0.3851 | Acc(val) 0.5356 |*
Epoch 00049 | Loss(train) 2.6325 | Acc(train) 0.3904 | Acc(val) 0.5362 |*
Epoch 00050 | Loss(train) 2.6026 | Acc(train) 0.3944 | Acc(val) 0.5431 |*
Epoch 00051 | Loss(train) 2.5861 | Acc(train) 0.4019 | Acc(val) 0.5479 |*
Epoch 00052 | Loss(train) 2.6155 | Acc(train) 0.4093 | Acc(val) 0.5511 |*
Epoch 00053 | Loss(train) 2.5798 | Acc(train) 0.4074 | Acc(val) 0.5516 |*
Epoch 00054 | Loss(train) 2.6203 | Acc(train) 0.3981 | Acc(val) 0.5452 |
Epoch 00055 | Loss(train) 2.6001 | Acc(train) 0.4098 | Acc(val) 0.5431 |
Epoch 00056 | Loss(train) 2.5770 | Acc(train) 0.3987 | Acc(val) 0.5388 |
Epoch 00057 | Loss(train) 2.6026 | Acc(train) 0.3989 | Acc(val) 0.5362 |
Epoch 00058 | Loss(train) 2.5727 | Acc(train) 0.4085 | Acc(val) 0.5362 |
Epoch 00059 | Loss(train) 2.5617 | Acc(train) 0.4019 | Acc(val) 0.5340 |
Epoch 00060 | Loss(train) 2.5759 | Acc(train) 0.4061 | Acc(val) 0.5399 |
Epoch 00061 | Loss(train) 2.5573 | Acc(train) 0.4120 | Acc(val) 0.5452 |
Epoch 00062 | Loss(train) 2.5540 | Acc(train) 0.4114 | Acc(val) 0.5537 |*
Epoch 00063 | Loss(train) 2.5619 | Acc(train) 0.4146 | Acc(val) 0.5559 |*
Epoch 00064 | Loss(train) 2.5430 | Acc(train) 0.4101 | Acc(val) 0.5580 |*
Epoch 00065 | Loss(train) 2.5708 | Acc(train) 0.4056 | Acc(val) 0.5612 |*
Epoch 00066 | Loss(train) 2.5591 | Acc(train) 0.4013 | Acc(val) 0.5622 |*
Epoch 00067 | Loss(train) 2.5583 | Acc(train) 0.4029 | Acc(val) 0.5606 |
Epoch 00068 | Loss(train) 2.5409 | Acc(train) 0.4114 | Acc(val) 0.5590 |
Epoch 00069 | Loss(train) 2.5331 | Acc(train) 0.4085 | Acc(val) 0.5564 |
Epoch 00070 | Loss(train) 2.5228 | Acc(train) 0.4258 | Acc(val) 0.5559 |
Epoch 00071 | Loss(train) 2.5670 | Acc(train) 0.4048 | Acc(val) 0.5585 |
Epoch 00072 | Loss(train) 2.5359 | Acc(train) 0.4165 | Acc(val) 0.5548 |
Epoch 00073 | Loss(train) 2.5328 | Acc(train) 0.4088 | Acc(val) 0.5590 |
Epoch 00074 | Loss(train) 2.5468 | Acc(train) 0.4077 | Acc(val) 0.5606 |
Epoch 00075 | Loss(train) 2.5161 | Acc(train) 0.4311 | Acc(val) 0.5601 |
Epoch 00076 | Loss(train) 2.5485 | Acc(train) 0.4221 | Acc(val) 0.5628 |*
Epoch 00077 | Loss(train) 2.4832 | Acc(train) 0.4378 | Acc(val) 0.5670 |*
Epoch 00078 | Loss(train) 2.5778 | Acc(train) 0.4048 | Acc(val) 0.5654 |
Epoch 00079 | Loss(train) 2.5055 | Acc(train) 0.4168 | Acc(val) 0.5670 |
Epoch 00080 | Loss(train) 2.5148 | Acc(train) 0.4242 | Acc(val) 0.5638 |
Epoch 00081 | Loss(train) 2.5018 | Acc(train) 0.4277 | Acc(val) 0.5622 |
Epoch 00082 | Loss(train) 2.5211 | Acc(train) 0.4112 | Acc(val) 0.5596 |
Epoch 00083 | Loss(train) 2.5094 | Acc(train) 0.4117 | Acc(val) 0.5574 |
Epoch 00084 | Loss(train) 2.4896 | Acc(train) 0.4306 | Acc(val) 0.5569 |
Epoch 00085 | Loss(train) 2.4963 | Acc(train) 0.4234 | Acc(val) 0.5580 |
Epoch 00086 | Loss(train) 2.5695 | Acc(train) 0.4016 | Acc(val) 0.5596 |
Epoch 00087 | Loss(train) 2.4971 | Acc(train) 0.4234 | Acc(val) 0.5644 |
Epoch 00088 | Loss(train) 2.5280 | Acc(train) 0.4186 | Acc(val) 0.5691 |*
Epoch 00089 | Loss(train) 2.4927 | Acc(train) 0.4234 | Acc(val) 0.5702 |*
Epoch 00090 | Loss(train) 2.5168 | Acc(train) 0.4165 | Acc(val) 0.5697 |
Epoch 00091 | Loss(train) 2.5198 | Acc(train) 0.4189 | Acc(val) 0.5691 |
Epoch 00092 | Loss(train) 2.5140 | Acc(train) 0.4205 | Acc(val) 0.5676 |
Epoch 00093 | Loss(train) 2.5063 | Acc(train) 0.4215 | Acc(val) 0.5660 |
Epoch 00094 | Loss(train) 2.5064 | Acc(train) 0.4255 | Acc(val) 0.5676 |
Epoch 00095 | Loss(train) 2.5227 | Acc(train) 0.4245 | Acc(val) 0.5665 |
Epoch 00096 | Loss(train) 2.5323 | Acc(train) 0.4202 | Acc(val) 0.5644 |
Epoch 00097 | Loss(train) 2.5043 | Acc(train) 0.4261 | Acc(val) 0.5649 |
Epoch 00098 | Loss(train) 2.4869 | Acc(train) 0.4287 | Acc(val) 0.5644 |
Epoch 00099 | Loss(train) 2.5171 | Acc(train) 0.4197 | Acc(val) 0.5644 |
Epoch 00100 | Loss(train) 2.5574 | Acc(train) 0.4168 | Acc(val) 0.5638 |
Epoch 00101 | Loss(train) 2.5032 | Acc(train) 0.4229 | Acc(val) 0.5665 |
Epoch 00102 | Loss(train) 2.5095 | Acc(train) 0.4247 | Acc(val) 0.5633 |
Epoch 00103 | Loss(train) 2.5124 | Acc(train) 0.4226 | Acc(val) 0.5676 |
Epoch 00104 | Loss(train) 2.4805 | Acc(train) 0.4261 | Acc(val) 0.5676 |
Epoch 00105 | Loss(train) 2.5058 | Acc(train) 0.4221 | Acc(val) 0.5691 |
Epoch 00106 | Loss(train) 2.4862 | Acc(train) 0.4170 | Acc(val) 0.5718 |*
Epoch 00107 | Loss(train) 2.4867 | Acc(train) 0.4274 | Acc(val) 0.5761 |*
Epoch 00108 | Loss(train) 2.5214 | Acc(train) 0.4181 | Acc(val) 0.5755 |
Epoch 00109 | Loss(train) 2.5122 | Acc(train) 0.4205 | Acc(val) 0.5793 |*
Epoch 00110 | Loss(train) 2.5258 | Acc(train) 0.4277 | Acc(val) 0.5723 |
Epoch 00111 | Loss(train) 2.5000 | Acc(train) 0.4231 | Acc(val) 0.5665 |
Epoch 00112 | Loss(train) 2.5078 | Acc(train) 0.4277 | Acc(val) 0.5660 |
Epoch 00113 | Loss(train) 2.4912 | Acc(train) 0.4314 | Acc(val) 0.5670 |
Epoch 00114 | Loss(train) 2.5085 | Acc(train) 0.4213 | Acc(val) 0.5665 |
Epoch 00115 | Loss(train) 2.4919 | Acc(train) 0.4319 | Acc(val) 0.5654 |
Epoch 00116 | Loss(train) 2.5215 | Acc(train) 0.4152 | Acc(val) 0.5665 |
Epoch 00117 | Loss(train) 2.4769 | Acc(train) 0.4279 | Acc(val) 0.5681 |
Epoch 00118 | Loss(train) 2.5169 | Acc(train) 0.4205 | Acc(val) 0.5713 |
Epoch 00119 | Loss(train) 2.4846 | Acc(train) 0.4306 | Acc(val) 0.5729 |
Epoch 00120 | Loss(train) 2.5175 | Acc(train) 0.4223 | Acc(val) 0.5750 |
Epoch 00121 | Loss(train) 2.5200 | Acc(train) 0.4250 | Acc(val) 0.5755 |
Epoch 00122 | Loss(train) 2.4951 | Acc(train) 0.4226 | Acc(val) 0.5707 |
Epoch 00123 | Loss(train) 2.4869 | Acc(train) 0.4319 | Acc(val) 0.5676 |
Epoch 00124 | Loss(train) 2.5059 | Acc(train) 0.4191 | Acc(val) 0.5622 |
Epoch 00125 | Loss(train) 2.4891 | Acc(train) 0.4215 | Acc(val) 0.5601 |
Epoch 00126 | Loss(train) 2.4782 | Acc(train) 0.4271 | Acc(val) 0.5617 |
Epoch 00127 | Loss(train) 2.4923 | Acc(train) 0.4255 | Acc(val) 0.5660 |
Epoch 00128 | Loss(train) 2.5106 | Acc(train) 0.4162 | Acc(val) 0.5676 |
Epoch 00129 | Loss(train) 2.4898 | Acc(train) 0.4309 | Acc(val) 0.5649 |
Epoch 00130 | Loss(train) 2.5169 | Acc(train) 0.4303 | Acc(val) 0.5644 |
Epoch 00131 | Loss(train) 2.5155 | Acc(train) 0.4181 | Acc(val) 0.5644 |
Epoch 00132 | Loss(train) 2.5123 | Acc(train) 0.4186 | Acc(val) 0.5617 |
Epoch 00133 | Loss(train) 2.4661 | Acc(train) 0.4338 | Acc(val) 0.5622 |
Epoch 00134 | Loss(train) 2.5317 | Acc(train) 0.4077 | Acc(val) 0.5660 |
Epoch 00135 | Loss(train) 2.4846 | Acc(train) 0.4311 | Acc(val) 0.5691 |
Epoch 00136 | Loss(train) 2.5186 | Acc(train) 0.4322 | Acc(val) 0.5660 |
Epoch 00137 | Loss(train) 2.4930 | Acc(train) 0.4282 | Acc(val) 0.5665 |
Epoch 00138 | Loss(train) 2.5191 | Acc(train) 0.4293 | Acc(val) 0.5654 |
Epoch 00139 | Loss(train) 2.5023 | Acc(train) 0.4149 | Acc(val) 0.5654 |
Epoch 00140 | Loss(train) 2.5171 | Acc(train) 0.4250 | Acc(val) 0.5644 |
Epoch 00141 | Loss(train) 2.4636 | Acc(train) 0.4348 | Acc(val) 0.5633 |
Epoch 00142 | Loss(train) 2.4653 | Acc(train) 0.4383 | Acc(val) 0.5644 |
Epoch 00143 | Loss(train) 2.5133 | Acc(train) 0.4207 | Acc(val) 0.5622 |
Epoch 00144 | Loss(train) 2.4996 | Acc(train) 0.4205 | Acc(val) 0.5633 |
Epoch 00145 | Loss(train) 2.4628 | Acc(train) 0.4359 | Acc(val) 0.5622 |
Epoch 00146 | Loss(train) 2.5134 | Acc(train) 0.4184 | Acc(val) 0.5670 |
Epoch 00147 | Loss(train) 2.5005 | Acc(train) 0.4332 | Acc(val) 0.5707 |
Epoch 00148 | Loss(train) 2.5030 | Acc(train) 0.4199 | Acc(val) 0.5660 |
Epoch 00149 | Loss(train) 2.4581 | Acc(train) 0.4303 | Acc(val) 0.5649 |
Epoch 00150 | Loss(train) 2.4710 | Acc(train) 0.4324 | Acc(val) 0.5633 |
Epoch 00151 | Loss(train) 2.5055 | Acc(train) 0.4152 | Acc(val) 0.5633 |
Epoch 00152 | Loss(train) 2.4892 | Acc(train) 0.4271 | Acc(val) 0.5628 |
Epoch 00153 | Loss(train) 2.4830 | Acc(train) 0.4210 | Acc(val) 0.5633 |
Epoch 00154 | Loss(train) 2.4874 | Acc(train) 0.4237 | Acc(val) 0.5644 |
Epoch 00155 | Loss(train) 2.4621 | Acc(train) 0.4386 | Acc(val) 0.5654 |
Epoch 00156 | Loss(train) 2.4822 | Acc(train) 0.4245 | Acc(val) 0.5691 |
Epoch 00157 | Loss(train) 2.4767 | Acc(train) 0.4335 | Acc(val) 0.5713 |
Epoch 00158 | Loss(train) 2.4818 | Acc(train) 0.4364 | Acc(val) 0.5723 |
Early stopping at epoch 158
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 714.21 MB
GPU Memory Reserved: 2060.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2483 | Acc(train) 0.0120 | Acc(val) 0.0729 |*
Epoch 00002 | Loss(train) 4.2085 | Acc(train) 0.0939 | Acc(val) 0.0989 |*
Epoch 00003 | Loss(train) 4.1562 | Acc(train) 0.1199 | Acc(val) 0.1037 |*
Epoch 00004 | Loss(train) 4.0894 | Acc(train) 0.1173 | Acc(val) 0.1117 |*
Epoch 00005 | Loss(train) 4.0067 | Acc(train) 0.1258 | Acc(val) 0.1128 |*
Epoch 00006 | Loss(train) 3.9322 | Acc(train) 0.1186 | Acc(val) 0.1133 |*
Epoch 00007 | Loss(train) 3.8728 | Acc(train) 0.1146 | Acc(val) 0.1213 |*
Epoch 00008 | Loss(train) 3.8145 | Acc(train) 0.1234 | Acc(val) 0.1426 |*
Epoch 00009 | Loss(train) 3.7761 | Acc(train) 0.1367 | Acc(val) 0.1612 |*
Epoch 00010 | Loss(train) 3.7138 | Acc(train) 0.1561 | Acc(val) 0.1899 |*
Epoch 00011 | Loss(train) 3.6397 | Acc(train) 0.1816 | Acc(val) 0.2202 |*
Epoch 00012 | Loss(train) 3.5564 | Acc(train) 0.2133 | Acc(val) 0.2537 |*
Epoch 00013 | Loss(train) 3.5109 | Acc(train) 0.2335 | Acc(val) 0.2989 |*
Epoch 00014 | Loss(train) 3.4223 | Acc(train) 0.2689 | Acc(val) 0.3399 |*
Epoch 00015 | Loss(train) 3.3677 | Acc(train) 0.2811 | Acc(val) 0.3761 |*
Epoch 00016 | Loss(train) 3.3400 | Acc(train) 0.2899 | Acc(val) 0.3968 |*
Epoch 00017 | Loss(train) 3.2892 | Acc(train) 0.3016 | Acc(val) 0.4122 |*
Epoch 00018 | Loss(train) 3.2168 | Acc(train) 0.3106 | Acc(val) 0.4197 |*
Epoch 00019 | Loss(train) 3.1512 | Acc(train) 0.3170 | Acc(val) 0.4181 |
Epoch 00020 | Loss(train) 3.1136 | Acc(train) 0.3165 | Acc(val) 0.4191 |
Epoch 00021 | Loss(train) 3.1244 | Acc(train) 0.2973 | Acc(val) 0.4202 |*
Epoch 00022 | Loss(train) 3.0389 | Acc(train) 0.3207 | Acc(val) 0.4234 |*
Epoch 00023 | Loss(train) 3.0017 | Acc(train) 0.3218 | Acc(val) 0.4282 |*
Epoch 00024 | Loss(train) 2.9630 | Acc(train) 0.3255 | Acc(val) 0.4314 |*
Epoch 00025 | Loss(train) 2.9374 | Acc(train) 0.3362 | Acc(val) 0.4404 |*
Epoch 00026 | Loss(train) 2.9130 | Acc(train) 0.3255 | Acc(val) 0.4500 |*
Epoch 00027 | Loss(train) 2.8744 | Acc(train) 0.3495 | Acc(val) 0.4628 |*
Epoch 00028 | Loss(train) 2.8269 | Acc(train) 0.3548 | Acc(val) 0.4729 |*
Epoch 00029 | Loss(train) 2.8315 | Acc(train) 0.3407 | Acc(val) 0.4814 |*
Epoch 00030 | Loss(train) 2.8253 | Acc(train) 0.3500 | Acc(val) 0.4883 |*
Epoch 00031 | Loss(train) 2.8059 | Acc(train) 0.3463 | Acc(val) 0.4915 |*
Epoch 00032 | Loss(train) 2.7745 | Acc(train) 0.3644 | Acc(val) 0.4979 |*
Epoch 00033 | Loss(train) 2.7958 | Acc(train) 0.3497 | Acc(val) 0.5005 |*
Epoch 00034 | Loss(train) 2.7590 | Acc(train) 0.3577 | Acc(val) 0.5000 |
Epoch 00035 | Loss(train) 2.7199 | Acc(train) 0.3803 | Acc(val) 0.4963 |
Epoch 00036 | Loss(train) 2.6943 | Acc(train) 0.3723 | Acc(val) 0.4957 |
Epoch 00037 | Loss(train) 2.7132 | Acc(train) 0.3662 | Acc(val) 0.4979 |
Epoch 00038 | Loss(train) 2.6777 | Acc(train) 0.3867 | Acc(val) 0.5000 |
Epoch 00039 | Loss(train) 2.6857 | Acc(train) 0.3763 | Acc(val) 0.5011 |*
Epoch 00040 | Loss(train) 2.7017 | Acc(train) 0.3737 | Acc(val) 0.5117 |*
Epoch 00041 | Loss(train) 2.6676 | Acc(train) 0.3806 | Acc(val) 0.5191 |*
Epoch 00042 | Loss(train) 2.6818 | Acc(train) 0.3862 | Acc(val) 0.5223 |*
Epoch 00043 | Loss(train) 2.6486 | Acc(train) 0.3827 | Acc(val) 0.5282 |*
Epoch 00044 | Loss(train) 2.6570 | Acc(train) 0.3902 | Acc(val) 0.5309 |*
Epoch 00045 | Loss(train) 2.6209 | Acc(train) 0.3984 | Acc(val) 0.5303 |
Epoch 00046 | Loss(train) 2.6192 | Acc(train) 0.3939 | Acc(val) 0.5293 |
Epoch 00047 | Loss(train) 2.6411 | Acc(train) 0.3899 | Acc(val) 0.5287 |
Epoch 00048 | Loss(train) 2.6345 | Acc(train) 0.3944 | Acc(val) 0.5266 |
Epoch 00049 | Loss(train) 2.6298 | Acc(train) 0.3806 | Acc(val) 0.5282 |
Epoch 00050 | Loss(train) 2.6522 | Acc(train) 0.3846 | Acc(val) 0.5324 |*
Epoch 00051 | Loss(train) 2.5999 | Acc(train) 0.3928 | Acc(val) 0.5383 |*
Epoch 00052 | Loss(train) 2.6138 | Acc(train) 0.4003 | Acc(val) 0.5394 |*
Epoch 00053 | Loss(train) 2.5854 | Acc(train) 0.4096 | Acc(val) 0.5447 |*
Epoch 00054 | Loss(train) 2.5866 | Acc(train) 0.4013 | Acc(val) 0.5500 |*
Epoch 00055 | Loss(train) 2.5522 | Acc(train) 0.4069 | Acc(val) 0.5505 |*
Epoch 00056 | Loss(train) 2.5867 | Acc(train) 0.4000 | Acc(val) 0.5473 |
Epoch 00057 | Loss(train) 2.5881 | Acc(train) 0.3960 | Acc(val) 0.5479 |
Epoch 00058 | Loss(train) 2.5855 | Acc(train) 0.4027 | Acc(val) 0.5505 |
Epoch 00059 | Loss(train) 2.5909 | Acc(train) 0.4037 | Acc(val) 0.5521 |*
Epoch 00060 | Loss(train) 2.5976 | Acc(train) 0.3912 | Acc(val) 0.5574 |*
Epoch 00061 | Loss(train) 2.5628 | Acc(train) 0.4098 | Acc(val) 0.5590 |*
Epoch 00062 | Loss(train) 2.5812 | Acc(train) 0.4082 | Acc(val) 0.5574 |
Epoch 00063 | Loss(train) 2.5452 | Acc(train) 0.4197 | Acc(val) 0.5590 |
Epoch 00064 | Loss(train) 2.5619 | Acc(train) 0.4072 | Acc(val) 0.5580 |
Epoch 00065 | Loss(train) 2.5234 | Acc(train) 0.4210 | Acc(val) 0.5521 |
Epoch 00066 | Loss(train) 2.5343 | Acc(train) 0.4112 | Acc(val) 0.5500 |
Epoch 00067 | Loss(train) 2.5423 | Acc(train) 0.4066 | Acc(val) 0.5489 |
Epoch 00068 | Loss(train) 2.5477 | Acc(train) 0.4093 | Acc(val) 0.5495 |
Epoch 00069 | Loss(train) 2.5582 | Acc(train) 0.4053 | Acc(val) 0.5473 |
Epoch 00070 | Loss(train) 2.5275 | Acc(train) 0.4197 | Acc(val) 0.5479 |
Epoch 00071 | Loss(train) 2.5468 | Acc(train) 0.4154 | Acc(val) 0.5537 |
Epoch 00072 | Loss(train) 2.5847 | Acc(train) 0.3957 | Acc(val) 0.5511 |
Epoch 00073 | Loss(train) 2.5402 | Acc(train) 0.4109 | Acc(val) 0.5516 |
Epoch 00074 | Loss(train) 2.5483 | Acc(train) 0.4125 | Acc(val) 0.5527 |
Epoch 00075 | Loss(train) 2.5236 | Acc(train) 0.4149 | Acc(val) 0.5527 |
Epoch 00076 | Loss(train) 2.5096 | Acc(train) 0.4213 | Acc(val) 0.5457 |
Epoch 00077 | Loss(train) 2.5289 | Acc(train) 0.4130 | Acc(val) 0.5447 |
Epoch 00078 | Loss(train) 2.4938 | Acc(train) 0.4168 | Acc(val) 0.5484 |
Epoch 00079 | Loss(train) 2.5103 | Acc(train) 0.4146 | Acc(val) 0.5489 |
Epoch 00080 | Loss(train) 2.5378 | Acc(train) 0.4074 | Acc(val) 0.5457 |
Epoch 00081 | Loss(train) 2.5270 | Acc(train) 0.4247 | Acc(val) 0.5484 |
Epoch 00082 | Loss(train) 2.5320 | Acc(train) 0.4207 | Acc(val) 0.5495 |
Epoch 00083 | Loss(train) 2.5435 | Acc(train) 0.4101 | Acc(val) 0.5527 |
Epoch 00084 | Loss(train) 2.5208 | Acc(train) 0.4202 | Acc(val) 0.5543 |
Epoch 00085 | Loss(train) 2.5322 | Acc(train) 0.4173 | Acc(val) 0.5564 |
Epoch 00086 | Loss(train) 2.5149 | Acc(train) 0.4277 | Acc(val) 0.5521 |
Epoch 00087 | Loss(train) 2.5152 | Acc(train) 0.4149 | Acc(val) 0.5548 |
Epoch 00088 | Loss(train) 2.5340 | Acc(train) 0.4234 | Acc(val) 0.5559 |
Epoch 00089 | Loss(train) 2.5321 | Acc(train) 0.4178 | Acc(val) 0.5537 |
Epoch 00090 | Loss(train) 2.4908 | Acc(train) 0.4309 | Acc(val) 0.5585 |
Epoch 00091 | Loss(train) 2.5019 | Acc(train) 0.4274 | Acc(val) 0.5622 |*
Epoch 00092 | Loss(train) 2.5135 | Acc(train) 0.4239 | Acc(val) 0.5612 |
Epoch 00093 | Loss(train) 2.5010 | Acc(train) 0.4221 | Acc(val) 0.5617 |
Epoch 00094 | Loss(train) 2.5146 | Acc(train) 0.4144 | Acc(val) 0.5569 |
Epoch 00095 | Loss(train) 2.5076 | Acc(train) 0.4184 | Acc(val) 0.5553 |
Epoch 00096 | Loss(train) 2.5266 | Acc(train) 0.4184 | Acc(val) 0.5548 |
Epoch 00097 | Loss(train) 2.5221 | Acc(train) 0.4181 | Acc(val) 0.5590 |
Epoch 00098 | Loss(train) 2.5136 | Acc(train) 0.4154 | Acc(val) 0.5660 |*
Epoch 00099 | Loss(train) 2.4814 | Acc(train) 0.4335 | Acc(val) 0.5681 |*
Epoch 00100 | Loss(train) 2.4831 | Acc(train) 0.4245 | Acc(val) 0.5713 |*
Epoch 00101 | Loss(train) 2.5213 | Acc(train) 0.4237 | Acc(val) 0.5739 |*
Epoch 00102 | Loss(train) 2.4857 | Acc(train) 0.4261 | Acc(val) 0.5739 |
Epoch 00103 | Loss(train) 2.5332 | Acc(train) 0.4247 | Acc(val) 0.5697 |
Epoch 00104 | Loss(train) 2.5114 | Acc(train) 0.4298 | Acc(val) 0.5676 |
Epoch 00105 | Loss(train) 2.5362 | Acc(train) 0.4199 | Acc(val) 0.5665 |
Epoch 00106 | Loss(train) 2.4782 | Acc(train) 0.4460 | Acc(val) 0.5622 |
Epoch 00107 | Loss(train) 2.5047 | Acc(train) 0.4242 | Acc(val) 0.5617 |
Epoch 00108 | Loss(train) 2.4862 | Acc(train) 0.4221 | Acc(val) 0.5596 |
Epoch 00109 | Loss(train) 2.5142 | Acc(train) 0.4144 | Acc(val) 0.5569 |
Epoch 00110 | Loss(train) 2.4782 | Acc(train) 0.4263 | Acc(val) 0.5596 |
Epoch 00111 | Loss(train) 2.5005 | Acc(train) 0.4303 | Acc(val) 0.5644 |
Epoch 00112 | Loss(train) 2.5181 | Acc(train) 0.4261 | Acc(val) 0.5718 |
Epoch 00113 | Loss(train) 2.4680 | Acc(train) 0.4229 | Acc(val) 0.5729 |
Epoch 00114 | Loss(train) 2.5291 | Acc(train) 0.4258 | Acc(val) 0.5702 |
Epoch 00115 | Loss(train) 2.5086 | Acc(train) 0.4295 | Acc(val) 0.5702 |
Epoch 00116 | Loss(train) 2.5110 | Acc(train) 0.4338 | Acc(val) 0.5649 |
Epoch 00117 | Loss(train) 2.4852 | Acc(train) 0.4324 | Acc(val) 0.5612 |
Epoch 00118 | Loss(train) 2.4835 | Acc(train) 0.4245 | Acc(val) 0.5580 |
Epoch 00119 | Loss(train) 2.5002 | Acc(train) 0.4152 | Acc(val) 0.5585 |
Epoch 00120 | Loss(train) 2.5162 | Acc(train) 0.4223 | Acc(val) 0.5628 |
Epoch 00121 | Loss(train) 2.5079 | Acc(train) 0.4184 | Acc(val) 0.5691 |
Epoch 00122 | Loss(train) 2.4994 | Acc(train) 0.4239 | Acc(val) 0.5739 |
Epoch 00123 | Loss(train) 2.4948 | Acc(train) 0.4215 | Acc(val) 0.5750 |*
Epoch 00124 | Loss(train) 2.4652 | Acc(train) 0.4309 | Acc(val) 0.5697 |
Epoch 00125 | Loss(train) 2.5308 | Acc(train) 0.4176 | Acc(val) 0.5691 |
Epoch 00126 | Loss(train) 2.5045 | Acc(train) 0.4178 | Acc(val) 0.5676 |
Epoch 00127 | Loss(train) 2.5116 | Acc(train) 0.4263 | Acc(val) 0.5638 |
Epoch 00128 | Loss(train) 2.5151 | Acc(train) 0.4218 | Acc(val) 0.5628 |
Epoch 00129 | Loss(train) 2.4933 | Acc(train) 0.4221 | Acc(val) 0.5622 |
Epoch 00130 | Loss(train) 2.5005 | Acc(train) 0.4293 | Acc(val) 0.5617 |
Epoch 00131 | Loss(train) 2.4853 | Acc(train) 0.4298 | Acc(val) 0.5654 |
Epoch 00132 | Loss(train) 2.5004 | Acc(train) 0.4210 | Acc(val) 0.5676 |
Epoch 00133 | Loss(train) 2.5083 | Acc(train) 0.4250 | Acc(val) 0.5702 |
Epoch 00134 | Loss(train) 2.5004 | Acc(train) 0.4199 | Acc(val) 0.5729 |
Epoch 00135 | Loss(train) 2.4893 | Acc(train) 0.4364 | Acc(val) 0.5713 |
Epoch 00136 | Loss(train) 2.4928 | Acc(train) 0.4298 | Acc(val) 0.5713 |
Epoch 00137 | Loss(train) 2.5314 | Acc(train) 0.4223 | Acc(val) 0.5702 |
Epoch 00138 | Loss(train) 2.4928 | Acc(train) 0.4271 | Acc(val) 0.5729 |
Epoch 00139 | Loss(train) 2.5184 | Acc(train) 0.4207 | Acc(val) 0.5681 |
Epoch 00140 | Loss(train) 2.4965 | Acc(train) 0.4186 | Acc(val) 0.5617 |
Epoch 00141 | Loss(train) 2.4886 | Acc(train) 0.4173 | Acc(val) 0.5649 |
Epoch 00142 | Loss(train) 2.4977 | Acc(train) 0.4234 | Acc(val) 0.5654 |
Epoch 00143 | Loss(train) 2.4980 | Acc(train) 0.4215 | Acc(val) 0.5686 |
Epoch 00144 | Loss(train) 2.4776 | Acc(train) 0.4218 | Acc(val) 0.5707 |
Epoch 00145 | Loss(train) 2.5299 | Acc(train) 0.4191 | Acc(val) 0.5782 |*
Epoch 00146 | Loss(train) 2.4806 | Acc(train) 0.4346 | Acc(val) 0.5750 |
Epoch 00147 | Loss(train) 2.4991 | Acc(train) 0.4189 | Acc(val) 0.5729 |
Epoch 00148 | Loss(train) 2.4982 | Acc(train) 0.4263 | Acc(val) 0.5713 |
Epoch 00149 | Loss(train) 2.5125 | Acc(train) 0.4298 | Acc(val) 0.5649 |
Epoch 00150 | Loss(train) 2.4836 | Acc(train) 0.4311 | Acc(val) 0.5660 |
Epoch 00151 | Loss(train) 2.5055 | Acc(train) 0.4152 | Acc(val) 0.5644 |
Epoch 00152 | Loss(train) 2.5167 | Acc(train) 0.4082 | Acc(val) 0.5654 |
Epoch 00153 | Loss(train) 2.5043 | Acc(train) 0.4215 | Acc(val) 0.5622 |
Epoch 00154 | Loss(train) 2.4972 | Acc(train) 0.4207 | Acc(val) 0.5665 |
Epoch 00155 | Loss(train) 2.4875 | Acc(train) 0.4301 | Acc(val) 0.5670 |
Epoch 00156 | Loss(train) 2.4978 | Acc(train) 0.4186 | Acc(val) 0.5761 |
Epoch 00157 | Loss(train) 2.5259 | Acc(train) 0.4168 | Acc(val) 0.5766 |
Epoch 00158 | Loss(train) 2.4940 | Acc(train) 0.4184 | Acc(val) 0.5739 |
Epoch 00159 | Loss(train) 2.4854 | Acc(train) 0.4335 | Acc(val) 0.5686 |
Epoch 00160 | Loss(train) 2.4670 | Acc(train) 0.4404 | Acc(val) 0.5622 |
Epoch 00161 | Loss(train) 2.4684 | Acc(train) 0.4399 | Acc(val) 0.5660 |
Epoch 00162 | Loss(train) 2.4886 | Acc(train) 0.4298 | Acc(val) 0.5628 |
Epoch 00163 | Loss(train) 2.5265 | Acc(train) 0.4080 | Acc(val) 0.5601 |
Epoch 00164 | Loss(train) 2.4994 | Acc(train) 0.4245 | Acc(val) 0.5617 |
Epoch 00165 | Loss(train) 2.4713 | Acc(train) 0.4322 | Acc(val) 0.5676 |
Epoch 00166 | Loss(train) 2.5037 | Acc(train) 0.4261 | Acc(val) 0.5670 |
Epoch 00167 | Loss(train) 2.5441 | Acc(train) 0.4165 | Acc(val) 0.5676 |
Epoch 00168 | Loss(train) 2.4951 | Acc(train) 0.4378 | Acc(val) 0.5665 |
Epoch 00169 | Loss(train) 2.4891 | Acc(train) 0.4258 | Acc(val) 0.5697 |
Epoch 00170 | Loss(train) 2.4707 | Acc(train) 0.4343 | Acc(val) 0.5713 |
Epoch 00171 | Loss(train) 2.4683 | Acc(train) 0.4258 | Acc(val) 0.5697 |
Epoch 00172 | Loss(train) 2.4795 | Acc(train) 0.4202 | Acc(val) 0.5660 |
Epoch 00173 | Loss(train) 2.5085 | Acc(train) 0.4176 | Acc(val) 0.5638 |
Epoch 00174 | Loss(train) 2.4850 | Acc(train) 0.4285 | Acc(val) 0.5670 |
Epoch 00175 | Loss(train) 2.4386 | Acc(train) 0.4410 | Acc(val) 0.5691 |
Epoch 00176 | Loss(train) 2.4924 | Acc(train) 0.4255 | Acc(val) 0.5702 |
Epoch 00177 | Loss(train) 2.4846 | Acc(train) 0.4154 | Acc(val) 0.5697 |
Epoch 00178 | Loss(train) 2.4848 | Acc(train) 0.4346 | Acc(val) 0.5691 |
Epoch 00179 | Loss(train) 2.4981 | Acc(train) 0.4261 | Acc(val) 0.5734 |
Epoch 00180 | Loss(train) 2.4559 | Acc(train) 0.4370 | Acc(val) 0.5755 |
Epoch 00181 | Loss(train) 2.4605 | Acc(train) 0.4319 | Acc(val) 0.5755 |
Epoch 00182 | Loss(train) 2.4627 | Acc(train) 0.4295 | Acc(val) 0.5787 |*
Epoch 00183 | Loss(train) 2.4828 | Acc(train) 0.4380 | Acc(val) 0.5745 |
Epoch 00184 | Loss(train) 2.4741 | Acc(train) 0.4340 | Acc(val) 0.5723 |
Epoch 00185 | Loss(train) 2.4859 | Acc(train) 0.4274 | Acc(val) 0.5718 |
Epoch 00186 | Loss(train) 2.5118 | Acc(train) 0.4332 | Acc(val) 0.5686 |
Epoch 00187 | Loss(train) 2.4986 | Acc(train) 0.4157 | Acc(val) 0.5702 |
Epoch 00188 | Loss(train) 2.4916 | Acc(train) 0.4218 | Acc(val) 0.5686 |
Epoch 00189 | Loss(train) 2.5132 | Acc(train) 0.4133 | Acc(val) 0.5761 |
Epoch 00190 | Loss(train) 2.4477 | Acc(train) 0.4441 | Acc(val) 0.5761 |
Epoch 00191 | Loss(train) 2.4892 | Acc(train) 0.4396 | Acc(val) 0.5766 |
Epoch 00192 | Loss(train) 2.5096 | Acc(train) 0.4210 | Acc(val) 0.5771 |
Epoch 00193 | Loss(train) 2.5001 | Acc(train) 0.4324 | Acc(val) 0.5750 |
Epoch 00194 | Loss(train) 2.5038 | Acc(train) 0.4277 | Acc(val) 0.5761 |
Epoch 00195 | Loss(train) 2.4649 | Acc(train) 0.4460 | Acc(val) 0.5739 |
Epoch 00196 | Loss(train) 2.5102 | Acc(train) 0.4191 | Acc(val) 0.5697 |
Epoch 00197 | Loss(train) 2.5015 | Acc(train) 0.4215 | Acc(val) 0.5718 |
Epoch 00198 | Loss(train) 2.4947 | Acc(train) 0.4293 | Acc(val) 0.5745 |
Epoch 00199 | Loss(train) 2.5209 | Acc(train) 0.4285 | Acc(val) 0.5771 |
Epoch 00200 | Loss(train) 2.4657 | Acc(train) 0.4327 | Acc(val) 0.5793 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 713.53 MB
GPU Memory Reserved: 2060.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2535 | Acc(train) 0.0106 | Acc(val) 0.0761 |*
Epoch 00002 | Loss(train) 4.2106 | Acc(train) 0.0758 | Acc(val) 0.1660 |*
Epoch 00003 | Loss(train) 4.1558 | Acc(train) 0.1551 | Acc(val) 0.2160 |*
Epoch 00004 | Loss(train) 4.0860 | Acc(train) 0.1809 | Acc(val) 0.2266 |*
Epoch 00005 | Loss(train) 3.9997 | Acc(train) 0.1835 | Acc(val) 0.2191 |
Epoch 00006 | Loss(train) 3.9213 | Acc(train) 0.1723 | Acc(val) 0.2048 |
Epoch 00007 | Loss(train) 3.8620 | Acc(train) 0.1652 | Acc(val) 0.1926 |
Epoch 00008 | Loss(train) 3.8009 | Acc(train) 0.1617 | Acc(val) 0.1809 |
Epoch 00009 | Loss(train) 3.7548 | Acc(train) 0.1545 | Acc(val) 0.1777 |
Epoch 00010 | Loss(train) 3.6834 | Acc(train) 0.1636 | Acc(val) 0.1920 |
Epoch 00011 | Loss(train) 3.6214 | Acc(train) 0.1755 | Acc(val) 0.2186 |
Epoch 00012 | Loss(train) 3.5463 | Acc(train) 0.2082 | Acc(val) 0.2665 |*
Epoch 00013 | Loss(train) 3.4882 | Acc(train) 0.2351 | Acc(val) 0.3144 |*
Epoch 00014 | Loss(train) 3.4185 | Acc(train) 0.2707 | Acc(val) 0.3654 |*
Epoch 00015 | Loss(train) 3.3627 | Acc(train) 0.2870 | Acc(val) 0.3936 |*
Epoch 00016 | Loss(train) 3.3123 | Acc(train) 0.3048 | Acc(val) 0.4245 |*
Epoch 00017 | Loss(train) 3.2384 | Acc(train) 0.3128 | Acc(val) 0.4330 |*
Epoch 00018 | Loss(train) 3.2190 | Acc(train) 0.3082 | Acc(val) 0.4319 |
Epoch 00019 | Loss(train) 3.1381 | Acc(train) 0.3189 | Acc(val) 0.4250 |
Epoch 00020 | Loss(train) 3.0806 | Acc(train) 0.3231 | Acc(val) 0.4186 |
Epoch 00021 | Loss(train) 3.0690 | Acc(train) 0.3128 | Acc(val) 0.4149 |
Epoch 00022 | Loss(train) 3.0301 | Acc(train) 0.3066 | Acc(val) 0.4144 |
Epoch 00023 | Loss(train) 2.9952 | Acc(train) 0.3231 | Acc(val) 0.4149 |
Epoch 00024 | Loss(train) 2.9514 | Acc(train) 0.3157 | Acc(val) 0.4218 |
Epoch 00025 | Loss(train) 2.9244 | Acc(train) 0.3197 | Acc(val) 0.4293 |
Epoch 00026 | Loss(train) 2.9186 | Acc(train) 0.3191 | Acc(val) 0.4383 |*
Epoch 00027 | Loss(train) 2.8946 | Acc(train) 0.3324 | Acc(val) 0.4548 |*
Epoch 00028 | Loss(train) 2.8560 | Acc(train) 0.3370 | Acc(val) 0.4665 |*
Epoch 00029 | Loss(train) 2.8947 | Acc(train) 0.3354 | Acc(val) 0.4803 |*
Epoch 00030 | Loss(train) 2.8251 | Acc(train) 0.3574 | Acc(val) 0.4979 |*
Epoch 00031 | Loss(train) 2.8092 | Acc(train) 0.3654 | Acc(val) 0.5048 |*
Epoch 00032 | Loss(train) 2.7890 | Acc(train) 0.3622 | Acc(val) 0.5085 |*
Epoch 00033 | Loss(train) 2.7788 | Acc(train) 0.3628 | Acc(val) 0.5106 |*
Epoch 00034 | Loss(train) 2.7385 | Acc(train) 0.3710 | Acc(val) 0.5053 |
Epoch 00035 | Loss(train) 2.7208 | Acc(train) 0.3723 | Acc(val) 0.5011 |
Epoch 00036 | Loss(train) 2.7416 | Acc(train) 0.3649 | Acc(val) 0.5016 |
Epoch 00037 | Loss(train) 2.7100 | Acc(train) 0.3646 | Acc(val) 0.5027 |
Epoch 00038 | Loss(train) 2.7225 | Acc(train) 0.3676 | Acc(val) 0.5032 |
Epoch 00039 | Loss(train) 2.6779 | Acc(train) 0.3806 | Acc(val) 0.5064 |
Epoch 00040 | Loss(train) 2.6789 | Acc(train) 0.3750 | Acc(val) 0.5080 |
Epoch 00041 | Loss(train) 2.6919 | Acc(train) 0.3707 | Acc(val) 0.5138 |*
Epoch 00042 | Loss(train) 2.6828 | Acc(train) 0.3848 | Acc(val) 0.5202 |*
Epoch 00043 | Loss(train) 2.6446 | Acc(train) 0.3907 | Acc(val) 0.5271 |*
Epoch 00044 | Loss(train) 2.6692 | Acc(train) 0.3883 | Acc(val) 0.5298 |*
Epoch 00045 | Loss(train) 2.6289 | Acc(train) 0.4101 | Acc(val) 0.5298 |
Epoch 00046 | Loss(train) 2.6216 | Acc(train) 0.3923 | Acc(val) 0.5346 |*
Epoch 00047 | Loss(train) 2.6455 | Acc(train) 0.3918 | Acc(val) 0.5340 |
Epoch 00048 | Loss(train) 2.6365 | Acc(train) 0.3928 | Acc(val) 0.5367 |*
Epoch 00049 | Loss(train) 2.6417 | Acc(train) 0.3915 | Acc(val) 0.5388 |*
Epoch 00050 | Loss(train) 2.6396 | Acc(train) 0.3920 | Acc(val) 0.5388 |
Epoch 00051 | Loss(train) 2.5882 | Acc(train) 0.4045 | Acc(val) 0.5436 |*
Epoch 00052 | Loss(train) 2.5360 | Acc(train) 0.4101 | Acc(val) 0.5441 |*
Epoch 00053 | Loss(train) 2.6412 | Acc(train) 0.4048 | Acc(val) 0.5452 |*
Epoch 00054 | Loss(train) 2.5413 | Acc(train) 0.4162 | Acc(val) 0.5473 |*
Epoch 00055 | Loss(train) 2.5799 | Acc(train) 0.4120 | Acc(val) 0.5484 |*
Epoch 00056 | Loss(train) 2.5854 | Acc(train) 0.4194 | Acc(val) 0.5489 |*
Epoch 00057 | Loss(train) 2.5715 | Acc(train) 0.4024 | Acc(val) 0.5484 |
Epoch 00058 | Loss(train) 2.5789 | Acc(train) 0.4098 | Acc(val) 0.5495 |*
Epoch 00059 | Loss(train) 2.6001 | Acc(train) 0.3957 | Acc(val) 0.5484 |
Epoch 00060 | Loss(train) 2.5382 | Acc(train) 0.4117 | Acc(val) 0.5426 |
Epoch 00061 | Loss(train) 2.5162 | Acc(train) 0.4194 | Acc(val) 0.5441 |
Epoch 00062 | Loss(train) 2.5430 | Acc(train) 0.4093 | Acc(val) 0.5452 |
Epoch 00063 | Loss(train) 2.5471 | Acc(train) 0.4032 | Acc(val) 0.5495 |
Epoch 00064 | Loss(train) 2.5241 | Acc(train) 0.4191 | Acc(val) 0.5548 |*
Epoch 00065 | Loss(train) 2.5638 | Acc(train) 0.4112 | Acc(val) 0.5543 |
Epoch 00066 | Loss(train) 2.5728 | Acc(train) 0.4072 | Acc(val) 0.5564 |*
Epoch 00067 | Loss(train) 2.5303 | Acc(train) 0.4149 | Acc(val) 0.5585 |*
Epoch 00068 | Loss(train) 2.5452 | Acc(train) 0.4213 | Acc(val) 0.5553 |
Epoch 00069 | Loss(train) 2.5407 | Acc(train) 0.4130 | Acc(val) 0.5516 |
Epoch 00070 | Loss(train) 2.5715 | Acc(train) 0.4082 | Acc(val) 0.5452 |
Epoch 00071 | Loss(train) 2.5462 | Acc(train) 0.4035 | Acc(val) 0.5452 |
Epoch 00072 | Loss(train) 2.5289 | Acc(train) 0.4173 | Acc(val) 0.5463 |
Epoch 00073 | Loss(train) 2.5600 | Acc(train) 0.3939 | Acc(val) 0.5511 |
Epoch 00074 | Loss(train) 2.5293 | Acc(train) 0.4231 | Acc(val) 0.5580 |
Epoch 00075 | Loss(train) 2.5392 | Acc(train) 0.4173 | Acc(val) 0.5596 |*
Epoch 00076 | Loss(train) 2.5336 | Acc(train) 0.4016 | Acc(val) 0.5590 |
Epoch 00077 | Loss(train) 2.5138 | Acc(train) 0.4301 | Acc(val) 0.5590 |
Epoch 00078 | Loss(train) 2.5054 | Acc(train) 0.4162 | Acc(val) 0.5574 |
Epoch 00079 | Loss(train) 2.5200 | Acc(train) 0.4162 | Acc(val) 0.5521 |
Epoch 00080 | Loss(train) 2.5014 | Acc(train) 0.4173 | Acc(val) 0.5527 |
Epoch 00081 | Loss(train) 2.5118 | Acc(train) 0.4184 | Acc(val) 0.5521 |
Epoch 00082 | Loss(train) 2.5017 | Acc(train) 0.4322 | Acc(val) 0.5521 |
Epoch 00083 | Loss(train) 2.5192 | Acc(train) 0.4109 | Acc(val) 0.5516 |
Epoch 00084 | Loss(train) 2.5257 | Acc(train) 0.4181 | Acc(val) 0.5527 |
Epoch 00085 | Loss(train) 2.5004 | Acc(train) 0.4194 | Acc(val) 0.5511 |
Epoch 00086 | Loss(train) 2.5200 | Acc(train) 0.4160 | Acc(val) 0.5574 |
Epoch 00087 | Loss(train) 2.5351 | Acc(train) 0.4154 | Acc(val) 0.5596 |
Epoch 00088 | Loss(train) 2.5409 | Acc(train) 0.4178 | Acc(val) 0.5649 |*
Epoch 00089 | Loss(train) 2.5040 | Acc(train) 0.4298 | Acc(val) 0.5665 |*
Epoch 00090 | Loss(train) 2.5142 | Acc(train) 0.4221 | Acc(val) 0.5702 |*
Epoch 00091 | Loss(train) 2.5396 | Acc(train) 0.4189 | Acc(val) 0.5723 |*
Epoch 00092 | Loss(train) 2.5125 | Acc(train) 0.4316 | Acc(val) 0.5723 |
Epoch 00093 | Loss(train) 2.5191 | Acc(train) 0.4184 | Acc(val) 0.5691 |
Epoch 00094 | Loss(train) 2.5415 | Acc(train) 0.4146 | Acc(val) 0.5654 |
Epoch 00095 | Loss(train) 2.5062 | Acc(train) 0.4191 | Acc(val) 0.5638 |
Epoch 00096 | Loss(train) 2.5395 | Acc(train) 0.4287 | Acc(val) 0.5622 |
Epoch 00097 | Loss(train) 2.5338 | Acc(train) 0.4128 | Acc(val) 0.5654 |
Epoch 00098 | Loss(train) 2.5150 | Acc(train) 0.4181 | Acc(val) 0.5665 |
Epoch 00099 | Loss(train) 2.5298 | Acc(train) 0.4157 | Acc(val) 0.5691 |
Epoch 00100 | Loss(train) 2.5137 | Acc(train) 0.4234 | Acc(val) 0.5697 |
Epoch 00101 | Loss(train) 2.4959 | Acc(train) 0.4282 | Acc(val) 0.5676 |
Epoch 00102 | Loss(train) 2.5085 | Acc(train) 0.4130 | Acc(val) 0.5622 |
Epoch 00103 | Loss(train) 2.5040 | Acc(train) 0.4191 | Acc(val) 0.5601 |
Epoch 00104 | Loss(train) 2.5042 | Acc(train) 0.4301 | Acc(val) 0.5638 |
Epoch 00105 | Loss(train) 2.5500 | Acc(train) 0.4130 | Acc(val) 0.5654 |
Epoch 00106 | Loss(train) 2.5222 | Acc(train) 0.4242 | Acc(val) 0.5628 |
Epoch 00107 | Loss(train) 2.5094 | Acc(train) 0.4197 | Acc(val) 0.5633 |
Epoch 00108 | Loss(train) 2.5192 | Acc(train) 0.4178 | Acc(val) 0.5622 |
Epoch 00109 | Loss(train) 2.5235 | Acc(train) 0.4162 | Acc(val) 0.5612 |
Epoch 00110 | Loss(train) 2.5281 | Acc(train) 0.4237 | Acc(val) 0.5606 |
Epoch 00111 | Loss(train) 2.4999 | Acc(train) 0.4194 | Acc(val) 0.5527 |
Epoch 00112 | Loss(train) 2.5168 | Acc(train) 0.4184 | Acc(val) 0.5532 |
Epoch 00113 | Loss(train) 2.5435 | Acc(train) 0.4088 | Acc(val) 0.5553 |
Epoch 00114 | Loss(train) 2.5193 | Acc(train) 0.4074 | Acc(val) 0.5574 |
Epoch 00115 | Loss(train) 2.5340 | Acc(train) 0.4202 | Acc(val) 0.5681 |
Epoch 00116 | Loss(train) 2.5332 | Acc(train) 0.4184 | Acc(val) 0.5729 |*
Epoch 00117 | Loss(train) 2.5080 | Acc(train) 0.4231 | Acc(val) 0.5702 |
Epoch 00118 | Loss(train) 2.5036 | Acc(train) 0.4287 | Acc(val) 0.5686 |
Epoch 00119 | Loss(train) 2.4789 | Acc(train) 0.4293 | Acc(val) 0.5670 |
Epoch 00120 | Loss(train) 2.4996 | Acc(train) 0.4261 | Acc(val) 0.5660 |
Epoch 00121 | Loss(train) 2.5207 | Acc(train) 0.4245 | Acc(val) 0.5601 |
Epoch 00122 | Loss(train) 2.4552 | Acc(train) 0.4386 | Acc(val) 0.5532 |
Epoch 00123 | Loss(train) 2.4858 | Acc(train) 0.4287 | Acc(val) 0.5580 |
Epoch 00124 | Loss(train) 2.4962 | Acc(train) 0.4138 | Acc(val) 0.5622 |
Epoch 00125 | Loss(train) 2.4729 | Acc(train) 0.4295 | Acc(val) 0.5734 |*
Epoch 00126 | Loss(train) 2.5069 | Acc(train) 0.4261 | Acc(val) 0.5819 |*
Epoch 00127 | Loss(train) 2.5421 | Acc(train) 0.4128 | Acc(val) 0.5862 |*
Epoch 00128 | Loss(train) 2.4811 | Acc(train) 0.4412 | Acc(val) 0.5824 |
Epoch 00129 | Loss(train) 2.4891 | Acc(train) 0.4277 | Acc(val) 0.5793 |
Epoch 00130 | Loss(train) 2.5032 | Acc(train) 0.4207 | Acc(val) 0.5723 |
Epoch 00131 | Loss(train) 2.5123 | Acc(train) 0.4316 | Acc(val) 0.5644 |
Epoch 00132 | Loss(train) 2.5265 | Acc(train) 0.4205 | Acc(val) 0.5548 |
Epoch 00133 | Loss(train) 2.5000 | Acc(train) 0.4226 | Acc(val) 0.5527 |
Epoch 00134 | Loss(train) 2.5113 | Acc(train) 0.4245 | Acc(val) 0.5638 |
Epoch 00135 | Loss(train) 2.5209 | Acc(train) 0.4210 | Acc(val) 0.5691 |
Epoch 00136 | Loss(train) 2.4963 | Acc(train) 0.4258 | Acc(val) 0.5750 |
Epoch 00137 | Loss(train) 2.5093 | Acc(train) 0.4170 | Acc(val) 0.5793 |
Epoch 00138 | Loss(train) 2.5049 | Acc(train) 0.4255 | Acc(val) 0.5777 |
Epoch 00139 | Loss(train) 2.4708 | Acc(train) 0.4399 | Acc(val) 0.5723 |
Epoch 00140 | Loss(train) 2.4792 | Acc(train) 0.4356 | Acc(val) 0.5702 |
Epoch 00141 | Loss(train) 2.4837 | Acc(train) 0.4309 | Acc(val) 0.5676 |
Epoch 00142 | Loss(train) 2.5388 | Acc(train) 0.4154 | Acc(val) 0.5665 |
Epoch 00143 | Loss(train) 2.5387 | Acc(train) 0.4186 | Acc(val) 0.5697 |
Epoch 00144 | Loss(train) 2.4971 | Acc(train) 0.4282 | Acc(val) 0.5707 |
Epoch 00145 | Loss(train) 2.5338 | Acc(train) 0.4128 | Acc(val) 0.5713 |
Epoch 00146 | Loss(train) 2.5203 | Acc(train) 0.4168 | Acc(val) 0.5713 |
Epoch 00147 | Loss(train) 2.4943 | Acc(train) 0.4269 | Acc(val) 0.5707 |
Epoch 00148 | Loss(train) 2.5136 | Acc(train) 0.4098 | Acc(val) 0.5713 |
Epoch 00149 | Loss(train) 2.4948 | Acc(train) 0.4348 | Acc(val) 0.5686 |
Epoch 00150 | Loss(train) 2.5084 | Acc(train) 0.4263 | Acc(val) 0.5670 |
Epoch 00151 | Loss(train) 2.5163 | Acc(train) 0.4237 | Acc(val) 0.5654 |
Epoch 00152 | Loss(train) 2.4956 | Acc(train) 0.4316 | Acc(val) 0.5590 |
Epoch 00153 | Loss(train) 2.4821 | Acc(train) 0.4332 | Acc(val) 0.5585 |
Epoch 00154 | Loss(train) 2.4765 | Acc(train) 0.4343 | Acc(val) 0.5606 |
Epoch 00155 | Loss(train) 2.4680 | Acc(train) 0.4306 | Acc(val) 0.5585 |
Epoch 00156 | Loss(train) 2.4524 | Acc(train) 0.4338 | Acc(val) 0.5644 |
Epoch 00157 | Loss(train) 2.4862 | Acc(train) 0.4239 | Acc(val) 0.5676 |
Epoch 00158 | Loss(train) 2.5083 | Acc(train) 0.4149 | Acc(val) 0.5729 |
Epoch 00159 | Loss(train) 2.5104 | Acc(train) 0.4295 | Acc(val) 0.5755 |
Epoch 00160 | Loss(train) 2.4812 | Acc(train) 0.4367 | Acc(val) 0.5766 |
Epoch 00161 | Loss(train) 2.4998 | Acc(train) 0.4372 | Acc(val) 0.5750 |
Epoch 00162 | Loss(train) 2.4841 | Acc(train) 0.4332 | Acc(val) 0.5745 |
Epoch 00163 | Loss(train) 2.5398 | Acc(train) 0.4104 | Acc(val) 0.5718 |
Epoch 00164 | Loss(train) 2.5018 | Acc(train) 0.4319 | Acc(val) 0.5718 |
Epoch 00165 | Loss(train) 2.4943 | Acc(train) 0.4239 | Acc(val) 0.5729 |
Epoch 00166 | Loss(train) 2.5007 | Acc(train) 0.4282 | Acc(val) 0.5686 |
Epoch 00167 | Loss(train) 2.4662 | Acc(train) 0.4271 | Acc(val) 0.5644 |
Epoch 00168 | Loss(train) 2.4905 | Acc(train) 0.4343 | Acc(val) 0.5590 |
Epoch 00169 | Loss(train) 2.4965 | Acc(train) 0.4245 | Acc(val) 0.5612 |
Epoch 00170 | Loss(train) 2.5060 | Acc(train) 0.4303 | Acc(val) 0.5633 |
Epoch 00171 | Loss(train) 2.4630 | Acc(train) 0.4327 | Acc(val) 0.5601 |
Epoch 00172 | Loss(train) 2.4614 | Acc(train) 0.4287 | Acc(val) 0.5622 |
Epoch 00173 | Loss(train) 2.5175 | Acc(train) 0.4269 | Acc(val) 0.5665 |
Epoch 00174 | Loss(train) 2.4820 | Acc(train) 0.4239 | Acc(val) 0.5681 |
Epoch 00175 | Loss(train) 2.4789 | Acc(train) 0.4319 | Acc(val) 0.5676 |
Epoch 00176 | Loss(train) 2.4836 | Acc(train) 0.4340 | Acc(val) 0.5633 |
Early stopping at epoch 176
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 714.21 MB
GPU Memory Reserved: 2060.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2432 | Acc(train) 0.0239 | Acc(val) 0.1005 |*
Epoch 00002 | Loss(train) 4.2022 | Acc(train) 0.0973 | Acc(val) 0.1186 |*
Epoch 00003 | Loss(train) 4.1511 | Acc(train) 0.1191 | Acc(val) 0.1218 |*
Epoch 00004 | Loss(train) 4.0850 | Acc(train) 0.1383 | Acc(val) 0.1410 |*
Epoch 00005 | Loss(train) 4.0020 | Acc(train) 0.1463 | Acc(val) 0.1681 |*
Epoch 00006 | Loss(train) 3.9242 | Acc(train) 0.1487 | Acc(val) 0.1867 |*
Epoch 00007 | Loss(train) 3.8549 | Acc(train) 0.1593 | Acc(val) 0.2043 |*
Epoch 00008 | Loss(train) 3.7998 | Acc(train) 0.1686 | Acc(val) 0.1973 |
Epoch 00009 | Loss(train) 3.7316 | Acc(train) 0.1769 | Acc(val) 0.1878 |
Epoch 00010 | Loss(train) 3.6859 | Acc(train) 0.1676 | Acc(val) 0.1888 |
Epoch 00011 | Loss(train) 3.6313 | Acc(train) 0.1713 | Acc(val) 0.1995 |
Epoch 00012 | Loss(train) 3.5498 | Acc(train) 0.1931 | Acc(val) 0.2362 |*
Epoch 00013 | Loss(train) 3.4927 | Acc(train) 0.2136 | Acc(val) 0.2846 |*
Epoch 00014 | Loss(train) 3.4422 | Acc(train) 0.2370 | Acc(val) 0.3362 |*
Epoch 00015 | Loss(train) 3.3846 | Acc(train) 0.2598 | Acc(val) 0.3755 |*
Epoch 00016 | Loss(train) 3.3200 | Acc(train) 0.2859 | Acc(val) 0.4053 |*
Epoch 00017 | Loss(train) 3.2545 | Acc(train) 0.3053 | Acc(val) 0.4191 |*
Epoch 00018 | Loss(train) 3.2163 | Acc(train) 0.3082 | Acc(val) 0.4234 |*
Epoch 00019 | Loss(train) 3.1321 | Acc(train) 0.3247 | Acc(val) 0.4245 |*
Epoch 00020 | Loss(train) 3.1140 | Acc(train) 0.3178 | Acc(val) 0.4223 |
Epoch 00021 | Loss(train) 3.0638 | Acc(train) 0.3093 | Acc(val) 0.4202 |
Epoch 00022 | Loss(train) 3.0452 | Acc(train) 0.3064 | Acc(val) 0.4202 |
Epoch 00023 | Loss(train) 2.9733 | Acc(train) 0.3181 | Acc(val) 0.4239 |
Epoch 00024 | Loss(train) 2.9845 | Acc(train) 0.3072 | Acc(val) 0.4277 |*
Epoch 00025 | Loss(train) 2.9391 | Acc(train) 0.3245 | Acc(val) 0.4367 |*
Epoch 00026 | Loss(train) 2.8920 | Acc(train) 0.3322 | Acc(val) 0.4527 |*
Epoch 00027 | Loss(train) 2.8753 | Acc(train) 0.3391 | Acc(val) 0.4622 |*
Epoch 00028 | Loss(train) 2.8470 | Acc(train) 0.3468 | Acc(val) 0.4755 |*
Epoch 00029 | Loss(train) 2.8342 | Acc(train) 0.3439 | Acc(val) 0.4867 |*
Epoch 00030 | Loss(train) 2.8365 | Acc(train) 0.3489 | Acc(val) 0.4926 |*
Epoch 00031 | Loss(train) 2.7743 | Acc(train) 0.3590 | Acc(val) 0.4941 |*
Epoch 00032 | Loss(train) 2.8038 | Acc(train) 0.3519 | Acc(val) 0.5000 |*
Epoch 00033 | Loss(train) 2.7920 | Acc(train) 0.3593 | Acc(val) 0.5027 |*
Epoch 00034 | Loss(train) 2.7618 | Acc(train) 0.3638 | Acc(val) 0.5043 |*
Epoch 00035 | Loss(train) 2.7129 | Acc(train) 0.3758 | Acc(val) 0.5037 |
Epoch 00036 | Loss(train) 2.7505 | Acc(train) 0.3636 | Acc(val) 0.5053 |*
Epoch 00037 | Loss(train) 2.7232 | Acc(train) 0.3705 | Acc(val) 0.5064 |*
Epoch 00038 | Loss(train) 2.7408 | Acc(train) 0.3665 | Acc(val) 0.5096 |*
Epoch 00039 | Loss(train) 2.7215 | Acc(train) 0.3694 | Acc(val) 0.5128 |*
Epoch 00040 | Loss(train) 2.7010 | Acc(train) 0.3715 | Acc(val) 0.5186 |*
Epoch 00041 | Loss(train) 2.6907 | Acc(train) 0.3726 | Acc(val) 0.5245 |*
Epoch 00042 | Loss(train) 2.6748 | Acc(train) 0.3832 | Acc(val) 0.5261 |*
Epoch 00043 | Loss(train) 2.6440 | Acc(train) 0.3931 | Acc(val) 0.5266 |*
Epoch 00044 | Loss(train) 2.6367 | Acc(train) 0.3864 | Acc(val) 0.5287 |*
Epoch 00045 | Loss(train) 2.6397 | Acc(train) 0.3952 | Acc(val) 0.5282 |
Epoch 00046 | Loss(train) 2.6382 | Acc(train) 0.3904 | Acc(val) 0.5346 |*
Epoch 00047 | Loss(train) 2.6668 | Acc(train) 0.3862 | Acc(val) 0.5362 |*
Epoch 00048 | Loss(train) 2.6092 | Acc(train) 0.4037 | Acc(val) 0.5415 |*
Epoch 00049 | Loss(train) 2.6297 | Acc(train) 0.3971 | Acc(val) 0.5378 |
Epoch 00050 | Loss(train) 2.6183 | Acc(train) 0.3992 | Acc(val) 0.5404 |
Epoch 00051 | Loss(train) 2.6136 | Acc(train) 0.3973 | Acc(val) 0.5420 |*
Epoch 00052 | Loss(train) 2.5591 | Acc(train) 0.4141 | Acc(val) 0.5479 |*
Epoch 00053 | Loss(train) 2.6117 | Acc(train) 0.3989 | Acc(val) 0.5564 |*
Epoch 00054 | Loss(train) 2.5665 | Acc(train) 0.4082 | Acc(val) 0.5564 |
Epoch 00055 | Loss(train) 2.5296 | Acc(train) 0.4229 | Acc(val) 0.5537 |
Epoch 00056 | Loss(train) 2.5844 | Acc(train) 0.4122 | Acc(val) 0.5495 |
Epoch 00057 | Loss(train) 2.5624 | Acc(train) 0.4104 | Acc(val) 0.5479 |
Epoch 00058 | Loss(train) 2.5647 | Acc(train) 0.4122 | Acc(val) 0.5457 |
Epoch 00059 | Loss(train) 2.5579 | Acc(train) 0.4051 | Acc(val) 0.5479 |
Epoch 00060 | Loss(train) 2.5842 | Acc(train) 0.3944 | Acc(val) 0.5441 |
Epoch 00061 | Loss(train) 2.5364 | Acc(train) 0.4122 | Acc(val) 0.5463 |
Epoch 00062 | Loss(train) 2.6007 | Acc(train) 0.3968 | Acc(val) 0.5484 |
Epoch 00063 | Loss(train) 2.5197 | Acc(train) 0.4181 | Acc(val) 0.5500 |
Epoch 00064 | Loss(train) 2.5125 | Acc(train) 0.4186 | Acc(val) 0.5521 |
Epoch 00065 | Loss(train) 2.5557 | Acc(train) 0.4104 | Acc(val) 0.5537 |
Epoch 00066 | Loss(train) 2.5680 | Acc(train) 0.4112 | Acc(val) 0.5569 |*
Epoch 00067 | Loss(train) 2.5195 | Acc(train) 0.4234 | Acc(val) 0.5559 |
Epoch 00068 | Loss(train) 2.5402 | Acc(train) 0.4213 | Acc(val) 0.5553 |
Epoch 00069 | Loss(train) 2.5173 | Acc(train) 0.4176 | Acc(val) 0.5564 |
Epoch 00070 | Loss(train) 2.4735 | Acc(train) 0.4298 | Acc(val) 0.5553 |
Epoch 00071 | Loss(train) 2.5081 | Acc(train) 0.4130 | Acc(val) 0.5569 |
Epoch 00072 | Loss(train) 2.5476 | Acc(train) 0.4250 | Acc(val) 0.5585 |*
Epoch 00073 | Loss(train) 2.5307 | Acc(train) 0.4096 | Acc(val) 0.5559 |
Epoch 00074 | Loss(train) 2.5185 | Acc(train) 0.4271 | Acc(val) 0.5569 |
Epoch 00075 | Loss(train) 2.5154 | Acc(train) 0.4165 | Acc(val) 0.5596 |*
Epoch 00076 | Loss(train) 2.5199 | Acc(train) 0.4122 | Acc(val) 0.5601 |*
Epoch 00077 | Loss(train) 2.5115 | Acc(train) 0.4335 | Acc(val) 0.5601 |
Epoch 00078 | Loss(train) 2.4667 | Acc(train) 0.4404 | Acc(val) 0.5612 |*
Epoch 00079 | Loss(train) 2.5172 | Acc(train) 0.4237 | Acc(val) 0.5596 |
Epoch 00080 | Loss(train) 2.5027 | Acc(train) 0.4311 | Acc(val) 0.5590 |
Epoch 00081 | Loss(train) 2.5420 | Acc(train) 0.4194 | Acc(val) 0.5580 |
Epoch 00082 | Loss(train) 2.5129 | Acc(train) 0.4258 | Acc(val) 0.5580 |
Epoch 00083 | Loss(train) 2.5184 | Acc(train) 0.4245 | Acc(val) 0.5585 |
Epoch 00084 | Loss(train) 2.5214 | Acc(train) 0.4053 | Acc(val) 0.5574 |
Epoch 00085 | Loss(train) 2.5096 | Acc(train) 0.4298 | Acc(val) 0.5548 |
Epoch 00086 | Loss(train) 2.4960 | Acc(train) 0.4242 | Acc(val) 0.5505 |
Epoch 00087 | Loss(train) 2.5510 | Acc(train) 0.4109 | Acc(val) 0.5473 |
Epoch 00088 | Loss(train) 2.5274 | Acc(train) 0.4117 | Acc(val) 0.5468 |
Epoch 00089 | Loss(train) 2.4975 | Acc(train) 0.4229 | Acc(val) 0.5473 |
Epoch 00090 | Loss(train) 2.5245 | Acc(train) 0.4231 | Acc(val) 0.5543 |
Epoch 00091 | Loss(train) 2.5059 | Acc(train) 0.4226 | Acc(val) 0.5569 |
Epoch 00092 | Loss(train) 2.5288 | Acc(train) 0.4205 | Acc(val) 0.5574 |
Epoch 00093 | Loss(train) 2.5113 | Acc(train) 0.4138 | Acc(val) 0.5601 |
Epoch 00094 | Loss(train) 2.5032 | Acc(train) 0.4194 | Acc(val) 0.5622 |*
Epoch 00095 | Loss(train) 2.5219 | Acc(train) 0.4277 | Acc(val) 0.5622 |
Epoch 00096 | Loss(train) 2.5205 | Acc(train) 0.4146 | Acc(val) 0.5622 |
Epoch 00097 | Loss(train) 2.5025 | Acc(train) 0.4255 | Acc(val) 0.5585 |
Epoch 00098 | Loss(train) 2.5093 | Acc(train) 0.4170 | Acc(val) 0.5606 |
Epoch 00099 | Loss(train) 2.5018 | Acc(train) 0.4189 | Acc(val) 0.5612 |
Epoch 00100 | Loss(train) 2.5026 | Acc(train) 0.4245 | Acc(val) 0.5654 |*
Epoch 00101 | Loss(train) 2.5303 | Acc(train) 0.4077 | Acc(val) 0.5681 |*
Epoch 00102 | Loss(train) 2.5179 | Acc(train) 0.4138 | Acc(val) 0.5713 |*
Epoch 00103 | Loss(train) 2.5062 | Acc(train) 0.4287 | Acc(val) 0.5723 |*
Epoch 00104 | Loss(train) 2.5292 | Acc(train) 0.4133 | Acc(val) 0.5713 |
Epoch 00105 | Loss(train) 2.4839 | Acc(train) 0.4293 | Acc(val) 0.5697 |
Epoch 00106 | Loss(train) 2.5324 | Acc(train) 0.4242 | Acc(val) 0.5691 |
Epoch 00107 | Loss(train) 2.4885 | Acc(train) 0.4197 | Acc(val) 0.5697 |
Epoch 00108 | Loss(train) 2.5035 | Acc(train) 0.4231 | Acc(val) 0.5686 |
Epoch 00109 | Loss(train) 2.4898 | Acc(train) 0.4301 | Acc(val) 0.5681 |
Epoch 00110 | Loss(train) 2.5194 | Acc(train) 0.4149 | Acc(val) 0.5681 |
Epoch 00111 | Loss(train) 2.4990 | Acc(train) 0.4298 | Acc(val) 0.5686 |
Epoch 00112 | Loss(train) 2.5438 | Acc(train) 0.4128 | Acc(val) 0.5681 |
Epoch 00113 | Loss(train) 2.5026 | Acc(train) 0.4221 | Acc(val) 0.5676 |
Epoch 00114 | Loss(train) 2.5247 | Acc(train) 0.4250 | Acc(val) 0.5665 |
Epoch 00115 | Loss(train) 2.5106 | Acc(train) 0.4221 | Acc(val) 0.5686 |
Epoch 00116 | Loss(train) 2.4764 | Acc(train) 0.4391 | Acc(val) 0.5755 |*
Epoch 00117 | Loss(train) 2.5057 | Acc(train) 0.4247 | Acc(val) 0.5745 |
Epoch 00118 | Loss(train) 2.5250 | Acc(train) 0.4154 | Acc(val) 0.5734 |
Epoch 00119 | Loss(train) 2.5075 | Acc(train) 0.4199 | Acc(val) 0.5729 |
Epoch 00120 | Loss(train) 2.5358 | Acc(train) 0.4096 | Acc(val) 0.5691 |
Epoch 00121 | Loss(train) 2.5214 | Acc(train) 0.4186 | Acc(val) 0.5686 |
Epoch 00122 | Loss(train) 2.5162 | Acc(train) 0.4157 | Acc(val) 0.5718 |
Epoch 00123 | Loss(train) 2.4811 | Acc(train) 0.4258 | Acc(val) 0.5681 |
Epoch 00124 | Loss(train) 2.5183 | Acc(train) 0.4285 | Acc(val) 0.5670 |
Epoch 00125 | Loss(train) 2.4849 | Acc(train) 0.4223 | Acc(val) 0.5676 |
Epoch 00126 | Loss(train) 2.4928 | Acc(train) 0.4229 | Acc(val) 0.5665 |
Epoch 00127 | Loss(train) 2.5468 | Acc(train) 0.4112 | Acc(val) 0.5665 |
Epoch 00128 | Loss(train) 2.5208 | Acc(train) 0.4117 | Acc(val) 0.5707 |
Epoch 00129 | Loss(train) 2.5434 | Acc(train) 0.4176 | Acc(val) 0.5707 |
Epoch 00130 | Loss(train) 2.5284 | Acc(train) 0.4178 | Acc(val) 0.5723 |
Epoch 00131 | Loss(train) 2.5033 | Acc(train) 0.4223 | Acc(val) 0.5713 |
Epoch 00132 | Loss(train) 2.5105 | Acc(train) 0.4266 | Acc(val) 0.5707 |
Epoch 00133 | Loss(train) 2.4730 | Acc(train) 0.4407 | Acc(val) 0.5686 |
Epoch 00134 | Loss(train) 2.4908 | Acc(train) 0.4316 | Acc(val) 0.5670 |
Epoch 00135 | Loss(train) 2.5043 | Acc(train) 0.4261 | Acc(val) 0.5665 |
Epoch 00136 | Loss(train) 2.5170 | Acc(train) 0.4271 | Acc(val) 0.5665 |
Epoch 00137 | Loss(train) 2.4932 | Acc(train) 0.4255 | Acc(val) 0.5633 |
Epoch 00138 | Loss(train) 2.4836 | Acc(train) 0.4330 | Acc(val) 0.5681 |
Epoch 00139 | Loss(train) 2.4984 | Acc(train) 0.4197 | Acc(val) 0.5676 |
Epoch 00140 | Loss(train) 2.4821 | Acc(train) 0.4303 | Acc(val) 0.5660 |
Epoch 00141 | Loss(train) 2.5165 | Acc(train) 0.4207 | Acc(val) 0.5707 |
Epoch 00142 | Loss(train) 2.5135 | Acc(train) 0.4199 | Acc(val) 0.5713 |
Epoch 00143 | Loss(train) 2.5042 | Acc(train) 0.4293 | Acc(val) 0.5676 |
Epoch 00144 | Loss(train) 2.5001 | Acc(train) 0.4261 | Acc(val) 0.5691 |
Epoch 00145 | Loss(train) 2.5062 | Acc(train) 0.4258 | Acc(val) 0.5676 |
Epoch 00146 | Loss(train) 2.5361 | Acc(train) 0.4162 | Acc(val) 0.5660 |
Epoch 00147 | Loss(train) 2.4806 | Acc(train) 0.4348 | Acc(val) 0.5691 |
Epoch 00148 | Loss(train) 2.4979 | Acc(train) 0.4271 | Acc(val) 0.5686 |
Epoch 00149 | Loss(train) 2.4980 | Acc(train) 0.4202 | Acc(val) 0.5729 |
Epoch 00150 | Loss(train) 2.4869 | Acc(train) 0.4356 | Acc(val) 0.5729 |
Epoch 00151 | Loss(train) 2.4803 | Acc(train) 0.4287 | Acc(val) 0.5777 |*
Epoch 00152 | Loss(train) 2.4855 | Acc(train) 0.4293 | Acc(val) 0.5814 |*
Epoch 00153 | Loss(train) 2.4885 | Acc(train) 0.4335 | Acc(val) 0.5809 |
Epoch 00154 | Loss(train) 2.4800 | Acc(train) 0.4399 | Acc(val) 0.5782 |
Epoch 00155 | Loss(train) 2.4916 | Acc(train) 0.4340 | Acc(val) 0.5665 |
Epoch 00156 | Loss(train) 2.4941 | Acc(train) 0.4263 | Acc(val) 0.5660 |
Epoch 00157 | Loss(train) 2.4595 | Acc(train) 0.4367 | Acc(val) 0.5638 |
Epoch 00158 | Loss(train) 2.5018 | Acc(train) 0.4184 | Acc(val) 0.5596 |
Epoch 00159 | Loss(train) 2.4418 | Acc(train) 0.4436 | Acc(val) 0.5633 |
Epoch 00160 | Loss(train) 2.4946 | Acc(train) 0.4223 | Acc(val) 0.5697 |
Epoch 00161 | Loss(train) 2.5010 | Acc(train) 0.4181 | Acc(val) 0.5777 |
Epoch 00162 | Loss(train) 2.5278 | Acc(train) 0.4261 | Acc(val) 0.5803 |
Epoch 00163 | Loss(train) 2.4884 | Acc(train) 0.4319 | Acc(val) 0.5819 |*
Epoch 00164 | Loss(train) 2.4917 | Acc(train) 0.4277 | Acc(val) 0.5803 |
Epoch 00165 | Loss(train) 2.5223 | Acc(train) 0.4207 | Acc(val) 0.5782 |
Epoch 00166 | Loss(train) 2.4703 | Acc(train) 0.4250 | Acc(val) 0.5739 |
Epoch 00167 | Loss(train) 2.4984 | Acc(train) 0.4293 | Acc(val) 0.5654 |
Epoch 00168 | Loss(train) 2.4893 | Acc(train) 0.4287 | Acc(val) 0.5644 |
Epoch 00169 | Loss(train) 2.4707 | Acc(train) 0.4290 | Acc(val) 0.5617 |
Epoch 00170 | Loss(train) 2.4717 | Acc(train) 0.4396 | Acc(val) 0.5612 |
Epoch 00171 | Loss(train) 2.4924 | Acc(train) 0.4290 | Acc(val) 0.5676 |
Epoch 00172 | Loss(train) 2.5018 | Acc(train) 0.4301 | Acc(val) 0.5681 |
Epoch 00173 | Loss(train) 2.4832 | Acc(train) 0.4332 | Acc(val) 0.5750 |
Epoch 00174 | Loss(train) 2.4962 | Acc(train) 0.4306 | Acc(val) 0.5755 |
Epoch 00175 | Loss(train) 2.4965 | Acc(train) 0.4359 | Acc(val) 0.5745 |
Epoch 00176 | Loss(train) 2.5109 | Acc(train) 0.4199 | Acc(val) 0.5723 |
Epoch 00177 | Loss(train) 2.4779 | Acc(train) 0.4327 | Acc(val) 0.5691 |
Epoch 00178 | Loss(train) 2.4352 | Acc(train) 0.4370 | Acc(val) 0.5670 |
Epoch 00179 | Loss(train) 2.4961 | Acc(train) 0.4226 | Acc(val) 0.5697 |
Epoch 00180 | Loss(train) 2.4816 | Acc(train) 0.4274 | Acc(val) 0.5702 |
Epoch 00181 | Loss(train) 2.4707 | Acc(train) 0.4386 | Acc(val) 0.5723 |
Epoch 00182 | Loss(train) 2.4669 | Acc(train) 0.4423 | Acc(val) 0.5739 |
Epoch 00183 | Loss(train) 2.4870 | Acc(train) 0.4247 | Acc(val) 0.5681 |
Epoch 00184 | Loss(train) 2.4934 | Acc(train) 0.4269 | Acc(val) 0.5681 |
Epoch 00185 | Loss(train) 2.4746 | Acc(train) 0.4295 | Acc(val) 0.5697 |
Epoch 00186 | Loss(train) 2.4871 | Acc(train) 0.4144 | Acc(val) 0.5755 |
Epoch 00187 | Loss(train) 2.4809 | Acc(train) 0.4290 | Acc(val) 0.5739 |
Epoch 00188 | Loss(train) 2.5060 | Acc(train) 0.4311 | Acc(val) 0.5750 |
Epoch 00189 | Loss(train) 2.5062 | Acc(train) 0.4303 | Acc(val) 0.5771 |
Epoch 00190 | Loss(train) 2.4546 | Acc(train) 0.4319 | Acc(val) 0.5814 |
Epoch 00191 | Loss(train) 2.4656 | Acc(train) 0.4367 | Acc(val) 0.5750 |
Epoch 00192 | Loss(train) 2.4723 | Acc(train) 0.4322 | Acc(val) 0.5739 |
Epoch 00193 | Loss(train) 2.4741 | Acc(train) 0.4290 | Acc(val) 0.5707 |
Epoch 00194 | Loss(train) 2.4563 | Acc(train) 0.4330 | Acc(val) 0.5691 |
Epoch 00195 | Loss(train) 2.4663 | Acc(train) 0.4253 | Acc(val) 0.5729 |
Epoch 00196 | Loss(train) 2.5247 | Acc(train) 0.4303 | Acc(val) 0.5766 |
Epoch 00197 | Loss(train) 2.4776 | Acc(train) 0.4338 | Acc(val) 0.5739 |
Epoch 00198 | Loss(train) 2.5037 | Acc(train) 0.4269 | Acc(val) 0.5729 |
Epoch 00199 | Loss(train) 2.4908 | Acc(train) 0.4354 | Acc(val) 0.5713 |
Epoch 00200 | Loss(train) 2.4880 | Acc(train) 0.4282 | Acc(val) 0.5697 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 713.53 MB
GPU Memory Reserved: 2060.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2500 | Acc(train) 0.0202 | Acc(val) 0.1324 |*
Epoch 00002 | Loss(train) 4.2092 | Acc(train) 0.0918 | Acc(val) 0.1681 |*
Epoch 00003 | Loss(train) 4.1543 | Acc(train) 0.1426 | Acc(val) 0.1968 |*
Epoch 00004 | Loss(train) 4.0851 | Acc(train) 0.1689 | Acc(val) 0.2133 |*
Epoch 00005 | Loss(train) 4.0011 | Acc(train) 0.1739 | Acc(val) 0.2149 |*
Epoch 00006 | Loss(train) 3.9280 | Acc(train) 0.1731 | Acc(val) 0.2074 |
Epoch 00007 | Loss(train) 3.8584 | Acc(train) 0.1755 | Acc(val) 0.1782 |
Epoch 00008 | Loss(train) 3.7987 | Acc(train) 0.1620 | Acc(val) 0.1723 |
Epoch 00009 | Loss(train) 3.7599 | Acc(train) 0.1590 | Acc(val) 0.1723 |
Epoch 00010 | Loss(train) 3.6971 | Acc(train) 0.1686 | Acc(val) 0.1926 |
Epoch 00011 | Loss(train) 3.6311 | Acc(train) 0.1782 | Acc(val) 0.2234 |*
Epoch 00012 | Loss(train) 3.5522 | Acc(train) 0.2000 | Acc(val) 0.2543 |*
Epoch 00013 | Loss(train) 3.4990 | Acc(train) 0.2298 | Acc(val) 0.2920 |*
Epoch 00014 | Loss(train) 3.4337 | Acc(train) 0.2452 | Acc(val) 0.3356 |*
Epoch 00015 | Loss(train) 3.3598 | Acc(train) 0.2856 | Acc(val) 0.3718 |*
Epoch 00016 | Loss(train) 3.3066 | Acc(train) 0.3024 | Acc(val) 0.3941 |*
Epoch 00017 | Loss(train) 3.2672 | Acc(train) 0.2947 | Acc(val) 0.4080 |*
Epoch 00018 | Loss(train) 3.1975 | Acc(train) 0.3186 | Acc(val) 0.4181 |*
Epoch 00019 | Loss(train) 3.1910 | Acc(train) 0.3098 | Acc(val) 0.4197 |*
Epoch 00020 | Loss(train) 3.1055 | Acc(train) 0.3120 | Acc(val) 0.4239 |*
Epoch 00021 | Loss(train) 3.0936 | Acc(train) 0.3072 | Acc(val) 0.4261 |*
Epoch 00022 | Loss(train) 3.0168 | Acc(train) 0.3152 | Acc(val) 0.4234 |
Epoch 00023 | Loss(train) 2.9712 | Acc(train) 0.3327 | Acc(val) 0.4245 |
Epoch 00024 | Loss(train) 2.9611 | Acc(train) 0.3210 | Acc(val) 0.4309 |*
Epoch 00025 | Loss(train) 2.9389 | Acc(train) 0.3295 | Acc(val) 0.4426 |*
Epoch 00026 | Loss(train) 2.9223 | Acc(train) 0.3279 | Acc(val) 0.4489 |*
Epoch 00027 | Loss(train) 2.8764 | Acc(train) 0.3359 | Acc(val) 0.4633 |*
Epoch 00028 | Loss(train) 2.8495 | Acc(train) 0.3449 | Acc(val) 0.4766 |*
Epoch 00029 | Loss(train) 2.8349 | Acc(train) 0.3524 | Acc(val) 0.4931 |*
Epoch 00030 | Loss(train) 2.8043 | Acc(train) 0.3489 | Acc(val) 0.5053 |*
Epoch 00031 | Loss(train) 2.8221 | Acc(train) 0.3516 | Acc(val) 0.5133 |*
Epoch 00032 | Loss(train) 2.7769 | Acc(train) 0.3657 | Acc(val) 0.5138 |*
Epoch 00033 | Loss(train) 2.7640 | Acc(train) 0.3713 | Acc(val) 0.5181 |*
Epoch 00034 | Loss(train) 2.7471 | Acc(train) 0.3649 | Acc(val) 0.5122 |
Epoch 00035 | Loss(train) 2.7491 | Acc(train) 0.3699 | Acc(val) 0.5101 |
Epoch 00036 | Loss(train) 2.7193 | Acc(train) 0.3755 | Acc(val) 0.5112 |
Epoch 00037 | Loss(train) 2.6831 | Acc(train) 0.3758 | Acc(val) 0.5128 |
Epoch 00038 | Loss(train) 2.7322 | Acc(train) 0.3657 | Acc(val) 0.5117 |
Epoch 00039 | Loss(train) 2.6649 | Acc(train) 0.3822 | Acc(val) 0.5165 |
Epoch 00040 | Loss(train) 2.6930 | Acc(train) 0.3758 | Acc(val) 0.5202 |*
Epoch 00041 | Loss(train) 2.6823 | Acc(train) 0.3822 | Acc(val) 0.5234 |*
Epoch 00042 | Loss(train) 2.6791 | Acc(train) 0.3928 | Acc(val) 0.5303 |*
Epoch 00043 | Loss(train) 2.6525 | Acc(train) 0.3819 | Acc(val) 0.5351 |*
Epoch 00044 | Loss(train) 2.6639 | Acc(train) 0.3875 | Acc(val) 0.5372 |*
Epoch 00045 | Loss(train) 2.6509 | Acc(train) 0.3878 | Acc(val) 0.5388 |*
Epoch 00046 | Loss(train) 2.6665 | Acc(train) 0.3803 | Acc(val) 0.5394 |*
Epoch 00047 | Loss(train) 2.6205 | Acc(train) 0.3976 | Acc(val) 0.5399 |*
Epoch 00048 | Loss(train) 2.5997 | Acc(train) 0.4019 | Acc(val) 0.5410 |*
Epoch 00049 | Loss(train) 2.6079 | Acc(train) 0.4066 | Acc(val) 0.5463 |*
Epoch 00050 | Loss(train) 2.6215 | Acc(train) 0.3944 | Acc(val) 0.5479 |*
Epoch 00051 | Loss(train) 2.5936 | Acc(train) 0.4082 | Acc(val) 0.5532 |*
Epoch 00052 | Loss(train) 2.6331 | Acc(train) 0.3968 | Acc(val) 0.5521 |
Epoch 00053 | Loss(train) 2.5967 | Acc(train) 0.4059 | Acc(val) 0.5500 |
Epoch 00054 | Loss(train) 2.5964 | Acc(train) 0.4013 | Acc(val) 0.5431 |
Epoch 00055 | Loss(train) 2.6001 | Acc(train) 0.3931 | Acc(val) 0.5457 |
Epoch 00056 | Loss(train) 2.5912 | Acc(train) 0.3984 | Acc(val) 0.5447 |
Epoch 00057 | Loss(train) 2.5482 | Acc(train) 0.4016 | Acc(val) 0.5436 |
Epoch 00058 | Loss(train) 2.5228 | Acc(train) 0.4133 | Acc(val) 0.5410 |
Epoch 00059 | Loss(train) 2.5842 | Acc(train) 0.4064 | Acc(val) 0.5404 |
Epoch 00060 | Loss(train) 2.5526 | Acc(train) 0.4096 | Acc(val) 0.5447 |
Epoch 00061 | Loss(train) 2.5321 | Acc(train) 0.4178 | Acc(val) 0.5479 |
Epoch 00062 | Loss(train) 2.5611 | Acc(train) 0.4051 | Acc(val) 0.5500 |
Epoch 00063 | Loss(train) 2.5914 | Acc(train) 0.4016 | Acc(val) 0.5527 |
Epoch 00064 | Loss(train) 2.5268 | Acc(train) 0.4205 | Acc(val) 0.5532 |
Epoch 00065 | Loss(train) 2.5482 | Acc(train) 0.4066 | Acc(val) 0.5559 |*
Epoch 00066 | Loss(train) 2.5366 | Acc(train) 0.4210 | Acc(val) 0.5580 |*
Epoch 00067 | Loss(train) 2.5084 | Acc(train) 0.4269 | Acc(val) 0.5564 |
Epoch 00068 | Loss(train) 2.5092 | Acc(train) 0.4160 | Acc(val) 0.5596 |*
Epoch 00069 | Loss(train) 2.5440 | Acc(train) 0.4096 | Acc(val) 0.5622 |*
Epoch 00070 | Loss(train) 2.5338 | Acc(train) 0.4144 | Acc(val) 0.5665 |*
Epoch 00071 | Loss(train) 2.5291 | Acc(train) 0.4229 | Acc(val) 0.5665 |
Epoch 00072 | Loss(train) 2.5347 | Acc(train) 0.4202 | Acc(val) 0.5665 |
Epoch 00073 | Loss(train) 2.5390 | Acc(train) 0.4098 | Acc(val) 0.5660 |
Epoch 00074 | Loss(train) 2.5401 | Acc(train) 0.4133 | Acc(val) 0.5665 |
Epoch 00075 | Loss(train) 2.5253 | Acc(train) 0.4154 | Acc(val) 0.5686 |*
Epoch 00076 | Loss(train) 2.5086 | Acc(train) 0.4253 | Acc(val) 0.5681 |
Epoch 00077 | Loss(train) 2.5708 | Acc(train) 0.4176 | Acc(val) 0.5676 |
Epoch 00078 | Loss(train) 2.5379 | Acc(train) 0.4096 | Acc(val) 0.5665 |
Epoch 00079 | Loss(train) 2.5246 | Acc(train) 0.4215 | Acc(val) 0.5665 |
Epoch 00080 | Loss(train) 2.4822 | Acc(train) 0.4378 | Acc(val) 0.5670 |
Epoch 00081 | Loss(train) 2.5115 | Acc(train) 0.4229 | Acc(val) 0.5649 |
Epoch 00082 | Loss(train) 2.5245 | Acc(train) 0.4101 | Acc(val) 0.5617 |
Epoch 00083 | Loss(train) 2.5147 | Acc(train) 0.4173 | Acc(val) 0.5553 |
Epoch 00084 | Loss(train) 2.5166 | Acc(train) 0.4168 | Acc(val) 0.5553 |
Epoch 00085 | Loss(train) 2.5208 | Acc(train) 0.4128 | Acc(val) 0.5559 |
Epoch 00086 | Loss(train) 2.5088 | Acc(train) 0.4149 | Acc(val) 0.5574 |
Epoch 00087 | Loss(train) 2.5065 | Acc(train) 0.4160 | Acc(val) 0.5622 |
Epoch 00088 | Loss(train) 2.5061 | Acc(train) 0.4221 | Acc(val) 0.5638 |
Epoch 00089 | Loss(train) 2.4943 | Acc(train) 0.4202 | Acc(val) 0.5660 |
Epoch 00090 | Loss(train) 2.5338 | Acc(train) 0.4138 | Acc(val) 0.5638 |
Epoch 00091 | Loss(train) 2.4894 | Acc(train) 0.4191 | Acc(val) 0.5617 |
Epoch 00092 | Loss(train) 2.5462 | Acc(train) 0.4125 | Acc(val) 0.5532 |
Epoch 00093 | Loss(train) 2.4900 | Acc(train) 0.4306 | Acc(val) 0.5505 |
Epoch 00094 | Loss(train) 2.5038 | Acc(train) 0.4324 | Acc(val) 0.5463 |
Epoch 00095 | Loss(train) 2.4864 | Acc(train) 0.4309 | Acc(val) 0.5452 |
Epoch 00096 | Loss(train) 2.4989 | Acc(train) 0.4213 | Acc(val) 0.5468 |
Epoch 00097 | Loss(train) 2.4970 | Acc(train) 0.4197 | Acc(val) 0.5511 |
Epoch 00098 | Loss(train) 2.4830 | Acc(train) 0.4141 | Acc(val) 0.5617 |
Epoch 00099 | Loss(train) 2.5121 | Acc(train) 0.4271 | Acc(val) 0.5654 |
Epoch 00100 | Loss(train) 2.5240 | Acc(train) 0.4279 | Acc(val) 0.5702 |*
Epoch 00101 | Loss(train) 2.5004 | Acc(train) 0.4266 | Acc(val) 0.5702 |
Epoch 00102 | Loss(train) 2.5340 | Acc(train) 0.4271 | Acc(val) 0.5702 |
Epoch 00103 | Loss(train) 2.4975 | Acc(train) 0.4332 | Acc(val) 0.5681 |
Epoch 00104 | Loss(train) 2.4859 | Acc(train) 0.4322 | Acc(val) 0.5686 |
Epoch 00105 | Loss(train) 2.4807 | Acc(train) 0.4295 | Acc(val) 0.5670 |
Epoch 00106 | Loss(train) 2.5013 | Acc(train) 0.4221 | Acc(val) 0.5676 |
Epoch 00107 | Loss(train) 2.4983 | Acc(train) 0.4253 | Acc(val) 0.5617 |
Epoch 00108 | Loss(train) 2.5259 | Acc(train) 0.4149 | Acc(val) 0.5601 |
Epoch 00109 | Loss(train) 2.5321 | Acc(train) 0.4074 | Acc(val) 0.5633 |
Epoch 00110 | Loss(train) 2.5036 | Acc(train) 0.4186 | Acc(val) 0.5723 |*
Epoch 00111 | Loss(train) 2.5286 | Acc(train) 0.4178 | Acc(val) 0.5729 |*
Epoch 00112 | Loss(train) 2.5261 | Acc(train) 0.4138 | Acc(val) 0.5729 |
Epoch 00113 | Loss(train) 2.4952 | Acc(train) 0.4327 | Acc(val) 0.5771 |*
Epoch 00114 | Loss(train) 2.4886 | Acc(train) 0.4340 | Acc(val) 0.5755 |
Epoch 00115 | Loss(train) 2.5044 | Acc(train) 0.4274 | Acc(val) 0.5739 |
Epoch 00116 | Loss(train) 2.5056 | Acc(train) 0.4301 | Acc(val) 0.5723 |
Epoch 00117 | Loss(train) 2.4827 | Acc(train) 0.4356 | Acc(val) 0.5707 |
Epoch 00118 | Loss(train) 2.5237 | Acc(train) 0.4149 | Acc(val) 0.5670 |
Epoch 00119 | Loss(train) 2.4987 | Acc(train) 0.4186 | Acc(val) 0.5633 |
Epoch 00120 | Loss(train) 2.4889 | Acc(train) 0.4178 | Acc(val) 0.5644 |
Epoch 00121 | Loss(train) 2.5182 | Acc(train) 0.4149 | Acc(val) 0.5670 |
Epoch 00122 | Loss(train) 2.4750 | Acc(train) 0.4258 | Acc(val) 0.5676 |
Epoch 00123 | Loss(train) 2.4698 | Acc(train) 0.4343 | Acc(val) 0.5691 |
Epoch 00124 | Loss(train) 2.5202 | Acc(train) 0.4237 | Acc(val) 0.5697 |
Epoch 00125 | Loss(train) 2.4727 | Acc(train) 0.4372 | Acc(val) 0.5691 |
Epoch 00126 | Loss(train) 2.5222 | Acc(train) 0.4255 | Acc(val) 0.5670 |
Epoch 00127 | Loss(train) 2.5072 | Acc(train) 0.4165 | Acc(val) 0.5691 |
Epoch 00128 | Loss(train) 2.4894 | Acc(train) 0.4199 | Acc(val) 0.5670 |
Epoch 00129 | Loss(train) 2.4727 | Acc(train) 0.4343 | Acc(val) 0.5633 |
Epoch 00130 | Loss(train) 2.4767 | Acc(train) 0.4293 | Acc(val) 0.5622 |
Epoch 00131 | Loss(train) 2.5251 | Acc(train) 0.4165 | Acc(val) 0.5633 |
Epoch 00132 | Loss(train) 2.4930 | Acc(train) 0.4205 | Acc(val) 0.5617 |
Epoch 00133 | Loss(train) 2.4978 | Acc(train) 0.4202 | Acc(val) 0.5612 |
Epoch 00134 | Loss(train) 2.4920 | Acc(train) 0.4295 | Acc(val) 0.5606 |
Epoch 00135 | Loss(train) 2.4852 | Acc(train) 0.4314 | Acc(val) 0.5596 |
Epoch 00136 | Loss(train) 2.4774 | Acc(train) 0.4242 | Acc(val) 0.5617 |
Epoch 00137 | Loss(train) 2.5167 | Acc(train) 0.4263 | Acc(val) 0.5596 |
Epoch 00138 | Loss(train) 2.4715 | Acc(train) 0.4380 | Acc(val) 0.5644 |
Epoch 00139 | Loss(train) 2.5137 | Acc(train) 0.4229 | Acc(val) 0.5649 |
Epoch 00140 | Loss(train) 2.4852 | Acc(train) 0.4303 | Acc(val) 0.5670 |
Epoch 00141 | Loss(train) 2.4580 | Acc(train) 0.4516 | Acc(val) 0.5670 |
Epoch 00142 | Loss(train) 2.4672 | Acc(train) 0.4346 | Acc(val) 0.5622 |
Epoch 00143 | Loss(train) 2.5085 | Acc(train) 0.4330 | Acc(val) 0.5569 |
Epoch 00144 | Loss(train) 2.4911 | Acc(train) 0.4279 | Acc(val) 0.5564 |
Epoch 00145 | Loss(train) 2.4869 | Acc(train) 0.4277 | Acc(val) 0.5569 |
Epoch 00146 | Loss(train) 2.4901 | Acc(train) 0.4287 | Acc(val) 0.5574 |
Epoch 00147 | Loss(train) 2.4606 | Acc(train) 0.4375 | Acc(val) 0.5617 |
Epoch 00148 | Loss(train) 2.4945 | Acc(train) 0.4287 | Acc(val) 0.5612 |
Epoch 00149 | Loss(train) 2.5171 | Acc(train) 0.4226 | Acc(val) 0.5665 |
Epoch 00150 | Loss(train) 2.5051 | Acc(train) 0.4184 | Acc(val) 0.5707 |
Epoch 00151 | Loss(train) 2.4658 | Acc(train) 0.4319 | Acc(val) 0.5691 |
Epoch 00152 | Loss(train) 2.4724 | Acc(train) 0.4420 | Acc(val) 0.5718 |
Epoch 00153 | Loss(train) 2.5252 | Acc(train) 0.4229 | Acc(val) 0.5686 |
Epoch 00154 | Loss(train) 2.5199 | Acc(train) 0.4122 | Acc(val) 0.5676 |
Epoch 00155 | Loss(train) 2.4958 | Acc(train) 0.4327 | Acc(val) 0.5713 |
Epoch 00156 | Loss(train) 2.5252 | Acc(train) 0.4197 | Acc(val) 0.5697 |
Epoch 00157 | Loss(train) 2.4755 | Acc(train) 0.4311 | Acc(val) 0.5707 |
Epoch 00158 | Loss(train) 2.4686 | Acc(train) 0.4274 | Acc(val) 0.5691 |
Epoch 00159 | Loss(train) 2.5092 | Acc(train) 0.4226 | Acc(val) 0.5686 |
Epoch 00160 | Loss(train) 2.4746 | Acc(train) 0.4301 | Acc(val) 0.5734 |
Epoch 00161 | Loss(train) 2.5234 | Acc(train) 0.4178 | Acc(val) 0.5745 |
Epoch 00162 | Loss(train) 2.4928 | Acc(train) 0.4279 | Acc(val) 0.5771 |
Epoch 00163 | Loss(train) 2.5781 | Acc(train) 0.4093 | Acc(val) 0.5787 |*
Epoch 00164 | Loss(train) 2.5260 | Acc(train) 0.4285 | Acc(val) 0.5723 |
Epoch 00165 | Loss(train) 2.5003 | Acc(train) 0.4197 | Acc(val) 0.5713 |
Epoch 00166 | Loss(train) 2.4995 | Acc(train) 0.4285 | Acc(val) 0.5702 |
Epoch 00167 | Loss(train) 2.4995 | Acc(train) 0.4309 | Acc(val) 0.5670 |
Epoch 00168 | Loss(train) 2.4597 | Acc(train) 0.4362 | Acc(val) 0.5676 |
Epoch 00169 | Loss(train) 2.5028 | Acc(train) 0.4314 | Acc(val) 0.5686 |
Epoch 00170 | Loss(train) 2.5107 | Acc(train) 0.4202 | Acc(val) 0.5729 |
Epoch 00171 | Loss(train) 2.5304 | Acc(train) 0.4229 | Acc(val) 0.5729 |
Epoch 00172 | Loss(train) 2.5103 | Acc(train) 0.4274 | Acc(val) 0.5713 |
Epoch 00173 | Loss(train) 2.4854 | Acc(train) 0.4287 | Acc(val) 0.5707 |
Epoch 00174 | Loss(train) 2.5059 | Acc(train) 0.4229 | Acc(val) 0.5723 |
Epoch 00175 | Loss(train) 2.5103 | Acc(train) 0.4096 | Acc(val) 0.5718 |
Epoch 00176 | Loss(train) 2.4807 | Acc(train) 0.4269 | Acc(val) 0.5739 |
Epoch 00177 | Loss(train) 2.5025 | Acc(train) 0.4239 | Acc(val) 0.5739 |
Epoch 00178 | Loss(train) 2.5000 | Acc(train) 0.4231 | Acc(val) 0.5755 |
Epoch 00179 | Loss(train) 2.4736 | Acc(train) 0.4356 | Acc(val) 0.5755 |
Epoch 00180 | Loss(train) 2.5213 | Acc(train) 0.4120 | Acc(val) 0.5713 |
Epoch 00181 | Loss(train) 2.4745 | Acc(train) 0.4391 | Acc(val) 0.5707 |
Epoch 00182 | Loss(train) 2.4640 | Acc(train) 0.4314 | Acc(val) 0.5691 |
Epoch 00183 | Loss(train) 2.4530 | Acc(train) 0.4282 | Acc(val) 0.5665 |
Epoch 00184 | Loss(train) 2.5118 | Acc(train) 0.4207 | Acc(val) 0.5670 |
Epoch 00185 | Loss(train) 2.5035 | Acc(train) 0.4207 | Acc(val) 0.5691 |
Epoch 00186 | Loss(train) 2.4621 | Acc(train) 0.4338 | Acc(val) 0.5702 |
Epoch 00187 | Loss(train) 2.5170 | Acc(train) 0.4274 | Acc(val) 0.5729 |
Epoch 00188 | Loss(train) 2.4804 | Acc(train) 0.4218 | Acc(val) 0.5745 |
Epoch 00189 | Loss(train) 2.4781 | Acc(train) 0.4396 | Acc(val) 0.5739 |
Epoch 00190 | Loss(train) 2.5067 | Acc(train) 0.4194 | Acc(val) 0.5734 |
Epoch 00191 | Loss(train) 2.4565 | Acc(train) 0.4391 | Acc(val) 0.5745 |
Epoch 00192 | Loss(train) 2.4690 | Acc(train) 0.4359 | Acc(val) 0.5713 |
Epoch 00193 | Loss(train) 2.4634 | Acc(train) 0.4351 | Acc(val) 0.5670 |
Epoch 00194 | Loss(train) 2.4897 | Acc(train) 0.4269 | Acc(val) 0.5686 |
Epoch 00195 | Loss(train) 2.4841 | Acc(train) 0.4359 | Acc(val) 0.5691 |
Epoch 00196 | Loss(train) 2.4738 | Acc(train) 0.4372 | Acc(val) 0.5676 |
Epoch 00197 | Loss(train) 2.4551 | Acc(train) 0.4394 | Acc(val) 0.5654 |
Epoch 00198 | Loss(train) 2.4659 | Acc(train) 0.4279 | Acc(val) 0.5670 |
Epoch 00199 | Loss(train) 2.4834 | Acc(train) 0.4338 | Acc(val) 0.5644 |
Epoch 00200 | Loss(train) 2.4702 | Acc(train) 0.4287 | Acc(val) 0.5691 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'CaGCN', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.5}, gnn={'type': 'gat', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 714.21 MB
GPU Memory Reserved: 2060.00 MB
All runs:
Uncalibrated Test Accuracy: 57.51  0.34
Uncalibrated Difference: 37.97  0.50
Calibrated Test Accuracy: 57.51  0.34
Calibrated Difference: 4.79  0.34
