  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
Dataset: cora | #Nodes: 2708 | #Edges: 13264 | #Classes: 7 |#Features: 1433
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9467 | Acc(train) 0.1405 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9377 | Acc(train) 0.2957 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9294 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9188 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.9099 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8987 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8861 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8751 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8690 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8562 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8424 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.8284 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.8235 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.8125 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7964 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7922 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7779 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7657 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7523 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7354 | Acc(train) 0.2902 | Acc(val) 0.3026 |*
Epoch 00021 | Loss(train) 1.7282 | Acc(train) 0.2939 | Acc(val) 0.3026 |
Epoch 00022 | Loss(train) 1.7232 | Acc(train) 0.3031 | Acc(val) 0.3100 |*
Epoch 00023 | Loss(train) 1.7073 | Acc(train) 0.3068 | Acc(val) 0.3137 |*
Epoch 00024 | Loss(train) 1.7058 | Acc(train) 0.3105 | Acc(val) 0.3173 |*
Epoch 00025 | Loss(train) 1.6886 | Acc(train) 0.3253 | Acc(val) 0.3173 |
Epoch 00026 | Loss(train) 1.6831 | Acc(train) 0.3272 | Acc(val) 0.3173 |
Epoch 00027 | Loss(train) 1.6695 | Acc(train) 0.3346 | Acc(val) 0.3247 |*
Epoch 00028 | Loss(train) 1.6453 | Acc(train) 0.3401 | Acc(val) 0.3395 |*
Epoch 00029 | Loss(train) 1.6434 | Acc(train) 0.3586 | Acc(val) 0.3469 |*
Epoch 00030 | Loss(train) 1.6351 | Acc(train) 0.3808 | Acc(val) 0.3506 |*
Epoch 00031 | Loss(train) 1.6168 | Acc(train) 0.3826 | Acc(val) 0.3542 |*
Epoch 00032 | Loss(train) 1.6080 | Acc(train) 0.3919 | Acc(val) 0.3579 |*
Epoch 00033 | Loss(train) 1.5993 | Acc(train) 0.3715 | Acc(val) 0.3579 |
Epoch 00034 | Loss(train) 1.5925 | Acc(train) 0.3845 | Acc(val) 0.3616 |*
Epoch 00035 | Loss(train) 1.5758 | Acc(train) 0.4233 | Acc(val) 0.3690 |*
Epoch 00036 | Loss(train) 1.5532 | Acc(train) 0.4011 | Acc(val) 0.3801 |*
Epoch 00037 | Loss(train) 1.5618 | Acc(train) 0.4214 | Acc(val) 0.4022 |*
Epoch 00038 | Loss(train) 1.5382 | Acc(train) 0.4325 | Acc(val) 0.4207 |*
Epoch 00039 | Loss(train) 1.5235 | Acc(train) 0.4399 | Acc(val) 0.4354 |*
Epoch 00040 | Loss(train) 1.4931 | Acc(train) 0.4713 | Acc(val) 0.4391 |*
Epoch 00041 | Loss(train) 1.4970 | Acc(train) 0.4806 | Acc(val) 0.4539 |*
Epoch 00042 | Loss(train) 1.4981 | Acc(train) 0.4750 | Acc(val) 0.4686 |*
Epoch 00043 | Loss(train) 1.4642 | Acc(train) 0.5102 | Acc(val) 0.4760 |*
Epoch 00044 | Loss(train) 1.4439 | Acc(train) 0.5305 | Acc(val) 0.4834 |*
Epoch 00045 | Loss(train) 1.4456 | Acc(train) 0.5323 | Acc(val) 0.4945 |*
Epoch 00046 | Loss(train) 1.4247 | Acc(train) 0.5527 | Acc(val) 0.5018 |*
Epoch 00047 | Loss(train) 1.4264 | Acc(train) 0.5287 | Acc(val) 0.5129 |*
Epoch 00048 | Loss(train) 1.3968 | Acc(train) 0.5582 | Acc(val) 0.5277 |*
Epoch 00049 | Loss(train) 1.3952 | Acc(train) 0.5675 | Acc(val) 0.5535 |*
Epoch 00050 | Loss(train) 1.3787 | Acc(train) 0.5860 | Acc(val) 0.5535 |
Epoch 00051 | Loss(train) 1.3507 | Acc(train) 0.6155 | Acc(val) 0.5572 |*
Epoch 00052 | Loss(train) 1.3812 | Acc(train) 0.5675 | Acc(val) 0.5609 |*
Epoch 00053 | Loss(train) 1.3417 | Acc(train) 0.6155 | Acc(val) 0.5683 |*
Epoch 00054 | Loss(train) 1.3206 | Acc(train) 0.6248 | Acc(val) 0.5756 |*
Epoch 00055 | Loss(train) 1.3031 | Acc(train) 0.6266 | Acc(val) 0.5830 |*
Epoch 00056 | Loss(train) 1.3116 | Acc(train) 0.6174 | Acc(val) 0.6199 |*
Epoch 00057 | Loss(train) 1.3001 | Acc(train) 0.6396 | Acc(val) 0.6347 |*
Epoch 00058 | Loss(train) 1.2948 | Acc(train) 0.6044 | Acc(val) 0.6458 |*
Epoch 00059 | Loss(train) 1.2733 | Acc(train) 0.6470 | Acc(val) 0.6458 |
Epoch 00060 | Loss(train) 1.2514 | Acc(train) 0.6340 | Acc(val) 0.6494 |*
Epoch 00061 | Loss(train) 1.2635 | Acc(train) 0.6451 | Acc(val) 0.6605 |*
Epoch 00062 | Loss(train) 1.2395 | Acc(train) 0.6562 | Acc(val) 0.6605 |
Epoch 00063 | Loss(train) 1.2342 | Acc(train) 0.6728 | Acc(val) 0.6642 |*
Epoch 00064 | Loss(train) 1.2174 | Acc(train) 0.6562 | Acc(val) 0.6679 |*
Epoch 00065 | Loss(train) 1.1890 | Acc(train) 0.6784 | Acc(val) 0.6753 |*
Epoch 00066 | Loss(train) 1.1895 | Acc(train) 0.6691 | Acc(val) 0.6937 |*
Epoch 00067 | Loss(train) 1.1591 | Acc(train) 0.6987 | Acc(val) 0.6974 |*
Epoch 00068 | Loss(train) 1.1759 | Acc(train) 0.6876 | Acc(val) 0.7048 |*
Epoch 00069 | Loss(train) 1.1673 | Acc(train) 0.6913 | Acc(val) 0.7122 |*
Epoch 00070 | Loss(train) 1.1489 | Acc(train) 0.7006 | Acc(val) 0.7196 |*
Epoch 00071 | Loss(train) 1.1131 | Acc(train) 0.7116 | Acc(val) 0.7122 |
Epoch 00072 | Loss(train) 1.1532 | Acc(train) 0.6858 | Acc(val) 0.7122 |
Epoch 00073 | Loss(train) 1.1154 | Acc(train) 0.6895 | Acc(val) 0.7085 |
Epoch 00074 | Loss(train) 1.1399 | Acc(train) 0.6802 | Acc(val) 0.7085 |
Epoch 00075 | Loss(train) 1.0942 | Acc(train) 0.7006 | Acc(val) 0.7085 |
Epoch 00076 | Loss(train) 1.1109 | Acc(train) 0.7043 | Acc(val) 0.7196 |
Epoch 00077 | Loss(train) 1.0812 | Acc(train) 0.7098 | Acc(val) 0.7232 |*
Epoch 00078 | Loss(train) 1.0947 | Acc(train) 0.6858 | Acc(val) 0.7417 |*
Epoch 00079 | Loss(train) 1.0713 | Acc(train) 0.6932 | Acc(val) 0.7454 |*
Epoch 00080 | Loss(train) 1.0664 | Acc(train) 0.7079 | Acc(val) 0.7454 |
Epoch 00081 | Loss(train) 1.0507 | Acc(train) 0.7357 | Acc(val) 0.7454 |
Epoch 00082 | Loss(train) 1.0664 | Acc(train) 0.7079 | Acc(val) 0.7454 |
Epoch 00083 | Loss(train) 1.0446 | Acc(train) 0.7190 | Acc(val) 0.7454 |
Epoch 00084 | Loss(train) 1.0367 | Acc(train) 0.7246 | Acc(val) 0.7343 |
Epoch 00085 | Loss(train) 1.0203 | Acc(train) 0.7190 | Acc(val) 0.7380 |
Epoch 00086 | Loss(train) 1.0353 | Acc(train) 0.7153 | Acc(val) 0.7417 |
Epoch 00087 | Loss(train) 1.0116 | Acc(train) 0.7209 | Acc(val) 0.7454 |
Epoch 00088 | Loss(train) 1.0017 | Acc(train) 0.7264 | Acc(val) 0.7491 |*
Epoch 00089 | Loss(train) 1.0086 | Acc(train) 0.7264 | Acc(val) 0.7528 |*
Epoch 00090 | Loss(train) 1.0092 | Acc(train) 0.7523 | Acc(val) 0.7528 |
Epoch 00091 | Loss(train) 0.9863 | Acc(train) 0.7264 | Acc(val) 0.7491 |
Epoch 00092 | Loss(train) 0.9979 | Acc(train) 0.7320 | Acc(val) 0.7454 |
Epoch 00093 | Loss(train) 0.9459 | Acc(train) 0.7412 | Acc(val) 0.7454 |
Epoch 00094 | Loss(train) 0.9663 | Acc(train) 0.7135 | Acc(val) 0.7454 |
Epoch 00095 | Loss(train) 0.9467 | Acc(train) 0.7486 | Acc(val) 0.7454 |
Epoch 00096 | Loss(train) 0.9500 | Acc(train) 0.7579 | Acc(val) 0.7491 |
Epoch 00097 | Loss(train) 0.9386 | Acc(train) 0.7412 | Acc(val) 0.7491 |
Epoch 00098 | Loss(train) 0.9430 | Acc(train) 0.7412 | Acc(val) 0.7454 |
Epoch 00099 | Loss(train) 0.9359 | Acc(train) 0.7301 | Acc(val) 0.7454 |
Epoch 00100 | Loss(train) 0.9176 | Acc(train) 0.7505 | Acc(val) 0.7491 |
Epoch 00101 | Loss(train) 0.9302 | Acc(train) 0.7320 | Acc(val) 0.7528 |
Epoch 00102 | Loss(train) 0.9222 | Acc(train) 0.7301 | Acc(val) 0.7528 |
Epoch 00103 | Loss(train) 0.9281 | Acc(train) 0.7394 | Acc(val) 0.7565 |*
Epoch 00104 | Loss(train) 0.9266 | Acc(train) 0.7579 | Acc(val) 0.7565 |
Epoch 00105 | Loss(train) 0.8841 | Acc(train) 0.7874 | Acc(val) 0.7565 |
Epoch 00106 | Loss(train) 0.8838 | Acc(train) 0.7634 | Acc(val) 0.7601 |*
Epoch 00107 | Loss(train) 0.8846 | Acc(train) 0.7560 | Acc(val) 0.7565 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00108 | Loss(train) 0.8695 | Acc(train) 0.7745 | Acc(val) 0.7565 |
Epoch 00109 | Loss(train) 0.8782 | Acc(train) 0.7505 | Acc(val) 0.7601 |
Epoch 00110 | Loss(train) 0.8841 | Acc(train) 0.7505 | Acc(val) 0.7638 |*
Epoch 00111 | Loss(train) 0.8800 | Acc(train) 0.7486 | Acc(val) 0.7638 |
Epoch 00112 | Loss(train) 0.8815 | Acc(train) 0.7708 | Acc(val) 0.7675 |*
Epoch 00113 | Loss(train) 0.8387 | Acc(train) 0.7911 | Acc(val) 0.7749 |*
Epoch 00114 | Loss(train) 0.8555 | Acc(train) 0.7800 | Acc(val) 0.7712 |
Epoch 00115 | Loss(train) 0.8435 | Acc(train) 0.7837 | Acc(val) 0.7749 |
Epoch 00116 | Loss(train) 0.8464 | Acc(train) 0.7837 | Acc(val) 0.7749 |
Epoch 00117 | Loss(train) 0.8572 | Acc(train) 0.7726 | Acc(val) 0.7749 |
Epoch 00118 | Loss(train) 0.8440 | Acc(train) 0.7782 | Acc(val) 0.7749 |
Epoch 00119 | Loss(train) 0.8440 | Acc(train) 0.7948 | Acc(val) 0.7749 |
Epoch 00120 | Loss(train) 0.8441 | Acc(train) 0.7837 | Acc(val) 0.7786 |*
Epoch 00121 | Loss(train) 0.8177 | Acc(train) 0.7837 | Acc(val) 0.7786 |
Epoch 00122 | Loss(train) 0.8184 | Acc(train) 0.7967 | Acc(val) 0.7823 |*
Epoch 00123 | Loss(train) 0.8348 | Acc(train) 0.7819 | Acc(val) 0.7897 |*
Epoch 00124 | Loss(train) 0.7916 | Acc(train) 0.8041 | Acc(val) 0.7897 |
Epoch 00125 | Loss(train) 0.7954 | Acc(train) 0.8059 | Acc(val) 0.7934 |*
Epoch 00126 | Loss(train) 0.8102 | Acc(train) 0.8299 | Acc(val) 0.7970 |*
Epoch 00127 | Loss(train) 0.7878 | Acc(train) 0.8226 | Acc(val) 0.8044 |*
Epoch 00128 | Loss(train) 0.7914 | Acc(train) 0.8022 | Acc(val) 0.8044 |
Epoch 00129 | Loss(train) 0.8055 | Acc(train) 0.7837 | Acc(val) 0.8044 |
Epoch 00130 | Loss(train) 0.7859 | Acc(train) 0.7985 | Acc(val) 0.8081 |*
Epoch 00131 | Loss(train) 0.8115 | Acc(train) 0.7874 | Acc(val) 0.8081 |
Epoch 00132 | Loss(train) 0.7952 | Acc(train) 0.7911 | Acc(val) 0.8081 |
Epoch 00133 | Loss(train) 0.7619 | Acc(train) 0.8244 | Acc(val) 0.8081 |
Epoch 00134 | Loss(train) 0.7554 | Acc(train) 0.8281 | Acc(val) 0.8081 |
Epoch 00135 | Loss(train) 0.7711 | Acc(train) 0.8022 | Acc(val) 0.8118 |*
Epoch 00136 | Loss(train) 0.7968 | Acc(train) 0.8004 | Acc(val) 0.8155 |*
Epoch 00137 | Loss(train) 0.7704 | Acc(train) 0.8170 | Acc(val) 0.8155 |
Epoch 00138 | Loss(train) 0.7805 | Acc(train) 0.8336 | Acc(val) 0.8192 |*
Epoch 00139 | Loss(train) 0.7311 | Acc(train) 0.8373 | Acc(val) 0.8192 |
Epoch 00140 | Loss(train) 0.7523 | Acc(train) 0.8170 | Acc(val) 0.8192 |
Epoch 00141 | Loss(train) 0.7656 | Acc(train) 0.8244 | Acc(val) 0.8192 |
Epoch 00142 | Loss(train) 0.7574 | Acc(train) 0.8207 | Acc(val) 0.8192 |
Epoch 00143 | Loss(train) 0.7527 | Acc(train) 0.8133 | Acc(val) 0.8192 |
Epoch 00144 | Loss(train) 0.7412 | Acc(train) 0.8336 | Acc(val) 0.8192 |
Epoch 00145 | Loss(train) 0.7509 | Acc(train) 0.8355 | Acc(val) 0.8229 |*
Epoch 00146 | Loss(train) 0.7291 | Acc(train) 0.8189 | Acc(val) 0.8303 |*
Epoch 00147 | Loss(train) 0.7650 | Acc(train) 0.8096 | Acc(val) 0.8303 |
Epoch 00148 | Loss(train) 0.7397 | Acc(train) 0.8207 | Acc(val) 0.8413 |*
Epoch 00149 | Loss(train) 0.7027 | Acc(train) 0.8540 | Acc(val) 0.8339 |
Epoch 00150 | Loss(train) 0.7190 | Acc(train) 0.8410 | Acc(val) 0.8376 |
Epoch 00151 | Loss(train) 0.7290 | Acc(train) 0.8466 | Acc(val) 0.8339 |
Epoch 00152 | Loss(train) 0.7277 | Acc(train) 0.8244 | Acc(val) 0.8303 |
Epoch 00153 | Loss(train) 0.6959 | Acc(train) 0.8503 | Acc(val) 0.8339 |
Epoch 00154 | Loss(train) 0.7214 | Acc(train) 0.8336 | Acc(val) 0.8339 |
Epoch 00155 | Loss(train) 0.7010 | Acc(train) 0.8484 | Acc(val) 0.8376 |
Epoch 00156 | Loss(train) 0.7249 | Acc(train) 0.8133 | Acc(val) 0.8413 |
Epoch 00157 | Loss(train) 0.6678 | Acc(train) 0.8706 | Acc(val) 0.8413 |
Epoch 00158 | Loss(train) 0.6877 | Acc(train) 0.8614 | Acc(val) 0.8413 |
Epoch 00159 | Loss(train) 0.6839 | Acc(train) 0.8725 | Acc(val) 0.8450 |*
Epoch 00160 | Loss(train) 0.6991 | Acc(train) 0.8373 | Acc(val) 0.8487 |*
Epoch 00161 | Loss(train) 0.6894 | Acc(train) 0.8262 | Acc(val) 0.8487 |
Epoch 00162 | Loss(train) 0.7116 | Acc(train) 0.8410 | Acc(val) 0.8487 |
Epoch 00163 | Loss(train) 0.6749 | Acc(train) 0.8429 | Acc(val) 0.8487 |
Epoch 00164 | Loss(train) 0.6859 | Acc(train) 0.8447 | Acc(val) 0.8487 |
Epoch 00165 | Loss(train) 0.6799 | Acc(train) 0.8429 | Acc(val) 0.8450 |
Epoch 00166 | Loss(train) 0.6832 | Acc(train) 0.8540 | Acc(val) 0.8524 |*
Epoch 00167 | Loss(train) 0.6756 | Acc(train) 0.8410 | Acc(val) 0.8524 |
Epoch 00168 | Loss(train) 0.6746 | Acc(train) 0.8447 | Acc(val) 0.8524 |
Epoch 00169 | Loss(train) 0.6633 | Acc(train) 0.8632 | Acc(val) 0.8524 |
Epoch 00170 | Loss(train) 0.6760 | Acc(train) 0.8410 | Acc(val) 0.8524 |
Epoch 00171 | Loss(train) 0.6448 | Acc(train) 0.8632 | Acc(val) 0.8524 |
Epoch 00172 | Loss(train) 0.6575 | Acc(train) 0.8688 | Acc(val) 0.8524 |
Epoch 00173 | Loss(train) 0.6604 | Acc(train) 0.8540 | Acc(val) 0.8450 |
Epoch 00174 | Loss(train) 0.6825 | Acc(train) 0.8410 | Acc(val) 0.8487 |
Epoch 00175 | Loss(train) 0.6337 | Acc(train) 0.8558 | Acc(val) 0.8524 |
Epoch 00176 | Loss(train) 0.6512 | Acc(train) 0.8447 | Acc(val) 0.8635 |*
Epoch 00177 | Loss(train) 0.6477 | Acc(train) 0.8540 | Acc(val) 0.8635 |
Epoch 00178 | Loss(train) 0.6785 | Acc(train) 0.8521 | Acc(val) 0.8635 |
Epoch 00179 | Loss(train) 0.6738 | Acc(train) 0.8484 | Acc(val) 0.8672 |*
Epoch 00180 | Loss(train) 0.6477 | Acc(train) 0.8447 | Acc(val) 0.8672 |
Epoch 00181 | Loss(train) 0.6227 | Acc(train) 0.8632 | Acc(val) 0.8635 |
Epoch 00182 | Loss(train) 0.6494 | Acc(train) 0.8392 | Acc(val) 0.8598 |
Epoch 00183 | Loss(train) 0.6500 | Acc(train) 0.8429 | Acc(val) 0.8672 |
Epoch 00184 | Loss(train) 0.6390 | Acc(train) 0.8632 | Acc(val) 0.8672 |
Epoch 00185 | Loss(train) 0.6084 | Acc(train) 0.8762 | Acc(val) 0.8635 |
Epoch 00186 | Loss(train) 0.6446 | Acc(train) 0.8540 | Acc(val) 0.8672 |
Epoch 00187 | Loss(train) 0.6363 | Acc(train) 0.8521 | Acc(val) 0.8708 |*
Epoch 00188 | Loss(train) 0.6537 | Acc(train) 0.8410 | Acc(val) 0.8672 |
Epoch 00189 | Loss(train) 0.6302 | Acc(train) 0.8614 | Acc(val) 0.8635 |
Epoch 00190 | Loss(train) 0.6347 | Acc(train) 0.8540 | Acc(val) 0.8635 |
Epoch 00191 | Loss(train) 0.5950 | Acc(train) 0.8835 | Acc(val) 0.8635 |
Epoch 00192 | Loss(train) 0.6071 | Acc(train) 0.8743 | Acc(val) 0.8635 |
Epoch 00193 | Loss(train) 0.6162 | Acc(train) 0.8484 | Acc(val) 0.8672 |
Epoch 00194 | Loss(train) 0.6014 | Acc(train) 0.8799 | Acc(val) 0.8635 |
Epoch 00195 | Loss(train) 0.5991 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00196 | Loss(train) 0.5915 | Acc(train) 0.8743 | Acc(val) 0.8672 |
Epoch 00197 | Loss(train) 0.5804 | Acc(train) 0.8854 | Acc(val) 0.8672 |
Epoch 00198 | Loss(train) 0.5948 | Acc(train) 0.8854 | Acc(val) 0.8672 |
Epoch 00199 | Loss(train) 0.6129 | Acc(train) 0.8725 | Acc(val) 0.8635 |
Epoch 00200 | Loss(train) 0.6065 | Acc(train) 0.8651 | Acc(val) 0.8672 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9449 | Acc(train) 0.1608 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9302 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9117 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.8946 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8800 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8621 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8445 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8324 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8201 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8080 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.7932 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7902 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7759 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7739 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7594 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7497 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7427 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7346 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7183 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.6987 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.6970 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.7006 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00023 | Loss(train) 1.6710 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00024 | Loss(train) 1.6644 | Acc(train) 0.2884 | Acc(val) 0.3026 |*
Epoch 00025 | Loss(train) 1.6463 | Acc(train) 0.2994 | Acc(val) 0.3100 |*
Epoch 00026 | Loss(train) 1.6446 | Acc(train) 0.3031 | Acc(val) 0.3173 |*
Epoch 00027 | Loss(train) 1.6253 | Acc(train) 0.3179 | Acc(val) 0.3173 |
Epoch 00028 | Loss(train) 1.6152 | Acc(train) 0.3420 | Acc(val) 0.3284 |*
Epoch 00029 | Loss(train) 1.6057 | Acc(train) 0.3623 | Acc(val) 0.3321 |*
Epoch 00030 | Loss(train) 1.5892 | Acc(train) 0.3789 | Acc(val) 0.3469 |*
Epoch 00031 | Loss(train) 1.5805 | Acc(train) 0.4085 | Acc(val) 0.3469 |
Epoch 00032 | Loss(train) 1.5635 | Acc(train) 0.4104 | Acc(val) 0.3469 |
Epoch 00033 | Loss(train) 1.5582 | Acc(train) 0.3900 | Acc(val) 0.3506 |*
Epoch 00034 | Loss(train) 1.5445 | Acc(train) 0.4067 | Acc(val) 0.3506 |
Epoch 00035 | Loss(train) 1.5420 | Acc(train) 0.3789 | Acc(val) 0.3506 |
Epoch 00036 | Loss(train) 1.5070 | Acc(train) 0.4140 | Acc(val) 0.3653 |*
Epoch 00037 | Loss(train) 1.5014 | Acc(train) 0.4214 | Acc(val) 0.3727 |*
Epoch 00038 | Loss(train) 1.4945 | Acc(train) 0.4196 | Acc(val) 0.3727 |
Epoch 00039 | Loss(train) 1.4827 | Acc(train) 0.4455 | Acc(val) 0.3985 |*
Epoch 00040 | Loss(train) 1.4638 | Acc(train) 0.4529 | Acc(val) 0.4244 |*
Epoch 00041 | Loss(train) 1.4459 | Acc(train) 0.4732 | Acc(val) 0.4502 |*
Epoch 00042 | Loss(train) 1.4353 | Acc(train) 0.4954 | Acc(val) 0.4797 |*
Epoch 00043 | Loss(train) 1.4263 | Acc(train) 0.5231 | Acc(val) 0.5018 |*
Epoch 00044 | Loss(train) 1.4184 | Acc(train) 0.5360 | Acc(val) 0.5203 |*
Epoch 00045 | Loss(train) 1.3976 | Acc(train) 0.5638 | Acc(val) 0.5314 |*
Epoch 00046 | Loss(train) 1.3867 | Acc(train) 0.5804 | Acc(val) 0.5572 |*
Epoch 00047 | Loss(train) 1.3645 | Acc(train) 0.5989 | Acc(val) 0.5720 |*
Epoch 00048 | Loss(train) 1.3599 | Acc(train) 0.5878 | Acc(val) 0.5756 |*
Epoch 00049 | Loss(train) 1.3580 | Acc(train) 0.5860 | Acc(val) 0.5830 |*
Epoch 00050 | Loss(train) 1.3399 | Acc(train) 0.6007 | Acc(val) 0.5830 |
Epoch 00051 | Loss(train) 1.3184 | Acc(train) 0.6211 | Acc(val) 0.5941 |*
Epoch 00052 | Loss(train) 1.3215 | Acc(train) 0.6137 | Acc(val) 0.6015 |*
Epoch 00053 | Loss(train) 1.2968 | Acc(train) 0.6211 | Acc(val) 0.6162 |*
Epoch 00054 | Loss(train) 1.2884 | Acc(train) 0.6377 | Acc(val) 0.6162 |
Epoch 00055 | Loss(train) 1.2838 | Acc(train) 0.6248 | Acc(val) 0.6310 |*
Epoch 00056 | Loss(train) 1.2601 | Acc(train) 0.6543 | Acc(val) 0.6568 |*
Epoch 00057 | Loss(train) 1.2537 | Acc(train) 0.6580 | Acc(val) 0.6679 |*
Epoch 00058 | Loss(train) 1.2319 | Acc(train) 0.6747 | Acc(val) 0.6790 |*
Epoch 00059 | Loss(train) 1.2379 | Acc(train) 0.6710 | Acc(val) 0.6900 |*
Epoch 00060 | Loss(train) 1.2113 | Acc(train) 0.6932 | Acc(val) 0.6937 |*
Epoch 00061 | Loss(train) 1.1939 | Acc(train) 0.6839 | Acc(val) 0.7048 |*
Epoch 00062 | Loss(train) 1.1798 | Acc(train) 0.6895 | Acc(val) 0.7085 |*
Epoch 00063 | Loss(train) 1.1741 | Acc(train) 0.6932 | Acc(val) 0.7085 |
Epoch 00064 | Loss(train) 1.1688 | Acc(train) 0.6876 | Acc(val) 0.7085 |
Epoch 00065 | Loss(train) 1.1570 | Acc(train) 0.6987 | Acc(val) 0.7085 |
Epoch 00066 | Loss(train) 1.1430 | Acc(train) 0.6858 | Acc(val) 0.7085 |
Epoch 00067 | Loss(train) 1.1265 | Acc(train) 0.7061 | Acc(val) 0.7122 |*
Epoch 00068 | Loss(train) 1.1201 | Acc(train) 0.7079 | Acc(val) 0.7122 |
Epoch 00069 | Loss(train) 1.1052 | Acc(train) 0.7227 | Acc(val) 0.7159 |*
Epoch 00070 | Loss(train) 1.0851 | Acc(train) 0.7135 | Acc(val) 0.7232 |*
Epoch 00071 | Loss(train) 1.1077 | Acc(train) 0.7338 | Acc(val) 0.7306 |*
Epoch 00072 | Loss(train) 1.0884 | Acc(train) 0.7246 | Acc(val) 0.7306 |
Epoch 00073 | Loss(train) 1.0744 | Acc(train) 0.7301 | Acc(val) 0.7343 |*
Epoch 00074 | Loss(train) 1.0577 | Acc(train) 0.7098 | Acc(val) 0.7343 |
Epoch 00075 | Loss(train) 1.0620 | Acc(train) 0.7153 | Acc(val) 0.7380 |*
Epoch 00076 | Loss(train) 1.0190 | Acc(train) 0.7394 | Acc(val) 0.7380 |
Epoch 00077 | Loss(train) 1.0166 | Acc(train) 0.7394 | Acc(val) 0.7380 |
Epoch 00078 | Loss(train) 1.0150 | Acc(train) 0.7542 | Acc(val) 0.7417 |*
Epoch 00079 | Loss(train) 1.0152 | Acc(train) 0.7246 | Acc(val) 0.7417 |
Epoch 00080 | Loss(train) 1.0006 | Acc(train) 0.7689 | Acc(val) 0.7417 |
Epoch 00081 | Loss(train) 0.9910 | Acc(train) 0.7357 | Acc(val) 0.7417 |
Epoch 00082 | Loss(train) 0.9789 | Acc(train) 0.7634 | Acc(val) 0.7491 |*
Epoch 00083 | Loss(train) 0.9808 | Acc(train) 0.7542 | Acc(val) 0.7454 |
Epoch 00084 | Loss(train) 0.9448 | Acc(train) 0.7468 | Acc(val) 0.7565 |*
Epoch 00085 | Loss(train) 0.9539 | Acc(train) 0.7726 | Acc(val) 0.7601 |*
Epoch 00086 | Loss(train) 0.9663 | Acc(train) 0.7412 | Acc(val) 0.7601 |
Epoch 00087 | Loss(train) 0.9416 | Acc(train) 0.7560 | Acc(val) 0.7638 |*
Epoch 00088 | Loss(train) 0.9145 | Acc(train) 0.8041 | Acc(val) 0.7638 |
Epoch 00089 | Loss(train) 0.9357 | Acc(train) 0.7671 | Acc(val) 0.7638 |
Epoch 00090 | Loss(train) 0.9131 | Acc(train) 0.7763 | Acc(val) 0.7638 |
Epoch 00091 | Loss(train) 0.9125 | Acc(train) 0.7745 | Acc(val) 0.7675 |*
Epoch 00092 | Loss(train) 0.8739 | Acc(train) 0.7985 | Acc(val) 0.7712 |*
Epoch 00093 | Loss(train) 0.9032 | Acc(train) 0.8078 | Acc(val) 0.7749 |*
Epoch 00094 | Loss(train) 0.8631 | Acc(train) 0.8115 | Acc(val) 0.7860 |*
Epoch 00095 | Loss(train) 0.8663 | Acc(train) 0.7967 | Acc(val) 0.7860 |
Epoch 00096 | Loss(train) 0.8975 | Acc(train) 0.7930 | Acc(val) 0.7860 |
Epoch 00097 | Loss(train) 0.8806 | Acc(train) 0.7967 | Acc(val) 0.7934 |*
Epoch 00098 | Loss(train) 0.8609 | Acc(train) 0.8096 | Acc(val) 0.7970 |*
Epoch 00099 | Loss(train) 0.8538 | Acc(train) 0.8059 | Acc(val) 0.7970 |
Epoch 00100 | Loss(train) 0.8508 | Acc(train) 0.8078 | Acc(val) 0.8044 |*
Epoch 00101 | Loss(train) 0.8312 | Acc(train) 0.8189 | Acc(val) 0.8007 |
Epoch 00102 | Loss(train) 0.8470 | Acc(train) 0.7948 | Acc(val) 0.8044 |
Epoch 00103 | Loss(train) 0.8186 | Acc(train) 0.8244 | Acc(val) 0.8044 |
Epoch 00104 | Loss(train) 0.8333 | Acc(train) 0.8096 | Acc(val) 0.8044 |
Epoch 00105 | Loss(train) 0.8251 | Acc(train) 0.8133 | Acc(val) 0.8044 |
Epoch 00106 | Loss(train) 0.8237 | Acc(train) 0.8115 | Acc(val) 0.8044 |
Epoch 00107 | Loss(train) 0.8223 | Acc(train) 0.8004 | Acc(val) 0.8044 |
Epoch 00108 | Loss(train) 0.8051 | Acc(train) 0.8170 | Acc(val) 0.8118 |*
Epoch 00109 | Loss(train) 0.7959 | Acc(train) 0.8207 | Acc(val) 0.8155 |*
Epoch 00110 | Loss(train) 0.8109 | Acc(train) 0.8299 | Acc(val) 0.8192 |*
Epoch 00111 | Loss(train) 0.7895 | Acc(train) 0.8170 | Acc(val) 0.8229 |*
Epoch 00112 | Loss(train) 0.8063 | Acc(train) 0.8189 | Acc(val) 0.8266 |*
Epoch 00113 | Loss(train) 0.7855 | Acc(train) 0.8207 | Acc(val) 0.8303 |*
Epoch 00114 | Loss(train) 0.8034 | Acc(train) 0.8152 | Acc(val) 0.8303 |
Epoch 00115 | Loss(train) 0.7446 | Acc(train) 0.8503 | Acc(val) 0.8339 |*
Epoch 00116 | Loss(train) 0.7720 | Acc(train) 0.8447 | Acc(val) 0.8339 |
Epoch 00117 | Loss(train) 0.7475 | Acc(train) 0.8189 | Acc(val) 0.8303 |
Epoch 00118 | Loss(train) 0.7478 | Acc(train) 0.8669 | Acc(val) 0.8376 |*
Epoch 00119 | Loss(train) 0.7555 | Acc(train) 0.8318 | Acc(val) 0.8413 |*
Epoch 00120 | Loss(train) 0.7678 | Acc(train) 0.8299 | Acc(val) 0.8450 |*
Epoch 00121 | Loss(train) 0.7361 | Acc(train) 0.8484 | Acc(val) 0.8450 |
Epoch 00122 | Loss(train) 0.7532 | Acc(train) 0.8392 | Acc(val) 0.8413 |
Epoch 00123 | Loss(train) 0.7177 | Acc(train) 0.8540 | Acc(val) 0.8376 |
Epoch 00124 | Loss(train) 0.7221 | Acc(train) 0.8521 | Acc(val) 0.8376 |
Epoch 00125 | Loss(train) 0.7403 | Acc(train) 0.8484 | Acc(val) 0.8413 |
Epoch 00126 | Loss(train) 0.7376 | Acc(train) 0.8318 | Acc(val) 0.8413 |
Epoch 00127 | Loss(train) 0.7274 | Acc(train) 0.8410 | Acc(val) 0.8524 |*
Epoch 00128 | Loss(train) 0.7105 | Acc(train) 0.8540 | Acc(val) 0.8524 |
Epoch 00129 | Loss(train) 0.7034 | Acc(train) 0.8558 | Acc(val) 0.8561 |*
Epoch 00130 | Loss(train) 0.7247 | Acc(train) 0.8373 | Acc(val) 0.8561 |
Epoch 00131 | Loss(train) 0.6906 | Acc(train) 0.8688 | Acc(val) 0.8561 |
Epoch 00132 | Loss(train) 0.6858 | Acc(train) 0.8651 | Acc(val) 0.8561 |
Epoch 00133 | Loss(train) 0.6850 | Acc(train) 0.8429 | Acc(val) 0.8487 |
Epoch 00134 | Loss(train) 0.6916 | Acc(train) 0.8632 | Acc(val) 0.8487 |
Epoch 00135 | Loss(train) 0.6883 | Acc(train) 0.8651 | Acc(val) 0.8487 |
Epoch 00136 | Loss(train) 0.6923 | Acc(train) 0.8447 | Acc(val) 0.8450 |
Epoch 00137 | Loss(train) 0.6948 | Acc(train) 0.8262 | Acc(val) 0.8450 |
Epoch 00138 | Loss(train) 0.6836 | Acc(train) 0.8595 | Acc(val) 0.8487 |
Epoch 00139 | Loss(train) 0.6863 | Acc(train) 0.8595 | Acc(val) 0.8487 |
Epoch 00140 | Loss(train) 0.6886 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00141 | Loss(train) 0.6820 | Acc(train) 0.8484 | Acc(val) 0.8487 |
Epoch 00142 | Loss(train) 0.6690 | Acc(train) 0.8632 | Acc(val) 0.8487 |
Epoch 00143 | Loss(train) 0.6787 | Acc(train) 0.8429 | Acc(val) 0.8487 |
Epoch 00144 | Loss(train) 0.6536 | Acc(train) 0.8762 | Acc(val) 0.8487 |
Epoch 00145 | Loss(train) 0.6578 | Acc(train) 0.8521 | Acc(val) 0.8487 |
Epoch 00146 | Loss(train) 0.6706 | Acc(train) 0.8595 | Acc(val) 0.8487 |
Epoch 00147 | Loss(train) 0.6902 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00148 | Loss(train) 0.6661 | Acc(train) 0.8651 | Acc(val) 0.8487 |
Epoch 00149 | Loss(train) 0.6763 | Acc(train) 0.8577 | Acc(val) 0.8487 |
Epoch 00150 | Loss(train) 0.6477 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00151 | Loss(train) 0.6515 | Acc(train) 0.8632 | Acc(val) 0.8524 |
Epoch 00152 | Loss(train) 0.6476 | Acc(train) 0.8854 | Acc(val) 0.8524 |
Epoch 00153 | Loss(train) 0.6271 | Acc(train) 0.8762 | Acc(val) 0.8524 |
Epoch 00154 | Loss(train) 0.6368 | Acc(train) 0.8595 | Acc(val) 0.8487 |
Epoch 00155 | Loss(train) 0.6376 | Acc(train) 0.8743 | Acc(val) 0.8450 |
Epoch 00156 | Loss(train) 0.6413 | Acc(train) 0.8743 | Acc(val) 0.8450 |
Epoch 00157 | Loss(train) 0.6272 | Acc(train) 0.8780 | Acc(val) 0.8450 |
Epoch 00158 | Loss(train) 0.6437 | Acc(train) 0.8669 | Acc(val) 0.8524 |
Epoch 00159 | Loss(train) 0.6364 | Acc(train) 0.8651 | Acc(val) 0.8561 |
Epoch 00160 | Loss(train) 0.6069 | Acc(train) 0.8799 | Acc(val) 0.8561 |
Epoch 00161 | Loss(train) 0.6290 | Acc(train) 0.8651 | Acc(val) 0.8561 |
Epoch 00162 | Loss(train) 0.6147 | Acc(train) 0.8743 | Acc(val) 0.8524 |
Epoch 00163 | Loss(train) 0.6093 | Acc(train) 0.8706 | Acc(val) 0.8524 |
Epoch 00164 | Loss(train) 0.6447 | Acc(train) 0.8762 | Acc(val) 0.8524 |
Epoch 00165 | Loss(train) 0.6333 | Acc(train) 0.8558 | Acc(val) 0.8635 |*
Epoch 00166 | Loss(train) 0.6064 | Acc(train) 0.8872 | Acc(val) 0.8635 |
Epoch 00167 | Loss(train) 0.6174 | Acc(train) 0.8725 | Acc(val) 0.8635 |
Epoch 00168 | Loss(train) 0.6086 | Acc(train) 0.8891 | Acc(val) 0.8598 |
Epoch 00169 | Loss(train) 0.5952 | Acc(train) 0.8743 | Acc(val) 0.8561 |
Epoch 00170 | Loss(train) 0.6185 | Acc(train) 0.8928 | Acc(val) 0.8561 |
Epoch 00171 | Loss(train) 0.6263 | Acc(train) 0.8780 | Acc(val) 0.8635 |
Epoch 00172 | Loss(train) 0.5975 | Acc(train) 0.8799 | Acc(val) 0.8635 |
Epoch 00173 | Loss(train) 0.5961 | Acc(train) 0.8817 | Acc(val) 0.8598 |
Epoch 00174 | Loss(train) 0.6096 | Acc(train) 0.8799 | Acc(val) 0.8561 |
Epoch 00175 | Loss(train) 0.5873 | Acc(train) 0.8817 | Acc(val) 0.8561 |
Epoch 00176 | Loss(train) 0.5853 | Acc(train) 0.8817 | Acc(val) 0.8598 |
Epoch 00177 | Loss(train) 0.6036 | Acc(train) 0.8651 | Acc(val) 0.8635 |
Epoch 00178 | Loss(train) 0.5769 | Acc(train) 0.8854 | Acc(val) 0.8635 |
Epoch 00179 | Loss(train) 0.5999 | Acc(train) 0.8743 | Acc(val) 0.8598 |
Epoch 00180 | Loss(train) 0.5789 | Acc(train) 0.8835 | Acc(val) 0.8598 |
Epoch 00181 | Loss(train) 0.5877 | Acc(train) 0.8706 | Acc(val) 0.8598 |
Epoch 00182 | Loss(train) 0.6014 | Acc(train) 0.8725 | Acc(val) 0.8598 |
Epoch 00183 | Loss(train) 0.5822 | Acc(train) 0.8688 | Acc(val) 0.8635 |
Epoch 00184 | Loss(train) 0.5812 | Acc(train) 0.8909 | Acc(val) 0.8635 |
Epoch 00185 | Loss(train) 0.5659 | Acc(train) 0.8983 | Acc(val) 0.8635 |
Epoch 00186 | Loss(train) 0.5784 | Acc(train) 0.8854 | Acc(val) 0.8598 |
Epoch 00187 | Loss(train) 0.5775 | Acc(train) 0.8799 | Acc(val) 0.8598 |
Epoch 00188 | Loss(train) 0.5644 | Acc(train) 0.8817 | Acc(val) 0.8598 |
Epoch 00189 | Loss(train) 0.5743 | Acc(train) 0.8799 | Acc(val) 0.8635 |
Epoch 00190 | Loss(train) 0.5825 | Acc(train) 0.8725 | Acc(val) 0.8672 |*
Epoch 00191 | Loss(train) 0.5510 | Acc(train) 0.8909 | Acc(val) 0.8598 |
Epoch 00192 | Loss(train) 0.5681 | Acc(train) 0.8965 | Acc(val) 0.8635 |
Epoch 00193 | Loss(train) 0.5782 | Acc(train) 0.8817 | Acc(val) 0.8672 |
Epoch 00194 | Loss(train) 0.5738 | Acc(train) 0.8725 | Acc(val) 0.8635 |
Epoch 00195 | Loss(train) 0.5760 | Acc(train) 0.8817 | Acc(val) 0.8635 |
Epoch 00196 | Loss(train) 0.5645 | Acc(train) 0.8946 | Acc(val) 0.8635 |
Epoch 00197 | Loss(train) 0.5510 | Acc(train) 0.8799 | Acc(val) 0.8635 |
Epoch 00198 | Loss(train) 0.5723 | Acc(train) 0.8872 | Acc(val) 0.8561 |
Epoch 00199 | Loss(train) 0.5529 | Acc(train) 0.9039 | Acc(val) 0.8561 |
Epoch 00200 | Loss(train) 0.5472 | Acc(train) 0.8854 | Acc(val) 0.8561 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9457 | Acc(train) 0.1201 | Acc(val) 0.3026 |*
Epoch 00002 | Loss(train) 1.9348 | Acc(train) 0.3013 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9234 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9115 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8971 | Acc(train) 0.2976 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8837 | Acc(train) 0.3105 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8687 | Acc(train) 0.2957 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8546 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8458 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8300 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8170 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7966 | Acc(train) 0.3031 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7951 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7774 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7742 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7596 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7487 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7386 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7304 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7167 | Acc(train) 0.2957 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.7165 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.7055 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00023 | Loss(train) 1.6866 | Acc(train) 0.3031 | Acc(val) 0.2989 |
Epoch 00024 | Loss(train) 1.6794 | Acc(train) 0.2957 | Acc(val) 0.3026 |
Epoch 00025 | Loss(train) 1.6667 | Acc(train) 0.2976 | Acc(val) 0.3137 |*
Epoch 00026 | Loss(train) 1.6528 | Acc(train) 0.3216 | Acc(val) 0.3137 |
Epoch 00027 | Loss(train) 1.6383 | Acc(train) 0.3216 | Acc(val) 0.3173 |*
Epoch 00028 | Loss(train) 1.6305 | Acc(train) 0.3457 | Acc(val) 0.3210 |*
Epoch 00029 | Loss(train) 1.6257 | Acc(train) 0.3586 | Acc(val) 0.3358 |*
Epoch 00030 | Loss(train) 1.5987 | Acc(train) 0.3697 | Acc(val) 0.3432 |*
Epoch 00031 | Loss(train) 1.5768 | Acc(train) 0.4011 | Acc(val) 0.3506 |*
Epoch 00032 | Loss(train) 1.5848 | Acc(train) 0.4030 | Acc(val) 0.3542 |*
Epoch 00033 | Loss(train) 1.5644 | Acc(train) 0.4085 | Acc(val) 0.3727 |*
Epoch 00034 | Loss(train) 1.5487 | Acc(train) 0.4436 | Acc(val) 0.3838 |*
Epoch 00035 | Loss(train) 1.5377 | Acc(train) 0.4307 | Acc(val) 0.3875 |*
Epoch 00036 | Loss(train) 1.5336 | Acc(train) 0.4510 | Acc(val) 0.4059 |*
Epoch 00037 | Loss(train) 1.5104 | Acc(train) 0.4677 | Acc(val) 0.4207 |*
Epoch 00038 | Loss(train) 1.5010 | Acc(train) 0.4750 | Acc(val) 0.4317 |*
Epoch 00039 | Loss(train) 1.4774 | Acc(train) 0.5009 | Acc(val) 0.4465 |*
Epoch 00040 | Loss(train) 1.4792 | Acc(train) 0.5065 | Acc(val) 0.4539 |*
Epoch 00041 | Loss(train) 1.4577 | Acc(train) 0.5139 | Acc(val) 0.4539 |
Epoch 00042 | Loss(train) 1.4526 | Acc(train) 0.5157 | Acc(val) 0.4723 |*
Epoch 00043 | Loss(train) 1.4558 | Acc(train) 0.5083 | Acc(val) 0.5018 |*
Epoch 00044 | Loss(train) 1.4046 | Acc(train) 0.5397 | Acc(val) 0.5166 |*
Epoch 00045 | Loss(train) 1.4089 | Acc(train) 0.5638 | Acc(val) 0.5424 |*
Epoch 00046 | Loss(train) 1.3802 | Acc(train) 0.5675 | Acc(val) 0.5535 |*
Epoch 00047 | Loss(train) 1.3903 | Acc(train) 0.5896 | Acc(val) 0.5646 |*
Epoch 00048 | Loss(train) 1.3711 | Acc(train) 0.5508 | Acc(val) 0.5720 |*
Epoch 00049 | Loss(train) 1.3535 | Acc(train) 0.5767 | Acc(val) 0.5720 |
Epoch 00050 | Loss(train) 1.3464 | Acc(train) 0.5823 | Acc(val) 0.5830 |*
Epoch 00051 | Loss(train) 1.3213 | Acc(train) 0.6303 | Acc(val) 0.5904 |*
Epoch 00052 | Loss(train) 1.3111 | Acc(train) 0.6192 | Acc(val) 0.5941 |*
Epoch 00053 | Loss(train) 1.3145 | Acc(train) 0.6044 | Acc(val) 0.5941 |
Epoch 00054 | Loss(train) 1.2875 | Acc(train) 0.6211 | Acc(val) 0.6052 |*
Epoch 00055 | Loss(train) 1.2961 | Acc(train) 0.6192 | Acc(val) 0.6125 |*
Epoch 00056 | Loss(train) 1.2461 | Acc(train) 0.6470 | Acc(val) 0.6347 |*
Epoch 00057 | Loss(train) 1.2499 | Acc(train) 0.6433 | Acc(val) 0.6384 |*
Epoch 00058 | Loss(train) 1.2262 | Acc(train) 0.6747 | Acc(val) 0.6421 |*
Epoch 00059 | Loss(train) 1.2131 | Acc(train) 0.6599 | Acc(val) 0.6605 |*
Epoch 00060 | Loss(train) 1.2046 | Acc(train) 0.6451 | Acc(val) 0.6716 |*
Epoch 00061 | Loss(train) 1.2248 | Acc(train) 0.6543 | Acc(val) 0.6716 |
Epoch 00062 | Loss(train) 1.2041 | Acc(train) 0.6525 | Acc(val) 0.6900 |*
Epoch 00063 | Loss(train) 1.2003 | Acc(train) 0.6876 | Acc(val) 0.7048 |*
Epoch 00064 | Loss(train) 1.1810 | Acc(train) 0.6728 | Acc(val) 0.7048 |
Epoch 00065 | Loss(train) 1.1691 | Acc(train) 0.7061 | Acc(val) 0.7085 |*
Epoch 00066 | Loss(train) 1.1602 | Acc(train) 0.6802 | Acc(val) 0.7122 |*
Epoch 00067 | Loss(train) 1.1339 | Acc(train) 0.7153 | Acc(val) 0.7122 |
Epoch 00068 | Loss(train) 1.1207 | Acc(train) 0.7024 | Acc(val) 0.7122 |
Epoch 00069 | Loss(train) 1.1251 | Acc(train) 0.7190 | Acc(val) 0.7122 |
Epoch 00070 | Loss(train) 1.1004 | Acc(train) 0.7190 | Acc(val) 0.7122 |
Epoch 00071 | Loss(train) 1.1172 | Acc(train) 0.7024 | Acc(val) 0.7196 |*
Epoch 00072 | Loss(train) 1.0763 | Acc(train) 0.7135 | Acc(val) 0.7343 |*
Epoch 00073 | Loss(train) 1.0751 | Acc(train) 0.7098 | Acc(val) 0.7491 |*
Epoch 00074 | Loss(train) 1.0518 | Acc(train) 0.7301 | Acc(val) 0.7565 |*
Epoch 00075 | Loss(train) 1.0643 | Acc(train) 0.7357 | Acc(val) 0.7601 |*
Epoch 00076 | Loss(train) 1.0439 | Acc(train) 0.7412 | Acc(val) 0.7675 |*
Epoch 00077 | Loss(train) 1.0196 | Acc(train) 0.7394 | Acc(val) 0.7675 |
Epoch 00078 | Loss(train) 1.0482 | Acc(train) 0.7375 | Acc(val) 0.7675 |
Epoch 00079 | Loss(train) 1.0202 | Acc(train) 0.7616 | Acc(val) 0.7712 |*
Epoch 00080 | Loss(train) 1.0067 | Acc(train) 0.7431 | Acc(val) 0.7712 |
Epoch 00081 | Loss(train) 0.9923 | Acc(train) 0.7542 | Acc(val) 0.7786 |*
Epoch 00082 | Loss(train) 0.9913 | Acc(train) 0.7431 | Acc(val) 0.7860 |*
Epoch 00083 | Loss(train) 0.9914 | Acc(train) 0.7431 | Acc(val) 0.7897 |*
Epoch 00084 | Loss(train) 0.9858 | Acc(train) 0.7560 | Acc(val) 0.7897 |
Epoch 00085 | Loss(train) 0.9588 | Acc(train) 0.7837 | Acc(val) 0.7897 |
Epoch 00086 | Loss(train) 0.9860 | Acc(train) 0.7542 | Acc(val) 0.7897 |
Epoch 00087 | Loss(train) 0.9492 | Acc(train) 0.7800 | Acc(val) 0.7860 |
Epoch 00088 | Loss(train) 0.9519 | Acc(train) 0.7634 | Acc(val) 0.7860 |
Epoch 00089 | Loss(train) 0.9379 | Acc(train) 0.7708 | Acc(val) 0.7860 |
Epoch 00090 | Loss(train) 0.9223 | Acc(train) 0.7763 | Acc(val) 0.7897 |
Epoch 00091 | Loss(train) 0.9447 | Acc(train) 0.7726 | Acc(val) 0.7934 |*
Epoch 00092 | Loss(train) 0.9061 | Acc(train) 0.7967 | Acc(val) 0.8044 |*
Epoch 00093 | Loss(train) 0.8959 | Acc(train) 0.7689 | Acc(val) 0.8118 |*
Epoch 00094 | Loss(train) 0.8849 | Acc(train) 0.7985 | Acc(val) 0.8192 |*
Epoch 00095 | Loss(train) 0.9067 | Acc(train) 0.7856 | Acc(val) 0.8192 |
Epoch 00096 | Loss(train) 0.8977 | Acc(train) 0.7911 | Acc(val) 0.8192 |
Epoch 00097 | Loss(train) 0.8743 | Acc(train) 0.7967 | Acc(val) 0.8155 |
Epoch 00098 | Loss(train) 0.8836 | Acc(train) 0.7874 | Acc(val) 0.8155 |
Epoch 00099 | Loss(train) 0.8769 | Acc(train) 0.8004 | Acc(val) 0.8155 |
Epoch 00100 | Loss(train) 0.8850 | Acc(train) 0.7967 | Acc(val) 0.8118 |
Epoch 00101 | Loss(train) 0.8634 | Acc(train) 0.7893 | Acc(val) 0.8081 |
Epoch 00102 | Loss(train) 0.8463 | Acc(train) 0.8004 | Acc(val) 0.8081 |
Epoch 00103 | Loss(train) 0.8635 | Acc(train) 0.7911 | Acc(val) 0.8155 |
Epoch 00104 | Loss(train) 0.8499 | Acc(train) 0.8096 | Acc(val) 0.8155 |
Epoch 00105 | Loss(train) 0.8204 | Acc(train) 0.8355 | Acc(val) 0.8155 |
Epoch 00106 | Loss(train) 0.8368 | Acc(train) 0.8041 | Acc(val) 0.8192 |
Epoch 00107 | Loss(train) 0.8476 | Acc(train) 0.8041 | Acc(val) 0.8229 |*
Epoch 00108 | Loss(train) 0.8019 | Acc(train) 0.8299 | Acc(val) 0.8266 |*
Epoch 00109 | Loss(train) 0.8003 | Acc(train) 0.8299 | Acc(val) 0.8303 |*
Epoch 00110 | Loss(train) 0.8011 | Acc(train) 0.8336 | Acc(val) 0.8339 |*
Epoch 00111 | Loss(train) 0.8098 | Acc(train) 0.8281 | Acc(val) 0.8413 |*
Epoch 00112 | Loss(train) 0.8066 | Acc(train) 0.8059 | Acc(val) 0.8413 |
Epoch 00113 | Loss(train) 0.8034 | Acc(train) 0.8022 | Acc(val) 0.8413 |
Epoch 00114 | Loss(train) 0.8116 | Acc(train) 0.7893 | Acc(val) 0.8413 |
Epoch 00115 | Loss(train) 0.7696 | Acc(train) 0.8262 | Acc(val) 0.8487 |*
Epoch 00116 | Loss(train) 0.7667 | Acc(train) 0.8447 | Acc(val) 0.8524 |*
Epoch 00117 | Loss(train) 0.7831 | Acc(train) 0.8410 | Acc(val) 0.8524 |
Epoch 00118 | Loss(train) 0.7436 | Acc(train) 0.8632 | Acc(val) 0.8487 |
Epoch 00119 | Loss(train) 0.7752 | Acc(train) 0.8336 | Acc(val) 0.8487 |
Epoch 00120 | Loss(train) 0.7739 | Acc(train) 0.8281 | Acc(val) 0.8487 |
Epoch 00121 | Loss(train) 0.7316 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00122 | Loss(train) 0.7436 | Acc(train) 0.8484 | Acc(val) 0.8524 |
Epoch 00123 | Loss(train) 0.7525 | Acc(train) 0.8336 | Acc(val) 0.8561 |*
Epoch 00124 | Loss(train) 0.7484 | Acc(train) 0.8189 | Acc(val) 0.8598 |*
Epoch 00125 | Loss(train) 0.7422 | Acc(train) 0.8281 | Acc(val) 0.8598 |
Epoch 00126 | Loss(train) 0.7288 | Acc(train) 0.8577 | Acc(val) 0.8561 |
Epoch 00127 | Loss(train) 0.7311 | Acc(train) 0.8503 | Acc(val) 0.8561 |
Epoch 00128 | Loss(train) 0.7189 | Acc(train) 0.8447 | Acc(val) 0.8598 |
Epoch 00129 | Loss(train) 0.6891 | Acc(train) 0.8632 | Acc(val) 0.8635 |*
Epoch 00130 | Loss(train) 0.7210 | Acc(train) 0.8410 | Acc(val) 0.8708 |*
Epoch 00131 | Loss(train) 0.7134 | Acc(train) 0.8373 | Acc(val) 0.8708 |
Epoch 00132 | Loss(train) 0.7080 | Acc(train) 0.8632 | Acc(val) 0.8708 |
Epoch 00133 | Loss(train) 0.7243 | Acc(train) 0.8355 | Acc(val) 0.8708 |
Epoch 00134 | Loss(train) 0.7024 | Acc(train) 0.8521 | Acc(val) 0.8672 |
Epoch 00135 | Loss(train) 0.7211 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00136 | Loss(train) 0.7048 | Acc(train) 0.8410 | Acc(val) 0.8672 |
Epoch 00137 | Loss(train) 0.6875 | Acc(train) 0.8688 | Acc(val) 0.8635 |
Epoch 00138 | Loss(train) 0.6822 | Acc(train) 0.8614 | Acc(val) 0.8635 |
Epoch 00139 | Loss(train) 0.6958 | Acc(train) 0.8392 | Acc(val) 0.8635 |
Epoch 00140 | Loss(train) 0.7031 | Acc(train) 0.8577 | Acc(val) 0.8672 |
Epoch 00141 | Loss(train) 0.6858 | Acc(train) 0.8521 | Acc(val) 0.8672 |
Epoch 00142 | Loss(train) 0.7077 | Acc(train) 0.8558 | Acc(val) 0.8672 |
Epoch 00143 | Loss(train) 0.6838 | Acc(train) 0.8484 | Acc(val) 0.8672 |
Epoch 00144 | Loss(train) 0.6858 | Acc(train) 0.8558 | Acc(val) 0.8672 |
Epoch 00145 | Loss(train) 0.6614 | Acc(train) 0.8706 | Acc(val) 0.8635 |
Epoch 00146 | Loss(train) 0.6803 | Acc(train) 0.8540 | Acc(val) 0.8672 |
Epoch 00147 | Loss(train) 0.6741 | Acc(train) 0.8595 | Acc(val) 0.8672 |
Epoch 00148 | Loss(train) 0.6574 | Acc(train) 0.8706 | Acc(val) 0.8708 |
Epoch 00149 | Loss(train) 0.6856 | Acc(train) 0.8614 | Acc(val) 0.8745 |*
Epoch 00150 | Loss(train) 0.6666 | Acc(train) 0.8651 | Acc(val) 0.8708 |
Epoch 00151 | Loss(train) 0.6487 | Acc(train) 0.8706 | Acc(val) 0.8745 |
Epoch 00152 | Loss(train) 0.6803 | Acc(train) 0.8466 | Acc(val) 0.8745 |
Epoch 00153 | Loss(train) 0.6662 | Acc(train) 0.8632 | Acc(val) 0.8782 |*
Epoch 00154 | Loss(train) 0.6532 | Acc(train) 0.8595 | Acc(val) 0.8745 |
Epoch 00155 | Loss(train) 0.6653 | Acc(train) 0.8688 | Acc(val) 0.8708 |
Epoch 00156 | Loss(train) 0.6485 | Acc(train) 0.8614 | Acc(val) 0.8708 |
Epoch 00157 | Loss(train) 0.6415 | Acc(train) 0.8872 | Acc(val) 0.8745 |
Epoch 00158 | Loss(train) 0.6539 | Acc(train) 0.8669 | Acc(val) 0.8782 |
Epoch 00159 | Loss(train) 0.6450 | Acc(train) 0.8688 | Acc(val) 0.8782 |
Epoch 00160 | Loss(train) 0.6440 | Acc(train) 0.8632 | Acc(val) 0.8745 |
Epoch 00161 | Loss(train) 0.6195 | Acc(train) 0.8891 | Acc(val) 0.8745 |
Epoch 00162 | Loss(train) 0.6818 | Acc(train) 0.8484 | Acc(val) 0.8745 |
Epoch 00163 | Loss(train) 0.6460 | Acc(train) 0.8614 | Acc(val) 0.8745 |
Epoch 00164 | Loss(train) 0.6251 | Acc(train) 0.8928 | Acc(val) 0.8782 |
Epoch 00165 | Loss(train) 0.6242 | Acc(train) 0.8780 | Acc(val) 0.8856 |*
Epoch 00166 | Loss(train) 0.6336 | Acc(train) 0.8891 | Acc(val) 0.8893 |*
Epoch 00167 | Loss(train) 0.6210 | Acc(train) 0.8835 | Acc(val) 0.8856 |
Epoch 00168 | Loss(train) 0.6162 | Acc(train) 0.8688 | Acc(val) 0.8819 |
Epoch 00169 | Loss(train) 0.6116 | Acc(train) 0.8762 | Acc(val) 0.8782 |
Epoch 00170 | Loss(train) 0.6348 | Acc(train) 0.8725 | Acc(val) 0.8782 |
Epoch 00171 | Loss(train) 0.6031 | Acc(train) 0.8872 | Acc(val) 0.8782 |
Epoch 00172 | Loss(train) 0.6227 | Acc(train) 0.8780 | Acc(val) 0.8745 |
Epoch 00173 | Loss(train) 0.5994 | Acc(train) 0.8762 | Acc(val) 0.8782 |
Epoch 00174 | Loss(train) 0.6145 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00175 | Loss(train) 0.5679 | Acc(train) 0.9076 | Acc(val) 0.8745 |
Epoch 00176 | Loss(train) 0.6349 | Acc(train) 0.8762 | Acc(val) 0.8819 |
Epoch 00177 | Loss(train) 0.6268 | Acc(train) 0.8669 | Acc(val) 0.8782 |
Epoch 00178 | Loss(train) 0.6220 | Acc(train) 0.8909 | Acc(val) 0.8819 |
Epoch 00179 | Loss(train) 0.5971 | Acc(train) 0.8854 | Acc(val) 0.8856 |
Epoch 00180 | Loss(train) 0.5955 | Acc(train) 0.8817 | Acc(val) 0.8819 |
Epoch 00181 | Loss(train) 0.5965 | Acc(train) 0.8706 | Acc(val) 0.8782 |
Epoch 00182 | Loss(train) 0.5880 | Acc(train) 0.8817 | Acc(val) 0.8782 |
Epoch 00183 | Loss(train) 0.5998 | Acc(train) 0.8725 | Acc(val) 0.8782 |
Epoch 00184 | Loss(train) 0.6022 | Acc(train) 0.8632 | Acc(val) 0.8819 |
Epoch 00185 | Loss(train) 0.5783 | Acc(train) 0.8854 | Acc(val) 0.8819 |
Epoch 00186 | Loss(train) 0.5797 | Acc(train) 0.8780 | Acc(val) 0.8856 |
Epoch 00187 | Loss(train) 0.6052 | Acc(train) 0.8835 | Acc(val) 0.8856 |
Epoch 00188 | Loss(train) 0.5631 | Acc(train) 0.8946 | Acc(val) 0.8856 |
Epoch 00189 | Loss(train) 0.5640 | Acc(train) 0.8799 | Acc(val) 0.8856 |
Epoch 00190 | Loss(train) 0.5779 | Acc(train) 0.8799 | Acc(val) 0.8856 |
Epoch 00191 | Loss(train) 0.5953 | Acc(train) 0.8688 | Acc(val) 0.8819 |
Epoch 00192 | Loss(train) 0.5816 | Acc(train) 0.8854 | Acc(val) 0.8819 |
Epoch 00193 | Loss(train) 0.5765 | Acc(train) 0.8891 | Acc(val) 0.8856 |
Epoch 00194 | Loss(train) 0.6234 | Acc(train) 0.8521 | Acc(val) 0.8856 |
Epoch 00195 | Loss(train) 0.5492 | Acc(train) 0.8817 | Acc(val) 0.8856 |
Epoch 00196 | Loss(train) 0.5721 | Acc(train) 0.8872 | Acc(val) 0.8856 |
Epoch 00197 | Loss(train) 0.5954 | Acc(train) 0.8725 | Acc(val) 0.8856 |
Epoch 00198 | Loss(train) 0.5582 | Acc(train) 0.9002 | Acc(val) 0.8819 |
Epoch 00199 | Loss(train) 0.5616 | Acc(train) 0.9113 | Acc(val) 0.8856 |
Epoch 00200 | Loss(train) 0.5601 | Acc(train) 0.8909 | Acc(val) 0.8856 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9454 | Acc(train) 0.1756 | Acc(val) 0.2804 |*
Epoch 00002 | Loss(train) 1.9347 | Acc(train) 0.3198 | Acc(val) 0.3911 |*
Epoch 00003 | Loss(train) 1.9224 | Acc(train) 0.3216 | Acc(val) 0.3284 |
Epoch 00004 | Loss(train) 1.9115 | Acc(train) 0.3272 | Acc(val) 0.3100 |
Epoch 00005 | Loss(train) 1.8973 | Acc(train) 0.3309 | Acc(val) 0.3026 |
Epoch 00006 | Loss(train) 1.8844 | Acc(train) 0.3364 | Acc(val) 0.3026 |
Epoch 00007 | Loss(train) 1.8719 | Acc(train) 0.3124 | Acc(val) 0.3026 |
Epoch 00008 | Loss(train) 1.8585 | Acc(train) 0.2976 | Acc(val) 0.3026 |
Epoch 00009 | Loss(train) 1.8400 | Acc(train) 0.3142 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8283 | Acc(train) 0.3050 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8178 | Acc(train) 0.3142 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7985 | Acc(train) 0.3013 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7907 | Acc(train) 0.3031 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7836 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7680 | Acc(train) 0.3050 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7630 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7557 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7397 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7386 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7139 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.7117 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.6983 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00023 | Loss(train) 1.6882 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00024 | Loss(train) 1.6773 | Acc(train) 0.2957 | Acc(val) 0.2989 |
Epoch 00025 | Loss(train) 1.6609 | Acc(train) 0.3179 | Acc(val) 0.3063 |
Epoch 00026 | Loss(train) 1.6485 | Acc(train) 0.3198 | Acc(val) 0.3063 |
Epoch 00027 | Loss(train) 1.6479 | Acc(train) 0.3420 | Acc(val) 0.3173 |
Epoch 00028 | Loss(train) 1.6280 | Acc(train) 0.3660 | Acc(val) 0.3321 |
Epoch 00029 | Loss(train) 1.6090 | Acc(train) 0.3641 | Acc(val) 0.3432 |
Epoch 00030 | Loss(train) 1.6039 | Acc(train) 0.3974 | Acc(val) 0.3506 |
Epoch 00031 | Loss(train) 1.5841 | Acc(train) 0.4344 | Acc(val) 0.3542 |
Epoch 00032 | Loss(train) 1.5716 | Acc(train) 0.4529 | Acc(val) 0.3616 |
Epoch 00033 | Loss(train) 1.5454 | Acc(train) 0.4584 | Acc(val) 0.4059 |*
Epoch 00034 | Loss(train) 1.5378 | Acc(train) 0.4769 | Acc(val) 0.4207 |*
Epoch 00035 | Loss(train) 1.5283 | Acc(train) 0.4972 | Acc(val) 0.4502 |*
Epoch 00036 | Loss(train) 1.5179 | Acc(train) 0.5083 | Acc(val) 0.4760 |*
Epoch 00037 | Loss(train) 1.5090 | Acc(train) 0.5065 | Acc(val) 0.5092 |*
Epoch 00038 | Loss(train) 1.4843 | Acc(train) 0.5139 | Acc(val) 0.5351 |*
Epoch 00039 | Loss(train) 1.4738 | Acc(train) 0.5582 | Acc(val) 0.5609 |*
Epoch 00040 | Loss(train) 1.4717 | Acc(train) 0.5582 | Acc(val) 0.5720 |*
Epoch 00041 | Loss(train) 1.4435 | Acc(train) 0.5730 | Acc(val) 0.5756 |*
Epoch 00042 | Loss(train) 1.4421 | Acc(train) 0.5656 | Acc(val) 0.5793 |*
Epoch 00043 | Loss(train) 1.4373 | Acc(train) 0.5564 | Acc(val) 0.5904 |*
Epoch 00044 | Loss(train) 1.3943 | Acc(train) 0.5952 | Acc(val) 0.5904 |
Epoch 00045 | Loss(train) 1.3769 | Acc(train) 0.6044 | Acc(val) 0.6125 |*
Epoch 00046 | Loss(train) 1.3667 | Acc(train) 0.5970 | Acc(val) 0.6125 |
Epoch 00047 | Loss(train) 1.3599 | Acc(train) 0.6155 | Acc(val) 0.6125 |
Epoch 00048 | Loss(train) 1.3410 | Acc(train) 0.6359 | Acc(val) 0.6236 |*
Epoch 00049 | Loss(train) 1.3259 | Acc(train) 0.6488 | Acc(val) 0.6273 |*
Epoch 00050 | Loss(train) 1.3145 | Acc(train) 0.6340 | Acc(val) 0.6273 |
Epoch 00051 | Loss(train) 1.3028 | Acc(train) 0.6673 | Acc(val) 0.6347 |*
Epoch 00052 | Loss(train) 1.2901 | Acc(train) 0.6451 | Acc(val) 0.6458 |*
Epoch 00053 | Loss(train) 1.2698 | Acc(train) 0.6636 | Acc(val) 0.6642 |*
Epoch 00054 | Loss(train) 1.2426 | Acc(train) 0.6617 | Acc(val) 0.6716 |*
Epoch 00055 | Loss(train) 1.2130 | Acc(train) 0.6821 | Acc(val) 0.6900 |*
Epoch 00056 | Loss(train) 1.2197 | Acc(train) 0.6580 | Acc(val) 0.6937 |*
Epoch 00057 | Loss(train) 1.2238 | Acc(train) 0.6691 | Acc(val) 0.7011 |*
Epoch 00058 | Loss(train) 1.1924 | Acc(train) 0.6969 | Acc(val) 0.7011 |
Epoch 00059 | Loss(train) 1.1942 | Acc(train) 0.6802 | Acc(val) 0.6937 |
Epoch 00060 | Loss(train) 1.1808 | Acc(train) 0.6950 | Acc(val) 0.6937 |
Epoch 00061 | Loss(train) 1.1512 | Acc(train) 0.7043 | Acc(val) 0.7122 |*
Epoch 00062 | Loss(train) 1.1482 | Acc(train) 0.7135 | Acc(val) 0.7122 |
Epoch 00063 | Loss(train) 1.1432 | Acc(train) 0.6987 | Acc(val) 0.7159 |*
Epoch 00064 | Loss(train) 1.1223 | Acc(train) 0.6969 | Acc(val) 0.7159 |
Epoch 00065 | Loss(train) 1.1169 | Acc(train) 0.7135 | Acc(val) 0.7232 |*
Epoch 00066 | Loss(train) 1.1062 | Acc(train) 0.7172 | Acc(val) 0.7306 |*
Epoch 00067 | Loss(train) 1.0965 | Acc(train) 0.7246 | Acc(val) 0.7380 |*
Epoch 00068 | Loss(train) 1.0761 | Acc(train) 0.7357 | Acc(val) 0.7454 |*
Epoch 00069 | Loss(train) 1.0640 | Acc(train) 0.7449 | Acc(val) 0.7454 |
Epoch 00070 | Loss(train) 1.0486 | Acc(train) 0.7357 | Acc(val) 0.7491 |*
Epoch 00071 | Loss(train) 1.0360 | Acc(train) 0.7431 | Acc(val) 0.7565 |*
Epoch 00072 | Loss(train) 1.0412 | Acc(train) 0.7301 | Acc(val) 0.7601 |*
Epoch 00073 | Loss(train) 1.0374 | Acc(train) 0.7301 | Acc(val) 0.7638 |*
Epoch 00074 | Loss(train) 1.0158 | Acc(train) 0.7468 | Acc(val) 0.7675 |*
Epoch 00075 | Loss(train) 0.9925 | Acc(train) 0.7560 | Acc(val) 0.7675 |
Epoch 00076 | Loss(train) 0.9818 | Acc(train) 0.7763 | Acc(val) 0.7749 |*
Epoch 00077 | Loss(train) 0.9896 | Acc(train) 0.7782 | Acc(val) 0.7786 |*
Epoch 00078 | Loss(train) 0.9573 | Acc(train) 0.7652 | Acc(val) 0.7786 |
Epoch 00079 | Loss(train) 0.9810 | Acc(train) 0.7819 | Acc(val) 0.7823 |*
Epoch 00080 | Loss(train) 0.9498 | Acc(train) 0.7893 | Acc(val) 0.7823 |
Epoch 00081 | Loss(train) 0.9233 | Acc(train) 0.7726 | Acc(val) 0.7823 |
Epoch 00082 | Loss(train) 0.9356 | Acc(train) 0.7800 | Acc(val) 0.7786 |
Epoch 00083 | Loss(train) 0.9248 | Acc(train) 0.7800 | Acc(val) 0.7823 |
Epoch 00084 | Loss(train) 0.9210 | Acc(train) 0.8115 | Acc(val) 0.7897 |*
Epoch 00085 | Loss(train) 0.9074 | Acc(train) 0.7985 | Acc(val) 0.7860 |
Epoch 00086 | Loss(train) 0.8922 | Acc(train) 0.8059 | Acc(val) 0.7934 |*
Epoch 00087 | Loss(train) 0.9002 | Acc(train) 0.8059 | Acc(val) 0.7970 |*
Epoch 00088 | Loss(train) 0.8839 | Acc(train) 0.7874 | Acc(val) 0.8044 |*
Epoch 00089 | Loss(train) 0.8793 | Acc(train) 0.7948 | Acc(val) 0.8007 |
Epoch 00090 | Loss(train) 0.8489 | Acc(train) 0.8244 | Acc(val) 0.8044 |
Epoch 00091 | Loss(train) 0.8461 | Acc(train) 0.8392 | Acc(val) 0.8044 |
Epoch 00092 | Loss(train) 0.8298 | Acc(train) 0.8281 | Acc(val) 0.8081 |*
Epoch 00093 | Loss(train) 0.8431 | Acc(train) 0.8022 | Acc(val) 0.8118 |*
Epoch 00094 | Loss(train) 0.8335 | Acc(train) 0.8189 | Acc(val) 0.8192 |*
Epoch 00095 | Loss(train) 0.8316 | Acc(train) 0.8207 | Acc(val) 0.8229 |*
Epoch 00096 | Loss(train) 0.8236 | Acc(train) 0.8152 | Acc(val) 0.8229 |
Epoch 00097 | Loss(train) 0.8049 | Acc(train) 0.8281 | Acc(val) 0.8229 |
Epoch 00098 | Loss(train) 0.8277 | Acc(train) 0.8410 | Acc(val) 0.8192 |
Epoch 00099 | Loss(train) 0.7862 | Acc(train) 0.8299 | Acc(val) 0.8192 |
Epoch 00100 | Loss(train) 0.7875 | Acc(train) 0.8336 | Acc(val) 0.8192 |
Epoch 00101 | Loss(train) 0.8075 | Acc(train) 0.8466 | Acc(val) 0.8303 |*
Epoch 00102 | Loss(train) 0.7936 | Acc(train) 0.8318 | Acc(val) 0.8339 |*
Epoch 00103 | Loss(train) 0.7642 | Acc(train) 0.8410 | Acc(val) 0.8339 |
Epoch 00104 | Loss(train) 0.7847 | Acc(train) 0.8299 | Acc(val) 0.8339 |
Epoch 00105 | Loss(train) 0.7689 | Acc(train) 0.8281 | Acc(val) 0.8376 |*
Epoch 00106 | Loss(train) 0.7433 | Acc(train) 0.8447 | Acc(val) 0.8339 |
Epoch 00107 | Loss(train) 0.7590 | Acc(train) 0.8577 | Acc(val) 0.8339 |
Epoch 00108 | Loss(train) 0.7542 | Acc(train) 0.8503 | Acc(val) 0.8413 |*
Epoch 00109 | Loss(train) 0.7389 | Acc(train) 0.8669 | Acc(val) 0.8376 |
Epoch 00110 | Loss(train) 0.7490 | Acc(train) 0.8558 | Acc(val) 0.8376 |
Epoch 00111 | Loss(train) 0.7234 | Acc(train) 0.8558 | Acc(val) 0.8376 |
Epoch 00112 | Loss(train) 0.7020 | Acc(train) 0.8799 | Acc(val) 0.8413 |
Epoch 00113 | Loss(train) 0.7298 | Acc(train) 0.8725 | Acc(val) 0.8413 |
Epoch 00114 | Loss(train) 0.7127 | Acc(train) 0.8632 | Acc(val) 0.8450 |*
Epoch 00115 | Loss(train) 0.6834 | Acc(train) 0.8651 | Acc(val) 0.8450 |
Epoch 00116 | Loss(train) 0.7021 | Acc(train) 0.8503 | Acc(val) 0.8450 |
Epoch 00117 | Loss(train) 0.7034 | Acc(train) 0.8706 | Acc(val) 0.8413 |
Epoch 00118 | Loss(train) 0.6994 | Acc(train) 0.8669 | Acc(val) 0.8413 |
Epoch 00119 | Loss(train) 0.6855 | Acc(train) 0.8780 | Acc(val) 0.8487 |*
Epoch 00120 | Loss(train) 0.6923 | Acc(train) 0.8669 | Acc(val) 0.8524 |*
Epoch 00121 | Loss(train) 0.6872 | Acc(train) 0.8725 | Acc(val) 0.8450 |
Epoch 00122 | Loss(train) 0.6699 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00123 | Loss(train) 0.6825 | Acc(train) 0.8725 | Acc(val) 0.8524 |
Epoch 00124 | Loss(train) 0.6565 | Acc(train) 0.8743 | Acc(val) 0.8561 |*
Epoch 00125 | Loss(train) 0.6739 | Acc(train) 0.8706 | Acc(val) 0.8524 |
Epoch 00126 | Loss(train) 0.6739 | Acc(train) 0.8558 | Acc(val) 0.8487 |
Epoch 00127 | Loss(train) 0.6510 | Acc(train) 0.8688 | Acc(val) 0.8561 |
Epoch 00128 | Loss(train) 0.6664 | Acc(train) 0.8558 | Acc(val) 0.8598 |*
Epoch 00129 | Loss(train) 0.6462 | Acc(train) 0.8762 | Acc(val) 0.8635 |*
Epoch 00130 | Loss(train) 0.6403 | Acc(train) 0.8706 | Acc(val) 0.8635 |
Epoch 00131 | Loss(train) 0.6633 | Acc(train) 0.8558 | Acc(val) 0.8635 |
Epoch 00132 | Loss(train) 0.6361 | Acc(train) 0.8780 | Acc(val) 0.8635 |
Epoch 00133 | Loss(train) 0.6526 | Acc(train) 0.8632 | Acc(val) 0.8598 |
Epoch 00134 | Loss(train) 0.6338 | Acc(train) 0.8780 | Acc(val) 0.8598 |
Epoch 00135 | Loss(train) 0.6347 | Acc(train) 0.8725 | Acc(val) 0.8598 |
Epoch 00136 | Loss(train) 0.6385 | Acc(train) 0.8817 | Acc(val) 0.8561 |
Epoch 00137 | Loss(train) 0.6218 | Acc(train) 0.8762 | Acc(val) 0.8635 |
Epoch 00138 | Loss(train) 0.6234 | Acc(train) 0.8762 | Acc(val) 0.8672 |*
Epoch 00139 | Loss(train) 0.6234 | Acc(train) 0.8706 | Acc(val) 0.8672 |
Epoch 00140 | Loss(train) 0.6182 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00141 | Loss(train) 0.6080 | Acc(train) 0.8743 | Acc(val) 0.8672 |
Epoch 00142 | Loss(train) 0.6321 | Acc(train) 0.8688 | Acc(val) 0.8745 |*
Epoch 00143 | Loss(train) 0.6336 | Acc(train) 0.8651 | Acc(val) 0.8708 |
Epoch 00144 | Loss(train) 0.6032 | Acc(train) 0.8799 | Acc(val) 0.8598 |
Epoch 00145 | Loss(train) 0.6052 | Acc(train) 0.8891 | Acc(val) 0.8598 |
Epoch 00146 | Loss(train) 0.5730 | Acc(train) 0.8946 | Acc(val) 0.8672 |
Epoch 00147 | Loss(train) 0.6089 | Acc(train) 0.8835 | Acc(val) 0.8635 |
Epoch 00148 | Loss(train) 0.5897 | Acc(train) 0.8928 | Acc(val) 0.8635 |
Epoch 00149 | Loss(train) 0.5833 | Acc(train) 0.8854 | Acc(val) 0.8672 |
Epoch 00150 | Loss(train) 0.5996 | Acc(train) 0.8854 | Acc(val) 0.8708 |
Epoch 00151 | Loss(train) 0.5811 | Acc(train) 0.8928 | Acc(val) 0.8708 |
Epoch 00152 | Loss(train) 0.5812 | Acc(train) 0.8835 | Acc(val) 0.8708 |
Epoch 00153 | Loss(train) 0.5780 | Acc(train) 0.9002 | Acc(val) 0.8708 |
Epoch 00154 | Loss(train) 0.5944 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00155 | Loss(train) 0.5924 | Acc(train) 0.8817 | Acc(val) 0.8672 |
Epoch 00156 | Loss(train) 0.5593 | Acc(train) 0.9039 | Acc(val) 0.8635 |
Epoch 00157 | Loss(train) 0.5888 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00158 | Loss(train) 0.5884 | Acc(train) 0.8909 | Acc(val) 0.8708 |
Epoch 00159 | Loss(train) 0.5740 | Acc(train) 0.8965 | Acc(val) 0.8745 |
Epoch 00160 | Loss(train) 0.5762 | Acc(train) 0.8872 | Acc(val) 0.8782 |*
Epoch 00161 | Loss(train) 0.5605 | Acc(train) 0.8909 | Acc(val) 0.8782 |
Epoch 00162 | Loss(train) 0.5702 | Acc(train) 0.8872 | Acc(val) 0.8782 |
Epoch 00163 | Loss(train) 0.5515 | Acc(train) 0.9002 | Acc(val) 0.8745 |
Epoch 00164 | Loss(train) 0.5821 | Acc(train) 0.8817 | Acc(val) 0.8708 |
Epoch 00165 | Loss(train) 0.5590 | Acc(train) 0.8706 | Acc(val) 0.8708 |
Epoch 00166 | Loss(train) 0.5440 | Acc(train) 0.8817 | Acc(val) 0.8708 |
Epoch 00167 | Loss(train) 0.5367 | Acc(train) 0.9002 | Acc(val) 0.8672 |
Epoch 00168 | Loss(train) 0.5307 | Acc(train) 0.8983 | Acc(val) 0.8708 |
Epoch 00169 | Loss(train) 0.5432 | Acc(train) 0.8762 | Acc(val) 0.8782 |
Epoch 00170 | Loss(train) 0.5308 | Acc(train) 0.8891 | Acc(val) 0.8745 |
Epoch 00171 | Loss(train) 0.5598 | Acc(train) 0.8835 | Acc(val) 0.8819 |*
Epoch 00172 | Loss(train) 0.5343 | Acc(train) 0.9076 | Acc(val) 0.8708 |
Epoch 00173 | Loss(train) 0.5405 | Acc(train) 0.9002 | Acc(val) 0.8672 |
Epoch 00174 | Loss(train) 0.5410 | Acc(train) 0.8983 | Acc(val) 0.8672 |
Epoch 00175 | Loss(train) 0.5581 | Acc(train) 0.8928 | Acc(val) 0.8708 |
Epoch 00176 | Loss(train) 0.5554 | Acc(train) 0.8835 | Acc(val) 0.8819 |
Epoch 00177 | Loss(train) 0.5589 | Acc(train) 0.8780 | Acc(val) 0.8856 |*
Epoch 00178 | Loss(train) 0.5201 | Acc(train) 0.9057 | Acc(val) 0.8856 |
Epoch 00179 | Loss(train) 0.5330 | Acc(train) 0.8872 | Acc(val) 0.8856 |
Epoch 00180 | Loss(train) 0.5234 | Acc(train) 0.8946 | Acc(val) 0.8893 |*
Epoch 00181 | Loss(train) 0.5435 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00182 | Loss(train) 0.5357 | Acc(train) 0.8909 | Acc(val) 0.8672 |
Epoch 00183 | Loss(train) 0.5480 | Acc(train) 0.8909 | Acc(val) 0.8672 |
Epoch 00184 | Loss(train) 0.5354 | Acc(train) 0.8909 | Acc(val) 0.8745 |
Epoch 00185 | Loss(train) 0.5623 | Acc(train) 0.8854 | Acc(val) 0.8782 |
Epoch 00186 | Loss(train) 0.5390 | Acc(train) 0.8909 | Acc(val) 0.8893 |
Epoch 00187 | Loss(train) 0.5148 | Acc(train) 0.8928 | Acc(val) 0.8893 |
Epoch 00188 | Loss(train) 0.5387 | Acc(train) 0.8983 | Acc(val) 0.8819 |
Epoch 00189 | Loss(train) 0.5016 | Acc(train) 0.9187 | Acc(val) 0.8782 |
Epoch 00190 | Loss(train) 0.5198 | Acc(train) 0.8909 | Acc(val) 0.8819 |
Epoch 00191 | Loss(train) 0.5253 | Acc(train) 0.8983 | Acc(val) 0.8782 |
Epoch 00192 | Loss(train) 0.5127 | Acc(train) 0.8965 | Acc(val) 0.8672 |
Epoch 00193 | Loss(train) 0.5176 | Acc(train) 0.8946 | Acc(val) 0.8672 |
Epoch 00194 | Loss(train) 0.5142 | Acc(train) 0.8928 | Acc(val) 0.8672 |
Epoch 00195 | Loss(train) 0.5115 | Acc(train) 0.9039 | Acc(val) 0.8745 |
Epoch 00196 | Loss(train) 0.5136 | Acc(train) 0.8965 | Acc(val) 0.8782 |
Epoch 00197 | Loss(train) 0.5051 | Acc(train) 0.9020 | Acc(val) 0.8782 |
Epoch 00198 | Loss(train) 0.5113 | Acc(train) 0.9039 | Acc(val) 0.8782 |
Epoch 00199 | Loss(train) 0.4831 | Acc(train) 0.9020 | Acc(val) 0.8782 |
Epoch 00200 | Loss(train) 0.5187 | Acc(train) 0.8909 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9456 | Acc(train) 0.1460 | Acc(val) 0.3173 |*
Epoch 00002 | Loss(train) 1.9370 | Acc(train) 0.2773 | Acc(val) 0.3469 |*
Epoch 00003 | Loss(train) 1.9280 | Acc(train) 0.3179 | Acc(val) 0.3727 |*
Epoch 00004 | Loss(train) 1.9174 | Acc(train) 0.3586 | Acc(val) 0.3801 |*
Epoch 00005 | Loss(train) 1.9053 | Acc(train) 0.3457 | Acc(val) 0.3801 |
Epoch 00006 | Loss(train) 1.8948 | Acc(train) 0.3401 | Acc(val) 0.3801 |
Epoch 00007 | Loss(train) 1.8825 | Acc(train) 0.3512 | Acc(val) 0.3579 |
Epoch 00008 | Loss(train) 1.8732 | Acc(train) 0.3549 | Acc(val) 0.3395 |
Epoch 00009 | Loss(train) 1.8583 | Acc(train) 0.3346 | Acc(val) 0.3321 |
Epoch 00010 | Loss(train) 1.8484 | Acc(train) 0.3290 | Acc(val) 0.3210 |
Epoch 00011 | Loss(train) 1.8334 | Acc(train) 0.3327 | Acc(val) 0.3173 |
Epoch 00012 | Loss(train) 1.8233 | Acc(train) 0.3383 | Acc(val) 0.3137 |
Epoch 00013 | Loss(train) 1.8150 | Acc(train) 0.3198 | Acc(val) 0.3063 |
Epoch 00014 | Loss(train) 1.8033 | Acc(train) 0.3105 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7868 | Acc(train) 0.3161 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7782 | Acc(train) 0.2994 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7656 | Acc(train) 0.3031 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7520 | Acc(train) 0.3031 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7529 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7300 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.7255 | Acc(train) 0.2994 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.7175 | Acc(train) 0.2957 | Acc(val) 0.2989 |
Epoch 00023 | Loss(train) 1.6999 | Acc(train) 0.2976 | Acc(val) 0.2989 |
Epoch 00024 | Loss(train) 1.6922 | Acc(train) 0.2976 | Acc(val) 0.3026 |
Epoch 00025 | Loss(train) 1.6845 | Acc(train) 0.3050 | Acc(val) 0.3026 |
Epoch 00026 | Loss(train) 1.6599 | Acc(train) 0.3179 | Acc(val) 0.3026 |
Epoch 00027 | Loss(train) 1.6596 | Acc(train) 0.3216 | Acc(val) 0.3100 |
Epoch 00028 | Loss(train) 1.6348 | Acc(train) 0.3309 | Acc(val) 0.3173 |
Epoch 00029 | Loss(train) 1.6337 | Acc(train) 0.3549 | Acc(val) 0.3247 |
Epoch 00030 | Loss(train) 1.6169 | Acc(train) 0.3697 | Acc(val) 0.3358 |
Epoch 00031 | Loss(train) 1.6152 | Acc(train) 0.3789 | Acc(val) 0.3542 |
Epoch 00032 | Loss(train) 1.5990 | Acc(train) 0.4177 | Acc(val) 0.3579 |
Epoch 00033 | Loss(train) 1.5893 | Acc(train) 0.4085 | Acc(val) 0.3801 |
Epoch 00034 | Loss(train) 1.5730 | Acc(train) 0.4325 | Acc(val) 0.4059 |*
Epoch 00035 | Loss(train) 1.5602 | Acc(train) 0.4492 | Acc(val) 0.4207 |*
Epoch 00036 | Loss(train) 1.5459 | Acc(train) 0.4362 | Acc(val) 0.4280 |*
Epoch 00037 | Loss(train) 1.5343 | Acc(train) 0.4418 | Acc(val) 0.4317 |*
Epoch 00038 | Loss(train) 1.5226 | Acc(train) 0.4732 | Acc(val) 0.4391 |*
Epoch 00039 | Loss(train) 1.5055 | Acc(train) 0.4824 | Acc(val) 0.4539 |*
Epoch 00040 | Loss(train) 1.5008 | Acc(train) 0.4954 | Acc(val) 0.4834 |*
Epoch 00041 | Loss(train) 1.4931 | Acc(train) 0.5287 | Acc(val) 0.5018 |*
Epoch 00042 | Loss(train) 1.4752 | Acc(train) 0.5231 | Acc(val) 0.5203 |*
Epoch 00043 | Loss(train) 1.4588 | Acc(train) 0.5490 | Acc(val) 0.5314 |*
Epoch 00044 | Loss(train) 1.4343 | Acc(train) 0.5712 | Acc(val) 0.5498 |*
Epoch 00045 | Loss(train) 1.4370 | Acc(train) 0.5471 | Acc(val) 0.5572 |*
Epoch 00046 | Loss(train) 1.4170 | Acc(train) 0.5601 | Acc(val) 0.5720 |*
Epoch 00047 | Loss(train) 1.4004 | Acc(train) 0.5823 | Acc(val) 0.5867 |*
Epoch 00048 | Loss(train) 1.3853 | Acc(train) 0.5786 | Acc(val) 0.5904 |*
Epoch 00049 | Loss(train) 1.3682 | Acc(train) 0.5933 | Acc(val) 0.5978 |*
Epoch 00050 | Loss(train) 1.3535 | Acc(train) 0.6211 | Acc(val) 0.6052 |*
Epoch 00051 | Loss(train) 1.3443 | Acc(train) 0.6248 | Acc(val) 0.6089 |*
Epoch 00052 | Loss(train) 1.3264 | Acc(train) 0.6377 | Acc(val) 0.6236 |*
Epoch 00053 | Loss(train) 1.3153 | Acc(train) 0.6396 | Acc(val) 0.6347 |*
Epoch 00054 | Loss(train) 1.3074 | Acc(train) 0.6414 | Acc(val) 0.6384 |*
Epoch 00055 | Loss(train) 1.2975 | Acc(train) 0.6359 | Acc(val) 0.6458 |*
Epoch 00056 | Loss(train) 1.2495 | Acc(train) 0.6802 | Acc(val) 0.6494 |*
Epoch 00057 | Loss(train) 1.2498 | Acc(train) 0.6580 | Acc(val) 0.6716 |*
Epoch 00058 | Loss(train) 1.2418 | Acc(train) 0.6636 | Acc(val) 0.6753 |*
Epoch 00059 | Loss(train) 1.2374 | Acc(train) 0.6562 | Acc(val) 0.6863 |*
Epoch 00060 | Loss(train) 1.2192 | Acc(train) 0.6654 | Acc(val) 0.6937 |*
Epoch 00061 | Loss(train) 1.2179 | Acc(train) 0.6932 | Acc(val) 0.7122 |*
Epoch 00062 | Loss(train) 1.1798 | Acc(train) 0.6821 | Acc(val) 0.7159 |*
Epoch 00063 | Loss(train) 1.1867 | Acc(train) 0.6950 | Acc(val) 0.7122 |
Epoch 00064 | Loss(train) 1.1609 | Acc(train) 0.6913 | Acc(val) 0.7232 |*
Epoch 00065 | Loss(train) 1.1365 | Acc(train) 0.7024 | Acc(val) 0.7269 |*
Epoch 00066 | Loss(train) 1.1642 | Acc(train) 0.7061 | Acc(val) 0.7269 |
Epoch 00067 | Loss(train) 1.1386 | Acc(train) 0.7172 | Acc(val) 0.7306 |*
Epoch 00068 | Loss(train) 1.1254 | Acc(train) 0.6987 | Acc(val) 0.7343 |*
Epoch 00069 | Loss(train) 1.1118 | Acc(train) 0.7227 | Acc(val) 0.7343 |
Epoch 00070 | Loss(train) 1.0975 | Acc(train) 0.7172 | Acc(val) 0.7417 |*
Epoch 00071 | Loss(train) 1.1005 | Acc(train) 0.7338 | Acc(val) 0.7454 |*
Epoch 00072 | Loss(train) 1.0772 | Acc(train) 0.7431 | Acc(val) 0.7454 |
Epoch 00073 | Loss(train) 1.0608 | Acc(train) 0.7135 | Acc(val) 0.7491 |*
Epoch 00074 | Loss(train) 1.0624 | Acc(train) 0.7431 | Acc(val) 0.7491 |
Epoch 00075 | Loss(train) 1.0450 | Acc(train) 0.7301 | Acc(val) 0.7491 |
Epoch 00076 | Loss(train) 1.0125 | Acc(train) 0.7726 | Acc(val) 0.7528 |*
Epoch 00077 | Loss(train) 1.0276 | Acc(train) 0.7412 | Acc(val) 0.7528 |
Epoch 00078 | Loss(train) 1.0384 | Acc(train) 0.7246 | Acc(val) 0.7565 |*
Epoch 00079 | Loss(train) 1.0005 | Acc(train) 0.7486 | Acc(val) 0.7528 |
Epoch 00080 | Loss(train) 1.0211 | Acc(train) 0.7486 | Acc(val) 0.7565 |
Epoch 00081 | Loss(train) 1.0160 | Acc(train) 0.7616 | Acc(val) 0.7601 |*
Epoch 00082 | Loss(train) 0.9856 | Acc(train) 0.7505 | Acc(val) 0.7638 |*
Epoch 00083 | Loss(train) 0.9884 | Acc(train) 0.7689 | Acc(val) 0.7749 |*
Epoch 00084 | Loss(train) 0.9822 | Acc(train) 0.7542 | Acc(val) 0.7675 |
Epoch 00085 | Loss(train) 0.9550 | Acc(train) 0.7726 | Acc(val) 0.7712 |
Epoch 00086 | Loss(train) 0.9514 | Acc(train) 0.7689 | Acc(val) 0.7786 |*
Epoch 00087 | Loss(train) 0.9320 | Acc(train) 0.7745 | Acc(val) 0.7786 |
Epoch 00088 | Loss(train) 0.9482 | Acc(train) 0.7745 | Acc(val) 0.7786 |
Epoch 00089 | Loss(train) 0.9287 | Acc(train) 0.7930 | Acc(val) 0.7823 |*
Epoch 00090 | Loss(train) 0.9167 | Acc(train) 0.7985 | Acc(val) 0.7897 |*
Epoch 00091 | Loss(train) 0.9001 | Acc(train) 0.7930 | Acc(val) 0.7934 |*
Epoch 00092 | Loss(train) 0.9342 | Acc(train) 0.7837 | Acc(val) 0.7934 |
Epoch 00093 | Loss(train) 0.8871 | Acc(train) 0.8041 | Acc(val) 0.7934 |
Epoch 00094 | Loss(train) 0.8918 | Acc(train) 0.7893 | Acc(val) 0.7934 |
Epoch 00095 | Loss(train) 0.8880 | Acc(train) 0.7837 | Acc(val) 0.7934 |
Epoch 00096 | Loss(train) 0.8822 | Acc(train) 0.8059 | Acc(val) 0.7934 |
Epoch 00097 | Loss(train) 0.8565 | Acc(train) 0.8078 | Acc(val) 0.7934 |
Epoch 00098 | Loss(train) 0.8748 | Acc(train) 0.8170 | Acc(val) 0.7934 |
Epoch 00099 | Loss(train) 0.8587 | Acc(train) 0.8004 | Acc(val) 0.8081 |*
Epoch 00100 | Loss(train) 0.8486 | Acc(train) 0.8133 | Acc(val) 0.8155 |*
Epoch 00101 | Loss(train) 0.8499 | Acc(train) 0.8355 | Acc(val) 0.8155 |
Epoch 00102 | Loss(train) 0.8492 | Acc(train) 0.8096 | Acc(val) 0.8155 |
Epoch 00103 | Loss(train) 0.8352 | Acc(train) 0.8318 | Acc(val) 0.8155 |
Epoch 00104 | Loss(train) 0.8402 | Acc(train) 0.8189 | Acc(val) 0.8155 |
Epoch 00105 | Loss(train) 0.8428 | Acc(train) 0.8133 | Acc(val) 0.8155 |
Epoch 00106 | Loss(train) 0.8225 | Acc(train) 0.8262 | Acc(val) 0.8155 |
Epoch 00107 | Loss(train) 0.8241 | Acc(train) 0.7874 | Acc(val) 0.8155 |
Epoch 00108 | Loss(train) 0.7996 | Acc(train) 0.8392 | Acc(val) 0.8155 |
Epoch 00109 | Loss(train) 0.8111 | Acc(train) 0.8355 | Acc(val) 0.8229 |*
Epoch 00110 | Loss(train) 0.8156 | Acc(train) 0.8281 | Acc(val) 0.8266 |*
Epoch 00111 | Loss(train) 0.7782 | Acc(train) 0.8244 | Acc(val) 0.8303 |*
Epoch 00112 | Loss(train) 0.7716 | Acc(train) 0.8355 | Acc(val) 0.8303 |
Epoch 00113 | Loss(train) 0.7809 | Acc(train) 0.8078 | Acc(val) 0.8303 |
Epoch 00114 | Loss(train) 0.7669 | Acc(train) 0.8429 | Acc(val) 0.8303 |
Epoch 00115 | Loss(train) 0.7715 | Acc(train) 0.8355 | Acc(val) 0.8303 |
Epoch 00116 | Loss(train) 0.7675 | Acc(train) 0.8466 | Acc(val) 0.8303 |
Epoch 00117 | Loss(train) 0.7697 | Acc(train) 0.8392 | Acc(val) 0.8303 |
Epoch 00118 | Loss(train) 0.7607 | Acc(train) 0.8318 | Acc(val) 0.8339 |*
Epoch 00119 | Loss(train) 0.7641 | Acc(train) 0.8410 | Acc(val) 0.8339 |
Epoch 00120 | Loss(train) 0.7703 | Acc(train) 0.8244 | Acc(val) 0.8376 |*
Epoch 00121 | Loss(train) 0.7610 | Acc(train) 0.8484 | Acc(val) 0.8339 |
Epoch 00122 | Loss(train) 0.7560 | Acc(train) 0.8429 | Acc(val) 0.8376 |
Epoch 00123 | Loss(train) 0.7570 | Acc(train) 0.8262 | Acc(val) 0.8376 |
Epoch 00124 | Loss(train) 0.7388 | Acc(train) 0.8466 | Acc(val) 0.8413 |*
Epoch 00125 | Loss(train) 0.7230 | Acc(train) 0.8521 | Acc(val) 0.8413 |
Epoch 00126 | Loss(train) 0.7257 | Acc(train) 0.8614 | Acc(val) 0.8413 |
Epoch 00127 | Loss(train) 0.7487 | Acc(train) 0.8521 | Acc(val) 0.8450 |*
Epoch 00128 | Loss(train) 0.7169 | Acc(train) 0.8466 | Acc(val) 0.8450 |
Epoch 00129 | Loss(train) 0.7310 | Acc(train) 0.8336 | Acc(val) 0.8450 |
Epoch 00130 | Loss(train) 0.7245 | Acc(train) 0.8521 | Acc(val) 0.8450 |
Epoch 00131 | Loss(train) 0.7102 | Acc(train) 0.8614 | Acc(val) 0.8450 |
Epoch 00132 | Loss(train) 0.7208 | Acc(train) 0.8373 | Acc(val) 0.8450 |
Epoch 00133 | Loss(train) 0.6746 | Acc(train) 0.8577 | Acc(val) 0.8487 |*
Epoch 00134 | Loss(train) 0.7253 | Acc(train) 0.8484 | Acc(val) 0.8524 |*
Epoch 00135 | Loss(train) 0.7102 | Acc(train) 0.8299 | Acc(val) 0.8561 |*
Epoch 00136 | Loss(train) 0.7188 | Acc(train) 0.8410 | Acc(val) 0.8598 |*
Epoch 00137 | Loss(train) 0.6999 | Acc(train) 0.8521 | Acc(val) 0.8598 |
Epoch 00138 | Loss(train) 0.6926 | Acc(train) 0.8595 | Acc(val) 0.8598 |
Epoch 00139 | Loss(train) 0.7126 | Acc(train) 0.8429 | Acc(val) 0.8561 |
Epoch 00140 | Loss(train) 0.6749 | Acc(train) 0.8669 | Acc(val) 0.8524 |
Epoch 00141 | Loss(train) 0.7009 | Acc(train) 0.8540 | Acc(val) 0.8524 |
Epoch 00142 | Loss(train) 0.6703 | Acc(train) 0.8817 | Acc(val) 0.8487 |
Epoch 00143 | Loss(train) 0.6665 | Acc(train) 0.8725 | Acc(val) 0.8487 |
Epoch 00144 | Loss(train) 0.6738 | Acc(train) 0.8577 | Acc(val) 0.8561 |
Epoch 00145 | Loss(train) 0.6894 | Acc(train) 0.8466 | Acc(val) 0.8598 |
Epoch 00146 | Loss(train) 0.6752 | Acc(train) 0.8669 | Acc(val) 0.8561 |
Epoch 00147 | Loss(train) 0.6479 | Acc(train) 0.8688 | Acc(val) 0.8561 |
Epoch 00148 | Loss(train) 0.6629 | Acc(train) 0.8706 | Acc(val) 0.8561 |
Epoch 00149 | Loss(train) 0.6618 | Acc(train) 0.8780 | Acc(val) 0.8524 |
Epoch 00150 | Loss(train) 0.6683 | Acc(train) 0.8688 | Acc(val) 0.8524 |
Epoch 00151 | Loss(train) 0.6777 | Acc(train) 0.8558 | Acc(val) 0.8561 |
Epoch 00152 | Loss(train) 0.6546 | Acc(train) 0.8780 | Acc(val) 0.8561 |
Epoch 00153 | Loss(train) 0.6625 | Acc(train) 0.8614 | Acc(val) 0.8561 |
Epoch 00154 | Loss(train) 0.6549 | Acc(train) 0.8651 | Acc(val) 0.8598 |
Epoch 00155 | Loss(train) 0.6542 | Acc(train) 0.8521 | Acc(val) 0.8598 |
Epoch 00156 | Loss(train) 0.6588 | Acc(train) 0.8614 | Acc(val) 0.8672 |*
Epoch 00157 | Loss(train) 0.6562 | Acc(train) 0.8540 | Acc(val) 0.8708 |*
Epoch 00158 | Loss(train) 0.6409 | Acc(train) 0.8817 | Acc(val) 0.8672 |
Epoch 00159 | Loss(train) 0.6777 | Acc(train) 0.8521 | Acc(val) 0.8598 |
Epoch 00160 | Loss(train) 0.6269 | Acc(train) 0.8872 | Acc(val) 0.8598 |
Epoch 00161 | Loss(train) 0.6293 | Acc(train) 0.8799 | Acc(val) 0.8598 |
Epoch 00162 | Loss(train) 0.6383 | Acc(train) 0.8706 | Acc(val) 0.8598 |
Epoch 00163 | Loss(train) 0.6352 | Acc(train) 0.8817 | Acc(val) 0.8598 |
Epoch 00164 | Loss(train) 0.6421 | Acc(train) 0.8706 | Acc(val) 0.8561 |
Epoch 00165 | Loss(train) 0.6046 | Acc(train) 0.8817 | Acc(val) 0.8561 |
Epoch 00166 | Loss(train) 0.6183 | Acc(train) 0.8669 | Acc(val) 0.8561 |
Epoch 00167 | Loss(train) 0.6077 | Acc(train) 0.8909 | Acc(val) 0.8635 |
Epoch 00168 | Loss(train) 0.5927 | Acc(train) 0.8946 | Acc(val) 0.8745 |*
Epoch 00169 | Loss(train) 0.6242 | Acc(train) 0.8743 | Acc(val) 0.8708 |
Epoch 00170 | Loss(train) 0.5926 | Acc(train) 0.8854 | Acc(val) 0.8708 |
Epoch 00171 | Loss(train) 0.5889 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00172 | Loss(train) 0.6366 | Acc(train) 0.8614 | Acc(val) 0.8672 |
Epoch 00173 | Loss(train) 0.5827 | Acc(train) 0.8854 | Acc(val) 0.8708 |
Epoch 00174 | Loss(train) 0.6146 | Acc(train) 0.8521 | Acc(val) 0.8745 |
Epoch 00175 | Loss(train) 0.5867 | Acc(train) 0.8780 | Acc(val) 0.8745 |
Epoch 00176 | Loss(train) 0.5959 | Acc(train) 0.8799 | Acc(val) 0.8745 |
Epoch 00177 | Loss(train) 0.5970 | Acc(train) 0.8928 | Acc(val) 0.8672 |
Epoch 00178 | Loss(train) 0.5851 | Acc(train) 0.8946 | Acc(val) 0.8635 |
Epoch 00179 | Loss(train) 0.5929 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00180 | Loss(train) 0.5986 | Acc(train) 0.8743 | Acc(val) 0.8708 |
Epoch 00181 | Loss(train) 0.5842 | Acc(train) 0.8725 | Acc(val) 0.8708 |
Epoch 00182 | Loss(train) 0.6108 | Acc(train) 0.8854 | Acc(val) 0.8708 |
Epoch 00183 | Loss(train) 0.6026 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00184 | Loss(train) 0.5788 | Acc(train) 0.8743 | Acc(val) 0.8745 |
Epoch 00185 | Loss(train) 0.5762 | Acc(train) 0.8946 | Acc(val) 0.8745 |
Epoch 00186 | Loss(train) 0.6060 | Acc(train) 0.8872 | Acc(val) 0.8745 |
Epoch 00187 | Loss(train) 0.5851 | Acc(train) 0.8854 | Acc(val) 0.8782 |*
Epoch 00188 | Loss(train) 0.5731 | Acc(train) 0.8780 | Acc(val) 0.8745 |
Epoch 00189 | Loss(train) 0.5918 | Acc(train) 0.8688 | Acc(val) 0.8745 |
Epoch 00190 | Loss(train) 0.5581 | Acc(train) 0.8928 | Acc(val) 0.8745 |
Epoch 00191 | Loss(train) 0.5897 | Acc(train) 0.8872 | Acc(val) 0.8745 |
Epoch 00192 | Loss(train) 0.5594 | Acc(train) 0.8688 | Acc(val) 0.8745 |
Epoch 00193 | Loss(train) 0.5586 | Acc(train) 0.8946 | Acc(val) 0.8745 |
Epoch 00194 | Loss(train) 0.5849 | Acc(train) 0.8762 | Acc(val) 0.8745 |
Epoch 00195 | Loss(train) 0.5775 | Acc(train) 0.8946 | Acc(val) 0.8745 |
Epoch 00196 | Loss(train) 0.5853 | Acc(train) 0.8835 | Acc(val) 0.8782 |
Epoch 00197 | Loss(train) 0.5750 | Acc(train) 0.8688 | Acc(val) 0.8708 |
Epoch 00198 | Loss(train) 0.5569 | Acc(train) 0.8780 | Acc(val) 0.8745 |
Epoch 00199 | Loss(train) 0.5506 | Acc(train) 0.8965 | Acc(val) 0.8708 |
Epoch 00200 | Loss(train) 0.5587 | Acc(train) 0.8891 | Acc(val) 0.8708 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9457 | Acc(train) 0.1516 | Acc(val) 0.3026 |*
Epoch 00002 | Loss(train) 1.9333 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9197 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9074 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8933 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8785 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8702 | Acc(train) 0.2921 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8550 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8383 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8263 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8209 | Acc(train) 0.2791 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.8075 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7897 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7846 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7687 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7557 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7455 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7533 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7306 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7240 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.7190 | Acc(train) 0.2902 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.6953 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00023 | Loss(train) 1.6877 | Acc(train) 0.3050 | Acc(val) 0.2989 |
Epoch 00024 | Loss(train) 1.6855 | Acc(train) 0.3050 | Acc(val) 0.3063 |*
Epoch 00025 | Loss(train) 1.6662 | Acc(train) 0.3198 | Acc(val) 0.3063 |
Epoch 00026 | Loss(train) 1.6498 | Acc(train) 0.3290 | Acc(val) 0.3247 |*
Epoch 00027 | Loss(train) 1.6527 | Acc(train) 0.3346 | Acc(val) 0.3358 |*
Epoch 00028 | Loss(train) 1.6356 | Acc(train) 0.3604 | Acc(val) 0.3395 |*
Epoch 00029 | Loss(train) 1.6246 | Acc(train) 0.3937 | Acc(val) 0.3432 |*
Epoch 00030 | Loss(train) 1.6099 | Acc(train) 0.3974 | Acc(val) 0.3432 |
Epoch 00031 | Loss(train) 1.5964 | Acc(train) 0.4048 | Acc(val) 0.3653 |*
Epoch 00032 | Loss(train) 1.5847 | Acc(train) 0.4104 | Acc(val) 0.3764 |*
Epoch 00033 | Loss(train) 1.5726 | Acc(train) 0.4399 | Acc(val) 0.3801 |*
Epoch 00034 | Loss(train) 1.5511 | Acc(train) 0.4492 | Acc(val) 0.4022 |*
Epoch 00035 | Loss(train) 1.5367 | Acc(train) 0.4713 | Acc(val) 0.4096 |*
Epoch 00036 | Loss(train) 1.5223 | Acc(train) 0.4713 | Acc(val) 0.4207 |*
Epoch 00037 | Loss(train) 1.5234 | Acc(train) 0.4843 | Acc(val) 0.4280 |*
Epoch 00038 | Loss(train) 1.5071 | Acc(train) 0.4806 | Acc(val) 0.4391 |*
Epoch 00039 | Loss(train) 1.4813 | Acc(train) 0.5231 | Acc(val) 0.4502 |*
Epoch 00040 | Loss(train) 1.4729 | Acc(train) 0.4861 | Acc(val) 0.4539 |*
Epoch 00041 | Loss(train) 1.4680 | Acc(train) 0.5102 | Acc(val) 0.4797 |*
Epoch 00042 | Loss(train) 1.4503 | Acc(train) 0.5139 | Acc(val) 0.4945 |*
Epoch 00043 | Loss(train) 1.4382 | Acc(train) 0.5416 | Acc(val) 0.5092 |*
Epoch 00044 | Loss(train) 1.4224 | Acc(train) 0.5416 | Acc(val) 0.5314 |*
Epoch 00045 | Loss(train) 1.4071 | Acc(train) 0.5601 | Acc(val) 0.5351 |*
Epoch 00046 | Loss(train) 1.3908 | Acc(train) 0.5749 | Acc(val) 0.5535 |*
Epoch 00047 | Loss(train) 1.3845 | Acc(train) 0.5767 | Acc(val) 0.5793 |*
Epoch 00048 | Loss(train) 1.3746 | Acc(train) 0.5749 | Acc(val) 0.5904 |*
Epoch 00049 | Loss(train) 1.3753 | Acc(train) 0.6007 | Acc(val) 0.6125 |*
Epoch 00050 | Loss(train) 1.3697 | Acc(train) 0.6007 | Acc(val) 0.6125 |
Epoch 00051 | Loss(train) 1.3282 | Acc(train) 0.6063 | Acc(val) 0.6273 |*
Epoch 00052 | Loss(train) 1.3262 | Acc(train) 0.6007 | Acc(val) 0.6347 |*
Epoch 00053 | Loss(train) 1.2990 | Acc(train) 0.6155 | Acc(val) 0.6458 |*
Epoch 00054 | Loss(train) 1.2886 | Acc(train) 0.6192 | Acc(val) 0.6494 |*
Epoch 00055 | Loss(train) 1.2755 | Acc(train) 0.6192 | Acc(val) 0.6605 |*
Epoch 00056 | Loss(train) 1.2729 | Acc(train) 0.6155 | Acc(val) 0.6790 |*
Epoch 00057 | Loss(train) 1.2665 | Acc(train) 0.6599 | Acc(val) 0.6827 |*
Epoch 00058 | Loss(train) 1.2512 | Acc(train) 0.6710 | Acc(val) 0.6900 |*
Epoch 00059 | Loss(train) 1.2455 | Acc(train) 0.6377 | Acc(val) 0.7085 |*
Epoch 00060 | Loss(train) 1.2280 | Acc(train) 0.6525 | Acc(val) 0.7122 |*
Epoch 00061 | Loss(train) 1.2022 | Acc(train) 0.6691 | Acc(val) 0.7159 |*
Epoch 00062 | Loss(train) 1.2033 | Acc(train) 0.6673 | Acc(val) 0.7232 |*
Epoch 00063 | Loss(train) 1.1883 | Acc(train) 0.6691 | Acc(val) 0.7269 |*
Epoch 00064 | Loss(train) 1.1645 | Acc(train) 0.7006 | Acc(val) 0.7269 |
Epoch 00065 | Loss(train) 1.1349 | Acc(train) 0.7043 | Acc(val) 0.7269 |
Epoch 00066 | Loss(train) 1.1711 | Acc(train) 0.6821 | Acc(val) 0.7232 |
Epoch 00067 | Loss(train) 1.1235 | Acc(train) 0.6987 | Acc(val) 0.7269 |
Epoch 00068 | Loss(train) 1.1024 | Acc(train) 0.7153 | Acc(val) 0.7343 |*
Epoch 00069 | Loss(train) 1.1186 | Acc(train) 0.7043 | Acc(val) 0.7380 |*
Epoch 00070 | Loss(train) 1.1153 | Acc(train) 0.6987 | Acc(val) 0.7380 |
Epoch 00071 | Loss(train) 1.1005 | Acc(train) 0.7043 | Acc(val) 0.7417 |*
Epoch 00072 | Loss(train) 1.0826 | Acc(train) 0.7209 | Acc(val) 0.7454 |*
Epoch 00073 | Loss(train) 1.0615 | Acc(train) 0.7320 | Acc(val) 0.7491 |*
Epoch 00074 | Loss(train) 1.0658 | Acc(train) 0.7357 | Acc(val) 0.7528 |*
Epoch 00075 | Loss(train) 1.0373 | Acc(train) 0.7431 | Acc(val) 0.7565 |*
Epoch 00076 | Loss(train) 1.0538 | Acc(train) 0.7227 | Acc(val) 0.7601 |*
Epoch 00077 | Loss(train) 1.0235 | Acc(train) 0.7597 | Acc(val) 0.7638 |*
Epoch 00078 | Loss(train) 1.0005 | Acc(train) 0.7708 | Acc(val) 0.7675 |*
Epoch 00079 | Loss(train) 0.9967 | Acc(train) 0.7671 | Acc(val) 0.7786 |*
Epoch 00080 | Loss(train) 1.0185 | Acc(train) 0.7431 | Acc(val) 0.7786 |
Epoch 00081 | Loss(train) 1.0140 | Acc(train) 0.7431 | Acc(val) 0.7823 |*
Epoch 00082 | Loss(train) 0.9915 | Acc(train) 0.7560 | Acc(val) 0.7823 |
Epoch 00083 | Loss(train) 0.9750 | Acc(train) 0.7634 | Acc(val) 0.7897 |*
Epoch 00084 | Loss(train) 0.9718 | Acc(train) 0.7597 | Acc(val) 0.7897 |
Epoch 00085 | Loss(train) 0.9550 | Acc(train) 0.7745 | Acc(val) 0.7897 |
Epoch 00086 | Loss(train) 0.9446 | Acc(train) 0.7782 | Acc(val) 0.7897 |
Epoch 00087 | Loss(train) 0.9521 | Acc(train) 0.7689 | Acc(val) 0.7970 |*
Epoch 00088 | Loss(train) 0.9109 | Acc(train) 0.8078 | Acc(val) 0.7970 |
Epoch 00089 | Loss(train) 0.9460 | Acc(train) 0.7763 | Acc(val) 0.8007 |*
Epoch 00090 | Loss(train) 0.9379 | Acc(train) 0.7856 | Acc(val) 0.8007 |
Epoch 00091 | Loss(train) 0.9333 | Acc(train) 0.7819 | Acc(val) 0.8044 |*
Epoch 00092 | Loss(train) 0.8926 | Acc(train) 0.8078 | Acc(val) 0.8155 |*
Epoch 00093 | Loss(train) 0.8705 | Acc(train) 0.8096 | Acc(val) 0.8192 |*
Epoch 00094 | Loss(train) 0.8739 | Acc(train) 0.7967 | Acc(val) 0.8229 |*
Epoch 00095 | Loss(train) 0.8570 | Acc(train) 0.8059 | Acc(val) 0.8192 |
Epoch 00096 | Loss(train) 0.8708 | Acc(train) 0.8004 | Acc(val) 0.8229 |
Epoch 00097 | Loss(train) 0.8756 | Acc(train) 0.7967 | Acc(val) 0.8192 |
Epoch 00098 | Loss(train) 0.8640 | Acc(train) 0.8022 | Acc(val) 0.8229 |
Epoch 00099 | Loss(train) 0.8448 | Acc(train) 0.8004 | Acc(val) 0.8192 |
Epoch 00100 | Loss(train) 0.8459 | Acc(train) 0.8096 | Acc(val) 0.8229 |
Epoch 00101 | Loss(train) 0.8084 | Acc(train) 0.8244 | Acc(val) 0.8266 |*
Epoch 00102 | Loss(train) 0.8565 | Acc(train) 0.8152 | Acc(val) 0.8339 |*
Epoch 00103 | Loss(train) 0.8472 | Acc(train) 0.8059 | Acc(val) 0.8303 |
Epoch 00104 | Loss(train) 0.8144 | Acc(train) 0.8226 | Acc(val) 0.8376 |*
Epoch 00105 | Loss(train) 0.8345 | Acc(train) 0.8226 | Acc(val) 0.8376 |
Epoch 00106 | Loss(train) 0.7876 | Acc(train) 0.8373 | Acc(val) 0.8413 |*
Epoch 00107 | Loss(train) 0.7941 | Acc(train) 0.8410 | Acc(val) 0.8413 |
Epoch 00108 | Loss(train) 0.8026 | Acc(train) 0.8022 | Acc(val) 0.8413 |
Epoch 00109 | Loss(train) 0.7969 | Acc(train) 0.8299 | Acc(val) 0.8413 |
Epoch 00110 | Loss(train) 0.7903 | Acc(train) 0.8244 | Acc(val) 0.8376 |
Epoch 00111 | Loss(train) 0.7710 | Acc(train) 0.8207 | Acc(val) 0.8376 |
Epoch 00112 | Loss(train) 0.7584 | Acc(train) 0.8577 | Acc(val) 0.8339 |
Epoch 00113 | Loss(train) 0.7639 | Acc(train) 0.8503 | Acc(val) 0.8413 |
Epoch 00114 | Loss(train) 0.7807 | Acc(train) 0.8466 | Acc(val) 0.8413 |
Epoch 00115 | Loss(train) 0.7785 | Acc(train) 0.8466 | Acc(val) 0.8413 |
Epoch 00116 | Loss(train) 0.7739 | Acc(train) 0.8299 | Acc(val) 0.8487 |*
Epoch 00117 | Loss(train) 0.7138 | Acc(train) 0.8651 | Acc(val) 0.8524 |*
Epoch 00118 | Loss(train) 0.7415 | Acc(train) 0.8355 | Acc(val) 0.8524 |
Epoch 00119 | Loss(train) 0.7637 | Acc(train) 0.8299 | Acc(val) 0.8450 |
Epoch 00120 | Loss(train) 0.7250 | Acc(train) 0.8706 | Acc(val) 0.8487 |
Epoch 00121 | Loss(train) 0.7375 | Acc(train) 0.8521 | Acc(val) 0.8487 |
Epoch 00122 | Loss(train) 0.7117 | Acc(train) 0.8614 | Acc(val) 0.8450 |
Epoch 00123 | Loss(train) 0.7322 | Acc(train) 0.8392 | Acc(val) 0.8487 |
Epoch 00124 | Loss(train) 0.7234 | Acc(train) 0.8614 | Acc(val) 0.8487 |
Epoch 00125 | Loss(train) 0.7115 | Acc(train) 0.8669 | Acc(val) 0.8487 |
Epoch 00126 | Loss(train) 0.7399 | Acc(train) 0.8521 | Acc(val) 0.8487 |
Epoch 00127 | Loss(train) 0.6907 | Acc(train) 0.8614 | Acc(val) 0.8487 |
Epoch 00128 | Loss(train) 0.6991 | Acc(train) 0.8429 | Acc(val) 0.8524 |
Epoch 00129 | Loss(train) 0.7022 | Acc(train) 0.8614 | Acc(val) 0.8524 |
Epoch 00130 | Loss(train) 0.6923 | Acc(train) 0.8799 | Acc(val) 0.8524 |
Epoch 00131 | Loss(train) 0.7034 | Acc(train) 0.8447 | Acc(val) 0.8524 |
Epoch 00132 | Loss(train) 0.6673 | Acc(train) 0.8743 | Acc(val) 0.8487 |
Epoch 00133 | Loss(train) 0.6689 | Acc(train) 0.8762 | Acc(val) 0.8524 |
Epoch 00134 | Loss(train) 0.6974 | Acc(train) 0.8614 | Acc(val) 0.8524 |
Epoch 00135 | Loss(train) 0.6934 | Acc(train) 0.8632 | Acc(val) 0.8561 |*
Epoch 00136 | Loss(train) 0.6678 | Acc(train) 0.8688 | Acc(val) 0.8598 |*
Epoch 00137 | Loss(train) 0.6699 | Acc(train) 0.8614 | Acc(val) 0.8598 |
Epoch 00138 | Loss(train) 0.6878 | Acc(train) 0.8595 | Acc(val) 0.8524 |
Epoch 00139 | Loss(train) 0.6665 | Acc(train) 0.8558 | Acc(val) 0.8561 |
Epoch 00140 | Loss(train) 0.6496 | Acc(train) 0.8799 | Acc(val) 0.8524 |
Epoch 00141 | Loss(train) 0.6457 | Acc(train) 0.8872 | Acc(val) 0.8561 |
Epoch 00142 | Loss(train) 0.6407 | Acc(train) 0.8706 | Acc(val) 0.8598 |
Epoch 00143 | Loss(train) 0.6617 | Acc(train) 0.8762 | Acc(val) 0.8524 |
Epoch 00144 | Loss(train) 0.6702 | Acc(train) 0.8503 | Acc(val) 0.8561 |
Epoch 00145 | Loss(train) 0.6553 | Acc(train) 0.8614 | Acc(val) 0.8598 |
Epoch 00146 | Loss(train) 0.6498 | Acc(train) 0.8780 | Acc(val) 0.8561 |
Epoch 00147 | Loss(train) 0.6607 | Acc(train) 0.8614 | Acc(val) 0.8598 |
Epoch 00148 | Loss(train) 0.6334 | Acc(train) 0.8669 | Acc(val) 0.8672 |*
Epoch 00149 | Loss(train) 0.6434 | Acc(train) 0.8484 | Acc(val) 0.8708 |*
Epoch 00150 | Loss(train) 0.6348 | Acc(train) 0.8725 | Acc(val) 0.8635 |
Epoch 00151 | Loss(train) 0.6252 | Acc(train) 0.8632 | Acc(val) 0.8561 |
Epoch 00152 | Loss(train) 0.6496 | Acc(train) 0.8799 | Acc(val) 0.8561 |
Epoch 00153 | Loss(train) 0.6508 | Acc(train) 0.8799 | Acc(val) 0.8524 |
Epoch 00154 | Loss(train) 0.6257 | Acc(train) 0.8817 | Acc(val) 0.8524 |
Epoch 00155 | Loss(train) 0.6376 | Acc(train) 0.8669 | Acc(val) 0.8561 |
Epoch 00156 | Loss(train) 0.6202 | Acc(train) 0.8688 | Acc(val) 0.8672 |
Epoch 00157 | Loss(train) 0.6359 | Acc(train) 0.8614 | Acc(val) 0.8745 |*
Epoch 00158 | Loss(train) 0.6094 | Acc(train) 0.8706 | Acc(val) 0.8745 |
Epoch 00159 | Loss(train) 0.6079 | Acc(train) 0.8762 | Acc(val) 0.8782 |*
Epoch 00160 | Loss(train) 0.6144 | Acc(train) 0.8706 | Acc(val) 0.8819 |*
Epoch 00161 | Loss(train) 0.6199 | Acc(train) 0.8706 | Acc(val) 0.8708 |
Epoch 00162 | Loss(train) 0.6134 | Acc(train) 0.8909 | Acc(val) 0.8745 |
Epoch 00163 | Loss(train) 0.5909 | Acc(train) 0.8928 | Acc(val) 0.8635 |
Epoch 00164 | Loss(train) 0.6042 | Acc(train) 0.8762 | Acc(val) 0.8598 |
Epoch 00165 | Loss(train) 0.5996 | Acc(train) 0.8725 | Acc(val) 0.8598 |
Epoch 00166 | Loss(train) 0.5946 | Acc(train) 0.8669 | Acc(val) 0.8635 |
Epoch 00167 | Loss(train) 0.5787 | Acc(train) 0.9002 | Acc(val) 0.8672 |
Epoch 00168 | Loss(train) 0.5974 | Acc(train) 0.8872 | Acc(val) 0.8708 |
Epoch 00169 | Loss(train) 0.5784 | Acc(train) 0.8706 | Acc(val) 0.8708 |
Epoch 00170 | Loss(train) 0.5756 | Acc(train) 0.9150 | Acc(val) 0.8708 |
Epoch 00171 | Loss(train) 0.5589 | Acc(train) 0.8946 | Acc(val) 0.8708 |
Epoch 00172 | Loss(train) 0.5858 | Acc(train) 0.8909 | Acc(val) 0.8708 |
Epoch 00173 | Loss(train) 0.5585 | Acc(train) 0.9002 | Acc(val) 0.8708 |
Epoch 00174 | Loss(train) 0.5814 | Acc(train) 0.8743 | Acc(val) 0.8672 |
Epoch 00175 | Loss(train) 0.5836 | Acc(train) 0.8928 | Acc(val) 0.8745 |
Epoch 00176 | Loss(train) 0.5841 | Acc(train) 0.8706 | Acc(val) 0.8708 |
Epoch 00177 | Loss(train) 0.5708 | Acc(train) 0.8909 | Acc(val) 0.8708 |
Epoch 00178 | Loss(train) 0.5732 | Acc(train) 0.8983 | Acc(val) 0.8745 |
Epoch 00179 | Loss(train) 0.5780 | Acc(train) 0.8872 | Acc(val) 0.8672 |
Epoch 00180 | Loss(train) 0.5521 | Acc(train) 0.8909 | Acc(val) 0.8708 |
Epoch 00181 | Loss(train) 0.5546 | Acc(train) 0.8872 | Acc(val) 0.8708 |
Epoch 00182 | Loss(train) 0.5549 | Acc(train) 0.8946 | Acc(val) 0.8782 |
Epoch 00183 | Loss(train) 0.5701 | Acc(train) 0.8835 | Acc(val) 0.8782 |
Epoch 00184 | Loss(train) 0.5849 | Acc(train) 0.8799 | Acc(val) 0.8782 |
Epoch 00185 | Loss(train) 0.5441 | Acc(train) 0.9020 | Acc(val) 0.8782 |
Epoch 00186 | Loss(train) 0.5585 | Acc(train) 0.8946 | Acc(val) 0.8708 |
Epoch 00187 | Loss(train) 0.5413 | Acc(train) 0.8854 | Acc(val) 0.8672 |
Epoch 00188 | Loss(train) 0.5519 | Acc(train) 0.9057 | Acc(val) 0.8708 |
Epoch 00189 | Loss(train) 0.5565 | Acc(train) 0.8891 | Acc(val) 0.8672 |
Epoch 00190 | Loss(train) 0.5484 | Acc(train) 0.9039 | Acc(val) 0.8635 |
Epoch 00191 | Loss(train) 0.5653 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00192 | Loss(train) 0.5244 | Acc(train) 0.8983 | Acc(val) 0.8672 |
Epoch 00193 | Loss(train) 0.5106 | Acc(train) 0.9020 | Acc(val) 0.8672 |
Epoch 00194 | Loss(train) 0.5509 | Acc(train) 0.8946 | Acc(val) 0.8708 |
Epoch 00195 | Loss(train) 0.5337 | Acc(train) 0.8965 | Acc(val) 0.8708 |
Epoch 00196 | Loss(train) 0.5693 | Acc(train) 0.8817 | Acc(val) 0.8708 |
Epoch 00197 | Loss(train) 0.5382 | Acc(train) 0.9039 | Acc(val) 0.8708 |
Epoch 00198 | Loss(train) 0.5470 | Acc(train) 0.9002 | Acc(val) 0.8672 |
Epoch 00199 | Loss(train) 0.5385 | Acc(train) 0.8983 | Acc(val) 0.8672 |
Epoch 00200 | Loss(train) 0.5406 | Acc(train) 0.8965 | Acc(val) 0.8782 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9450 | Acc(train) 0.1719 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9298 | Acc(train) 0.2791 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9141 | Acc(train) 0.2773 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.8977 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8828 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8692 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8532 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8387 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8272 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8172 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.7977 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7933 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7875 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7691 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7559 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7514 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7462 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7388 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7306 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7131 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.7105 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.6990 | Acc(train) 0.2847 | Acc(val) 0.3026 |*
Epoch 00023 | Loss(train) 1.6860 | Acc(train) 0.2976 | Acc(val) 0.3026 |
Epoch 00024 | Loss(train) 1.6835 | Acc(train) 0.3068 | Acc(val) 0.3026 |
Epoch 00025 | Loss(train) 1.6549 | Acc(train) 0.3235 | Acc(val) 0.3210 |*
Epoch 00026 | Loss(train) 1.6559 | Acc(train) 0.3216 | Acc(val) 0.3247 |*
Epoch 00027 | Loss(train) 1.6415 | Acc(train) 0.3327 | Acc(val) 0.3284 |*
Epoch 00028 | Loss(train) 1.6360 | Acc(train) 0.3567 | Acc(val) 0.3321 |*
Epoch 00029 | Loss(train) 1.6208 | Acc(train) 0.3567 | Acc(val) 0.3321 |
Epoch 00030 | Loss(train) 1.6043 | Acc(train) 0.3641 | Acc(val) 0.3358 |*
Epoch 00031 | Loss(train) 1.6018 | Acc(train) 0.3752 | Acc(val) 0.3395 |*
Epoch 00032 | Loss(train) 1.5828 | Acc(train) 0.3919 | Acc(val) 0.3395 |
Epoch 00033 | Loss(train) 1.5630 | Acc(train) 0.3900 | Acc(val) 0.3395 |
Epoch 00034 | Loss(train) 1.5535 | Acc(train) 0.3863 | Acc(val) 0.3432 |*
Epoch 00035 | Loss(train) 1.5585 | Acc(train) 0.4030 | Acc(val) 0.3542 |*
Epoch 00036 | Loss(train) 1.5410 | Acc(train) 0.4288 | Acc(val) 0.3727 |*
Epoch 00037 | Loss(train) 1.5271 | Acc(train) 0.4196 | Acc(val) 0.3875 |*
Epoch 00038 | Loss(train) 1.5126 | Acc(train) 0.4658 | Acc(val) 0.4133 |*
Epoch 00039 | Loss(train) 1.5183 | Acc(train) 0.4510 | Acc(val) 0.4317 |*
Epoch 00040 | Loss(train) 1.4843 | Acc(train) 0.4621 | Acc(val) 0.4428 |*
Epoch 00041 | Loss(train) 1.4914 | Acc(train) 0.4713 | Acc(val) 0.4613 |*
Epoch 00042 | Loss(train) 1.4611 | Acc(train) 0.4935 | Acc(val) 0.4723 |*
Epoch 00043 | Loss(train) 1.4615 | Acc(train) 0.4732 | Acc(val) 0.4908 |*
Epoch 00044 | Loss(train) 1.4500 | Acc(train) 0.4917 | Acc(val) 0.5018 |*
Epoch 00045 | Loss(train) 1.4451 | Acc(train) 0.5231 | Acc(val) 0.5166 |*
Epoch 00046 | Loss(train) 1.4211 | Acc(train) 0.5416 | Acc(val) 0.5240 |*
Epoch 00047 | Loss(train) 1.4099 | Acc(train) 0.5287 | Acc(val) 0.5314 |*
Epoch 00048 | Loss(train) 1.3893 | Acc(train) 0.5527 | Acc(val) 0.5387 |*
Epoch 00049 | Loss(train) 1.3917 | Acc(train) 0.5564 | Acc(val) 0.5498 |*
Epoch 00050 | Loss(train) 1.3563 | Acc(train) 0.5545 | Acc(val) 0.5720 |*
Epoch 00051 | Loss(train) 1.3500 | Acc(train) 0.5675 | Acc(val) 0.5793 |*
Epoch 00052 | Loss(train) 1.3409 | Acc(train) 0.5970 | Acc(val) 0.5978 |*
Epoch 00053 | Loss(train) 1.3343 | Acc(train) 0.5952 | Acc(val) 0.6089 |*
Epoch 00054 | Loss(train) 1.3020 | Acc(train) 0.6137 | Acc(val) 0.6236 |*
Epoch 00055 | Loss(train) 1.3206 | Acc(train) 0.6026 | Acc(val) 0.6384 |*
Epoch 00056 | Loss(train) 1.2910 | Acc(train) 0.6359 | Acc(val) 0.6494 |*
Epoch 00057 | Loss(train) 1.2801 | Acc(train) 0.6155 | Acc(val) 0.6605 |*
Epoch 00058 | Loss(train) 1.2748 | Acc(train) 0.6525 | Acc(val) 0.6642 |*
Epoch 00059 | Loss(train) 1.2604 | Acc(train) 0.6543 | Acc(val) 0.6716 |*
Epoch 00060 | Loss(train) 1.2355 | Acc(train) 0.6673 | Acc(val) 0.6716 |
Epoch 00061 | Loss(train) 1.2394 | Acc(train) 0.6673 | Acc(val) 0.6827 |*
Epoch 00062 | Loss(train) 1.2045 | Acc(train) 0.7043 | Acc(val) 0.7011 |*
Epoch 00063 | Loss(train) 1.1980 | Acc(train) 0.6858 | Acc(val) 0.7232 |*
Epoch 00064 | Loss(train) 1.1996 | Acc(train) 0.6876 | Acc(val) 0.7232 |
Epoch 00065 | Loss(train) 1.1993 | Acc(train) 0.6765 | Acc(val) 0.7343 |*
Epoch 00066 | Loss(train) 1.1625 | Acc(train) 0.7098 | Acc(val) 0.7417 |*
Epoch 00067 | Loss(train) 1.1773 | Acc(train) 0.6802 | Acc(val) 0.7454 |*
Epoch 00068 | Loss(train) 1.1439 | Acc(train) 0.7061 | Acc(val) 0.7491 |*
Epoch 00069 | Loss(train) 1.1265 | Acc(train) 0.7209 | Acc(val) 0.7528 |*
Epoch 00070 | Loss(train) 1.1318 | Acc(train) 0.7190 | Acc(val) 0.7565 |*
Epoch 00071 | Loss(train) 1.1021 | Acc(train) 0.7283 | Acc(val) 0.7601 |*
Epoch 00072 | Loss(train) 1.0896 | Acc(train) 0.7264 | Acc(val) 0.7638 |*
Epoch 00073 | Loss(train) 1.0943 | Acc(train) 0.7153 | Acc(val) 0.7638 |
Epoch 00074 | Loss(train) 1.0995 | Acc(train) 0.7024 | Acc(val) 0.7638 |
Epoch 00075 | Loss(train) 1.0798 | Acc(train) 0.7338 | Acc(val) 0.7638 |
Epoch 00076 | Loss(train) 1.0608 | Acc(train) 0.7301 | Acc(val) 0.7675 |*
Epoch 00077 | Loss(train) 1.0668 | Acc(train) 0.7227 | Acc(val) 0.7749 |*
Epoch 00078 | Loss(train) 1.0533 | Acc(train) 0.7505 | Acc(val) 0.7749 |
Epoch 00079 | Loss(train) 1.0126 | Acc(train) 0.7708 | Acc(val) 0.7749 |
Epoch 00080 | Loss(train) 1.0384 | Acc(train) 0.7486 | Acc(val) 0.7749 |
Epoch 00081 | Loss(train) 0.9966 | Acc(train) 0.7616 | Acc(val) 0.7823 |*
Epoch 00082 | Loss(train) 0.9916 | Acc(train) 0.7505 | Acc(val) 0.7860 |*
Epoch 00083 | Loss(train) 1.0077 | Acc(train) 0.7283 | Acc(val) 0.7823 |
Epoch 00084 | Loss(train) 0.9625 | Acc(train) 0.7652 | Acc(val) 0.7860 |
Epoch 00085 | Loss(train) 0.9794 | Acc(train) 0.7745 | Acc(val) 0.7860 |
Epoch 00086 | Loss(train) 0.9812 | Acc(train) 0.7819 | Acc(val) 0.7860 |
Epoch 00087 | Loss(train) 0.9510 | Acc(train) 0.7616 | Acc(val) 0.7897 |*
Epoch 00088 | Loss(train) 0.9651 | Acc(train) 0.7634 | Acc(val) 0.7934 |*
Epoch 00089 | Loss(train) 0.9221 | Acc(train) 0.7800 | Acc(val) 0.7970 |*
Epoch 00090 | Loss(train) 0.9517 | Acc(train) 0.7726 | Acc(val) 0.8081 |*
Epoch 00091 | Loss(train) 0.9251 | Acc(train) 0.7948 | Acc(val) 0.8118 |*
Epoch 00092 | Loss(train) 0.9233 | Acc(train) 0.7893 | Acc(val) 0.8118 |
Epoch 00093 | Loss(train) 0.8926 | Acc(train) 0.7967 | Acc(val) 0.8118 |
Epoch 00094 | Loss(train) 0.8842 | Acc(train) 0.7819 | Acc(val) 0.8192 |*
Epoch 00095 | Loss(train) 0.8850 | Acc(train) 0.8207 | Acc(val) 0.8229 |*
Epoch 00096 | Loss(train) 0.9118 | Acc(train) 0.7911 | Acc(val) 0.8303 |*
Epoch 00097 | Loss(train) 0.8860 | Acc(train) 0.8022 | Acc(val) 0.8266 |
Epoch 00098 | Loss(train) 0.8915 | Acc(train) 0.7930 | Acc(val) 0.8229 |
Epoch 00099 | Loss(train) 0.8827 | Acc(train) 0.8115 | Acc(val) 0.8192 |
Epoch 00100 | Loss(train) 0.8778 | Acc(train) 0.7948 | Acc(val) 0.8192 |
Epoch 00101 | Loss(train) 0.8780 | Acc(train) 0.7856 | Acc(val) 0.8376 |*
Epoch 00102 | Loss(train) 0.8661 | Acc(train) 0.8189 | Acc(val) 0.8339 |
Epoch 00103 | Loss(train) 0.8673 | Acc(train) 0.8004 | Acc(val) 0.8376 |
Epoch 00104 | Loss(train) 0.8360 | Acc(train) 0.8207 | Acc(val) 0.8376 |
Epoch 00105 | Loss(train) 0.8373 | Acc(train) 0.8226 | Acc(val) 0.8303 |
Epoch 00106 | Loss(train) 0.8208 | Acc(train) 0.8004 | Acc(val) 0.8339 |
Epoch 00107 | Loss(train) 0.8278 | Acc(train) 0.8115 | Acc(val) 0.8413 |*
Epoch 00108 | Loss(train) 0.8241 | Acc(train) 0.8152 | Acc(val) 0.8413 |
Epoch 00109 | Loss(train) 0.8305 | Acc(train) 0.8207 | Acc(val) 0.8413 |
Epoch 00110 | Loss(train) 0.7940 | Acc(train) 0.8262 | Acc(val) 0.8450 |*
Epoch 00111 | Loss(train) 0.8095 | Acc(train) 0.8078 | Acc(val) 0.8487 |*
Epoch 00112 | Loss(train) 0.7938 | Acc(train) 0.8336 | Acc(val) 0.8524 |*
Epoch 00113 | Loss(train) 0.8047 | Acc(train) 0.8096 | Acc(val) 0.8598 |*
Epoch 00114 | Loss(train) 0.7899 | Acc(train) 0.8244 | Acc(val) 0.8598 |
Epoch 00115 | Loss(train) 0.7637 | Acc(train) 0.8447 | Acc(val) 0.8635 |*
Epoch 00116 | Loss(train) 0.7598 | Acc(train) 0.8503 | Acc(val) 0.8672 |*
Epoch 00117 | Loss(train) 0.8034 | Acc(train) 0.7967 | Acc(val) 0.8635 |
Epoch 00118 | Loss(train) 0.7567 | Acc(train) 0.8373 | Acc(val) 0.8561 |
Epoch 00119 | Loss(train) 0.7514 | Acc(train) 0.8447 | Acc(val) 0.8561 |
Epoch 00120 | Loss(train) 0.7442 | Acc(train) 0.8226 | Acc(val) 0.8450 |
Epoch 00121 | Loss(train) 0.7477 | Acc(train) 0.8189 | Acc(val) 0.8450 |
Epoch 00122 | Loss(train) 0.7537 | Acc(train) 0.8484 | Acc(val) 0.8487 |
Epoch 00123 | Loss(train) 0.7639 | Acc(train) 0.8207 | Acc(val) 0.8561 |
Epoch 00124 | Loss(train) 0.7799 | Acc(train) 0.8318 | Acc(val) 0.8635 |
Epoch 00125 | Loss(train) 0.7476 | Acc(train) 0.8318 | Acc(val) 0.8598 |
Epoch 00126 | Loss(train) 0.7411 | Acc(train) 0.8429 | Acc(val) 0.8635 |
Epoch 00127 | Loss(train) 0.7443 | Acc(train) 0.8466 | Acc(val) 0.8635 |
Epoch 00128 | Loss(train) 0.7248 | Acc(train) 0.8373 | Acc(val) 0.8598 |
Epoch 00129 | Loss(train) 0.7187 | Acc(train) 0.8447 | Acc(val) 0.8524 |
Epoch 00130 | Loss(train) 0.7055 | Acc(train) 0.8484 | Acc(val) 0.8561 |
Epoch 00131 | Loss(train) 0.7053 | Acc(train) 0.8466 | Acc(val) 0.8598 |
Epoch 00132 | Loss(train) 0.6967 | Acc(train) 0.8577 | Acc(val) 0.8524 |
Epoch 00133 | Loss(train) 0.7024 | Acc(train) 0.8540 | Acc(val) 0.8598 |
Epoch 00134 | Loss(train) 0.7067 | Acc(train) 0.8577 | Acc(val) 0.8635 |
Epoch 00135 | Loss(train) 0.7074 | Acc(train) 0.8521 | Acc(val) 0.8672 |
Epoch 00136 | Loss(train) 0.6978 | Acc(train) 0.8577 | Acc(val) 0.8672 |
Epoch 00137 | Loss(train) 0.7195 | Acc(train) 0.8355 | Acc(val) 0.8635 |
Epoch 00138 | Loss(train) 0.7026 | Acc(train) 0.8595 | Acc(val) 0.8598 |
Epoch 00139 | Loss(train) 0.6951 | Acc(train) 0.8558 | Acc(val) 0.8561 |
Epoch 00140 | Loss(train) 0.6749 | Acc(train) 0.8540 | Acc(val) 0.8598 |
Epoch 00141 | Loss(train) 0.6779 | Acc(train) 0.8688 | Acc(val) 0.8635 |
Epoch 00142 | Loss(train) 0.6900 | Acc(train) 0.8503 | Acc(val) 0.8708 |*
Epoch 00143 | Loss(train) 0.6819 | Acc(train) 0.8558 | Acc(val) 0.8708 |
Epoch 00144 | Loss(train) 0.6940 | Acc(train) 0.8355 | Acc(val) 0.8745 |*
Epoch 00145 | Loss(train) 0.6628 | Acc(train) 0.8762 | Acc(val) 0.8745 |
Epoch 00146 | Loss(train) 0.6802 | Acc(train) 0.8725 | Acc(val) 0.8708 |
Epoch 00147 | Loss(train) 0.6413 | Acc(train) 0.8762 | Acc(val) 0.8635 |
Epoch 00148 | Loss(train) 0.6749 | Acc(train) 0.8688 | Acc(val) 0.8672 |
Epoch 00149 | Loss(train) 0.6568 | Acc(train) 0.8743 | Acc(val) 0.8708 |
Epoch 00150 | Loss(train) 0.6675 | Acc(train) 0.8725 | Acc(val) 0.8708 |
Epoch 00151 | Loss(train) 0.6714 | Acc(train) 0.8318 | Acc(val) 0.8782 |*
Epoch 00152 | Loss(train) 0.6650 | Acc(train) 0.8688 | Acc(val) 0.8782 |
Epoch 00153 | Loss(train) 0.6595 | Acc(train) 0.8669 | Acc(val) 0.8708 |
Epoch 00154 | Loss(train) 0.6493 | Acc(train) 0.8651 | Acc(val) 0.8708 |
Epoch 00155 | Loss(train) 0.6492 | Acc(train) 0.8540 | Acc(val) 0.8708 |
Epoch 00156 | Loss(train) 0.6787 | Acc(train) 0.8632 | Acc(val) 0.8782 |
Epoch 00157 | Loss(train) 0.6473 | Acc(train) 0.8688 | Acc(val) 0.8708 |
Epoch 00158 | Loss(train) 0.6446 | Acc(train) 0.8632 | Acc(val) 0.8708 |
Epoch 00159 | Loss(train) 0.6433 | Acc(train) 0.8725 | Acc(val) 0.8672 |
Epoch 00160 | Loss(train) 0.6322 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00161 | Loss(train) 0.6110 | Acc(train) 0.8799 | Acc(val) 0.8708 |
Epoch 00162 | Loss(train) 0.6493 | Acc(train) 0.8577 | Acc(val) 0.8745 |
Epoch 00163 | Loss(train) 0.6237 | Acc(train) 0.8651 | Acc(val) 0.8782 |
Epoch 00164 | Loss(train) 0.6156 | Acc(train) 0.8743 | Acc(val) 0.8745 |
Epoch 00165 | Loss(train) 0.6140 | Acc(train) 0.8558 | Acc(val) 0.8782 |
Epoch 00166 | Loss(train) 0.6552 | Acc(train) 0.8558 | Acc(val) 0.8745 |
Epoch 00167 | Loss(train) 0.5895 | Acc(train) 0.8928 | Acc(val) 0.8708 |
Epoch 00168 | Loss(train) 0.6304 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00169 | Loss(train) 0.6038 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00170 | Loss(train) 0.5988 | Acc(train) 0.8891 | Acc(val) 0.8782 |
Epoch 00171 | Loss(train) 0.6021 | Acc(train) 0.8651 | Acc(val) 0.8856 |*
Epoch 00172 | Loss(train) 0.6285 | Acc(train) 0.8540 | Acc(val) 0.8819 |
Epoch 00173 | Loss(train) 0.6038 | Acc(train) 0.8872 | Acc(val) 0.8745 |
Epoch 00174 | Loss(train) 0.6110 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00175 | Loss(train) 0.6175 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00176 | Loss(train) 0.6254 | Acc(train) 0.8577 | Acc(val) 0.8672 |
Epoch 00177 | Loss(train) 0.5898 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00178 | Loss(train) 0.6061 | Acc(train) 0.8725 | Acc(val) 0.8745 |
Epoch 00179 | Loss(train) 0.5823 | Acc(train) 0.8706 | Acc(val) 0.8782 |
Epoch 00180 | Loss(train) 0.6030 | Acc(train) 0.8762 | Acc(val) 0.8856 |
Epoch 00181 | Loss(train) 0.6006 | Acc(train) 0.8688 | Acc(val) 0.8893 |*
Epoch 00182 | Loss(train) 0.5967 | Acc(train) 0.8854 | Acc(val) 0.8893 |
Epoch 00183 | Loss(train) 0.5959 | Acc(train) 0.8780 | Acc(val) 0.8893 |
Epoch 00184 | Loss(train) 0.6043 | Acc(train) 0.8669 | Acc(val) 0.8819 |
Epoch 00185 | Loss(train) 0.5835 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00186 | Loss(train) 0.5985 | Acc(train) 0.8817 | Acc(val) 0.8745 |
Epoch 00187 | Loss(train) 0.5970 | Acc(train) 0.8688 | Acc(val) 0.8745 |
Epoch 00188 | Loss(train) 0.5623 | Acc(train) 0.8946 | Acc(val) 0.8782 |
Epoch 00189 | Loss(train) 0.5822 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00190 | Loss(train) 0.5512 | Acc(train) 0.8965 | Acc(val) 0.8819 |
Epoch 00191 | Loss(train) 0.6012 | Acc(train) 0.8799 | Acc(val) 0.8893 |
Epoch 00192 | Loss(train) 0.5640 | Acc(train) 0.8909 | Acc(val) 0.8893 |
Epoch 00193 | Loss(train) 0.5608 | Acc(train) 0.8817 | Acc(val) 0.8856 |
Epoch 00194 | Loss(train) 0.5607 | Acc(train) 0.8965 | Acc(val) 0.8819 |
Epoch 00195 | Loss(train) 0.5870 | Acc(train) 0.8651 | Acc(val) 0.8819 |
Epoch 00196 | Loss(train) 0.5810 | Acc(train) 0.8835 | Acc(val) 0.8782 |
Epoch 00197 | Loss(train) 0.5763 | Acc(train) 0.8706 | Acc(val) 0.8782 |
Epoch 00198 | Loss(train) 0.5742 | Acc(train) 0.8835 | Acc(val) 0.8782 |
Epoch 00199 | Loss(train) 0.5609 | Acc(train) 0.8891 | Acc(val) 0.8856 |
Epoch 00200 | Loss(train) 0.5477 | Acc(train) 0.8909 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9453 | Acc(train) 0.2070 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9319 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9183 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9056 | Acc(train) 0.2791 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8908 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8766 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8643 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8526 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8435 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8199 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8100 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7952 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7826 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7688 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7678 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7531 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7446 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7326 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7219 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7079 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00021 | Loss(train) 1.6919 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00022 | Loss(train) 1.6955 | Acc(train) 0.2976 | Acc(val) 0.3026 |*
Epoch 00023 | Loss(train) 1.6610 | Acc(train) 0.3105 | Acc(val) 0.3026 |
Epoch 00024 | Loss(train) 1.6623 | Acc(train) 0.3161 | Acc(val) 0.3210 |*
Epoch 00025 | Loss(train) 1.6455 | Acc(train) 0.3383 | Acc(val) 0.3210 |
Epoch 00026 | Loss(train) 1.6263 | Acc(train) 0.3494 | Acc(val) 0.3247 |*
Epoch 00027 | Loss(train) 1.6212 | Acc(train) 0.3660 | Acc(val) 0.3506 |*
Epoch 00028 | Loss(train) 1.6125 | Acc(train) 0.3808 | Acc(val) 0.3801 |*
Epoch 00029 | Loss(train) 1.5942 | Acc(train) 0.4140 | Acc(val) 0.3911 |*
Epoch 00030 | Loss(train) 1.5806 | Acc(train) 0.4159 | Acc(val) 0.3911 |
Epoch 00031 | Loss(train) 1.5591 | Acc(train) 0.4492 | Acc(val) 0.3985 |*
Epoch 00032 | Loss(train) 1.5549 | Acc(train) 0.4399 | Acc(val) 0.4096 |*
Epoch 00033 | Loss(train) 1.5400 | Acc(train) 0.4529 | Acc(val) 0.4096 |
Epoch 00034 | Loss(train) 1.5227 | Acc(train) 0.4695 | Acc(val) 0.4096 |
Epoch 00035 | Loss(train) 1.5156 | Acc(train) 0.4658 | Acc(val) 0.4096 |
Epoch 00036 | Loss(train) 1.4962 | Acc(train) 0.4640 | Acc(val) 0.4096 |
Epoch 00037 | Loss(train) 1.4790 | Acc(train) 0.4584 | Acc(val) 0.4170 |*
Epoch 00038 | Loss(train) 1.4808 | Acc(train) 0.4769 | Acc(val) 0.4244 |*
Epoch 00039 | Loss(train) 1.4586 | Acc(train) 0.4806 | Acc(val) 0.4317 |*
Epoch 00040 | Loss(train) 1.4478 | Acc(train) 0.4880 | Acc(val) 0.4539 |*
Epoch 00041 | Loss(train) 1.4361 | Acc(train) 0.4935 | Acc(val) 0.4834 |*
Epoch 00042 | Loss(train) 1.4223 | Acc(train) 0.5250 | Acc(val) 0.5129 |*
Epoch 00043 | Loss(train) 1.4050 | Acc(train) 0.5176 | Acc(val) 0.5240 |*
Epoch 00044 | Loss(train) 1.3768 | Acc(train) 0.5619 | Acc(val) 0.5498 |*
Epoch 00045 | Loss(train) 1.3907 | Acc(train) 0.5508 | Acc(val) 0.5683 |*
Epoch 00046 | Loss(train) 1.3610 | Acc(train) 0.5804 | Acc(val) 0.5720 |*
Epoch 00047 | Loss(train) 1.3282 | Acc(train) 0.6100 | Acc(val) 0.5756 |*
Epoch 00048 | Loss(train) 1.3170 | Acc(train) 0.6007 | Acc(val) 0.5904 |*
Epoch 00049 | Loss(train) 1.3200 | Acc(train) 0.5860 | Acc(val) 0.5978 |*
Epoch 00050 | Loss(train) 1.3198 | Acc(train) 0.6155 | Acc(val) 0.6052 |*
Epoch 00051 | Loss(train) 1.2948 | Acc(train) 0.6155 | Acc(val) 0.6199 |*
Epoch 00052 | Loss(train) 1.2818 | Acc(train) 0.6026 | Acc(val) 0.6310 |*
Epoch 00053 | Loss(train) 1.2709 | Acc(train) 0.6155 | Acc(val) 0.6421 |*
Epoch 00054 | Loss(train) 1.2580 | Acc(train) 0.6599 | Acc(val) 0.6716 |*
Epoch 00055 | Loss(train) 1.2483 | Acc(train) 0.6359 | Acc(val) 0.6863 |*
Epoch 00056 | Loss(train) 1.2495 | Acc(train) 0.6377 | Acc(val) 0.6827 |
Epoch 00057 | Loss(train) 1.2366 | Acc(train) 0.6340 | Acc(val) 0.7048 |*
Epoch 00058 | Loss(train) 1.2016 | Acc(train) 0.6543 | Acc(val) 0.7085 |*
Epoch 00059 | Loss(train) 1.2013 | Acc(train) 0.6673 | Acc(val) 0.7085 |
Epoch 00060 | Loss(train) 1.1622 | Acc(train) 0.6913 | Acc(val) 0.7159 |*
Epoch 00061 | Loss(train) 1.1670 | Acc(train) 0.6932 | Acc(val) 0.7196 |*
Epoch 00062 | Loss(train) 1.1625 | Acc(train) 0.7079 | Acc(val) 0.7196 |
Epoch 00063 | Loss(train) 1.1454 | Acc(train) 0.6876 | Acc(val) 0.7196 |
Epoch 00064 | Loss(train) 1.1422 | Acc(train) 0.7006 | Acc(val) 0.7269 |*
Epoch 00065 | Loss(train) 1.1309 | Acc(train) 0.6821 | Acc(val) 0.7269 |
Epoch 00066 | Loss(train) 1.1021 | Acc(train) 0.7209 | Acc(val) 0.7269 |
Epoch 00067 | Loss(train) 1.0963 | Acc(train) 0.7024 | Acc(val) 0.7269 |
Epoch 00068 | Loss(train) 1.0828 | Acc(train) 0.7172 | Acc(val) 0.7380 |*
Epoch 00069 | Loss(train) 1.0772 | Acc(train) 0.7153 | Acc(val) 0.7417 |*
Epoch 00070 | Loss(train) 1.0670 | Acc(train) 0.7043 | Acc(val) 0.7454 |*
Epoch 00071 | Loss(train) 1.0505 | Acc(train) 0.7079 | Acc(val) 0.7454 |
Epoch 00072 | Loss(train) 1.0385 | Acc(train) 0.7061 | Acc(val) 0.7417 |
Epoch 00073 | Loss(train) 1.0399 | Acc(train) 0.7320 | Acc(val) 0.7417 |
Epoch 00074 | Loss(train) 1.0293 | Acc(train) 0.7116 | Acc(val) 0.7454 |
Epoch 00075 | Loss(train) 1.0098 | Acc(train) 0.7431 | Acc(val) 0.7528 |*
Epoch 00076 | Loss(train) 0.9805 | Acc(train) 0.7763 | Acc(val) 0.7601 |*
Epoch 00077 | Loss(train) 0.9892 | Acc(train) 0.7412 | Acc(val) 0.7712 |*
Epoch 00078 | Loss(train) 0.9779 | Acc(train) 0.7671 | Acc(val) 0.7712 |
Epoch 00079 | Loss(train) 0.9779 | Acc(train) 0.7320 | Acc(val) 0.7749 |*
Epoch 00080 | Loss(train) 0.9971 | Acc(train) 0.7412 | Acc(val) 0.7712 |
Epoch 00081 | Loss(train) 0.9503 | Acc(train) 0.7523 | Acc(val) 0.7786 |*
Epoch 00082 | Loss(train) 0.9291 | Acc(train) 0.7819 | Acc(val) 0.7823 |*
Epoch 00083 | Loss(train) 0.9403 | Acc(train) 0.7745 | Acc(val) 0.7823 |
Epoch 00084 | Loss(train) 0.9251 | Acc(train) 0.7874 | Acc(val) 0.7897 |*
Epoch 00085 | Loss(train) 0.9156 | Acc(train) 0.7874 | Acc(val) 0.7970 |*
Epoch 00086 | Loss(train) 0.9165 | Acc(train) 0.8022 | Acc(val) 0.8007 |*
Epoch 00087 | Loss(train) 0.9080 | Acc(train) 0.7782 | Acc(val) 0.7970 |
Epoch 00088 | Loss(train) 0.9038 | Acc(train) 0.7856 | Acc(val) 0.7970 |
Epoch 00089 | Loss(train) 0.8842 | Acc(train) 0.8022 | Acc(val) 0.8007 |
Epoch 00090 | Loss(train) 0.8837 | Acc(train) 0.8078 | Acc(val) 0.8081 |*
Epoch 00091 | Loss(train) 0.8911 | Acc(train) 0.7837 | Acc(val) 0.8155 |*
Epoch 00092 | Loss(train) 0.8865 | Acc(train) 0.7726 | Acc(val) 0.8192 |*
Epoch 00093 | Loss(train) 0.8592 | Acc(train) 0.8041 | Acc(val) 0.8192 |
Epoch 00094 | Loss(train) 0.8610 | Acc(train) 0.8041 | Acc(val) 0.8155 |
Epoch 00095 | Loss(train) 0.8398 | Acc(train) 0.8170 | Acc(val) 0.8155 |
Epoch 00096 | Loss(train) 0.8426 | Acc(train) 0.8041 | Acc(val) 0.8118 |
Epoch 00097 | Loss(train) 0.8508 | Acc(train) 0.7911 | Acc(val) 0.8192 |
Epoch 00098 | Loss(train) 0.8238 | Acc(train) 0.8004 | Acc(val) 0.8229 |*
Epoch 00099 | Loss(train) 0.8476 | Acc(train) 0.7967 | Acc(val) 0.8229 |
Epoch 00100 | Loss(train) 0.8241 | Acc(train) 0.8152 | Acc(val) 0.8229 |
Epoch 00101 | Loss(train) 0.8252 | Acc(train) 0.8115 | Acc(val) 0.8229 |
Epoch 00102 | Loss(train) 0.8263 | Acc(train) 0.8170 | Acc(val) 0.8192 |
Epoch 00103 | Loss(train) 0.7913 | Acc(train) 0.8373 | Acc(val) 0.8155 |
Epoch 00104 | Loss(train) 0.7928 | Acc(train) 0.8189 | Acc(val) 0.8229 |
Epoch 00105 | Loss(train) 0.7857 | Acc(train) 0.8170 | Acc(val) 0.8266 |*
Epoch 00106 | Loss(train) 0.7563 | Acc(train) 0.8466 | Acc(val) 0.8303 |*
Epoch 00107 | Loss(train) 0.7610 | Acc(train) 0.8725 | Acc(val) 0.8413 |*
Epoch 00108 | Loss(train) 0.7706 | Acc(train) 0.8262 | Acc(val) 0.8413 |
Epoch 00109 | Loss(train) 0.7639 | Acc(train) 0.8336 | Acc(val) 0.8339 |
Epoch 00110 | Loss(train) 0.7823 | Acc(train) 0.8299 | Acc(val) 0.8413 |
Epoch 00111 | Loss(train) 0.7497 | Acc(train) 0.8558 | Acc(val) 0.8339 |
Epoch 00112 | Loss(train) 0.7347 | Acc(train) 0.8410 | Acc(val) 0.8339 |
Epoch 00113 | Loss(train) 0.7295 | Acc(train) 0.8706 | Acc(val) 0.8413 |
Epoch 00114 | Loss(train) 0.7251 | Acc(train) 0.8558 | Acc(val) 0.8598 |*
Epoch 00115 | Loss(train) 0.7285 | Acc(train) 0.8651 | Acc(val) 0.8598 |
Epoch 00116 | Loss(train) 0.7522 | Acc(train) 0.8447 | Acc(val) 0.8561 |
Epoch 00117 | Loss(train) 0.7113 | Acc(train) 0.8521 | Acc(val) 0.8635 |*
Epoch 00118 | Loss(train) 0.7122 | Acc(train) 0.8651 | Acc(val) 0.8598 |
Epoch 00119 | Loss(train) 0.6979 | Acc(train) 0.8577 | Acc(val) 0.8561 |
Epoch 00120 | Loss(train) 0.7279 | Acc(train) 0.8281 | Acc(val) 0.8524 |
Epoch 00121 | Loss(train) 0.7103 | Acc(train) 0.8595 | Acc(val) 0.8561 |
Epoch 00122 | Loss(train) 0.7100 | Acc(train) 0.8595 | Acc(val) 0.8524 |
Epoch 00123 | Loss(train) 0.7036 | Acc(train) 0.8725 | Acc(val) 0.8561 |
Epoch 00124 | Loss(train) 0.7058 | Acc(train) 0.8595 | Acc(val) 0.8598 |
Epoch 00125 | Loss(train) 0.7093 | Acc(train) 0.8632 | Acc(val) 0.8635 |
Epoch 00126 | Loss(train) 0.6781 | Acc(train) 0.8669 | Acc(val) 0.8708 |*
Epoch 00127 | Loss(train) 0.7117 | Acc(train) 0.8614 | Acc(val) 0.8708 |
Epoch 00128 | Loss(train) 0.7108 | Acc(train) 0.8447 | Acc(val) 0.8708 |
Epoch 00129 | Loss(train) 0.6908 | Acc(train) 0.8651 | Acc(val) 0.8672 |
Epoch 00130 | Loss(train) 0.6676 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00131 | Loss(train) 0.6676 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00132 | Loss(train) 0.6683 | Acc(train) 0.8558 | Acc(val) 0.8672 |
Epoch 00133 | Loss(train) 0.6679 | Acc(train) 0.8540 | Acc(val) 0.8672 |
Epoch 00134 | Loss(train) 0.6702 | Acc(train) 0.8669 | Acc(val) 0.8708 |
Epoch 00135 | Loss(train) 0.6699 | Acc(train) 0.8558 | Acc(val) 0.8708 |
Epoch 00136 | Loss(train) 0.6511 | Acc(train) 0.8688 | Acc(val) 0.8672 |
Epoch 00137 | Loss(train) 0.6381 | Acc(train) 0.8595 | Acc(val) 0.8635 |
Epoch 00138 | Loss(train) 0.6492 | Acc(train) 0.8817 | Acc(val) 0.8635 |
Epoch 00139 | Loss(train) 0.6574 | Acc(train) 0.8799 | Acc(val) 0.8635 |
Epoch 00140 | Loss(train) 0.6542 | Acc(train) 0.8540 | Acc(val) 0.8708 |
Epoch 00141 | Loss(train) 0.6355 | Acc(train) 0.8780 | Acc(val) 0.8782 |*
Epoch 00142 | Loss(train) 0.6622 | Acc(train) 0.8558 | Acc(val) 0.8782 |
Epoch 00143 | Loss(train) 0.6290 | Acc(train) 0.8854 | Acc(val) 0.8819 |*
Epoch 00144 | Loss(train) 0.6293 | Acc(train) 0.8725 | Acc(val) 0.8819 |
Epoch 00145 | Loss(train) 0.6327 | Acc(train) 0.8854 | Acc(val) 0.8819 |
Epoch 00146 | Loss(train) 0.6142 | Acc(train) 0.8872 | Acc(val) 0.8782 |
Epoch 00147 | Loss(train) 0.6143 | Acc(train) 0.8817 | Acc(val) 0.8745 |
Epoch 00148 | Loss(train) 0.5951 | Acc(train) 0.8817 | Acc(val) 0.8708 |
Epoch 00149 | Loss(train) 0.6054 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00150 | Loss(train) 0.5976 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00151 | Loss(train) 0.6196 | Acc(train) 0.8725 | Acc(val) 0.8708 |
Epoch 00152 | Loss(train) 0.6286 | Acc(train) 0.8540 | Acc(val) 0.8819 |
Epoch 00153 | Loss(train) 0.6081 | Acc(train) 0.8854 | Acc(val) 0.8893 |*
Epoch 00154 | Loss(train) 0.5878 | Acc(train) 0.8891 | Acc(val) 0.8819 |
Epoch 00155 | Loss(train) 0.6245 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00156 | Loss(train) 0.6073 | Acc(train) 0.8725 | Acc(val) 0.8782 |
Epoch 00157 | Loss(train) 0.6103 | Acc(train) 0.8854 | Acc(val) 0.8782 |
Epoch 00158 | Loss(train) 0.5872 | Acc(train) 0.8799 | Acc(val) 0.8782 |
Epoch 00159 | Loss(train) 0.5946 | Acc(train) 0.8854 | Acc(val) 0.8819 |
Epoch 00160 | Loss(train) 0.5890 | Acc(train) 0.8872 | Acc(val) 0.8819 |
Epoch 00161 | Loss(train) 0.5981 | Acc(train) 0.8762 | Acc(val) 0.8819 |
Epoch 00162 | Loss(train) 0.5820 | Acc(train) 0.8854 | Acc(val) 0.8856 |
Epoch 00163 | Loss(train) 0.5990 | Acc(train) 0.8909 | Acc(val) 0.8893 |
Epoch 00164 | Loss(train) 0.5744 | Acc(train) 0.8835 | Acc(val) 0.8893 |
Epoch 00165 | Loss(train) 0.5711 | Acc(train) 0.8762 | Acc(val) 0.8893 |
Epoch 00166 | Loss(train) 0.5796 | Acc(train) 0.9020 | Acc(val) 0.8856 |
Epoch 00167 | Loss(train) 0.5941 | Acc(train) 0.8725 | Acc(val) 0.8819 |
Epoch 00168 | Loss(train) 0.5612 | Acc(train) 0.8965 | Acc(val) 0.8819 |
Epoch 00169 | Loss(train) 0.5777 | Acc(train) 0.8817 | Acc(val) 0.8819 |
Epoch 00170 | Loss(train) 0.5560 | Acc(train) 0.8909 | Acc(val) 0.8819 |
Epoch 00171 | Loss(train) 0.5548 | Acc(train) 0.8909 | Acc(val) 0.8856 |
Epoch 00172 | Loss(train) 0.5676 | Acc(train) 0.8965 | Acc(val) 0.8856 |
Epoch 00173 | Loss(train) 0.5958 | Acc(train) 0.8854 | Acc(val) 0.8856 |
Epoch 00174 | Loss(train) 0.5454 | Acc(train) 0.8891 | Acc(val) 0.8819 |
Epoch 00175 | Loss(train) 0.5332 | Acc(train) 0.8928 | Acc(val) 0.8856 |
Epoch 00176 | Loss(train) 0.5523 | Acc(train) 0.9020 | Acc(val) 0.8893 |
Epoch 00177 | Loss(train) 0.5246 | Acc(train) 0.8946 | Acc(val) 0.8856 |
Epoch 00178 | Loss(train) 0.5629 | Acc(train) 0.8762 | Acc(val) 0.8856 |
Epoch 00179 | Loss(train) 0.5925 | Acc(train) 0.8743 | Acc(val) 0.8856 |
Epoch 00180 | Loss(train) 0.5499 | Acc(train) 0.8965 | Acc(val) 0.8782 |
Epoch 00181 | Loss(train) 0.5673 | Acc(train) 0.8946 | Acc(val) 0.8819 |
Epoch 00182 | Loss(train) 0.5536 | Acc(train) 0.8817 | Acc(val) 0.8819 |
Epoch 00183 | Loss(train) 0.5571 | Acc(train) 0.8891 | Acc(val) 0.8856 |
Epoch 00184 | Loss(train) 0.5476 | Acc(train) 0.8854 | Acc(val) 0.8893 |
Epoch 00185 | Loss(train) 0.5292 | Acc(train) 0.9150 | Acc(val) 0.8893 |
Epoch 00186 | Loss(train) 0.5630 | Acc(train) 0.9076 | Acc(val) 0.8856 |
Epoch 00187 | Loss(train) 0.5445 | Acc(train) 0.8928 | Acc(val) 0.8819 |
Epoch 00188 | Loss(train) 0.5705 | Acc(train) 0.8835 | Acc(val) 0.8819 |
Epoch 00189 | Loss(train) 0.5345 | Acc(train) 0.8928 | Acc(val) 0.8819 |
Epoch 00190 | Loss(train) 0.5278 | Acc(train) 0.8817 | Acc(val) 0.8782 |
Epoch 00191 | Loss(train) 0.5629 | Acc(train) 0.8780 | Acc(val) 0.8819 |
Epoch 00192 | Loss(train) 0.5472 | Acc(train) 0.8946 | Acc(val) 0.8856 |
Epoch 00193 | Loss(train) 0.5175 | Acc(train) 0.9002 | Acc(val) 0.8856 |
Epoch 00194 | Loss(train) 0.5357 | Acc(train) 0.9020 | Acc(val) 0.8856 |
Epoch 00195 | Loss(train) 0.5129 | Acc(train) 0.8983 | Acc(val) 0.8856 |
Epoch 00196 | Loss(train) 0.5458 | Acc(train) 0.8965 | Acc(val) 0.8856 |
Epoch 00197 | Loss(train) 0.5184 | Acc(train) 0.8928 | Acc(val) 0.8856 |
Epoch 00198 | Loss(train) 0.5336 | Acc(train) 0.8909 | Acc(val) 0.8893 |
Epoch 00199 | Loss(train) 0.5191 | Acc(train) 0.9187 | Acc(val) 0.8856 |
Epoch 00200 | Loss(train) 0.5297 | Acc(train) 0.8946 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9448 | Acc(train) 0.2274 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9339 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9219 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9068 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.8901 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.8727 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8610 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8470 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8288 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8219 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8088 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.7910 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.7843 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.7638 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.7524 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7449 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7426 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7283 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7132 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00020 | Loss(train) 1.7037 | Acc(train) 0.2884 | Acc(val) 0.3063 |*
Epoch 00021 | Loss(train) 1.6894 | Acc(train) 0.2994 | Acc(val) 0.3137 |*
Epoch 00022 | Loss(train) 1.6738 | Acc(train) 0.3105 | Acc(val) 0.3137 |
Epoch 00023 | Loss(train) 1.6626 | Acc(train) 0.3253 | Acc(val) 0.3137 |
Epoch 00024 | Loss(train) 1.6539 | Acc(train) 0.3364 | Acc(val) 0.3173 |*
Epoch 00025 | Loss(train) 1.6423 | Acc(train) 0.3346 | Acc(val) 0.3173 |
Epoch 00026 | Loss(train) 1.6332 | Acc(train) 0.3438 | Acc(val) 0.3284 |*
Epoch 00027 | Loss(train) 1.6200 | Acc(train) 0.3641 | Acc(val) 0.3284 |
Epoch 00028 | Loss(train) 1.6082 | Acc(train) 0.3438 | Acc(val) 0.3358 |*
Epoch 00029 | Loss(train) 1.5980 | Acc(train) 0.3623 | Acc(val) 0.3358 |
Epoch 00030 | Loss(train) 1.5862 | Acc(train) 0.3715 | Acc(val) 0.3432 |*
Epoch 00031 | Loss(train) 1.5675 | Acc(train) 0.3900 | Acc(val) 0.3469 |*
Epoch 00032 | Loss(train) 1.5618 | Acc(train) 0.3845 | Acc(val) 0.3542 |*
Epoch 00033 | Loss(train) 1.5414 | Acc(train) 0.4030 | Acc(val) 0.3616 |*
Epoch 00034 | Loss(train) 1.5280 | Acc(train) 0.4011 | Acc(val) 0.3690 |*
Epoch 00035 | Loss(train) 1.5137 | Acc(train) 0.4067 | Acc(val) 0.3727 |*
Epoch 00036 | Loss(train) 1.4936 | Acc(train) 0.4362 | Acc(val) 0.3801 |*
Epoch 00037 | Loss(train) 1.4886 | Acc(train) 0.4362 | Acc(val) 0.3838 |*
Epoch 00038 | Loss(train) 1.4837 | Acc(train) 0.4399 | Acc(val) 0.3948 |*
Epoch 00039 | Loss(train) 1.4552 | Acc(train) 0.4640 | Acc(val) 0.3985 |*
Epoch 00040 | Loss(train) 1.4569 | Acc(train) 0.4529 | Acc(val) 0.4059 |*
Epoch 00041 | Loss(train) 1.4378 | Acc(train) 0.4677 | Acc(val) 0.4207 |*
Epoch 00042 | Loss(train) 1.4315 | Acc(train) 0.4991 | Acc(val) 0.4391 |*
Epoch 00043 | Loss(train) 1.4056 | Acc(train) 0.5268 | Acc(val) 0.4539 |*
Epoch 00044 | Loss(train) 1.4005 | Acc(train) 0.5102 | Acc(val) 0.4797 |*
Epoch 00045 | Loss(train) 1.3915 | Acc(train) 0.5379 | Acc(val) 0.5018 |*
Epoch 00046 | Loss(train) 1.3875 | Acc(train) 0.5693 | Acc(val) 0.5166 |*
Epoch 00047 | Loss(train) 1.3603 | Acc(train) 0.5656 | Acc(val) 0.5314 |*
Epoch 00048 | Loss(train) 1.3333 | Acc(train) 0.5952 | Acc(val) 0.5498 |*
Epoch 00049 | Loss(train) 1.3408 | Acc(train) 0.5952 | Acc(val) 0.5646 |*
Epoch 00050 | Loss(train) 1.3205 | Acc(train) 0.5841 | Acc(val) 0.5867 |*
Epoch 00051 | Loss(train) 1.3065 | Acc(train) 0.6044 | Acc(val) 0.6052 |*
Epoch 00052 | Loss(train) 1.3128 | Acc(train) 0.6155 | Acc(val) 0.6199 |*
Epoch 00053 | Loss(train) 1.2909 | Acc(train) 0.6433 | Acc(val) 0.6384 |*
Epoch 00054 | Loss(train) 1.2704 | Acc(train) 0.6359 | Acc(val) 0.6458 |*
Epoch 00055 | Loss(train) 1.2800 | Acc(train) 0.6710 | Acc(val) 0.6568 |*
Epoch 00056 | Loss(train) 1.2472 | Acc(train) 0.6562 | Acc(val) 0.6642 |*
Epoch 00057 | Loss(train) 1.2391 | Acc(train) 0.6506 | Acc(val) 0.6790 |*
Epoch 00058 | Loss(train) 1.2336 | Acc(train) 0.6654 | Acc(val) 0.6827 |*
Epoch 00059 | Loss(train) 1.2184 | Acc(train) 0.6728 | Acc(val) 0.6937 |*
Epoch 00060 | Loss(train) 1.2062 | Acc(train) 0.6876 | Acc(val) 0.7048 |*
Epoch 00061 | Loss(train) 1.1984 | Acc(train) 0.6784 | Acc(val) 0.7122 |*
Epoch 00062 | Loss(train) 1.1898 | Acc(train) 0.6913 | Acc(val) 0.7269 |*
Epoch 00063 | Loss(train) 1.1677 | Acc(train) 0.6932 | Acc(val) 0.7343 |*
Epoch 00064 | Loss(train) 1.1619 | Acc(train) 0.7079 | Acc(val) 0.7343 |
Epoch 00065 | Loss(train) 1.1488 | Acc(train) 0.7172 | Acc(val) 0.7380 |*
Epoch 00066 | Loss(train) 1.1284 | Acc(train) 0.7190 | Acc(val) 0.7417 |*
Epoch 00067 | Loss(train) 1.1306 | Acc(train) 0.7283 | Acc(val) 0.7417 |
Epoch 00068 | Loss(train) 1.1106 | Acc(train) 0.7209 | Acc(val) 0.7417 |
Epoch 00069 | Loss(train) 1.0944 | Acc(train) 0.7412 | Acc(val) 0.7417 |
Epoch 00070 | Loss(train) 1.1014 | Acc(train) 0.7375 | Acc(val) 0.7417 |
Epoch 00071 | Loss(train) 1.0686 | Acc(train) 0.7468 | Acc(val) 0.7417 |
Epoch 00072 | Loss(train) 1.0725 | Acc(train) 0.7190 | Acc(val) 0.7454 |*
Epoch 00073 | Loss(train) 1.0863 | Acc(train) 0.7172 | Acc(val) 0.7528 |*
Epoch 00074 | Loss(train) 1.0535 | Acc(train) 0.7246 | Acc(val) 0.7712 |*
Epoch 00075 | Loss(train) 1.0408 | Acc(train) 0.7468 | Acc(val) 0.7823 |*
Epoch 00076 | Loss(train) 1.0440 | Acc(train) 0.7394 | Acc(val) 0.7823 |
Epoch 00077 | Loss(train) 1.0165 | Acc(train) 0.7763 | Acc(val) 0.7823 |
Epoch 00078 | Loss(train) 1.0221 | Acc(train) 0.7357 | Acc(val) 0.7786 |
Epoch 00079 | Loss(train) 1.0102 | Acc(train) 0.7671 | Acc(val) 0.7786 |
Epoch 00080 | Loss(train) 1.0090 | Acc(train) 0.7616 | Acc(val) 0.7786 |
Epoch 00081 | Loss(train) 1.0083 | Acc(train) 0.7560 | Acc(val) 0.7823 |
Epoch 00082 | Loss(train) 0.9792 | Acc(train) 0.7708 | Acc(val) 0.7823 |
Epoch 00083 | Loss(train) 0.9921 | Acc(train) 0.7523 | Acc(val) 0.7860 |*
Epoch 00084 | Loss(train) 0.9863 | Acc(train) 0.7486 | Acc(val) 0.7934 |*
Epoch 00085 | Loss(train) 0.9518 | Acc(train) 0.7671 | Acc(val) 0.7860 |
Epoch 00086 | Loss(train) 0.9605 | Acc(train) 0.7782 | Acc(val) 0.7860 |
Epoch 00087 | Loss(train) 0.9545 | Acc(train) 0.7874 | Acc(val) 0.7823 |
Epoch 00088 | Loss(train) 0.9346 | Acc(train) 0.7856 | Acc(val) 0.7934 |
Epoch 00089 | Loss(train) 0.9246 | Acc(train) 0.7911 | Acc(val) 0.7934 |
Epoch 00090 | Loss(train) 0.9350 | Acc(train) 0.7856 | Acc(val) 0.7934 |
Epoch 00091 | Loss(train) 0.9185 | Acc(train) 0.7819 | Acc(val) 0.7897 |
Epoch 00092 | Loss(train) 0.9203 | Acc(train) 0.7671 | Acc(val) 0.7897 |
Epoch 00093 | Loss(train) 0.9024 | Acc(train) 0.7893 | Acc(val) 0.7897 |
Epoch 00094 | Loss(train) 0.9028 | Acc(train) 0.7837 | Acc(val) 0.7897 |
Epoch 00095 | Loss(train) 0.9003 | Acc(train) 0.7874 | Acc(val) 0.7970 |*
Epoch 00096 | Loss(train) 0.8863 | Acc(train) 0.7893 | Acc(val) 0.8044 |*
Epoch 00097 | Loss(train) 0.8671 | Acc(train) 0.8133 | Acc(val) 0.8081 |*
Epoch 00098 | Loss(train) 0.8835 | Acc(train) 0.7837 | Acc(val) 0.8118 |*
Epoch 00099 | Loss(train) 0.8808 | Acc(train) 0.7800 | Acc(val) 0.8118 |
Epoch 00100 | Loss(train) 0.8681 | Acc(train) 0.7911 | Acc(val) 0.8118 |
Epoch 00101 | Loss(train) 0.8621 | Acc(train) 0.8004 | Acc(val) 0.8044 |
Epoch 00102 | Loss(train) 0.8331 | Acc(train) 0.7856 | Acc(val) 0.8081 |
Epoch 00103 | Loss(train) 0.8258 | Acc(train) 0.8152 | Acc(val) 0.8081 |
Epoch 00104 | Loss(train) 0.8324 | Acc(train) 0.8022 | Acc(val) 0.8044 |
Epoch 00105 | Loss(train) 0.8388 | Acc(train) 0.8078 | Acc(val) 0.8118 |
Epoch 00106 | Loss(train) 0.8172 | Acc(train) 0.8078 | Acc(val) 0.8192 |*
Epoch 00107 | Loss(train) 0.8243 | Acc(train) 0.8096 | Acc(val) 0.8155 |
Epoch 00108 | Loss(train) 0.8335 | Acc(train) 0.8078 | Acc(val) 0.8155 |
Epoch 00109 | Loss(train) 0.8227 | Acc(train) 0.8059 | Acc(val) 0.8118 |
Epoch 00110 | Loss(train) 0.8098 | Acc(train) 0.8133 | Acc(val) 0.8118 |
Epoch 00111 | Loss(train) 0.8027 | Acc(train) 0.8133 | Acc(val) 0.8118 |
Epoch 00112 | Loss(train) 0.7893 | Acc(train) 0.8115 | Acc(val) 0.8192 |
Epoch 00113 | Loss(train) 0.7971 | Acc(train) 0.8152 | Acc(val) 0.8229 |*
Epoch 00114 | Loss(train) 0.7767 | Acc(train) 0.8115 | Acc(val) 0.8118 |
Epoch 00115 | Loss(train) 0.7878 | Acc(train) 0.8336 | Acc(val) 0.8118 |
Epoch 00116 | Loss(train) 0.7556 | Acc(train) 0.8262 | Acc(val) 0.8081 |
Epoch 00117 | Loss(train) 0.7947 | Acc(train) 0.8059 | Acc(val) 0.8081 |
Epoch 00118 | Loss(train) 0.7582 | Acc(train) 0.8299 | Acc(val) 0.8081 |
Epoch 00119 | Loss(train) 0.7806 | Acc(train) 0.8207 | Acc(val) 0.8118 |
Epoch 00120 | Loss(train) 0.7637 | Acc(train) 0.8189 | Acc(val) 0.8155 |
Epoch 00121 | Loss(train) 0.7647 | Acc(train) 0.8152 | Acc(val) 0.8192 |
Epoch 00122 | Loss(train) 0.7502 | Acc(train) 0.8207 | Acc(val) 0.8192 |
Epoch 00123 | Loss(train) 0.7512 | Acc(train) 0.8299 | Acc(val) 0.8192 |
Epoch 00124 | Loss(train) 0.7496 | Acc(train) 0.8281 | Acc(val) 0.8192 |
Epoch 00125 | Loss(train) 0.7576 | Acc(train) 0.8262 | Acc(val) 0.8192 |
Epoch 00126 | Loss(train) 0.7443 | Acc(train) 0.8336 | Acc(val) 0.8192 |
Epoch 00127 | Loss(train) 0.7258 | Acc(train) 0.8299 | Acc(val) 0.8229 |
Epoch 00128 | Loss(train) 0.7365 | Acc(train) 0.8299 | Acc(val) 0.8229 |
Epoch 00129 | Loss(train) 0.7122 | Acc(train) 0.8392 | Acc(val) 0.8229 |
Epoch 00130 | Loss(train) 0.7313 | Acc(train) 0.8410 | Acc(val) 0.8303 |*
Epoch 00131 | Loss(train) 0.7047 | Acc(train) 0.8466 | Acc(val) 0.8303 |
Epoch 00132 | Loss(train) 0.7073 | Acc(train) 0.8336 | Acc(val) 0.8303 |
Epoch 00133 | Loss(train) 0.7000 | Acc(train) 0.8447 | Acc(val) 0.8266 |
Epoch 00134 | Loss(train) 0.6922 | Acc(train) 0.8429 | Acc(val) 0.8303 |
Epoch 00135 | Loss(train) 0.7006 | Acc(train) 0.8521 | Acc(val) 0.8413 |*
Epoch 00136 | Loss(train) 0.6988 | Acc(train) 0.8466 | Acc(val) 0.8450 |*
Epoch 00137 | Loss(train) 0.6961 | Acc(train) 0.8447 | Acc(val) 0.8487 |*
Epoch 00138 | Loss(train) 0.6947 | Acc(train) 0.8595 | Acc(val) 0.8487 |
Epoch 00139 | Loss(train) 0.7194 | Acc(train) 0.8336 | Acc(val) 0.8487 |
Epoch 00140 | Loss(train) 0.6967 | Acc(train) 0.8503 | Acc(val) 0.8524 |*
Epoch 00141 | Loss(train) 0.6824 | Acc(train) 0.8651 | Acc(val) 0.8561 |*
Epoch 00142 | Loss(train) 0.6705 | Acc(train) 0.8595 | Acc(val) 0.8561 |
Epoch 00143 | Loss(train) 0.6875 | Acc(train) 0.8651 | Acc(val) 0.8561 |
Epoch 00144 | Loss(train) 0.6657 | Acc(train) 0.8503 | Acc(val) 0.8524 |
Epoch 00145 | Loss(train) 0.6473 | Acc(train) 0.8540 | Acc(val) 0.8524 |
Epoch 00146 | Loss(train) 0.6720 | Acc(train) 0.8503 | Acc(val) 0.8487 |
Epoch 00147 | Loss(train) 0.6462 | Acc(train) 0.8632 | Acc(val) 0.8487 |
Epoch 00148 | Loss(train) 0.6480 | Acc(train) 0.8558 | Acc(val) 0.8524 |
Epoch 00149 | Loss(train) 0.6476 | Acc(train) 0.8447 | Acc(val) 0.8561 |
Epoch 00150 | Loss(train) 0.6517 | Acc(train) 0.8780 | Acc(val) 0.8598 |*
Epoch 00151 | Loss(train) 0.6738 | Acc(train) 0.8725 | Acc(val) 0.8598 |
Epoch 00152 | Loss(train) 0.6259 | Acc(train) 0.8725 | Acc(val) 0.8598 |
Epoch 00153 | Loss(train) 0.6485 | Acc(train) 0.8688 | Acc(val) 0.8635 |*
Epoch 00154 | Loss(train) 0.6711 | Acc(train) 0.8521 | Acc(val) 0.8598 |
Epoch 00155 | Loss(train) 0.6467 | Acc(train) 0.8632 | Acc(val) 0.8524 |
Epoch 00156 | Loss(train) 0.6434 | Acc(train) 0.8891 | Acc(val) 0.8561 |
Epoch 00157 | Loss(train) 0.6330 | Acc(train) 0.8706 | Acc(val) 0.8561 |
Epoch 00158 | Loss(train) 0.6310 | Acc(train) 0.8835 | Acc(val) 0.8598 |
Epoch 00159 | Loss(train) 0.6140 | Acc(train) 0.8928 | Acc(val) 0.8635 |
Epoch 00160 | Loss(train) 0.6308 | Acc(train) 0.8891 | Acc(val) 0.8635 |
Epoch 00161 | Loss(train) 0.6062 | Acc(train) 0.8835 | Acc(val) 0.8672 |*
Epoch 00162 | Loss(train) 0.6195 | Acc(train) 0.8780 | Acc(val) 0.8708 |*
Epoch 00163 | Loss(train) 0.6086 | Acc(train) 0.8669 | Acc(val) 0.8672 |
Epoch 00164 | Loss(train) 0.6184 | Acc(train) 0.8743 | Acc(val) 0.8672 |
Epoch 00165 | Loss(train) 0.6197 | Acc(train) 0.8614 | Acc(val) 0.8708 |
Epoch 00166 | Loss(train) 0.5936 | Acc(train) 0.8762 | Acc(val) 0.8708 |
Epoch 00167 | Loss(train) 0.5973 | Acc(train) 0.8780 | Acc(val) 0.8708 |
Epoch 00168 | Loss(train) 0.6190 | Acc(train) 0.8651 | Acc(val) 0.8745 |*
Epoch 00169 | Loss(train) 0.5905 | Acc(train) 0.8946 | Acc(val) 0.8745 |
Epoch 00170 | Loss(train) 0.5752 | Acc(train) 0.9039 | Acc(val) 0.8745 |
Epoch 00171 | Loss(train) 0.6319 | Acc(train) 0.8503 | Acc(val) 0.8782 |*
Epoch 00172 | Loss(train) 0.6020 | Acc(train) 0.8780 | Acc(val) 0.8745 |
Epoch 00173 | Loss(train) 0.6009 | Acc(train) 0.8835 | Acc(val) 0.8672 |
Epoch 00174 | Loss(train) 0.6138 | Acc(train) 0.8706 | Acc(val) 0.8672 |
Epoch 00175 | Loss(train) 0.5794 | Acc(train) 0.8891 | Acc(val) 0.8672 |
Epoch 00176 | Loss(train) 0.5863 | Acc(train) 0.8835 | Acc(val) 0.8672 |
Epoch 00177 | Loss(train) 0.5825 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00178 | Loss(train) 0.5946 | Acc(train) 0.8891 | Acc(val) 0.8672 |
Epoch 00179 | Loss(train) 0.5684 | Acc(train) 0.8762 | Acc(val) 0.8672 |
Epoch 00180 | Loss(train) 0.5908 | Acc(train) 0.8946 | Acc(val) 0.8782 |
Epoch 00181 | Loss(train) 0.5918 | Acc(train) 0.8799 | Acc(val) 0.8782 |
Epoch 00182 | Loss(train) 0.5700 | Acc(train) 0.8817 | Acc(val) 0.8782 |
Epoch 00183 | Loss(train) 0.5921 | Acc(train) 0.8835 | Acc(val) 0.8745 |
Epoch 00184 | Loss(train) 0.5611 | Acc(train) 0.8835 | Acc(val) 0.8708 |
Epoch 00185 | Loss(train) 0.5579 | Acc(train) 0.9039 | Acc(val) 0.8672 |
Epoch 00186 | Loss(train) 0.5643 | Acc(train) 0.8983 | Acc(val) 0.8672 |
Epoch 00187 | Loss(train) 0.5814 | Acc(train) 0.8614 | Acc(val) 0.8745 |
Epoch 00188 | Loss(train) 0.5837 | Acc(train) 0.8817 | Acc(val) 0.8708 |
Epoch 00189 | Loss(train) 0.5361 | Acc(train) 0.8965 | Acc(val) 0.8819 |*
Epoch 00190 | Loss(train) 0.5777 | Acc(train) 0.8688 | Acc(val) 0.8856 |*
Epoch 00191 | Loss(train) 0.5535 | Acc(train) 0.8891 | Acc(val) 0.8819 |
Epoch 00192 | Loss(train) 0.5808 | Acc(train) 0.8688 | Acc(val) 0.8745 |
Epoch 00193 | Loss(train) 0.5906 | Acc(train) 0.8835 | Acc(val) 0.8745 |
Epoch 00194 | Loss(train) 0.5654 | Acc(train) 0.8928 | Acc(val) 0.8745 |
Epoch 00195 | Loss(train) 0.5885 | Acc(train) 0.8669 | Acc(val) 0.8708 |
Epoch 00196 | Loss(train) 0.5537 | Acc(train) 0.8872 | Acc(val) 0.8708 |
Epoch 00197 | Loss(train) 0.5704 | Acc(train) 0.8946 | Acc(val) 0.8782 |
Epoch 00198 | Loss(train) 0.5506 | Acc(train) 0.8891 | Acc(val) 0.8782 |
Epoch 00199 | Loss(train) 0.5649 | Acc(train) 0.9039 | Acc(val) 0.8819 |
Epoch 00200 | Loss(train) 0.5370 | Acc(train) 0.8762 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.9465 | Acc(train) 0.1017 | Acc(val) 0.2989 |*
Epoch 00002 | Loss(train) 1.9393 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00003 | Loss(train) 1.9314 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00004 | Loss(train) 1.9239 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00005 | Loss(train) 1.9151 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00006 | Loss(train) 1.9056 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00007 | Loss(train) 1.8953 | Acc(train) 0.2828 | Acc(val) 0.2989 |
Epoch 00008 | Loss(train) 1.8903 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00009 | Loss(train) 1.8801 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00010 | Loss(train) 1.8665 | Acc(train) 0.2810 | Acc(val) 0.2989 |
Epoch 00011 | Loss(train) 1.8565 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00012 | Loss(train) 1.8459 | Acc(train) 0.2847 | Acc(val) 0.2989 |
Epoch 00013 | Loss(train) 1.8378 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00014 | Loss(train) 1.8249 | Acc(train) 0.2865 | Acc(val) 0.2989 |
Epoch 00015 | Loss(train) 1.8123 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00016 | Loss(train) 1.7926 | Acc(train) 0.2976 | Acc(val) 0.2989 |
Epoch 00017 | Loss(train) 1.7934 | Acc(train) 0.2939 | Acc(val) 0.2989 |
Epoch 00018 | Loss(train) 1.7835 | Acc(train) 0.2884 | Acc(val) 0.2989 |
Epoch 00019 | Loss(train) 1.7753 | Acc(train) 0.2994 | Acc(val) 0.3026 |*
Epoch 00020 | Loss(train) 1.7616 | Acc(train) 0.2976 | Acc(val) 0.3063 |*
Epoch 00021 | Loss(train) 1.7527 | Acc(train) 0.2957 | Acc(val) 0.3137 |*
Epoch 00022 | Loss(train) 1.7400 | Acc(train) 0.3013 | Acc(val) 0.3137 |
Epoch 00023 | Loss(train) 1.7289 | Acc(train) 0.3142 | Acc(val) 0.3137 |
Epoch 00024 | Loss(train) 1.7244 | Acc(train) 0.3346 | Acc(val) 0.3137 |
Epoch 00025 | Loss(train) 1.7190 | Acc(train) 0.3401 | Acc(val) 0.3210 |*
Epoch 00026 | Loss(train) 1.7047 | Acc(train) 0.3420 | Acc(val) 0.3321 |*
Epoch 00027 | Loss(train) 1.7015 | Acc(train) 0.3530 | Acc(val) 0.3469 |*
Epoch 00028 | Loss(train) 1.6866 | Acc(train) 0.3604 | Acc(val) 0.3579 |*
Epoch 00029 | Loss(train) 1.6878 | Acc(train) 0.3641 | Acc(val) 0.3690 |*
Epoch 00030 | Loss(train) 1.6585 | Acc(train) 0.3900 | Acc(val) 0.3727 |*
Epoch 00031 | Loss(train) 1.6618 | Acc(train) 0.3974 | Acc(val) 0.3875 |*
Epoch 00032 | Loss(train) 1.6492 | Acc(train) 0.3993 | Acc(val) 0.3911 |*
Epoch 00033 | Loss(train) 1.6344 | Acc(train) 0.4177 | Acc(val) 0.3948 |*
Epoch 00034 | Loss(train) 1.6116 | Acc(train) 0.4140 | Acc(val) 0.3948 |
Epoch 00035 | Loss(train) 1.6064 | Acc(train) 0.4140 | Acc(val) 0.3948 |
Epoch 00036 | Loss(train) 1.6050 | Acc(train) 0.4196 | Acc(val) 0.3985 |*
Epoch 00037 | Loss(train) 1.5769 | Acc(train) 0.4307 | Acc(val) 0.3985 |
Epoch 00038 | Loss(train) 1.5684 | Acc(train) 0.4399 | Acc(val) 0.3985 |
Epoch 00039 | Loss(train) 1.5558 | Acc(train) 0.4492 | Acc(val) 0.4059 |*
Epoch 00040 | Loss(train) 1.5460 | Acc(train) 0.4436 | Acc(val) 0.4096 |*
Epoch 00041 | Loss(train) 1.5248 | Acc(train) 0.4492 | Acc(val) 0.4207 |*
Epoch 00042 | Loss(train) 1.5095 | Acc(train) 0.4824 | Acc(val) 0.4170 |
Epoch 00043 | Loss(train) 1.5219 | Acc(train) 0.4898 | Acc(val) 0.4280 |*
Epoch 00044 | Loss(train) 1.5166 | Acc(train) 0.4824 | Acc(val) 0.4391 |*
Epoch 00045 | Loss(train) 1.4852 | Acc(train) 0.5120 | Acc(val) 0.4686 |*
Epoch 00046 | Loss(train) 1.4685 | Acc(train) 0.5120 | Acc(val) 0.4908 |*
Epoch 00047 | Loss(train) 1.4588 | Acc(train) 0.5360 | Acc(val) 0.5092 |*
Epoch 00048 | Loss(train) 1.4464 | Acc(train) 0.5287 | Acc(val) 0.5314 |*
Epoch 00049 | Loss(train) 1.4288 | Acc(train) 0.5656 | Acc(val) 0.5424 |*
Epoch 00050 | Loss(train) 1.4219 | Acc(train) 0.5582 | Acc(val) 0.5535 |*
Epoch 00051 | Loss(train) 1.4247 | Acc(train) 0.5564 | Acc(val) 0.5572 |*
Epoch 00052 | Loss(train) 1.3941 | Acc(train) 0.5841 | Acc(val) 0.5756 |*
Epoch 00053 | Loss(train) 1.3751 | Acc(train) 0.5878 | Acc(val) 0.5756 |
Epoch 00054 | Loss(train) 1.3751 | Acc(train) 0.6044 | Acc(val) 0.5941 |*
Epoch 00055 | Loss(train) 1.3601 | Acc(train) 0.6063 | Acc(val) 0.5978 |*
Epoch 00056 | Loss(train) 1.3435 | Acc(train) 0.6137 | Acc(val) 0.6015 |*
Epoch 00057 | Loss(train) 1.3337 | Acc(train) 0.6081 | Acc(val) 0.6125 |*
Epoch 00058 | Loss(train) 1.3306 | Acc(train) 0.6044 | Acc(val) 0.6125 |
Epoch 00059 | Loss(train) 1.3022 | Acc(train) 0.6026 | Acc(val) 0.6125 |
Epoch 00060 | Loss(train) 1.2978 | Acc(train) 0.6192 | Acc(val) 0.6199 |*
Epoch 00061 | Loss(train) 1.2718 | Acc(train) 0.6414 | Acc(val) 0.6310 |*
Epoch 00062 | Loss(train) 1.2740 | Acc(train) 0.6506 | Acc(val) 0.6384 |*
Epoch 00063 | Loss(train) 1.2616 | Acc(train) 0.6359 | Acc(val) 0.6458 |*
Epoch 00064 | Loss(train) 1.2458 | Acc(train) 0.6488 | Acc(val) 0.6531 |*
Epoch 00065 | Loss(train) 1.2197 | Acc(train) 0.6599 | Acc(val) 0.6568 |*
Epoch 00066 | Loss(train) 1.2170 | Acc(train) 0.6580 | Acc(val) 0.6642 |*
Epoch 00067 | Loss(train) 1.2186 | Acc(train) 0.6506 | Acc(val) 0.6642 |
Epoch 00068 | Loss(train) 1.1880 | Acc(train) 0.6765 | Acc(val) 0.6605 |
Epoch 00069 | Loss(train) 1.1866 | Acc(train) 0.6580 | Acc(val) 0.6642 |
Epoch 00070 | Loss(train) 1.1620 | Acc(train) 0.6858 | Acc(val) 0.6642 |
Epoch 00071 | Loss(train) 1.1838 | Acc(train) 0.6728 | Acc(val) 0.6716 |*
Epoch 00072 | Loss(train) 1.1695 | Acc(train) 0.6562 | Acc(val) 0.6753 |*
Epoch 00073 | Loss(train) 1.1537 | Acc(train) 0.6765 | Acc(val) 0.6753 |
Epoch 00074 | Loss(train) 1.1549 | Acc(train) 0.6617 | Acc(val) 0.6827 |*
Epoch 00075 | Loss(train) 1.1303 | Acc(train) 0.6858 | Acc(val) 0.6900 |*
Epoch 00076 | Loss(train) 1.1278 | Acc(train) 0.6895 | Acc(val) 0.6900 |
Epoch 00077 | Loss(train) 1.1226 | Acc(train) 0.6987 | Acc(val) 0.6974 |*
Epoch 00078 | Loss(train) 1.0905 | Acc(train) 0.7227 | Acc(val) 0.7085 |*
Epoch 00079 | Loss(train) 1.1201 | Acc(train) 0.7024 | Acc(val) 0.7122 |*
Epoch 00080 | Loss(train) 1.1098 | Acc(train) 0.6913 | Acc(val) 0.7159 |*
Epoch 00081 | Loss(train) 1.0623 | Acc(train) 0.7227 | Acc(val) 0.7159 |
Epoch 00082 | Loss(train) 1.0572 | Acc(train) 0.7079 | Acc(val) 0.7196 |*
Epoch 00083 | Loss(train) 1.0414 | Acc(train) 0.7135 | Acc(val) 0.7159 |
Epoch 00084 | Loss(train) 1.0528 | Acc(train) 0.7116 | Acc(val) 0.7196 |
Epoch 00085 | Loss(train) 1.0258 | Acc(train) 0.7190 | Acc(val) 0.7159 |
Epoch 00086 | Loss(train) 1.0238 | Acc(train) 0.7486 | Acc(val) 0.7196 |
Epoch 00087 | Loss(train) 1.0312 | Acc(train) 0.7431 | Acc(val) 0.7196 |
Epoch 00088 | Loss(train) 1.0122 | Acc(train) 0.7320 | Acc(val) 0.7159 |
Epoch 00089 | Loss(train) 1.0054 | Acc(train) 0.7246 | Acc(val) 0.7159 |
Epoch 00090 | Loss(train) 1.0154 | Acc(train) 0.7061 | Acc(val) 0.7196 |
Epoch 00091 | Loss(train) 1.0023 | Acc(train) 0.7172 | Acc(val) 0.7196 |
Epoch 00092 | Loss(train) 0.9827 | Acc(train) 0.7726 | Acc(val) 0.7269 |*
Epoch 00093 | Loss(train) 0.9472 | Acc(train) 0.7911 | Acc(val) 0.7380 |*
Epoch 00094 | Loss(train) 0.9861 | Acc(train) 0.7449 | Acc(val) 0.7454 |*
Epoch 00095 | Loss(train) 0.9517 | Acc(train) 0.7431 | Acc(val) 0.7491 |*
Epoch 00096 | Loss(train) 0.9470 | Acc(train) 0.7726 | Acc(val) 0.7491 |
Epoch 00097 | Loss(train) 0.9558 | Acc(train) 0.7597 | Acc(val) 0.7491 |
Epoch 00098 | Loss(train) 0.9437 | Acc(train) 0.7523 | Acc(val) 0.7528 |*
Epoch 00099 | Loss(train) 0.9396 | Acc(train) 0.7505 | Acc(val) 0.7601 |*
Epoch 00100 | Loss(train) 0.9564 | Acc(train) 0.7597 | Acc(val) 0.7638 |*
Epoch 00101 | Loss(train) 0.9393 | Acc(train) 0.7449 | Acc(val) 0.7675 |*
Epoch 00102 | Loss(train) 0.9080 | Acc(train) 0.7819 | Acc(val) 0.7675 |
Epoch 00103 | Loss(train) 0.9374 | Acc(train) 0.7560 | Acc(val) 0.7675 |
Epoch 00104 | Loss(train) 0.8995 | Acc(train) 0.7874 | Acc(val) 0.7712 |*
Epoch 00105 | Loss(train) 0.8885 | Acc(train) 0.7597 | Acc(val) 0.7749 |*
Epoch 00106 | Loss(train) 0.8870 | Acc(train) 0.7726 | Acc(val) 0.7786 |*
Epoch 00107 | Loss(train) 0.9050 | Acc(train) 0.7800 | Acc(val) 0.7823 |*
Epoch 00108 | Loss(train) 0.9014 | Acc(train) 0.7579 | Acc(val) 0.7970 |*
Epoch 00109 | Loss(train) 0.8381 | Acc(train) 0.7985 | Acc(val) 0.8007 |*
Epoch 00110 | Loss(train) 0.8667 | Acc(train) 0.7708 | Acc(val) 0.7970 |
Epoch 00111 | Loss(train) 0.8646 | Acc(train) 0.7782 | Acc(val) 0.8007 |
Epoch 00112 | Loss(train) 0.8552 | Acc(train) 0.7856 | Acc(val) 0.8007 |
Epoch 00113 | Loss(train) 0.8947 | Acc(train) 0.7505 | Acc(val) 0.8081 |*
Epoch 00114 | Loss(train) 0.8389 | Acc(train) 0.8022 | Acc(val) 0.8081 |
Epoch 00115 | Loss(train) 0.8640 | Acc(train) 0.7837 | Acc(val) 0.8081 |
Epoch 00116 | Loss(train) 0.8314 | Acc(train) 0.7911 | Acc(val) 0.8044 |
Epoch 00117 | Loss(train) 0.8508 | Acc(train) 0.7985 | Acc(val) 0.8044 |
Epoch 00118 | Loss(train) 0.8037 | Acc(train) 0.7819 | Acc(val) 0.8081 |
Epoch 00119 | Loss(train) 0.8540 | Acc(train) 0.7837 | Acc(val) 0.8155 |*
Epoch 00120 | Loss(train) 0.8112 | Acc(train) 0.8022 | Acc(val) 0.8155 |
Epoch 00121 | Loss(train) 0.8272 | Acc(train) 0.7782 | Acc(val) 0.8192 |*
Epoch 00122 | Loss(train) 0.8226 | Acc(train) 0.7967 | Acc(val) 0.8266 |*
Epoch 00123 | Loss(train) 0.8145 | Acc(train) 0.7745 | Acc(val) 0.8303 |*
Epoch 00124 | Loss(train) 0.7854 | Acc(train) 0.8262 | Acc(val) 0.8303 |
Epoch 00125 | Loss(train) 0.8019 | Acc(train) 0.7911 | Acc(val) 0.8339 |*
Epoch 00126 | Loss(train) 0.7992 | Acc(train) 0.8355 | Acc(val) 0.8413 |*
Epoch 00127 | Loss(train) 0.7820 | Acc(train) 0.8004 | Acc(val) 0.8450 |*
Epoch 00128 | Loss(train) 0.7796 | Acc(train) 0.8189 | Acc(val) 0.8450 |
Epoch 00129 | Loss(train) 0.7771 | Acc(train) 0.8152 | Acc(val) 0.8450 |
Epoch 00130 | Loss(train) 0.7498 | Acc(train) 0.8299 | Acc(val) 0.8450 |
Epoch 00131 | Loss(train) 0.7653 | Acc(train) 0.8244 | Acc(val) 0.8413 |
Epoch 00132 | Loss(train) 0.7786 | Acc(train) 0.7985 | Acc(val) 0.8376 |
Epoch 00133 | Loss(train) 0.7800 | Acc(train) 0.8059 | Acc(val) 0.8376 |
Epoch 00134 | Loss(train) 0.7638 | Acc(train) 0.8226 | Acc(val) 0.8450 |
Epoch 00135 | Loss(train) 0.7520 | Acc(train) 0.8096 | Acc(val) 0.8487 |*
Epoch 00136 | Loss(train) 0.7513 | Acc(train) 0.8189 | Acc(val) 0.8561 |*
Epoch 00137 | Loss(train) 0.7637 | Acc(train) 0.8281 | Acc(val) 0.8672 |*
Epoch 00138 | Loss(train) 0.7513 | Acc(train) 0.8244 | Acc(val) 0.8672 |
Epoch 00139 | Loss(train) 0.7451 | Acc(train) 0.8355 | Acc(val) 0.8598 |
Epoch 00140 | Loss(train) 0.7402 | Acc(train) 0.8318 | Acc(val) 0.8561 |
Epoch 00141 | Loss(train) 0.7352 | Acc(train) 0.8336 | Acc(val) 0.8524 |
Epoch 00142 | Loss(train) 0.7369 | Acc(train) 0.8281 | Acc(val) 0.8450 |
Epoch 00143 | Loss(train) 0.7388 | Acc(train) 0.8262 | Acc(val) 0.8450 |
Epoch 00144 | Loss(train) 0.7285 | Acc(train) 0.8281 | Acc(val) 0.8561 |
Epoch 00145 | Loss(train) 0.7288 | Acc(train) 0.8410 | Acc(val) 0.8672 |
Epoch 00146 | Loss(train) 0.7226 | Acc(train) 0.8226 | Acc(val) 0.8708 |*
Epoch 00147 | Loss(train) 0.7056 | Acc(train) 0.8540 | Acc(val) 0.8672 |
Epoch 00148 | Loss(train) 0.7175 | Acc(train) 0.8392 | Acc(val) 0.8672 |
Epoch 00149 | Loss(train) 0.7048 | Acc(train) 0.8484 | Acc(val) 0.8635 |
Epoch 00150 | Loss(train) 0.7321 | Acc(train) 0.8281 | Acc(val) 0.8672 |
Epoch 00151 | Loss(train) 0.7047 | Acc(train) 0.8484 | Acc(val) 0.8635 |
Epoch 00152 | Loss(train) 0.6786 | Acc(train) 0.8632 | Acc(val) 0.8598 |
Epoch 00153 | Loss(train) 0.6969 | Acc(train) 0.8577 | Acc(val) 0.8708 |
Epoch 00154 | Loss(train) 0.6943 | Acc(train) 0.8540 | Acc(val) 0.8745 |*
Epoch 00155 | Loss(train) 0.7121 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00156 | Loss(train) 0.6958 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00157 | Loss(train) 0.6866 | Acc(train) 0.8429 | Acc(val) 0.8635 |
Epoch 00158 | Loss(train) 0.6909 | Acc(train) 0.8558 | Acc(val) 0.8672 |
Epoch 00159 | Loss(train) 0.6874 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00160 | Loss(train) 0.6942 | Acc(train) 0.8429 | Acc(val) 0.8635 |
Epoch 00161 | Loss(train) 0.6492 | Acc(train) 0.8558 | Acc(val) 0.8598 |
Epoch 00162 | Loss(train) 0.6709 | Acc(train) 0.8484 | Acc(val) 0.8635 |
Epoch 00163 | Loss(train) 0.6585 | Acc(train) 0.8503 | Acc(val) 0.8672 |
Epoch 00164 | Loss(train) 0.6451 | Acc(train) 0.8521 | Acc(val) 0.8708 |
Epoch 00165 | Loss(train) 0.6657 | Acc(train) 0.8669 | Acc(val) 0.8708 |
Epoch 00166 | Loss(train) 0.6513 | Acc(train) 0.8632 | Acc(val) 0.8745 |
Epoch 00167 | Loss(train) 0.6557 | Acc(train) 0.8669 | Acc(val) 0.8745 |
Epoch 00168 | Loss(train) 0.6524 | Acc(train) 0.8651 | Acc(val) 0.8782 |*
Epoch 00169 | Loss(train) 0.6419 | Acc(train) 0.8743 | Acc(val) 0.8782 |
Epoch 00170 | Loss(train) 0.6749 | Acc(train) 0.8503 | Acc(val) 0.8782 |
Epoch 00171 | Loss(train) 0.6563 | Acc(train) 0.8429 | Acc(val) 0.8782 |
Epoch 00172 | Loss(train) 0.6426 | Acc(train) 0.8725 | Acc(val) 0.8745 |
Epoch 00173 | Loss(train) 0.6475 | Acc(train) 0.8558 | Acc(val) 0.8745 |
Epoch 00174 | Loss(train) 0.6309 | Acc(train) 0.8614 | Acc(val) 0.8708 |
Epoch 00175 | Loss(train) 0.6168 | Acc(train) 0.8669 | Acc(val) 0.8708 |
Epoch 00176 | Loss(train) 0.6326 | Acc(train) 0.8780 | Acc(val) 0.8672 |
Epoch 00177 | Loss(train) 0.6564 | Acc(train) 0.8651 | Acc(val) 0.8745 |
Epoch 00178 | Loss(train) 0.6318 | Acc(train) 0.8669 | Acc(val) 0.8745 |
Epoch 00179 | Loss(train) 0.6418 | Acc(train) 0.8688 | Acc(val) 0.8782 |
Epoch 00180 | Loss(train) 0.6119 | Acc(train) 0.8780 | Acc(val) 0.8782 |
Epoch 00181 | Loss(train) 0.6403 | Acc(train) 0.8521 | Acc(val) 0.8782 |
Epoch 00182 | Loss(train) 0.6410 | Acc(train) 0.8651 | Acc(val) 0.8782 |
Epoch 00183 | Loss(train) 0.6564 | Acc(train) 0.8410 | Acc(val) 0.8782 |
Epoch 00184 | Loss(train) 0.6226 | Acc(train) 0.8558 | Acc(val) 0.8782 |
Epoch 00185 | Loss(train) 0.6162 | Acc(train) 0.8854 | Acc(val) 0.8782 |
Epoch 00186 | Loss(train) 0.6089 | Acc(train) 0.8577 | Acc(val) 0.8819 |*
Epoch 00187 | Loss(train) 0.6055 | Acc(train) 0.8762 | Acc(val) 0.8819 |
Epoch 00188 | Loss(train) 0.6158 | Acc(train) 0.8651 | Acc(val) 0.8819 |
Epoch 00189 | Loss(train) 0.6100 | Acc(train) 0.8706 | Acc(val) 0.8782 |
Epoch 00190 | Loss(train) 0.5942 | Acc(train) 0.9002 | Acc(val) 0.8782 |
Epoch 00191 | Loss(train) 0.6411 | Acc(train) 0.8762 | Acc(val) 0.8782 |
Epoch 00192 | Loss(train) 0.6090 | Acc(train) 0.8540 | Acc(val) 0.8782 |
Epoch 00193 | Loss(train) 0.5942 | Acc(train) 0.8799 | Acc(val) 0.8782 |
Epoch 00194 | Loss(train) 0.5904 | Acc(train) 0.8799 | Acc(val) 0.8782 |
Epoch 00195 | Loss(train) 0.6186 | Acc(train) 0.8595 | Acc(val) 0.8782 |
Epoch 00196 | Loss(train) 0.6046 | Acc(train) 0.8725 | Acc(val) 0.8782 |
Epoch 00197 | Loss(train) 0.6042 | Acc(train) 0.8688 | Acc(val) 0.8745 |
Epoch 00198 | Loss(train) 0.5922 | Acc(train) 0.8651 | Acc(val) 0.8819 |
Epoch 00199 | Loss(train) 0.6040 | Acc(train) 0.8835 | Acc(val) 0.8819 |
Epoch 00200 | Loss(train) 0.5852 | Acc(train) 0.8725 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.95, 'cal_hidden_dim': 8}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 1433, 'out_dim': 7}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 79.57 MB
GPU Memory Reserved: 100.00 MB
All runs:
Uncalibrated Test Accuracy: 85.66  0.45
Uncalibrated Difference: 22.44  1.17
Calibrated Test Accuracy: 85.66  0.45
Calibrated Difference: 2.13  0.51
