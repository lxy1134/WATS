/usr/local/lib/python3.11/dist-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning(
Dataset: cora-full | #Nodes: 18800 | #Edges: 144170 | #Classes: 70 |#Features: 8710
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2483 | Acc(train) 0.0141 | Acc(val) 0.1059 |*
Epoch 00002 | Loss(train) 4.2199 | Acc(train) 0.1051 | Acc(val) 0.1202 |*
Epoch 00003 | Loss(train) 4.1775 | Acc(train) 0.1274 | Acc(val) 0.1340 |*
Epoch 00004 | Loss(train) 4.1284 | Acc(train) 0.1314 | Acc(val) 0.1255 |
Epoch 00005 | Loss(train) 4.0749 | Acc(train) 0.1287 | Acc(val) 0.1218 |
Epoch 00006 | Loss(train) 4.0133 | Acc(train) 0.1215 | Acc(val) 0.1112 |
Epoch 00007 | Loss(train) 3.9584 | Acc(train) 0.1165 | Acc(val) 0.1053 |
Epoch 00008 | Loss(train) 3.8998 | Acc(train) 0.1218 | Acc(val) 0.1021 |
Epoch 00009 | Loss(train) 3.8575 | Acc(train) 0.1173 | Acc(val) 0.1043 |
Epoch 00010 | Loss(train) 3.8158 | Acc(train) 0.1237 | Acc(val) 0.1122 |
Epoch 00011 | Loss(train) 3.7874 | Acc(train) 0.1239 | Acc(val) 0.1250 |
Epoch 00012 | Loss(train) 3.7518 | Acc(train) 0.1298 | Acc(val) 0.1420 |*
Epoch 00013 | Loss(train) 3.7093 | Acc(train) 0.1473 | Acc(val) 0.1559 |*
Epoch 00014 | Loss(train) 3.6685 | Acc(train) 0.1553 | Acc(val) 0.1761 |*
Epoch 00015 | Loss(train) 3.6307 | Acc(train) 0.1691 | Acc(val) 0.1867 |*
Epoch 00016 | Loss(train) 3.5934 | Acc(train) 0.1766 | Acc(val) 0.2032 |*
Epoch 00017 | Loss(train) 3.5538 | Acc(train) 0.1965 | Acc(val) 0.2149 |*
Epoch 00018 | Loss(train) 3.5215 | Acc(train) 0.1923 | Acc(val) 0.2229 |*
Epoch 00019 | Loss(train) 3.4693 | Acc(train) 0.2059 | Acc(val) 0.2277 |*
Epoch 00020 | Loss(train) 3.4233 | Acc(train) 0.2144 | Acc(val) 0.2330 |*
Epoch 00021 | Loss(train) 3.3901 | Acc(train) 0.2178 | Acc(val) 0.2372 |*
Epoch 00022 | Loss(train) 3.3489 | Acc(train) 0.2263 | Acc(val) 0.2479 |*
Epoch 00023 | Loss(train) 3.3018 | Acc(train) 0.2301 | Acc(val) 0.2644 |*
Epoch 00024 | Loss(train) 3.2620 | Acc(train) 0.2415 | Acc(val) 0.2819 |*
Epoch 00025 | Loss(train) 3.2115 | Acc(train) 0.2572 | Acc(val) 0.3096 |*
Epoch 00026 | Loss(train) 3.1711 | Acc(train) 0.2734 | Acc(val) 0.3324 |*
Epoch 00027 | Loss(train) 3.1339 | Acc(train) 0.2846 | Acc(val) 0.3457 |*
Epoch 00028 | Loss(train) 3.0908 | Acc(train) 0.3037 | Acc(val) 0.3612 |*
Epoch 00029 | Loss(train) 3.0513 | Acc(train) 0.3141 | Acc(val) 0.3723 |*
Epoch 00030 | Loss(train) 3.0025 | Acc(train) 0.3351 | Acc(val) 0.3809 |*
Epoch 00031 | Loss(train) 2.9790 | Acc(train) 0.3354 | Acc(val) 0.3883 |*
Epoch 00032 | Loss(train) 2.9418 | Acc(train) 0.3362 | Acc(val) 0.4005 |*
Epoch 00033 | Loss(train) 2.8967 | Acc(train) 0.3465 | Acc(val) 0.4096 |*
Epoch 00034 | Loss(train) 2.8558 | Acc(train) 0.3630 | Acc(val) 0.4154 |*
Epoch 00035 | Loss(train) 2.8204 | Acc(train) 0.3625 | Acc(val) 0.4223 |*
Epoch 00036 | Loss(train) 2.7848 | Acc(train) 0.3750 | Acc(val) 0.4271 |*
Epoch 00037 | Loss(train) 2.7434 | Acc(train) 0.3867 | Acc(val) 0.4324 |*
Epoch 00038 | Loss(train) 2.7281 | Acc(train) 0.3955 | Acc(val) 0.4410 |*
Epoch 00039 | Loss(train) 2.6859 | Acc(train) 0.4048 | Acc(val) 0.4484 |*
Epoch 00040 | Loss(train) 2.6597 | Acc(train) 0.4053 | Acc(val) 0.4537 |*
Epoch 00041 | Loss(train) 2.6446 | Acc(train) 0.4106 | Acc(val) 0.4590 |*
Epoch 00042 | Loss(train) 2.6068 | Acc(train) 0.4186 | Acc(val) 0.4612 |*
Epoch 00043 | Loss(train) 2.5695 | Acc(train) 0.4287 | Acc(val) 0.4681 |*
Epoch 00044 | Loss(train) 2.5386 | Acc(train) 0.4266 | Acc(val) 0.4745 |*
Epoch 00045 | Loss(train) 2.5277 | Acc(train) 0.4309 | Acc(val) 0.4798 |*
Epoch 00046 | Loss(train) 2.5015 | Acc(train) 0.4319 | Acc(val) 0.4824 |*
Epoch 00047 | Loss(train) 2.4813 | Acc(train) 0.4348 | Acc(val) 0.4872 |*
Epoch 00048 | Loss(train) 2.4503 | Acc(train) 0.4441 | Acc(val) 0.4883 |*
Epoch 00049 | Loss(train) 2.4288 | Acc(train) 0.4495 | Acc(val) 0.4910 |*
Epoch 00050 | Loss(train) 2.4142 | Acc(train) 0.4489 | Acc(val) 0.4926 |*
Epoch 00051 | Loss(train) 2.4171 | Acc(train) 0.4529 | Acc(val) 0.4926 |
Epoch 00052 | Loss(train) 2.3750 | Acc(train) 0.4588 | Acc(val) 0.4957 |*
Epoch 00053 | Loss(train) 2.3611 | Acc(train) 0.4545 | Acc(val) 0.4995 |*
Epoch 00054 | Loss(train) 2.3447 | Acc(train) 0.4686 | Acc(val) 0.5064 |*
Epoch 00055 | Loss(train) 2.3364 | Acc(train) 0.4678 | Acc(val) 0.5122 |*
Epoch 00056 | Loss(train) 2.3117 | Acc(train) 0.4723 | Acc(val) 0.5170 |*
Epoch 00057 | Loss(train) 2.2969 | Acc(train) 0.4761 | Acc(val) 0.5218 |*
Epoch 00058 | Loss(train) 2.2935 | Acc(train) 0.4705 | Acc(val) 0.5207 |
Epoch 00059 | Loss(train) 2.2923 | Acc(train) 0.4710 | Acc(val) 0.5250 |*
Epoch 00060 | Loss(train) 2.2682 | Acc(train) 0.4875 | Acc(val) 0.5287 |*
Epoch 00061 | Loss(train) 2.2426 | Acc(train) 0.4859 | Acc(val) 0.5314 |*
Epoch 00062 | Loss(train) 2.2371 | Acc(train) 0.4872 | Acc(val) 0.5330 |*
Epoch 00063 | Loss(train) 2.2202 | Acc(train) 0.4947 | Acc(val) 0.5303 |
Epoch 00064 | Loss(train) 2.2212 | Acc(train) 0.4862 | Acc(val) 0.5319 |
Epoch 00065 | Loss(train) 2.2177 | Acc(train) 0.4827 | Acc(val) 0.5324 |
Epoch 00066 | Loss(train) 2.2204 | Acc(train) 0.4888 | Acc(val) 0.5346 |*
Epoch 00067 | Loss(train) 2.1979 | Acc(train) 0.5000 | Acc(val) 0.5404 |*
Epoch 00068 | Loss(train) 2.1929 | Acc(train) 0.4992 | Acc(val) 0.5410 |*
Epoch 00069 | Loss(train) 2.1772 | Acc(train) 0.5069 | Acc(val) 0.5404 |
Epoch 00070 | Loss(train) 2.1522 | Acc(train) 0.5098 | Acc(val) 0.5420 |*
Epoch 00071 | Loss(train) 2.1493 | Acc(train) 0.5122 | Acc(val) 0.5441 |*
Epoch 00072 | Loss(train) 2.1533 | Acc(train) 0.5109 | Acc(val) 0.5447 |*
Epoch 00073 | Loss(train) 2.1481 | Acc(train) 0.5061 | Acc(val) 0.5468 |*
Epoch 00074 | Loss(train) 2.1279 | Acc(train) 0.5149 | Acc(val) 0.5479 |*
Epoch 00075 | Loss(train) 2.1123 | Acc(train) 0.5202 | Acc(val) 0.5495 |*
Epoch 00076 | Loss(train) 2.1169 | Acc(train) 0.5205 | Acc(val) 0.5495 |
Epoch 00077 | Loss(train) 2.1185 | Acc(train) 0.5096 | Acc(val) 0.5505 |*
Epoch 00078 | Loss(train) 2.0991 | Acc(train) 0.5189 | Acc(val) 0.5516 |*
Epoch 00079 | Loss(train) 2.0948 | Acc(train) 0.5274 | Acc(val) 0.5511 |
Epoch 00080 | Loss(train) 2.0974 | Acc(train) 0.5202 | Acc(val) 0.5553 |*
Epoch 00081 | Loss(train) 2.0813 | Acc(train) 0.5215 | Acc(val) 0.5553 |
Epoch 00082 | Loss(train) 2.0785 | Acc(train) 0.5287 | Acc(val) 0.5564 |*
Epoch 00083 | Loss(train) 2.0849 | Acc(train) 0.5266 | Acc(val) 0.5601 |*
Epoch 00084 | Loss(train) 2.0684 | Acc(train) 0.5279 | Acc(val) 0.5606 |*
Epoch 00085 | Loss(train) 2.0749 | Acc(train) 0.5184 | Acc(val) 0.5633 |*
Epoch 00086 | Loss(train) 2.0687 | Acc(train) 0.5346 | Acc(val) 0.5665 |*
Epoch 00087 | Loss(train) 2.0527 | Acc(train) 0.5282 | Acc(val) 0.5660 |
Epoch 00088 | Loss(train) 2.0465 | Acc(train) 0.5282 | Acc(val) 0.5660 |
Epoch 00089 | Loss(train) 2.0575 | Acc(train) 0.5215 | Acc(val) 0.5676 |*
Epoch 00090 | Loss(train) 2.0582 | Acc(train) 0.5269 | Acc(val) 0.5670 |
Epoch 00091 | Loss(train) 2.0389 | Acc(train) 0.5242 | Acc(val) 0.5670 |
Epoch 00092 | Loss(train) 2.0414 | Acc(train) 0.5327 | Acc(val) 0.5702 |*
Epoch 00093 | Loss(train) 2.0465 | Acc(train) 0.5319 | Acc(val) 0.5707 |*
Epoch 00094 | Loss(train) 2.0252 | Acc(train) 0.5372 | Acc(val) 0.5697 |
Epoch 00095 | Loss(train) 2.0298 | Acc(train) 0.5309 | Acc(val) 0.5697 |
Epoch 00096 | Loss(train) 2.0254 | Acc(train) 0.5375 | Acc(val) 0.5707 |
Epoch 00097 | Loss(train) 2.0186 | Acc(train) 0.5303 | Acc(val) 0.5702 |
Epoch 00098 | Loss(train) 2.0272 | Acc(train) 0.5335 | Acc(val) 0.5713 |*
Epoch 00099 | Loss(train) 2.0192 | Acc(train) 0.5497 | Acc(val) 0.5723 |*
Epoch 00100 | Loss(train) 2.0174 | Acc(train) 0.5372 | Acc(val) 0.5713 |
Epoch 00101 | Loss(train) 2.0065 | Acc(train) 0.5359 | Acc(val) 0.5729 |*
Epoch 00102 | Loss(train) 2.0097 | Acc(train) 0.5402 | Acc(val) 0.5729 |
Epoch 00103 | Loss(train) 2.0072 | Acc(train) 0.5410 | Acc(val) 0.5707 |
Epoch 00104 | Loss(train) 2.0092 | Acc(train) 0.5351 | Acc(val) 0.5702 |
Epoch 00105 | Loss(train) 2.0073 | Acc(train) 0.5372 | Acc(val) 0.5713 |
Epoch 00106 | Loss(train) 1.9861 | Acc(train) 0.5452 | Acc(val) 0.5713 |
Epoch 00107 | Loss(train) 1.9934 | Acc(train) 0.5407 | Acc(val) 0.5713 |
Epoch 00108 | Loss(train) 1.9891 | Acc(train) 0.5420 | Acc(val) 0.5697 |
Epoch 00109 | Loss(train) 1.9904 | Acc(train) 0.5410 | Acc(val) 0.5723 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00110 | Loss(train) 1.9638 | Acc(train) 0.5532 | Acc(val) 0.5750 |*
Epoch 00111 | Loss(train) 1.9915 | Acc(train) 0.5489 | Acc(val) 0.5793 |*
Epoch 00112 | Loss(train) 1.9777 | Acc(train) 0.5476 | Acc(val) 0.5798 |*
Epoch 00113 | Loss(train) 1.9779 | Acc(train) 0.5476 | Acc(val) 0.5766 |
Epoch 00114 | Loss(train) 1.9699 | Acc(train) 0.5473 | Acc(val) 0.5787 |
Epoch 00115 | Loss(train) 1.9693 | Acc(train) 0.5471 | Acc(val) 0.5745 |
Epoch 00116 | Loss(train) 1.9725 | Acc(train) 0.5431 | Acc(val) 0.5745 |
Epoch 00117 | Loss(train) 1.9798 | Acc(train) 0.5545 | Acc(val) 0.5777 |
Epoch 00118 | Loss(train) 1.9773 | Acc(train) 0.5380 | Acc(val) 0.5803 |*
Epoch 00119 | Loss(train) 1.9815 | Acc(train) 0.5513 | Acc(val) 0.5814 |*
Epoch 00120 | Loss(train) 1.9848 | Acc(train) 0.5473 | Acc(val) 0.5819 |*
Epoch 00121 | Loss(train) 1.9639 | Acc(train) 0.5463 | Acc(val) 0.5777 |
Epoch 00122 | Loss(train) 1.9572 | Acc(train) 0.5468 | Acc(val) 0.5766 |
Epoch 00123 | Loss(train) 1.9672 | Acc(train) 0.5497 | Acc(val) 0.5761 |
Epoch 00124 | Loss(train) 1.9745 | Acc(train) 0.5495 | Acc(val) 0.5787 |
Epoch 00125 | Loss(train) 1.9652 | Acc(train) 0.5447 | Acc(val) 0.5835 |*
Epoch 00126 | Loss(train) 1.9636 | Acc(train) 0.5479 | Acc(val) 0.5862 |*
Epoch 00127 | Loss(train) 1.9753 | Acc(train) 0.5527 | Acc(val) 0.5835 |
Epoch 00128 | Loss(train) 1.9826 | Acc(train) 0.5519 | Acc(val) 0.5851 |
Epoch 00129 | Loss(train) 1.9625 | Acc(train) 0.5556 | Acc(val) 0.5846 |
Epoch 00130 | Loss(train) 1.9560 | Acc(train) 0.5559 | Acc(val) 0.5819 |
Epoch 00131 | Loss(train) 1.9377 | Acc(train) 0.5649 | Acc(val) 0.5787 |
Epoch 00132 | Loss(train) 1.9549 | Acc(train) 0.5572 | Acc(val) 0.5803 |
Epoch 00133 | Loss(train) 1.9548 | Acc(train) 0.5519 | Acc(val) 0.5830 |
Epoch 00134 | Loss(train) 1.9460 | Acc(train) 0.5596 | Acc(val) 0.5835 |
Epoch 00135 | Loss(train) 1.9435 | Acc(train) 0.5596 | Acc(val) 0.5819 |
Epoch 00136 | Loss(train) 1.9676 | Acc(train) 0.5463 | Acc(val) 0.5835 |
Epoch 00137 | Loss(train) 1.9530 | Acc(train) 0.5585 | Acc(val) 0.5840 |
Epoch 00138 | Loss(train) 1.9482 | Acc(train) 0.5487 | Acc(val) 0.5835 |
Epoch 00139 | Loss(train) 1.9541 | Acc(train) 0.5455 | Acc(val) 0.5814 |
Epoch 00140 | Loss(train) 1.9172 | Acc(train) 0.5551 | Acc(val) 0.5803 |
Epoch 00141 | Loss(train) 1.9419 | Acc(train) 0.5479 | Acc(val) 0.5830 |
Epoch 00142 | Loss(train) 1.9734 | Acc(train) 0.5447 | Acc(val) 0.5819 |
Epoch 00143 | Loss(train) 1.9366 | Acc(train) 0.5585 | Acc(val) 0.5867 |*
Epoch 00144 | Loss(train) 1.9436 | Acc(train) 0.5484 | Acc(val) 0.5883 |*
Epoch 00145 | Loss(train) 1.9551 | Acc(train) 0.5630 | Acc(val) 0.5856 |
Epoch 00146 | Loss(train) 1.9435 | Acc(train) 0.5606 | Acc(val) 0.5835 |
Epoch 00147 | Loss(train) 1.9481 | Acc(train) 0.5588 | Acc(val) 0.5878 |
Epoch 00148 | Loss(train) 1.9334 | Acc(train) 0.5596 | Acc(val) 0.5846 |
Epoch 00149 | Loss(train) 1.9301 | Acc(train) 0.5622 | Acc(val) 0.5840 |
Epoch 00150 | Loss(train) 1.9288 | Acc(train) 0.5657 | Acc(val) 0.5867 |
Epoch 00151 | Loss(train) 1.9415 | Acc(train) 0.5580 | Acc(val) 0.5883 |
Epoch 00152 | Loss(train) 1.9413 | Acc(train) 0.5559 | Acc(val) 0.5862 |
Epoch 00153 | Loss(train) 1.9545 | Acc(train) 0.5495 | Acc(val) 0.5840 |
Epoch 00154 | Loss(train) 1.9548 | Acc(train) 0.5516 | Acc(val) 0.5814 |
Epoch 00155 | Loss(train) 1.9263 | Acc(train) 0.5564 | Acc(val) 0.5824 |
Epoch 00156 | Loss(train) 1.9219 | Acc(train) 0.5652 | Acc(val) 0.5809 |
Epoch 00157 | Loss(train) 1.9300 | Acc(train) 0.5702 | Acc(val) 0.5835 |
Epoch 00158 | Loss(train) 1.9376 | Acc(train) 0.5513 | Acc(val) 0.5878 |
Epoch 00159 | Loss(train) 1.9459 | Acc(train) 0.5516 | Acc(val) 0.5899 |*
Epoch 00160 | Loss(train) 1.9407 | Acc(train) 0.5614 | Acc(val) 0.5878 |
Epoch 00161 | Loss(train) 1.9388 | Acc(train) 0.5553 | Acc(val) 0.5878 |
Epoch 00162 | Loss(train) 1.9201 | Acc(train) 0.5638 | Acc(val) 0.5878 |
Epoch 00163 | Loss(train) 1.9269 | Acc(train) 0.5598 | Acc(val) 0.5883 |
Epoch 00164 | Loss(train) 1.9102 | Acc(train) 0.5654 | Acc(val) 0.5878 |
Epoch 00165 | Loss(train) 1.9273 | Acc(train) 0.5521 | Acc(val) 0.5883 |
Epoch 00166 | Loss(train) 1.9232 | Acc(train) 0.5614 | Acc(val) 0.5904 |*
Epoch 00167 | Loss(train) 1.9301 | Acc(train) 0.5588 | Acc(val) 0.5920 |*
Epoch 00168 | Loss(train) 1.9180 | Acc(train) 0.5649 | Acc(val) 0.5894 |
Epoch 00169 | Loss(train) 1.9170 | Acc(train) 0.5521 | Acc(val) 0.5904 |
Epoch 00170 | Loss(train) 1.9255 | Acc(train) 0.5513 | Acc(val) 0.5894 |
Epoch 00171 | Loss(train) 1.9288 | Acc(train) 0.5604 | Acc(val) 0.5872 |
Epoch 00172 | Loss(train) 1.9231 | Acc(train) 0.5641 | Acc(val) 0.5851 |
Epoch 00173 | Loss(train) 1.9200 | Acc(train) 0.5614 | Acc(val) 0.5824 |
Epoch 00174 | Loss(train) 1.9258 | Acc(train) 0.5665 | Acc(val) 0.5867 |
Epoch 00175 | Loss(train) 1.9246 | Acc(train) 0.5543 | Acc(val) 0.5899 |
Epoch 00176 | Loss(train) 1.9219 | Acc(train) 0.5574 | Acc(val) 0.5894 |
Epoch 00177 | Loss(train) 1.9320 | Acc(train) 0.5553 | Acc(val) 0.5872 |
Epoch 00178 | Loss(train) 1.9110 | Acc(train) 0.5508 | Acc(val) 0.5862 |
Epoch 00179 | Loss(train) 1.9008 | Acc(train) 0.5537 | Acc(val) 0.5862 |
Epoch 00180 | Loss(train) 1.9238 | Acc(train) 0.5500 | Acc(val) 0.5910 |
Epoch 00181 | Loss(train) 1.9108 | Acc(train) 0.5665 | Acc(val) 0.5910 |
Epoch 00182 | Loss(train) 1.9280 | Acc(train) 0.5609 | Acc(val) 0.5910 |
Epoch 00183 | Loss(train) 1.9129 | Acc(train) 0.5662 | Acc(val) 0.5894 |
Epoch 00184 | Loss(train) 1.9087 | Acc(train) 0.5705 | Acc(val) 0.5899 |
Epoch 00185 | Loss(train) 1.9059 | Acc(train) 0.5737 | Acc(val) 0.5904 |
Epoch 00186 | Loss(train) 1.9290 | Acc(train) 0.5620 | Acc(val) 0.5899 |
Epoch 00187 | Loss(train) 1.9091 | Acc(train) 0.5686 | Acc(val) 0.5910 |
Epoch 00188 | Loss(train) 1.9277 | Acc(train) 0.5646 | Acc(val) 0.5926 |*
Epoch 00189 | Loss(train) 1.9199 | Acc(train) 0.5684 | Acc(val) 0.5920 |
Epoch 00190 | Loss(train) 1.9154 | Acc(train) 0.5710 | Acc(val) 0.5915 |
Epoch 00191 | Loss(train) 1.9084 | Acc(train) 0.5617 | Acc(val) 0.5846 |
Epoch 00192 | Loss(train) 1.9089 | Acc(train) 0.5644 | Acc(val) 0.5835 |
Epoch 00193 | Loss(train) 1.9098 | Acc(train) 0.5649 | Acc(val) 0.5840 |
Epoch 00194 | Loss(train) 1.9129 | Acc(train) 0.5686 | Acc(val) 0.5872 |
Epoch 00195 | Loss(train) 1.9184 | Acc(train) 0.5628 | Acc(val) 0.5878 |
Epoch 00196 | Loss(train) 1.9089 | Acc(train) 0.5638 | Acc(val) 0.5878 |
Epoch 00197 | Loss(train) 1.9183 | Acc(train) 0.5660 | Acc(val) 0.5878 |
Epoch 00198 | Loss(train) 1.9072 | Acc(train) 0.5561 | Acc(val) 0.5888 |
Epoch 00199 | Loss(train) 1.9053 | Acc(train) 0.5569 | Acc(val) 0.5894 |
Epoch 00200 | Loss(train) 1.9119 | Acc(train) 0.5598 | Acc(val) 0.5915 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 704.63 MB
GPU Memory Reserved: 1382.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2483 | Acc(train) 0.0122 | Acc(val) 0.1537 |*
Epoch 00002 | Loss(train) 4.2208 | Acc(train) 0.1112 | Acc(val) 0.2069 |*
Epoch 00003 | Loss(train) 4.1839 | Acc(train) 0.1604 | Acc(val) 0.2229 |*
Epoch 00004 | Loss(train) 4.1397 | Acc(train) 0.1726 | Acc(val) 0.2191 |
Epoch 00005 | Loss(train) 4.0912 | Acc(train) 0.1713 | Acc(val) 0.2032 |
Epoch 00006 | Loss(train) 4.0389 | Acc(train) 0.1612 | Acc(val) 0.1867 |
Epoch 00007 | Loss(train) 3.9790 | Acc(train) 0.1508 | Acc(val) 0.1803 |
Epoch 00008 | Loss(train) 3.9210 | Acc(train) 0.1505 | Acc(val) 0.1824 |
Epoch 00009 | Loss(train) 3.8813 | Acc(train) 0.1434 | Acc(val) 0.1862 |
Epoch 00010 | Loss(train) 3.8347 | Acc(train) 0.1537 | Acc(val) 0.1957 |
Epoch 00011 | Loss(train) 3.7980 | Acc(train) 0.1598 | Acc(val) 0.2048 |
Epoch 00012 | Loss(train) 3.7591 | Acc(train) 0.1684 | Acc(val) 0.2149 |
Epoch 00013 | Loss(train) 3.7251 | Acc(train) 0.1801 | Acc(val) 0.2176 |
Epoch 00014 | Loss(train) 3.6862 | Acc(train) 0.1822 | Acc(val) 0.2202 |
Epoch 00015 | Loss(train) 3.6458 | Acc(train) 0.1838 | Acc(val) 0.2271 |*
Epoch 00016 | Loss(train) 3.6067 | Acc(train) 0.1981 | Acc(val) 0.2340 |*
Epoch 00017 | Loss(train) 3.5548 | Acc(train) 0.2149 | Acc(val) 0.2468 |*
Epoch 00018 | Loss(train) 3.5285 | Acc(train) 0.2242 | Acc(val) 0.2543 |*
Epoch 00019 | Loss(train) 3.4742 | Acc(train) 0.2394 | Acc(val) 0.2660 |*
Epoch 00020 | Loss(train) 3.4363 | Acc(train) 0.2335 | Acc(val) 0.2702 |*
Epoch 00021 | Loss(train) 3.3990 | Acc(train) 0.2444 | Acc(val) 0.2755 |*
Epoch 00022 | Loss(train) 3.3405 | Acc(train) 0.2559 | Acc(val) 0.2803 |*
Epoch 00023 | Loss(train) 3.3097 | Acc(train) 0.2505 | Acc(val) 0.2936 |*
Epoch 00024 | Loss(train) 3.2603 | Acc(train) 0.2617 | Acc(val) 0.3080 |*
Epoch 00025 | Loss(train) 3.2260 | Acc(train) 0.2670 | Acc(val) 0.3213 |*
Epoch 00026 | Loss(train) 3.1715 | Acc(train) 0.2803 | Acc(val) 0.3367 |*
Epoch 00027 | Loss(train) 3.1366 | Acc(train) 0.2891 | Acc(val) 0.3495 |*
Epoch 00028 | Loss(train) 3.0842 | Acc(train) 0.3003 | Acc(val) 0.3622 |*
Epoch 00029 | Loss(train) 3.0396 | Acc(train) 0.3226 | Acc(val) 0.3745 |*
Epoch 00030 | Loss(train) 3.0061 | Acc(train) 0.3324 | Acc(val) 0.3798 |*
Epoch 00031 | Loss(train) 2.9752 | Acc(train) 0.3330 | Acc(val) 0.3856 |*
Epoch 00032 | Loss(train) 2.9212 | Acc(train) 0.3489 | Acc(val) 0.3979 |*
Epoch 00033 | Loss(train) 2.8837 | Acc(train) 0.3614 | Acc(val) 0.4069 |*
Epoch 00034 | Loss(train) 2.8451 | Acc(train) 0.3668 | Acc(val) 0.4170 |*
Epoch 00035 | Loss(train) 2.8077 | Acc(train) 0.3782 | Acc(val) 0.4261 |*
Epoch 00036 | Loss(train) 2.7810 | Acc(train) 0.3864 | Acc(val) 0.4340 |*
Epoch 00037 | Loss(train) 2.7474 | Acc(train) 0.3955 | Acc(val) 0.4383 |*
Epoch 00038 | Loss(train) 2.7237 | Acc(train) 0.3888 | Acc(val) 0.4468 |*
Epoch 00039 | Loss(train) 2.6885 | Acc(train) 0.4069 | Acc(val) 0.4574 |*
Epoch 00040 | Loss(train) 2.6557 | Acc(train) 0.4133 | Acc(val) 0.4628 |*
Epoch 00041 | Loss(train) 2.6224 | Acc(train) 0.4165 | Acc(val) 0.4644 |*
Epoch 00042 | Loss(train) 2.5974 | Acc(train) 0.4141 | Acc(val) 0.4681 |*
Epoch 00043 | Loss(train) 2.5750 | Acc(train) 0.4130 | Acc(val) 0.4691 |*
Epoch 00044 | Loss(train) 2.5308 | Acc(train) 0.4359 | Acc(val) 0.4707 |*
Epoch 00045 | Loss(train) 2.5274 | Acc(train) 0.4207 | Acc(val) 0.4755 |*
Epoch 00046 | Loss(train) 2.5048 | Acc(train) 0.4412 | Acc(val) 0.4809 |*
Epoch 00047 | Loss(train) 2.4814 | Acc(train) 0.4471 | Acc(val) 0.4856 |*
Epoch 00048 | Loss(train) 2.4466 | Acc(train) 0.4457 | Acc(val) 0.4867 |*
Epoch 00049 | Loss(train) 2.4492 | Acc(train) 0.4367 | Acc(val) 0.4878 |*
Epoch 00050 | Loss(train) 2.4056 | Acc(train) 0.4572 | Acc(val) 0.4915 |*
Epoch 00051 | Loss(train) 2.3966 | Acc(train) 0.4495 | Acc(val) 0.4947 |*
Epoch 00052 | Loss(train) 2.3762 | Acc(train) 0.4551 | Acc(val) 0.4984 |*
Epoch 00053 | Loss(train) 2.3551 | Acc(train) 0.4622 | Acc(val) 0.5027 |*
Epoch 00054 | Loss(train) 2.3504 | Acc(train) 0.4665 | Acc(val) 0.5074 |*
Epoch 00055 | Loss(train) 2.3316 | Acc(train) 0.4620 | Acc(val) 0.5101 |*
Epoch 00056 | Loss(train) 2.3374 | Acc(train) 0.4620 | Acc(val) 0.5133 |*
Epoch 00057 | Loss(train) 2.3024 | Acc(train) 0.4721 | Acc(val) 0.5160 |*
Epoch 00058 | Loss(train) 2.2939 | Acc(train) 0.4747 | Acc(val) 0.5223 |*
Epoch 00059 | Loss(train) 2.2867 | Acc(train) 0.4785 | Acc(val) 0.5197 |
Epoch 00060 | Loss(train) 2.2701 | Acc(train) 0.4737 | Acc(val) 0.5207 |
Epoch 00061 | Loss(train) 2.2551 | Acc(train) 0.4811 | Acc(val) 0.5213 |
Epoch 00062 | Loss(train) 2.2412 | Acc(train) 0.4864 | Acc(val) 0.5229 |*
Epoch 00063 | Loss(train) 2.2320 | Acc(train) 0.4864 | Acc(val) 0.5277 |*
Epoch 00064 | Loss(train) 2.2371 | Acc(train) 0.4705 | Acc(val) 0.5293 |*
Epoch 00065 | Loss(train) 2.2177 | Acc(train) 0.4875 | Acc(val) 0.5367 |*
Epoch 00066 | Loss(train) 2.2118 | Acc(train) 0.4894 | Acc(val) 0.5394 |*
Epoch 00067 | Loss(train) 2.1862 | Acc(train) 0.5037 | Acc(val) 0.5410 |*
Epoch 00068 | Loss(train) 2.1767 | Acc(train) 0.4965 | Acc(val) 0.5420 |*
Epoch 00069 | Loss(train) 2.1732 | Acc(train) 0.5120 | Acc(val) 0.5383 |
Epoch 00070 | Loss(train) 2.1664 | Acc(train) 0.5040 | Acc(val) 0.5340 |
Epoch 00071 | Loss(train) 2.1557 | Acc(train) 0.4910 | Acc(val) 0.5330 |
Epoch 00072 | Loss(train) 2.1524 | Acc(train) 0.5024 | Acc(val) 0.5319 |
Epoch 00073 | Loss(train) 2.1320 | Acc(train) 0.5088 | Acc(val) 0.5410 |
Epoch 00074 | Loss(train) 2.1320 | Acc(train) 0.5032 | Acc(val) 0.5463 |*
Epoch 00075 | Loss(train) 2.1338 | Acc(train) 0.5122 | Acc(val) 0.5489 |*
Epoch 00076 | Loss(train) 2.1137 | Acc(train) 0.5213 | Acc(val) 0.5521 |*
Epoch 00077 | Loss(train) 2.1360 | Acc(train) 0.5101 | Acc(val) 0.5548 |*
Epoch 00078 | Loss(train) 2.1198 | Acc(train) 0.5197 | Acc(val) 0.5543 |
Epoch 00079 | Loss(train) 2.0937 | Acc(train) 0.5210 | Acc(val) 0.5511 |
Epoch 00080 | Loss(train) 2.1023 | Acc(train) 0.5066 | Acc(val) 0.5500 |
Epoch 00081 | Loss(train) 2.0748 | Acc(train) 0.5138 | Acc(val) 0.5505 |
Epoch 00082 | Loss(train) 2.0842 | Acc(train) 0.5234 | Acc(val) 0.5527 |
Epoch 00083 | Loss(train) 2.0855 | Acc(train) 0.5114 | Acc(val) 0.5569 |*
Epoch 00084 | Loss(train) 2.0771 | Acc(train) 0.5215 | Acc(val) 0.5596 |*
Epoch 00085 | Loss(train) 2.0683 | Acc(train) 0.5258 | Acc(val) 0.5633 |*
Epoch 00086 | Loss(train) 2.0715 | Acc(train) 0.5197 | Acc(val) 0.5644 |*
Epoch 00087 | Loss(train) 2.0621 | Acc(train) 0.5285 | Acc(val) 0.5644 |
Epoch 00088 | Loss(train) 2.0629 | Acc(train) 0.5221 | Acc(val) 0.5649 |*
Epoch 00089 | Loss(train) 2.0590 | Acc(train) 0.5239 | Acc(val) 0.5660 |*
Epoch 00090 | Loss(train) 2.0381 | Acc(train) 0.5314 | Acc(val) 0.5670 |*
Epoch 00091 | Loss(train) 2.0418 | Acc(train) 0.5266 | Acc(val) 0.5707 |*
Epoch 00092 | Loss(train) 2.0473 | Acc(train) 0.5239 | Acc(val) 0.5707 |
Epoch 00093 | Loss(train) 2.0495 | Acc(train) 0.5319 | Acc(val) 0.5707 |
Epoch 00094 | Loss(train) 2.0301 | Acc(train) 0.5298 | Acc(val) 0.5702 |
Epoch 00095 | Loss(train) 2.0550 | Acc(train) 0.5247 | Acc(val) 0.5676 |
Epoch 00096 | Loss(train) 2.0315 | Acc(train) 0.5351 | Acc(val) 0.5691 |
Epoch 00097 | Loss(train) 2.0338 | Acc(train) 0.5287 | Acc(val) 0.5702 |
Epoch 00098 | Loss(train) 2.0312 | Acc(train) 0.5364 | Acc(val) 0.5691 |
Epoch 00099 | Loss(train) 2.0134 | Acc(train) 0.5402 | Acc(val) 0.5702 |
Epoch 00100 | Loss(train) 2.0302 | Acc(train) 0.5319 | Acc(val) 0.5723 |*
Epoch 00101 | Loss(train) 2.0225 | Acc(train) 0.5426 | Acc(val) 0.5755 |*
Epoch 00102 | Loss(train) 2.0025 | Acc(train) 0.5388 | Acc(val) 0.5739 |
Epoch 00103 | Loss(train) 1.9976 | Acc(train) 0.5391 | Acc(val) 0.5750 |
Epoch 00104 | Loss(train) 2.0071 | Acc(train) 0.5481 | Acc(val) 0.5755 |
Epoch 00105 | Loss(train) 2.0229 | Acc(train) 0.5309 | Acc(val) 0.5734 |
Epoch 00106 | Loss(train) 1.9997 | Acc(train) 0.5394 | Acc(val) 0.5734 |
Epoch 00107 | Loss(train) 2.0008 | Acc(train) 0.5391 | Acc(val) 0.5739 |
Epoch 00108 | Loss(train) 2.0153 | Acc(train) 0.5314 | Acc(val) 0.5761 |*
Epoch 00109 | Loss(train) 2.0138 | Acc(train) 0.5359 | Acc(val) 0.5777 |*
Epoch 00110 | Loss(train) 2.0043 | Acc(train) 0.5439 | Acc(val) 0.5777 |
Epoch 00111 | Loss(train) 1.9849 | Acc(train) 0.5452 | Acc(val) 0.5766 |
Epoch 00112 | Loss(train) 1.9905 | Acc(train) 0.5415 | Acc(val) 0.5777 |
Epoch 00113 | Loss(train) 1.9975 | Acc(train) 0.5412 | Acc(val) 0.5750 |
Epoch 00114 | Loss(train) 1.9899 | Acc(train) 0.5415 | Acc(val) 0.5734 |
Epoch 00115 | Loss(train) 1.9966 | Acc(train) 0.5452 | Acc(val) 0.5734 |
Epoch 00116 | Loss(train) 2.0045 | Acc(train) 0.5378 | Acc(val) 0.5745 |
Epoch 00117 | Loss(train) 2.0038 | Acc(train) 0.5441 | Acc(val) 0.5771 |
Epoch 00118 | Loss(train) 1.9844 | Acc(train) 0.5375 | Acc(val) 0.5809 |*
Epoch 00119 | Loss(train) 1.9731 | Acc(train) 0.5537 | Acc(val) 0.5814 |*
Epoch 00120 | Loss(train) 1.9963 | Acc(train) 0.5476 | Acc(val) 0.5787 |
Epoch 00121 | Loss(train) 1.9852 | Acc(train) 0.5380 | Acc(val) 0.5782 |
Epoch 00122 | Loss(train) 1.9725 | Acc(train) 0.5439 | Acc(val) 0.5782 |
Epoch 00123 | Loss(train) 1.9754 | Acc(train) 0.5481 | Acc(val) 0.5777 |
Epoch 00124 | Loss(train) 1.9725 | Acc(train) 0.5457 | Acc(val) 0.5777 |
Epoch 00125 | Loss(train) 1.9795 | Acc(train) 0.5511 | Acc(val) 0.5793 |
Epoch 00126 | Loss(train) 1.9684 | Acc(train) 0.5418 | Acc(val) 0.5793 |
Epoch 00127 | Loss(train) 1.9757 | Acc(train) 0.5487 | Acc(val) 0.5793 |
Epoch 00128 | Loss(train) 1.9624 | Acc(train) 0.5574 | Acc(val) 0.5793 |
Epoch 00129 | Loss(train) 1.9742 | Acc(train) 0.5420 | Acc(val) 0.5798 |
Epoch 00130 | Loss(train) 1.9843 | Acc(train) 0.5457 | Acc(val) 0.5771 |
Epoch 00131 | Loss(train) 1.9799 | Acc(train) 0.5394 | Acc(val) 0.5798 |
Epoch 00132 | Loss(train) 1.9615 | Acc(train) 0.5580 | Acc(val) 0.5798 |
Epoch 00133 | Loss(train) 1.9581 | Acc(train) 0.5441 | Acc(val) 0.5824 |*
Epoch 00134 | Loss(train) 1.9618 | Acc(train) 0.5519 | Acc(val) 0.5824 |
Epoch 00135 | Loss(train) 1.9629 | Acc(train) 0.5503 | Acc(val) 0.5851 |*
Epoch 00136 | Loss(train) 1.9668 | Acc(train) 0.5420 | Acc(val) 0.5830 |
Epoch 00137 | Loss(train) 1.9689 | Acc(train) 0.5484 | Acc(val) 0.5824 |
Epoch 00138 | Loss(train) 1.9592 | Acc(train) 0.5553 | Acc(val) 0.5809 |
Epoch 00139 | Loss(train) 1.9526 | Acc(train) 0.5543 | Acc(val) 0.5787 |
Epoch 00140 | Loss(train) 1.9819 | Acc(train) 0.5463 | Acc(val) 0.5798 |
Epoch 00141 | Loss(train) 1.9505 | Acc(train) 0.5473 | Acc(val) 0.5835 |
Epoch 00142 | Loss(train) 1.9527 | Acc(train) 0.5593 | Acc(val) 0.5830 |
Epoch 00143 | Loss(train) 1.9500 | Acc(train) 0.5556 | Acc(val) 0.5840 |
Epoch 00144 | Loss(train) 1.9530 | Acc(train) 0.5543 | Acc(val) 0.5835 |
Epoch 00145 | Loss(train) 1.9482 | Acc(train) 0.5532 | Acc(val) 0.5846 |
Epoch 00146 | Loss(train) 1.9335 | Acc(train) 0.5521 | Acc(val) 0.5819 |
Epoch 00147 | Loss(train) 1.9558 | Acc(train) 0.5548 | Acc(val) 0.5809 |
Epoch 00148 | Loss(train) 1.9377 | Acc(train) 0.5553 | Acc(val) 0.5803 |
Epoch 00149 | Loss(train) 1.9577 | Acc(train) 0.5476 | Acc(val) 0.5793 |
Epoch 00150 | Loss(train) 1.9410 | Acc(train) 0.5537 | Acc(val) 0.5803 |
Epoch 00151 | Loss(train) 1.9552 | Acc(train) 0.5540 | Acc(val) 0.5819 |
Epoch 00152 | Loss(train) 1.9537 | Acc(train) 0.5585 | Acc(val) 0.5793 |
Epoch 00153 | Loss(train) 1.9496 | Acc(train) 0.5644 | Acc(val) 0.5782 |
Epoch 00154 | Loss(train) 1.9507 | Acc(train) 0.5497 | Acc(val) 0.5761 |
Epoch 00155 | Loss(train) 1.9354 | Acc(train) 0.5564 | Acc(val) 0.5766 |
Epoch 00156 | Loss(train) 1.9513 | Acc(train) 0.5468 | Acc(val) 0.5761 |
Epoch 00157 | Loss(train) 1.9428 | Acc(train) 0.5532 | Acc(val) 0.5777 |
Epoch 00158 | Loss(train) 1.9344 | Acc(train) 0.5556 | Acc(val) 0.5798 |
Epoch 00159 | Loss(train) 1.9259 | Acc(train) 0.5601 | Acc(val) 0.5814 |
Epoch 00160 | Loss(train) 1.9477 | Acc(train) 0.5495 | Acc(val) 0.5835 |
Epoch 00161 | Loss(train) 1.9360 | Acc(train) 0.5561 | Acc(val) 0.5840 |
Epoch 00162 | Loss(train) 1.9331 | Acc(train) 0.5580 | Acc(val) 0.5867 |*
Epoch 00163 | Loss(train) 1.9298 | Acc(train) 0.5630 | Acc(val) 0.5835 |
Epoch 00164 | Loss(train) 1.9257 | Acc(train) 0.5569 | Acc(val) 0.5840 |
Epoch 00165 | Loss(train) 1.9509 | Acc(train) 0.5582 | Acc(val) 0.5835 |
Epoch 00166 | Loss(train) 1.9679 | Acc(train) 0.5487 | Acc(val) 0.5814 |
Epoch 00167 | Loss(train) 1.9365 | Acc(train) 0.5622 | Acc(val) 0.5803 |
Epoch 00168 | Loss(train) 1.9454 | Acc(train) 0.5543 | Acc(val) 0.5809 |
Epoch 00169 | Loss(train) 1.9375 | Acc(train) 0.5551 | Acc(val) 0.5814 |
Epoch 00170 | Loss(train) 1.9409 | Acc(train) 0.5588 | Acc(val) 0.5824 |
Epoch 00171 | Loss(train) 1.9251 | Acc(train) 0.5524 | Acc(val) 0.5878 |*
Epoch 00172 | Loss(train) 1.9265 | Acc(train) 0.5654 | Acc(val) 0.5883 |*
Epoch 00173 | Loss(train) 1.9602 | Acc(train) 0.5537 | Acc(val) 0.5878 |
Epoch 00174 | Loss(train) 1.9217 | Acc(train) 0.5617 | Acc(val) 0.5856 |
Epoch 00175 | Loss(train) 1.9417 | Acc(train) 0.5633 | Acc(val) 0.5824 |
Epoch 00176 | Loss(train) 1.9256 | Acc(train) 0.5598 | Acc(val) 0.5830 |
Epoch 00177 | Loss(train) 1.9356 | Acc(train) 0.5553 | Acc(val) 0.5809 |
Epoch 00178 | Loss(train) 1.9385 | Acc(train) 0.5593 | Acc(val) 0.5814 |
Epoch 00179 | Loss(train) 1.9245 | Acc(train) 0.5572 | Acc(val) 0.5830 |
Epoch 00180 | Loss(train) 1.9307 | Acc(train) 0.5553 | Acc(val) 0.5824 |
Epoch 00181 | Loss(train) 1.9318 | Acc(train) 0.5521 | Acc(val) 0.5830 |
Epoch 00182 | Loss(train) 1.9438 | Acc(train) 0.5527 | Acc(val) 0.5835 |
Epoch 00183 | Loss(train) 1.9511 | Acc(train) 0.5484 | Acc(val) 0.5856 |
Epoch 00184 | Loss(train) 1.9265 | Acc(train) 0.5633 | Acc(val) 0.5846 |
Epoch 00185 | Loss(train) 1.9440 | Acc(train) 0.5532 | Acc(val) 0.5814 |
Epoch 00186 | Loss(train) 1.9584 | Acc(train) 0.5476 | Acc(val) 0.5824 |
Epoch 00187 | Loss(train) 1.9196 | Acc(train) 0.5702 | Acc(val) 0.5846 |
Epoch 00188 | Loss(train) 1.9139 | Acc(train) 0.5612 | Acc(val) 0.5878 |
Epoch 00189 | Loss(train) 1.9142 | Acc(train) 0.5543 | Acc(val) 0.5878 |
Epoch 00190 | Loss(train) 1.9287 | Acc(train) 0.5633 | Acc(val) 0.5867 |
Epoch 00191 | Loss(train) 1.9283 | Acc(train) 0.5699 | Acc(val) 0.5867 |
Epoch 00192 | Loss(train) 1.9034 | Acc(train) 0.5678 | Acc(val) 0.5846 |
Epoch 00193 | Loss(train) 1.9239 | Acc(train) 0.5545 | Acc(val) 0.5840 |
Epoch 00194 | Loss(train) 1.9342 | Acc(train) 0.5628 | Acc(val) 0.5846 |
Epoch 00195 | Loss(train) 1.9242 | Acc(train) 0.5556 | Acc(val) 0.5846 |
Epoch 00196 | Loss(train) 1.9304 | Acc(train) 0.5585 | Acc(val) 0.5862 |
Epoch 00197 | Loss(train) 1.9137 | Acc(train) 0.5590 | Acc(val) 0.5878 |
Epoch 00198 | Loss(train) 1.9295 | Acc(train) 0.5588 | Acc(val) 0.5867 |
Epoch 00199 | Loss(train) 1.9246 | Acc(train) 0.5686 | Acc(val) 0.5856 |
Epoch 00200 | Loss(train) 1.9088 | Acc(train) 0.5636 | Acc(val) 0.5867 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2486 | Acc(train) 0.0178 | Acc(val) 0.1931 |*
Epoch 00002 | Loss(train) 4.2228 | Acc(train) 0.1176 | Acc(val) 0.2553 |*
Epoch 00003 | Loss(train) 4.1866 | Acc(train) 0.1561 | Acc(val) 0.2654 |*
Epoch 00004 | Loss(train) 4.1413 | Acc(train) 0.1811 | Acc(val) 0.2729 |*
Epoch 00005 | Loss(train) 4.0929 | Acc(train) 0.1835 | Acc(val) 0.2676 |
Epoch 00006 | Loss(train) 4.0418 | Acc(train) 0.1785 | Acc(val) 0.2649 |
Epoch 00007 | Loss(train) 3.9925 | Acc(train) 0.1668 | Acc(val) 0.2537 |
Epoch 00008 | Loss(train) 3.9380 | Acc(train) 0.1689 | Acc(val) 0.2537 |
Epoch 00009 | Loss(train) 3.8892 | Acc(train) 0.1676 | Acc(val) 0.2436 |
Epoch 00010 | Loss(train) 3.8564 | Acc(train) 0.1633 | Acc(val) 0.2176 |
Epoch 00011 | Loss(train) 3.8130 | Acc(train) 0.1601 | Acc(val) 0.1973 |
Epoch 00012 | Loss(train) 3.7839 | Acc(train) 0.1625 | Acc(val) 0.1846 |
Epoch 00013 | Loss(train) 3.7466 | Acc(train) 0.1497 | Acc(val) 0.1809 |
Epoch 00014 | Loss(train) 3.7131 | Acc(train) 0.1521 | Acc(val) 0.1840 |
Epoch 00015 | Loss(train) 3.6814 | Acc(train) 0.1705 | Acc(val) 0.1904 |
Epoch 00016 | Loss(train) 3.6281 | Acc(train) 0.1758 | Acc(val) 0.1952 |
Epoch 00017 | Loss(train) 3.5977 | Acc(train) 0.1883 | Acc(val) 0.2048 |
Epoch 00018 | Loss(train) 3.5587 | Acc(train) 0.1992 | Acc(val) 0.2176 |
Epoch 00019 | Loss(train) 3.5288 | Acc(train) 0.2051 | Acc(val) 0.2303 |
Epoch 00020 | Loss(train) 3.4746 | Acc(train) 0.2207 | Acc(val) 0.2399 |
Epoch 00021 | Loss(train) 3.4417 | Acc(train) 0.2253 | Acc(val) 0.2473 |
Epoch 00022 | Loss(train) 3.3990 | Acc(train) 0.2247 | Acc(val) 0.2559 |
Epoch 00023 | Loss(train) 3.3553 | Acc(train) 0.2412 | Acc(val) 0.2670 |
Epoch 00024 | Loss(train) 3.3053 | Acc(train) 0.2439 | Acc(val) 0.2782 |*
Epoch 00025 | Loss(train) 3.2755 | Acc(train) 0.2444 | Acc(val) 0.2973 |*
Epoch 00026 | Loss(train) 3.2207 | Acc(train) 0.2684 | Acc(val) 0.3165 |*
Epoch 00027 | Loss(train) 3.1764 | Acc(train) 0.2848 | Acc(val) 0.3340 |*
Epoch 00028 | Loss(train) 3.1486 | Acc(train) 0.2814 | Acc(val) 0.3426 |*
Epoch 00029 | Loss(train) 3.1013 | Acc(train) 0.2984 | Acc(val) 0.3574 |*
Epoch 00030 | Loss(train) 3.0583 | Acc(train) 0.3205 | Acc(val) 0.3660 |*
Epoch 00031 | Loss(train) 3.0318 | Acc(train) 0.3112 | Acc(val) 0.3729 |*
Epoch 00032 | Loss(train) 2.9851 | Acc(train) 0.3245 | Acc(val) 0.3824 |*
Epoch 00033 | Loss(train) 2.9559 | Acc(train) 0.3372 | Acc(val) 0.3851 |*
Epoch 00034 | Loss(train) 2.9102 | Acc(train) 0.3476 | Acc(val) 0.3920 |*
Epoch 00035 | Loss(train) 2.8938 | Acc(train) 0.3503 | Acc(val) 0.4021 |*
Epoch 00036 | Loss(train) 2.8534 | Acc(train) 0.3532 | Acc(val) 0.4106 |*
Epoch 00037 | Loss(train) 2.8251 | Acc(train) 0.3646 | Acc(val) 0.4170 |*
Epoch 00038 | Loss(train) 2.7906 | Acc(train) 0.3758 | Acc(val) 0.4261 |*
Epoch 00039 | Loss(train) 2.7609 | Acc(train) 0.3785 | Acc(val) 0.4303 |*
Epoch 00040 | Loss(train) 2.7465 | Acc(train) 0.3809 | Acc(val) 0.4362 |*
Epoch 00041 | Loss(train) 2.7045 | Acc(train) 0.3963 | Acc(val) 0.4426 |*
Epoch 00042 | Loss(train) 2.6755 | Acc(train) 0.4011 | Acc(val) 0.4452 |*
Epoch 00043 | Loss(train) 2.6451 | Acc(train) 0.4000 | Acc(val) 0.4500 |*
Epoch 00044 | Loss(train) 2.6237 | Acc(train) 0.4003 | Acc(val) 0.4516 |*
Epoch 00045 | Loss(train) 2.6091 | Acc(train) 0.4037 | Acc(val) 0.4548 |*
Epoch 00046 | Loss(train) 2.5754 | Acc(train) 0.4181 | Acc(val) 0.4633 |*
Epoch 00047 | Loss(train) 2.5656 | Acc(train) 0.4218 | Acc(val) 0.4660 |*
Epoch 00048 | Loss(train) 2.5302 | Acc(train) 0.4330 | Acc(val) 0.4686 |*
Epoch 00049 | Loss(train) 2.5178 | Acc(train) 0.4279 | Acc(val) 0.4691 |*
Epoch 00050 | Loss(train) 2.4971 | Acc(train) 0.4330 | Acc(val) 0.4713 |*
Epoch 00051 | Loss(train) 2.5009 | Acc(train) 0.4253 | Acc(val) 0.4766 |*
Epoch 00052 | Loss(train) 2.4595 | Acc(train) 0.4396 | Acc(val) 0.4840 |*
Epoch 00053 | Loss(train) 2.4525 | Acc(train) 0.4388 | Acc(val) 0.4910 |*
Epoch 00054 | Loss(train) 2.4274 | Acc(train) 0.4460 | Acc(val) 0.4926 |*
Epoch 00055 | Loss(train) 2.4152 | Acc(train) 0.4484 | Acc(val) 0.4926 |
Epoch 00056 | Loss(train) 2.3922 | Acc(train) 0.4588 | Acc(val) 0.4941 |*
Epoch 00057 | Loss(train) 2.3850 | Acc(train) 0.4535 | Acc(val) 0.4968 |*
Epoch 00058 | Loss(train) 2.3807 | Acc(train) 0.4641 | Acc(val) 0.4995 |*
Epoch 00059 | Loss(train) 2.3673 | Acc(train) 0.4553 | Acc(val) 0.5032 |*
Epoch 00060 | Loss(train) 2.3502 | Acc(train) 0.4684 | Acc(val) 0.5074 |*
Epoch 00061 | Loss(train) 2.3475 | Acc(train) 0.4670 | Acc(val) 0.5106 |*
Epoch 00062 | Loss(train) 2.3266 | Acc(train) 0.4622 | Acc(val) 0.5160 |*
Epoch 00063 | Loss(train) 2.2936 | Acc(train) 0.4806 | Acc(val) 0.5170 |*
Epoch 00064 | Loss(train) 2.2938 | Acc(train) 0.4769 | Acc(val) 0.5191 |*
Epoch 00065 | Loss(train) 2.2839 | Acc(train) 0.4806 | Acc(val) 0.5213 |*
Epoch 00066 | Loss(train) 2.2832 | Acc(train) 0.4793 | Acc(val) 0.5197 |
Epoch 00067 | Loss(train) 2.2617 | Acc(train) 0.4819 | Acc(val) 0.5218 |*
Epoch 00068 | Loss(train) 2.2557 | Acc(train) 0.4864 | Acc(val) 0.5213 |
Epoch 00069 | Loss(train) 2.2340 | Acc(train) 0.4838 | Acc(val) 0.5255 |*
Epoch 00070 | Loss(train) 2.2410 | Acc(train) 0.4886 | Acc(val) 0.5287 |*
Epoch 00071 | Loss(train) 2.2300 | Acc(train) 0.4721 | Acc(val) 0.5309 |*
Epoch 00072 | Loss(train) 2.2158 | Acc(train) 0.4910 | Acc(val) 0.5335 |*
Epoch 00073 | Loss(train) 2.2041 | Acc(train) 0.4997 | Acc(val) 0.5335 |
Epoch 00074 | Loss(train) 2.2238 | Acc(train) 0.4886 | Acc(val) 0.5314 |
Epoch 00075 | Loss(train) 2.2115 | Acc(train) 0.4846 | Acc(val) 0.5314 |
Epoch 00076 | Loss(train) 2.1988 | Acc(train) 0.4928 | Acc(val) 0.5335 |
Epoch 00077 | Loss(train) 2.1684 | Acc(train) 0.4968 | Acc(val) 0.5351 |*
Epoch 00078 | Loss(train) 2.1762 | Acc(train) 0.4976 | Acc(val) 0.5362 |*
Epoch 00079 | Loss(train) 2.1605 | Acc(train) 0.5064 | Acc(val) 0.5362 |
Epoch 00080 | Loss(train) 2.1725 | Acc(train) 0.5059 | Acc(val) 0.5383 |*
Epoch 00081 | Loss(train) 2.1487 | Acc(train) 0.5077 | Acc(val) 0.5399 |*
Epoch 00082 | Loss(train) 2.1315 | Acc(train) 0.5080 | Acc(val) 0.5404 |*
Epoch 00083 | Loss(train) 2.1357 | Acc(train) 0.5090 | Acc(val) 0.5420 |*
Epoch 00084 | Loss(train) 2.1436 | Acc(train) 0.5088 | Acc(val) 0.5447 |*
Epoch 00085 | Loss(train) 2.1416 | Acc(train) 0.5088 | Acc(val) 0.5431 |
Epoch 00086 | Loss(train) 2.1360 | Acc(train) 0.5114 | Acc(val) 0.5452 |*
Epoch 00087 | Loss(train) 2.1259 | Acc(train) 0.4979 | Acc(val) 0.5500 |*
Epoch 00088 | Loss(train) 2.1209 | Acc(train) 0.5168 | Acc(val) 0.5473 |
Epoch 00089 | Loss(train) 2.1139 | Acc(train) 0.5149 | Acc(val) 0.5473 |
Epoch 00090 | Loss(train) 2.1110 | Acc(train) 0.5101 | Acc(val) 0.5473 |
Epoch 00091 | Loss(train) 2.1250 | Acc(train) 0.5152 | Acc(val) 0.5479 |
Epoch 00092 | Loss(train) 2.1103 | Acc(train) 0.5138 | Acc(val) 0.5543 |*
Epoch 00093 | Loss(train) 2.1083 | Acc(train) 0.5114 | Acc(val) 0.5548 |*
Epoch 00094 | Loss(train) 2.0899 | Acc(train) 0.5279 | Acc(val) 0.5580 |*
Epoch 00095 | Loss(train) 2.0965 | Acc(train) 0.5077 | Acc(val) 0.5590 |*
Epoch 00096 | Loss(train) 2.0800 | Acc(train) 0.5250 | Acc(val) 0.5601 |*
Epoch 00097 | Loss(train) 2.0743 | Acc(train) 0.5237 | Acc(val) 0.5601 |
Epoch 00098 | Loss(train) 2.0665 | Acc(train) 0.5226 | Acc(val) 0.5601 |
Epoch 00099 | Loss(train) 2.0901 | Acc(train) 0.5229 | Acc(val) 0.5606 |*
Epoch 00100 | Loss(train) 2.0661 | Acc(train) 0.5176 | Acc(val) 0.5596 |
Epoch 00101 | Loss(train) 2.0618 | Acc(train) 0.5239 | Acc(val) 0.5606 |
Epoch 00102 | Loss(train) 2.0619 | Acc(train) 0.5181 | Acc(val) 0.5638 |*
Epoch 00103 | Loss(train) 2.0692 | Acc(train) 0.5165 | Acc(val) 0.5665 |*
Epoch 00104 | Loss(train) 2.0738 | Acc(train) 0.5282 | Acc(val) 0.5670 |*
Epoch 00105 | Loss(train) 2.0701 | Acc(train) 0.5282 | Acc(val) 0.5660 |
Epoch 00106 | Loss(train) 2.0545 | Acc(train) 0.5364 | Acc(val) 0.5670 |
Epoch 00107 | Loss(train) 2.0566 | Acc(train) 0.5261 | Acc(val) 0.5654 |
Epoch 00108 | Loss(train) 2.0571 | Acc(train) 0.5298 | Acc(val) 0.5649 |
Epoch 00109 | Loss(train) 2.0480 | Acc(train) 0.5298 | Acc(val) 0.5654 |
Epoch 00110 | Loss(train) 2.0449 | Acc(train) 0.5285 | Acc(val) 0.5686 |*
Epoch 00111 | Loss(train) 2.0320 | Acc(train) 0.5319 | Acc(val) 0.5707 |*
Epoch 00112 | Loss(train) 2.0479 | Acc(train) 0.5269 | Acc(val) 0.5702 |
Epoch 00113 | Loss(train) 2.0251 | Acc(train) 0.5303 | Acc(val) 0.5707 |
Epoch 00114 | Loss(train) 2.0395 | Acc(train) 0.5362 | Acc(val) 0.5697 |
Epoch 00115 | Loss(train) 2.0455 | Acc(train) 0.5269 | Acc(val) 0.5713 |*
Epoch 00116 | Loss(train) 2.0489 | Acc(train) 0.5258 | Acc(val) 0.5739 |*
Epoch 00117 | Loss(train) 2.0407 | Acc(train) 0.5282 | Acc(val) 0.5707 |
Epoch 00118 | Loss(train) 2.0503 | Acc(train) 0.5324 | Acc(val) 0.5697 |
Epoch 00119 | Loss(train) 2.0198 | Acc(train) 0.5527 | Acc(val) 0.5681 |
Epoch 00120 | Loss(train) 2.0216 | Acc(train) 0.5418 | Acc(val) 0.5670 |
Epoch 00121 | Loss(train) 2.0146 | Acc(train) 0.5306 | Acc(val) 0.5670 |
Epoch 00122 | Loss(train) 2.0327 | Acc(train) 0.5327 | Acc(val) 0.5686 |
Epoch 00123 | Loss(train) 2.0320 | Acc(train) 0.5332 | Acc(val) 0.5739 |
Epoch 00124 | Loss(train) 2.0240 | Acc(train) 0.5380 | Acc(val) 0.5734 |
Epoch 00125 | Loss(train) 2.0279 | Acc(train) 0.5332 | Acc(val) 0.5750 |*
Epoch 00126 | Loss(train) 2.0116 | Acc(train) 0.5364 | Acc(val) 0.5750 |
Epoch 00127 | Loss(train) 2.0157 | Acc(train) 0.5407 | Acc(val) 0.5729 |
Epoch 00128 | Loss(train) 1.9969 | Acc(train) 0.5441 | Acc(val) 0.5761 |*
Epoch 00129 | Loss(train) 1.9911 | Acc(train) 0.5452 | Acc(val) 0.5745 |
Epoch 00130 | Loss(train) 2.0292 | Acc(train) 0.5314 | Acc(val) 0.5745 |
Epoch 00131 | Loss(train) 2.0164 | Acc(train) 0.5290 | Acc(val) 0.5755 |
Epoch 00132 | Loss(train) 2.0013 | Acc(train) 0.5348 | Acc(val) 0.5761 |
Epoch 00133 | Loss(train) 1.9974 | Acc(train) 0.5431 | Acc(val) 0.5745 |
Epoch 00134 | Loss(train) 2.0041 | Acc(train) 0.5402 | Acc(val) 0.5793 |*
Epoch 00135 | Loss(train) 2.0147 | Acc(train) 0.5375 | Acc(val) 0.5777 |
Epoch 00136 | Loss(train) 1.9913 | Acc(train) 0.5404 | Acc(val) 0.5745 |
Epoch 00137 | Loss(train) 2.0116 | Acc(train) 0.5322 | Acc(val) 0.5766 |
Epoch 00138 | Loss(train) 1.9945 | Acc(train) 0.5468 | Acc(val) 0.5750 |
Epoch 00139 | Loss(train) 2.0092 | Acc(train) 0.5423 | Acc(val) 0.5750 |
Epoch 00140 | Loss(train) 1.9862 | Acc(train) 0.5487 | Acc(val) 0.5755 |
Epoch 00141 | Loss(train) 1.9990 | Acc(train) 0.5402 | Acc(val) 0.5761 |
Epoch 00142 | Loss(train) 2.0065 | Acc(train) 0.5386 | Acc(val) 0.5745 |
Epoch 00143 | Loss(train) 1.9941 | Acc(train) 0.5354 | Acc(val) 0.5750 |
Epoch 00144 | Loss(train) 1.9974 | Acc(train) 0.5444 | Acc(val) 0.5777 |
Epoch 00145 | Loss(train) 1.9858 | Acc(train) 0.5410 | Acc(val) 0.5771 |
Epoch 00146 | Loss(train) 1.9949 | Acc(train) 0.5402 | Acc(val) 0.5787 |
Epoch 00147 | Loss(train) 1.9710 | Acc(train) 0.5447 | Acc(val) 0.5782 |
Epoch 00148 | Loss(train) 1.9997 | Acc(train) 0.5423 | Acc(val) 0.5771 |
Epoch 00149 | Loss(train) 1.9971 | Acc(train) 0.5367 | Acc(val) 0.5761 |
Epoch 00150 | Loss(train) 1.9858 | Acc(train) 0.5415 | Acc(val) 0.5777 |
Epoch 00151 | Loss(train) 1.9888 | Acc(train) 0.5532 | Acc(val) 0.5761 |
Epoch 00152 | Loss(train) 1.9886 | Acc(train) 0.5428 | Acc(val) 0.5739 |
Epoch 00153 | Loss(train) 1.9827 | Acc(train) 0.5457 | Acc(val) 0.5766 |
Epoch 00154 | Loss(train) 1.9899 | Acc(train) 0.5476 | Acc(val) 0.5798 |*
Epoch 00155 | Loss(train) 1.9734 | Acc(train) 0.5439 | Acc(val) 0.5814 |*
Epoch 00156 | Loss(train) 1.9849 | Acc(train) 0.5324 | Acc(val) 0.5803 |
Epoch 00157 | Loss(train) 1.9784 | Acc(train) 0.5457 | Acc(val) 0.5793 |
Epoch 00158 | Loss(train) 1.9997 | Acc(train) 0.5388 | Acc(val) 0.5771 |
Epoch 00159 | Loss(train) 1.9852 | Acc(train) 0.5431 | Acc(val) 0.5745 |
Epoch 00160 | Loss(train) 1.9766 | Acc(train) 0.5487 | Acc(val) 0.5739 |
Epoch 00161 | Loss(train) 1.9796 | Acc(train) 0.5383 | Acc(val) 0.5755 |
Epoch 00162 | Loss(train) 1.9736 | Acc(train) 0.5505 | Acc(val) 0.5745 |
Epoch 00163 | Loss(train) 1.9949 | Acc(train) 0.5394 | Acc(val) 0.5766 |
Epoch 00164 | Loss(train) 1.9729 | Acc(train) 0.5447 | Acc(val) 0.5803 |
Epoch 00165 | Loss(train) 1.9784 | Acc(train) 0.5473 | Acc(val) 0.5824 |*
Epoch 00166 | Loss(train) 1.9840 | Acc(train) 0.5497 | Acc(val) 0.5830 |*
Epoch 00167 | Loss(train) 1.9641 | Acc(train) 0.5428 | Acc(val) 0.5830 |
Epoch 00168 | Loss(train) 1.9603 | Acc(train) 0.5495 | Acc(val) 0.5856 |*
Epoch 00169 | Loss(train) 1.9710 | Acc(train) 0.5484 | Acc(val) 0.5835 |
Epoch 00170 | Loss(train) 1.9685 | Acc(train) 0.5524 | Acc(val) 0.5840 |
Epoch 00171 | Loss(train) 1.9679 | Acc(train) 0.5500 | Acc(val) 0.5824 |
Epoch 00172 | Loss(train) 1.9767 | Acc(train) 0.5447 | Acc(val) 0.5809 |
Epoch 00173 | Loss(train) 1.9665 | Acc(train) 0.5449 | Acc(val) 0.5830 |
Epoch 00174 | Loss(train) 1.9736 | Acc(train) 0.5524 | Acc(val) 0.5878 |*
Epoch 00175 | Loss(train) 1.9636 | Acc(train) 0.5540 | Acc(val) 0.5899 |*
Epoch 00176 | Loss(train) 1.9768 | Acc(train) 0.5455 | Acc(val) 0.5867 |
Epoch 00177 | Loss(train) 1.9770 | Acc(train) 0.5465 | Acc(val) 0.5856 |
Epoch 00178 | Loss(train) 1.9540 | Acc(train) 0.5556 | Acc(val) 0.5846 |
Epoch 00179 | Loss(train) 1.9629 | Acc(train) 0.5460 | Acc(val) 0.5835 |
Epoch 00180 | Loss(train) 1.9503 | Acc(train) 0.5551 | Acc(val) 0.5824 |
Epoch 00181 | Loss(train) 1.9788 | Acc(train) 0.5449 | Acc(val) 0.5814 |
Epoch 00182 | Loss(train) 1.9574 | Acc(train) 0.5468 | Acc(val) 0.5809 |
Epoch 00183 | Loss(train) 1.9432 | Acc(train) 0.5487 | Acc(val) 0.5819 |
Epoch 00184 | Loss(train) 1.9587 | Acc(train) 0.5540 | Acc(val) 0.5835 |
Epoch 00185 | Loss(train) 1.9555 | Acc(train) 0.5548 | Acc(val) 0.5840 |
Epoch 00186 | Loss(train) 1.9547 | Acc(train) 0.5473 | Acc(val) 0.5856 |
Epoch 00187 | Loss(train) 1.9472 | Acc(train) 0.5527 | Acc(val) 0.5840 |
Epoch 00188 | Loss(train) 1.9566 | Acc(train) 0.5543 | Acc(val) 0.5851 |
Epoch 00189 | Loss(train) 1.9445 | Acc(train) 0.5529 | Acc(val) 0.5840 |
Epoch 00190 | Loss(train) 1.9558 | Acc(train) 0.5455 | Acc(val) 0.5846 |
Epoch 00191 | Loss(train) 1.9476 | Acc(train) 0.5503 | Acc(val) 0.5862 |
Epoch 00192 | Loss(train) 1.9495 | Acc(train) 0.5521 | Acc(val) 0.5899 |
Epoch 00193 | Loss(train) 1.9562 | Acc(train) 0.5500 | Acc(val) 0.5894 |
Epoch 00194 | Loss(train) 1.9483 | Acc(train) 0.5556 | Acc(val) 0.5894 |
Epoch 00195 | Loss(train) 1.9435 | Acc(train) 0.5598 | Acc(val) 0.5894 |
Epoch 00196 | Loss(train) 1.9507 | Acc(train) 0.5604 | Acc(val) 0.5878 |
Epoch 00197 | Loss(train) 1.9402 | Acc(train) 0.5561 | Acc(val) 0.5835 |
Epoch 00198 | Loss(train) 1.9182 | Acc(train) 0.5585 | Acc(val) 0.5824 |
Epoch 00199 | Loss(train) 1.9587 | Acc(train) 0.5551 | Acc(val) 0.5846 |
Epoch 00200 | Loss(train) 1.9634 | Acc(train) 0.5497 | Acc(val) 0.5878 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 704.63 MB
GPU Memory Reserved: 1382.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2487 | Acc(train) 0.0144 | Acc(val) 0.1399 |*
Epoch 00002 | Loss(train) 4.2215 | Acc(train) 0.0992 | Acc(val) 0.1878 |*
Epoch 00003 | Loss(train) 4.1817 | Acc(train) 0.1431 | Acc(val) 0.1814 |
Epoch 00004 | Loss(train) 4.1361 | Acc(train) 0.1428 | Acc(val) 0.1745 |
Epoch 00005 | Loss(train) 4.0816 | Acc(train) 0.1410 | Acc(val) 0.1691 |
Epoch 00006 | Loss(train) 4.0296 | Acc(train) 0.1460 | Acc(val) 0.1755 |
Epoch 00007 | Loss(train) 3.9758 | Acc(train) 0.1436 | Acc(val) 0.1787 |
Epoch 00008 | Loss(train) 3.9224 | Acc(train) 0.1441 | Acc(val) 0.1830 |
Epoch 00009 | Loss(train) 3.8801 | Acc(train) 0.1508 | Acc(val) 0.1878 |
Epoch 00010 | Loss(train) 3.8429 | Acc(train) 0.1503 | Acc(val) 0.1947 |*
Epoch 00011 | Loss(train) 3.8033 | Acc(train) 0.1668 | Acc(val) 0.1968 |*
Epoch 00012 | Loss(train) 3.7628 | Acc(train) 0.1694 | Acc(val) 0.2000 |*
Epoch 00013 | Loss(train) 3.7217 | Acc(train) 0.1771 | Acc(val) 0.2027 |*
Epoch 00014 | Loss(train) 3.6891 | Acc(train) 0.1766 | Acc(val) 0.2053 |*
Epoch 00015 | Loss(train) 3.6460 | Acc(train) 0.1910 | Acc(val) 0.2170 |*
Epoch 00016 | Loss(train) 3.6090 | Acc(train) 0.1989 | Acc(val) 0.2245 |*
Epoch 00017 | Loss(train) 3.5654 | Acc(train) 0.2096 | Acc(val) 0.2335 |*
Epoch 00018 | Loss(train) 3.5261 | Acc(train) 0.2176 | Acc(val) 0.2399 |*
Epoch 00019 | Loss(train) 3.4779 | Acc(train) 0.2229 | Acc(val) 0.2420 |*
Epoch 00020 | Loss(train) 3.4462 | Acc(train) 0.2184 | Acc(val) 0.2473 |*
Epoch 00021 | Loss(train) 3.3928 | Acc(train) 0.2332 | Acc(val) 0.2511 |*
Epoch 00022 | Loss(train) 3.3504 | Acc(train) 0.2324 | Acc(val) 0.2532 |*
Epoch 00023 | Loss(train) 3.3089 | Acc(train) 0.2402 | Acc(val) 0.2585 |*
Epoch 00024 | Loss(train) 3.2682 | Acc(train) 0.2479 | Acc(val) 0.2713 |*
Epoch 00025 | Loss(train) 3.2407 | Acc(train) 0.2511 | Acc(val) 0.2830 |*
Epoch 00026 | Loss(train) 3.1877 | Acc(train) 0.2686 | Acc(val) 0.2995 |*
Epoch 00027 | Loss(train) 3.1406 | Acc(train) 0.2771 | Acc(val) 0.3181 |*
Epoch 00028 | Loss(train) 3.1001 | Acc(train) 0.2912 | Acc(val) 0.3394 |*
Epoch 00029 | Loss(train) 3.0669 | Acc(train) 0.3043 | Acc(val) 0.3537 |*
Epoch 00030 | Loss(train) 3.0239 | Acc(train) 0.3144 | Acc(val) 0.3638 |*
Epoch 00031 | Loss(train) 2.9924 | Acc(train) 0.3346 | Acc(val) 0.3766 |*
Epoch 00032 | Loss(train) 2.9507 | Acc(train) 0.3306 | Acc(val) 0.3856 |*
Epoch 00033 | Loss(train) 2.9212 | Acc(train) 0.3370 | Acc(val) 0.3947 |*
Epoch 00034 | Loss(train) 2.8870 | Acc(train) 0.3412 | Acc(val) 0.4069 |*
Epoch 00035 | Loss(train) 2.8493 | Acc(train) 0.3553 | Acc(val) 0.4128 |*
Epoch 00036 | Loss(train) 2.8260 | Acc(train) 0.3638 | Acc(val) 0.4245 |*
Epoch 00037 | Loss(train) 2.7864 | Acc(train) 0.3819 | Acc(val) 0.4362 |*
Epoch 00038 | Loss(train) 2.7630 | Acc(train) 0.3694 | Acc(val) 0.4463 |*
Epoch 00039 | Loss(train) 2.7222 | Acc(train) 0.3955 | Acc(val) 0.4564 |*
Epoch 00040 | Loss(train) 2.7251 | Acc(train) 0.3896 | Acc(val) 0.4617 |*
Epoch 00041 | Loss(train) 2.6813 | Acc(train) 0.4021 | Acc(val) 0.4633 |*
Epoch 00042 | Loss(train) 2.6384 | Acc(train) 0.4170 | Acc(val) 0.4654 |*
Epoch 00043 | Loss(train) 2.6069 | Acc(train) 0.4088 | Acc(val) 0.4686 |*
Epoch 00044 | Loss(train) 2.6084 | Acc(train) 0.4146 | Acc(val) 0.4750 |*
Epoch 00045 | Loss(train) 2.5681 | Acc(train) 0.4303 | Acc(val) 0.4782 |*
Epoch 00046 | Loss(train) 2.5527 | Acc(train) 0.4176 | Acc(val) 0.4809 |*
Epoch 00047 | Loss(train) 2.5220 | Acc(train) 0.4271 | Acc(val) 0.4851 |*
Epoch 00048 | Loss(train) 2.4987 | Acc(train) 0.4359 | Acc(val) 0.4910 |*
Epoch 00049 | Loss(train) 2.4828 | Acc(train) 0.4404 | Acc(val) 0.4957 |*
Epoch 00050 | Loss(train) 2.4720 | Acc(train) 0.4457 | Acc(val) 0.4989 |*
Epoch 00051 | Loss(train) 2.4228 | Acc(train) 0.4588 | Acc(val) 0.5011 |*
Epoch 00052 | Loss(train) 2.4382 | Acc(train) 0.4460 | Acc(val) 0.5016 |*
Epoch 00053 | Loss(train) 2.4087 | Acc(train) 0.4593 | Acc(val) 0.5048 |*
Epoch 00054 | Loss(train) 2.3917 | Acc(train) 0.4489 | Acc(val) 0.5106 |*
Epoch 00055 | Loss(train) 2.3722 | Acc(train) 0.4593 | Acc(val) 0.5170 |*
Epoch 00056 | Loss(train) 2.3695 | Acc(train) 0.4636 | Acc(val) 0.5191 |*
Epoch 00057 | Loss(train) 2.3418 | Acc(train) 0.4660 | Acc(val) 0.5197 |*
Epoch 00058 | Loss(train) 2.3433 | Acc(train) 0.4543 | Acc(val) 0.5218 |*
Epoch 00059 | Loss(train) 2.3020 | Acc(train) 0.4750 | Acc(val) 0.5250 |*
Epoch 00060 | Loss(train) 2.3050 | Acc(train) 0.4830 | Acc(val) 0.5271 |*
Epoch 00061 | Loss(train) 2.3161 | Acc(train) 0.4670 | Acc(val) 0.5271 |
Epoch 00062 | Loss(train) 2.2827 | Acc(train) 0.4867 | Acc(val) 0.5261 |
Epoch 00063 | Loss(train) 2.2526 | Acc(train) 0.4832 | Acc(val) 0.5309 |*
Epoch 00064 | Loss(train) 2.2736 | Acc(train) 0.4819 | Acc(val) 0.5298 |
Epoch 00065 | Loss(train) 2.2375 | Acc(train) 0.4846 | Acc(val) 0.5346 |*
Epoch 00066 | Loss(train) 2.2411 | Acc(train) 0.4824 | Acc(val) 0.5383 |*
Epoch 00067 | Loss(train) 2.2310 | Acc(train) 0.4902 | Acc(val) 0.5388 |*
Epoch 00068 | Loss(train) 2.2190 | Acc(train) 0.4963 | Acc(val) 0.5394 |*
Epoch 00069 | Loss(train) 2.1923 | Acc(train) 0.4987 | Acc(val) 0.5415 |*
Epoch 00070 | Loss(train) 2.2087 | Acc(train) 0.4976 | Acc(val) 0.5404 |
Epoch 00071 | Loss(train) 2.1927 | Acc(train) 0.5011 | Acc(val) 0.5420 |*
Epoch 00072 | Loss(train) 2.2014 | Acc(train) 0.4947 | Acc(val) 0.5415 |
Epoch 00073 | Loss(train) 2.1836 | Acc(train) 0.4981 | Acc(val) 0.5431 |*
Epoch 00074 | Loss(train) 2.1685 | Acc(train) 0.5072 | Acc(val) 0.5479 |*
Epoch 00075 | Loss(train) 2.1641 | Acc(train) 0.5074 | Acc(val) 0.5505 |*
Epoch 00076 | Loss(train) 2.1818 | Acc(train) 0.4981 | Acc(val) 0.5532 |*
Epoch 00077 | Loss(train) 2.1422 | Acc(train) 0.5040 | Acc(val) 0.5505 |
Epoch 00078 | Loss(train) 2.1355 | Acc(train) 0.5059 | Acc(val) 0.5516 |
Epoch 00079 | Loss(train) 2.1457 | Acc(train) 0.5066 | Acc(val) 0.5500 |
Epoch 00080 | Loss(train) 2.1192 | Acc(train) 0.5066 | Acc(val) 0.5484 |
Epoch 00081 | Loss(train) 2.1245 | Acc(train) 0.5045 | Acc(val) 0.5489 |
Epoch 00082 | Loss(train) 2.1161 | Acc(train) 0.5085 | Acc(val) 0.5559 |*
Epoch 00083 | Loss(train) 2.1093 | Acc(train) 0.5154 | Acc(val) 0.5559 |
Epoch 00084 | Loss(train) 2.1125 | Acc(train) 0.5149 | Acc(val) 0.5596 |*
Epoch 00085 | Loss(train) 2.0920 | Acc(train) 0.5242 | Acc(val) 0.5628 |*
Epoch 00086 | Loss(train) 2.0949 | Acc(train) 0.5218 | Acc(val) 0.5638 |*
Epoch 00087 | Loss(train) 2.1146 | Acc(train) 0.5157 | Acc(val) 0.5622 |
Epoch 00088 | Loss(train) 2.0953 | Acc(train) 0.5149 | Acc(val) 0.5649 |*
Epoch 00089 | Loss(train) 2.1037 | Acc(train) 0.5176 | Acc(val) 0.5654 |*
Epoch 00090 | Loss(train) 2.0852 | Acc(train) 0.5160 | Acc(val) 0.5686 |*
Epoch 00091 | Loss(train) 2.0797 | Acc(train) 0.5186 | Acc(val) 0.5723 |*
Epoch 00092 | Loss(train) 2.0769 | Acc(train) 0.5149 | Acc(val) 0.5734 |*
Epoch 00093 | Loss(train) 2.0590 | Acc(train) 0.5279 | Acc(val) 0.5723 |
Epoch 00094 | Loss(train) 2.0729 | Acc(train) 0.5218 | Acc(val) 0.5681 |
Epoch 00095 | Loss(train) 2.0587 | Acc(train) 0.5274 | Acc(val) 0.5665 |
Epoch 00096 | Loss(train) 2.0670 | Acc(train) 0.5258 | Acc(val) 0.5676 |
Epoch 00097 | Loss(train) 2.0499 | Acc(train) 0.5261 | Acc(val) 0.5713 |
Epoch 00098 | Loss(train) 2.0613 | Acc(train) 0.5152 | Acc(val) 0.5739 |*
Epoch 00099 | Loss(train) 2.0568 | Acc(train) 0.5234 | Acc(val) 0.5761 |*
Epoch 00100 | Loss(train) 2.0658 | Acc(train) 0.5266 | Acc(val) 0.5750 |
Epoch 00101 | Loss(train) 2.0534 | Acc(train) 0.5298 | Acc(val) 0.5750 |
Epoch 00102 | Loss(train) 2.0444 | Acc(train) 0.5359 | Acc(val) 0.5707 |
Epoch 00103 | Loss(train) 2.0124 | Acc(train) 0.5303 | Acc(val) 0.5691 |
Epoch 00104 | Loss(train) 2.0322 | Acc(train) 0.5277 | Acc(val) 0.5718 |
Epoch 00105 | Loss(train) 2.0495 | Acc(train) 0.5298 | Acc(val) 0.5750 |
Epoch 00106 | Loss(train) 2.0471 | Acc(train) 0.5178 | Acc(val) 0.5793 |*
Epoch 00107 | Loss(train) 2.0203 | Acc(train) 0.5290 | Acc(val) 0.5798 |*
Epoch 00108 | Loss(train) 2.0111 | Acc(train) 0.5367 | Acc(val) 0.5803 |*
Epoch 00109 | Loss(train) 2.0220 | Acc(train) 0.5295 | Acc(val) 0.5798 |
Epoch 00110 | Loss(train) 2.0448 | Acc(train) 0.5311 | Acc(val) 0.5761 |
Epoch 00111 | Loss(train) 2.0174 | Acc(train) 0.5386 | Acc(val) 0.5734 |
Epoch 00112 | Loss(train) 2.0409 | Acc(train) 0.5322 | Acc(val) 0.5739 |
Epoch 00113 | Loss(train) 2.0297 | Acc(train) 0.5298 | Acc(val) 0.5755 |
Epoch 00114 | Loss(train) 2.0169 | Acc(train) 0.5380 | Acc(val) 0.5771 |
Epoch 00115 | Loss(train) 2.0107 | Acc(train) 0.5447 | Acc(val) 0.5809 |*
Epoch 00116 | Loss(train) 2.0250 | Acc(train) 0.5404 | Acc(val) 0.5809 |
Epoch 00117 | Loss(train) 2.0312 | Acc(train) 0.5391 | Acc(val) 0.5793 |
Epoch 00118 | Loss(train) 2.0104 | Acc(train) 0.5441 | Acc(val) 0.5771 |
Epoch 00119 | Loss(train) 2.0229 | Acc(train) 0.5511 | Acc(val) 0.5766 |
Epoch 00120 | Loss(train) 2.0222 | Acc(train) 0.5327 | Acc(val) 0.5771 |
Epoch 00121 | Loss(train) 2.0091 | Acc(train) 0.5410 | Acc(val) 0.5798 |
Epoch 00122 | Loss(train) 2.0042 | Acc(train) 0.5436 | Acc(val) 0.5846 |*
Epoch 00123 | Loss(train) 1.9914 | Acc(train) 0.5473 | Acc(val) 0.5856 |*
Epoch 00124 | Loss(train) 1.9826 | Acc(train) 0.5511 | Acc(val) 0.5867 |*
Epoch 00125 | Loss(train) 2.0207 | Acc(train) 0.5290 | Acc(val) 0.5846 |
Epoch 00126 | Loss(train) 1.9945 | Acc(train) 0.5391 | Acc(val) 0.5793 |
Epoch 00127 | Loss(train) 1.9967 | Acc(train) 0.5463 | Acc(val) 0.5798 |
Epoch 00128 | Loss(train) 2.0133 | Acc(train) 0.5335 | Acc(val) 0.5787 |
Epoch 00129 | Loss(train) 2.0076 | Acc(train) 0.5380 | Acc(val) 0.5824 |
Epoch 00130 | Loss(train) 2.0043 | Acc(train) 0.5348 | Acc(val) 0.5846 |
Epoch 00131 | Loss(train) 1.9907 | Acc(train) 0.5476 | Acc(val) 0.5835 |
Epoch 00132 | Loss(train) 2.0005 | Acc(train) 0.5351 | Acc(val) 0.5830 |
Epoch 00133 | Loss(train) 1.9917 | Acc(train) 0.5441 | Acc(val) 0.5809 |
Epoch 00134 | Loss(train) 1.9904 | Acc(train) 0.5471 | Acc(val) 0.5782 |
Epoch 00135 | Loss(train) 1.9942 | Acc(train) 0.5343 | Acc(val) 0.5787 |
Epoch 00136 | Loss(train) 1.9812 | Acc(train) 0.5535 | Acc(val) 0.5830 |
Epoch 00137 | Loss(train) 1.9614 | Acc(train) 0.5561 | Acc(val) 0.5846 |
Epoch 00138 | Loss(train) 1.9756 | Acc(train) 0.5481 | Acc(val) 0.5862 |
Epoch 00139 | Loss(train) 1.9844 | Acc(train) 0.5428 | Acc(val) 0.5851 |
Epoch 00140 | Loss(train) 1.9713 | Acc(train) 0.5436 | Acc(val) 0.5835 |
Epoch 00141 | Loss(train) 1.9886 | Acc(train) 0.5362 | Acc(val) 0.5840 |
Epoch 00142 | Loss(train) 1.9668 | Acc(train) 0.5426 | Acc(val) 0.5819 |
Epoch 00143 | Loss(train) 1.9787 | Acc(train) 0.5423 | Acc(val) 0.5830 |
Epoch 00144 | Loss(train) 1.9605 | Acc(train) 0.5505 | Acc(val) 0.5856 |
Epoch 00145 | Loss(train) 1.9595 | Acc(train) 0.5527 | Acc(val) 0.5878 |*
Epoch 00146 | Loss(train) 1.9640 | Acc(train) 0.5497 | Acc(val) 0.5867 |
Epoch 00147 | Loss(train) 1.9682 | Acc(train) 0.5495 | Acc(val) 0.5840 |
Epoch 00148 | Loss(train) 1.9804 | Acc(train) 0.5452 | Acc(val) 0.5803 |
Epoch 00149 | Loss(train) 1.9676 | Acc(train) 0.5418 | Acc(val) 0.5824 |
Epoch 00150 | Loss(train) 1.9847 | Acc(train) 0.5460 | Acc(val) 0.5883 |*
Epoch 00151 | Loss(train) 1.9654 | Acc(train) 0.5460 | Acc(val) 0.5904 |*
Epoch 00152 | Loss(train) 1.9733 | Acc(train) 0.5529 | Acc(val) 0.5872 |
Epoch 00153 | Loss(train) 1.9568 | Acc(train) 0.5548 | Acc(val) 0.5856 |
Epoch 00154 | Loss(train) 1.9706 | Acc(train) 0.5481 | Acc(val) 0.5846 |
Epoch 00155 | Loss(train) 1.9555 | Acc(train) 0.5492 | Acc(val) 0.5803 |
Epoch 00156 | Loss(train) 1.9789 | Acc(train) 0.5479 | Acc(val) 0.5782 |
Epoch 00157 | Loss(train) 1.9471 | Acc(train) 0.5535 | Acc(val) 0.5809 |
Epoch 00158 | Loss(train) 1.9663 | Acc(train) 0.5495 | Acc(val) 0.5856 |
Epoch 00159 | Loss(train) 1.9665 | Acc(train) 0.5503 | Acc(val) 0.5883 |
Epoch 00160 | Loss(train) 1.9901 | Acc(train) 0.5434 | Acc(val) 0.5856 |
Epoch 00161 | Loss(train) 1.9711 | Acc(train) 0.5465 | Acc(val) 0.5867 |
Epoch 00162 | Loss(train) 1.9501 | Acc(train) 0.5505 | Acc(val) 0.5851 |
Epoch 00163 | Loss(train) 1.9598 | Acc(train) 0.5537 | Acc(val) 0.5835 |
Epoch 00164 | Loss(train) 1.9598 | Acc(train) 0.5487 | Acc(val) 0.5856 |
Epoch 00165 | Loss(train) 1.9401 | Acc(train) 0.5553 | Acc(val) 0.5856 |
Epoch 00166 | Loss(train) 1.9493 | Acc(train) 0.5503 | Acc(val) 0.5851 |
Epoch 00167 | Loss(train) 1.9437 | Acc(train) 0.5625 | Acc(val) 0.5840 |
Epoch 00168 | Loss(train) 1.9409 | Acc(train) 0.5471 | Acc(val) 0.5835 |
Epoch 00169 | Loss(train) 1.9720 | Acc(train) 0.5471 | Acc(val) 0.5830 |
Epoch 00170 | Loss(train) 1.9593 | Acc(train) 0.5561 | Acc(val) 0.5856 |
Epoch 00171 | Loss(train) 1.9631 | Acc(train) 0.5415 | Acc(val) 0.5862 |
Epoch 00172 | Loss(train) 1.9527 | Acc(train) 0.5559 | Acc(val) 0.5872 |
Epoch 00173 | Loss(train) 1.9547 | Acc(train) 0.5487 | Acc(val) 0.5883 |
Epoch 00174 | Loss(train) 1.9582 | Acc(train) 0.5535 | Acc(val) 0.5867 |
Epoch 00175 | Loss(train) 1.9559 | Acc(train) 0.5609 | Acc(val) 0.5851 |
Epoch 00176 | Loss(train) 1.9500 | Acc(train) 0.5532 | Acc(val) 0.5846 |
Epoch 00177 | Loss(train) 1.9318 | Acc(train) 0.5553 | Acc(val) 0.5835 |
Epoch 00178 | Loss(train) 1.9408 | Acc(train) 0.5561 | Acc(val) 0.5846 |
Epoch 00179 | Loss(train) 1.9337 | Acc(train) 0.5564 | Acc(val) 0.5872 |
Epoch 00180 | Loss(train) 1.9374 | Acc(train) 0.5436 | Acc(val) 0.5878 |
Epoch 00181 | Loss(train) 1.9588 | Acc(train) 0.5508 | Acc(val) 0.5883 |
Epoch 00182 | Loss(train) 1.9504 | Acc(train) 0.5444 | Acc(val) 0.5872 |
Epoch 00183 | Loss(train) 1.9416 | Acc(train) 0.5596 | Acc(val) 0.5862 |
Epoch 00184 | Loss(train) 1.9533 | Acc(train) 0.5519 | Acc(val) 0.5856 |
Epoch 00185 | Loss(train) 1.9570 | Acc(train) 0.5489 | Acc(val) 0.5862 |
Epoch 00186 | Loss(train) 1.9439 | Acc(train) 0.5646 | Acc(val) 0.5888 |
Epoch 00187 | Loss(train) 1.9572 | Acc(train) 0.5388 | Acc(val) 0.5883 |
Epoch 00188 | Loss(train) 1.9340 | Acc(train) 0.5638 | Acc(val) 0.5883 |
Epoch 00189 | Loss(train) 1.9378 | Acc(train) 0.5569 | Acc(val) 0.5883 |
Epoch 00190 | Loss(train) 1.9391 | Acc(train) 0.5673 | Acc(val) 0.5840 |
Epoch 00191 | Loss(train) 1.9378 | Acc(train) 0.5561 | Acc(val) 0.5851 |
Epoch 00192 | Loss(train) 1.9444 | Acc(train) 0.5638 | Acc(val) 0.5846 |
Epoch 00193 | Loss(train) 1.9282 | Acc(train) 0.5588 | Acc(val) 0.5878 |
Epoch 00194 | Loss(train) 1.9326 | Acc(train) 0.5553 | Acc(val) 0.5888 |
Epoch 00195 | Loss(train) 1.9423 | Acc(train) 0.5574 | Acc(val) 0.5872 |
Epoch 00196 | Loss(train) 1.9359 | Acc(train) 0.5633 | Acc(val) 0.5926 |*
Epoch 00197 | Loss(train) 1.9355 | Acc(train) 0.5527 | Acc(val) 0.5920 |
Epoch 00198 | Loss(train) 1.9428 | Acc(train) 0.5548 | Acc(val) 0.5926 |
Epoch 00199 | Loss(train) 1.9531 | Acc(train) 0.5564 | Acc(val) 0.5915 |
Epoch 00200 | Loss(train) 1.9331 | Acc(train) 0.5622 | Acc(val) 0.5904 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2485 | Acc(train) 0.0138 | Acc(val) 0.1851 |*
Epoch 00002 | Loss(train) 4.2223 | Acc(train) 0.1407 | Acc(val) 0.2261 |*
Epoch 00003 | Loss(train) 4.1839 | Acc(train) 0.1665 | Acc(val) 0.2170 |
Epoch 00004 | Loss(train) 4.1384 | Acc(train) 0.1614 | Acc(val) 0.2128 |
Epoch 00005 | Loss(train) 4.0868 | Acc(train) 0.1545 | Acc(val) 0.2053 |
Epoch 00006 | Loss(train) 4.0243 | Acc(train) 0.1551 | Acc(val) 0.1952 |
Epoch 00007 | Loss(train) 3.9679 | Acc(train) 0.1521 | Acc(val) 0.1872 |
Epoch 00008 | Loss(train) 3.9166 | Acc(train) 0.1402 | Acc(val) 0.1809 |
Epoch 00009 | Loss(train) 3.8755 | Acc(train) 0.1383 | Acc(val) 0.1787 |
Epoch 00010 | Loss(train) 3.8348 | Acc(train) 0.1457 | Acc(val) 0.1809 |
Epoch 00011 | Loss(train) 3.7883 | Acc(train) 0.1481 | Acc(val) 0.1809 |
Epoch 00012 | Loss(train) 3.7623 | Acc(train) 0.1484 | Acc(val) 0.1883 |
Epoch 00013 | Loss(train) 3.7208 | Acc(train) 0.1649 | Acc(val) 0.1915 |
Epoch 00014 | Loss(train) 3.6811 | Acc(train) 0.1678 | Acc(val) 0.1941 |
Epoch 00015 | Loss(train) 3.6413 | Acc(train) 0.1755 | Acc(val) 0.2032 |
Epoch 00016 | Loss(train) 3.5928 | Acc(train) 0.1907 | Acc(val) 0.2117 |
Epoch 00017 | Loss(train) 3.5658 | Acc(train) 0.1918 | Acc(val) 0.2266 |*
Epoch 00018 | Loss(train) 3.5278 | Acc(train) 0.2061 | Acc(val) 0.2293 |*
Epoch 00019 | Loss(train) 3.4818 | Acc(train) 0.2098 | Acc(val) 0.2324 |*
Epoch 00020 | Loss(train) 3.4384 | Acc(train) 0.2191 | Acc(val) 0.2362 |*
Epoch 00021 | Loss(train) 3.4008 | Acc(train) 0.2170 | Acc(val) 0.2399 |*
Epoch 00022 | Loss(train) 3.3621 | Acc(train) 0.2223 | Acc(val) 0.2484 |*
Epoch 00023 | Loss(train) 3.3140 | Acc(train) 0.2295 | Acc(val) 0.2622 |*
Epoch 00024 | Loss(train) 3.2672 | Acc(train) 0.2356 | Acc(val) 0.2777 |*
Epoch 00025 | Loss(train) 3.2312 | Acc(train) 0.2566 | Acc(val) 0.2963 |*
Epoch 00026 | Loss(train) 3.1864 | Acc(train) 0.2593 | Acc(val) 0.3160 |*
Epoch 00027 | Loss(train) 3.1487 | Acc(train) 0.2840 | Acc(val) 0.3372 |*
Epoch 00028 | Loss(train) 3.1058 | Acc(train) 0.2947 | Acc(val) 0.3495 |*
Epoch 00029 | Loss(train) 3.0627 | Acc(train) 0.3019 | Acc(val) 0.3622 |*
Epoch 00030 | Loss(train) 3.0340 | Acc(train) 0.3165 | Acc(val) 0.3723 |*
Epoch 00031 | Loss(train) 2.9935 | Acc(train) 0.3194 | Acc(val) 0.3814 |*
Epoch 00032 | Loss(train) 2.9431 | Acc(train) 0.3410 | Acc(val) 0.3867 |*
Epoch 00033 | Loss(train) 2.9286 | Acc(train) 0.3484 | Acc(val) 0.3936 |*
Epoch 00034 | Loss(train) 2.8833 | Acc(train) 0.3505 | Acc(val) 0.4000 |*
Epoch 00035 | Loss(train) 2.8644 | Acc(train) 0.3676 | Acc(val) 0.4085 |*
Epoch 00036 | Loss(train) 2.8208 | Acc(train) 0.3729 | Acc(val) 0.4186 |*
Epoch 00037 | Loss(train) 2.7906 | Acc(train) 0.3816 | Acc(val) 0.4271 |*
Epoch 00038 | Loss(train) 2.7499 | Acc(train) 0.3976 | Acc(val) 0.4330 |*
Epoch 00039 | Loss(train) 2.7301 | Acc(train) 0.3952 | Acc(val) 0.4356 |*
Epoch 00040 | Loss(train) 2.7075 | Acc(train) 0.3965 | Acc(val) 0.4436 |*
Epoch 00041 | Loss(train) 2.6715 | Acc(train) 0.4011 | Acc(val) 0.4463 |*
Epoch 00042 | Loss(train) 2.6505 | Acc(train) 0.4059 | Acc(val) 0.4521 |*
Epoch 00043 | Loss(train) 2.6173 | Acc(train) 0.4242 | Acc(val) 0.4569 |*
Epoch 00044 | Loss(train) 2.5978 | Acc(train) 0.4274 | Acc(val) 0.4596 |*
Epoch 00045 | Loss(train) 2.5873 | Acc(train) 0.4218 | Acc(val) 0.4638 |*
Epoch 00046 | Loss(train) 2.5421 | Acc(train) 0.4189 | Acc(val) 0.4702 |*
Epoch 00047 | Loss(train) 2.5211 | Acc(train) 0.4348 | Acc(val) 0.4734 |*
Epoch 00048 | Loss(train) 2.5171 | Acc(train) 0.4370 | Acc(val) 0.4798 |*
Epoch 00049 | Loss(train) 2.4950 | Acc(train) 0.4415 | Acc(val) 0.4862 |*
Epoch 00050 | Loss(train) 2.4701 | Acc(train) 0.4439 | Acc(val) 0.4904 |*
Epoch 00051 | Loss(train) 2.4566 | Acc(train) 0.4426 | Acc(val) 0.4888 |
Epoch 00052 | Loss(train) 2.4343 | Acc(train) 0.4625 | Acc(val) 0.4910 |*
Epoch 00053 | Loss(train) 2.4157 | Acc(train) 0.4559 | Acc(val) 0.4941 |*
Epoch 00054 | Loss(train) 2.3967 | Acc(train) 0.4519 | Acc(val) 0.4979 |*
Epoch 00055 | Loss(train) 2.3880 | Acc(train) 0.4614 | Acc(val) 0.4995 |*
Epoch 00056 | Loss(train) 2.3729 | Acc(train) 0.4566 | Acc(val) 0.4995 |
Epoch 00057 | Loss(train) 2.3426 | Acc(train) 0.4612 | Acc(val) 0.5027 |*
Epoch 00058 | Loss(train) 2.3358 | Acc(train) 0.4686 | Acc(val) 0.5085 |*
Epoch 00059 | Loss(train) 2.3164 | Acc(train) 0.4628 | Acc(val) 0.5133 |*
Epoch 00060 | Loss(train) 2.2999 | Acc(train) 0.4859 | Acc(val) 0.5218 |*
Epoch 00061 | Loss(train) 2.3048 | Acc(train) 0.4745 | Acc(val) 0.5239 |*
Epoch 00062 | Loss(train) 2.2715 | Acc(train) 0.4832 | Acc(val) 0.5255 |*
Epoch 00063 | Loss(train) 2.2743 | Acc(train) 0.4747 | Acc(val) 0.5293 |*
Epoch 00064 | Loss(train) 2.2371 | Acc(train) 0.4870 | Acc(val) 0.5298 |*
Epoch 00065 | Loss(train) 2.2542 | Acc(train) 0.4854 | Acc(val) 0.5340 |*
Epoch 00066 | Loss(train) 2.2268 | Acc(train) 0.4931 | Acc(val) 0.5319 |
Epoch 00067 | Loss(train) 2.2289 | Acc(train) 0.4915 | Acc(val) 0.5303 |
Epoch 00068 | Loss(train) 2.2236 | Acc(train) 0.4854 | Acc(val) 0.5314 |
Epoch 00069 | Loss(train) 2.2113 | Acc(train) 0.4952 | Acc(val) 0.5346 |*
Epoch 00070 | Loss(train) 2.2231 | Acc(train) 0.4867 | Acc(val) 0.5372 |*
Epoch 00071 | Loss(train) 2.1947 | Acc(train) 0.5013 | Acc(val) 0.5452 |*
Epoch 00072 | Loss(train) 2.1953 | Acc(train) 0.5027 | Acc(val) 0.5489 |*
Epoch 00073 | Loss(train) 2.1863 | Acc(train) 0.4968 | Acc(val) 0.5457 |
Epoch 00074 | Loss(train) 2.1828 | Acc(train) 0.4952 | Acc(val) 0.5457 |
Epoch 00075 | Loss(train) 2.1645 | Acc(train) 0.5045 | Acc(val) 0.5457 |
Epoch 00076 | Loss(train) 2.1567 | Acc(train) 0.5077 | Acc(val) 0.5447 |
Epoch 00077 | Loss(train) 2.1465 | Acc(train) 0.5064 | Acc(val) 0.5457 |
Epoch 00078 | Loss(train) 2.1534 | Acc(train) 0.5053 | Acc(val) 0.5463 |
Epoch 00079 | Loss(train) 2.1477 | Acc(train) 0.4987 | Acc(val) 0.5484 |
Epoch 00080 | Loss(train) 2.1448 | Acc(train) 0.5085 | Acc(val) 0.5511 |*
Epoch 00081 | Loss(train) 2.1213 | Acc(train) 0.5149 | Acc(val) 0.5537 |*
Epoch 00082 | Loss(train) 2.1362 | Acc(train) 0.5024 | Acc(val) 0.5532 |
Epoch 00083 | Loss(train) 2.1260 | Acc(train) 0.5064 | Acc(val) 0.5532 |
Epoch 00084 | Loss(train) 2.1273 | Acc(train) 0.5090 | Acc(val) 0.5548 |*
Epoch 00085 | Loss(train) 2.1172 | Acc(train) 0.5197 | Acc(val) 0.5527 |
Epoch 00086 | Loss(train) 2.1016 | Acc(train) 0.5162 | Acc(val) 0.5548 |
Epoch 00087 | Loss(train) 2.1070 | Acc(train) 0.5149 | Acc(val) 0.5553 |*
Epoch 00088 | Loss(train) 2.1065 | Acc(train) 0.5293 | Acc(val) 0.5548 |
Epoch 00089 | Loss(train) 2.1085 | Acc(train) 0.5130 | Acc(val) 0.5564 |*
Epoch 00090 | Loss(train) 2.0921 | Acc(train) 0.5207 | Acc(val) 0.5559 |
Epoch 00091 | Loss(train) 2.0822 | Acc(train) 0.5229 | Acc(val) 0.5569 |*
Epoch 00092 | Loss(train) 2.0811 | Acc(train) 0.5146 | Acc(val) 0.5585 |*
Epoch 00093 | Loss(train) 2.0857 | Acc(train) 0.5184 | Acc(val) 0.5617 |*
Epoch 00094 | Loss(train) 2.0565 | Acc(train) 0.5282 | Acc(val) 0.5644 |*
Epoch 00095 | Loss(train) 2.0644 | Acc(train) 0.5215 | Acc(val) 0.5649 |*
Epoch 00096 | Loss(train) 2.0634 | Acc(train) 0.5239 | Acc(val) 0.5644 |
Epoch 00097 | Loss(train) 2.0693 | Acc(train) 0.5250 | Acc(val) 0.5633 |
Epoch 00098 | Loss(train) 2.0659 | Acc(train) 0.5194 | Acc(val) 0.5590 |
Epoch 00099 | Loss(train) 2.0359 | Acc(train) 0.5335 | Acc(val) 0.5638 |
Epoch 00100 | Loss(train) 2.0601 | Acc(train) 0.5202 | Acc(val) 0.5638 |
Epoch 00101 | Loss(train) 2.0491 | Acc(train) 0.5245 | Acc(val) 0.5676 |*
Epoch 00102 | Loss(train) 2.0519 | Acc(train) 0.5250 | Acc(val) 0.5718 |*
Epoch 00103 | Loss(train) 2.0556 | Acc(train) 0.5205 | Acc(val) 0.5729 |*
Epoch 00104 | Loss(train) 2.0429 | Acc(train) 0.5396 | Acc(val) 0.5729 |
Epoch 00105 | Loss(train) 2.0461 | Acc(train) 0.5277 | Acc(val) 0.5723 |
Epoch 00106 | Loss(train) 2.0492 | Acc(train) 0.5322 | Acc(val) 0.5702 |
Epoch 00107 | Loss(train) 2.0463 | Acc(train) 0.5247 | Acc(val) 0.5697 |
Epoch 00108 | Loss(train) 2.0154 | Acc(train) 0.5359 | Acc(val) 0.5697 |
Epoch 00109 | Loss(train) 2.0155 | Acc(train) 0.5404 | Acc(val) 0.5707 |
Epoch 00110 | Loss(train) 2.0218 | Acc(train) 0.5255 | Acc(val) 0.5718 |
Epoch 00111 | Loss(train) 2.0230 | Acc(train) 0.5330 | Acc(val) 0.5723 |
Epoch 00112 | Loss(train) 2.0261 | Acc(train) 0.5343 | Acc(val) 0.5729 |
Epoch 00113 | Loss(train) 2.0098 | Acc(train) 0.5354 | Acc(val) 0.5734 |*
Epoch 00114 | Loss(train) 2.0178 | Acc(train) 0.5343 | Acc(val) 0.5761 |*
Epoch 00115 | Loss(train) 2.0198 | Acc(train) 0.5441 | Acc(val) 0.5761 |
Epoch 00116 | Loss(train) 2.0286 | Acc(train) 0.5410 | Acc(val) 0.5787 |*
Epoch 00117 | Loss(train) 2.0026 | Acc(train) 0.5332 | Acc(val) 0.5755 |
Epoch 00118 | Loss(train) 2.0082 | Acc(train) 0.5290 | Acc(val) 0.5723 |
Epoch 00119 | Loss(train) 2.0093 | Acc(train) 0.5386 | Acc(val) 0.5718 |
Epoch 00120 | Loss(train) 2.0142 | Acc(train) 0.5383 | Acc(val) 0.5697 |
Epoch 00121 | Loss(train) 2.0147 | Acc(train) 0.5343 | Acc(val) 0.5739 |
Epoch 00122 | Loss(train) 2.0133 | Acc(train) 0.5282 | Acc(val) 0.5782 |
Epoch 00123 | Loss(train) 2.0019 | Acc(train) 0.5330 | Acc(val) 0.5798 |*
Epoch 00124 | Loss(train) 2.0172 | Acc(train) 0.5420 | Acc(val) 0.5798 |
Epoch 00125 | Loss(train) 1.9781 | Acc(train) 0.5516 | Acc(val) 0.5787 |
Epoch 00126 | Loss(train) 2.0043 | Acc(train) 0.5439 | Acc(val) 0.5771 |
Epoch 00127 | Loss(train) 1.9932 | Acc(train) 0.5407 | Acc(val) 0.5803 |*
Epoch 00128 | Loss(train) 1.9853 | Acc(train) 0.5303 | Acc(val) 0.5798 |
Epoch 00129 | Loss(train) 2.0084 | Acc(train) 0.5535 | Acc(val) 0.5803 |
Epoch 00130 | Loss(train) 1.9723 | Acc(train) 0.5436 | Acc(val) 0.5809 |*
Epoch 00131 | Loss(train) 1.9927 | Acc(train) 0.5404 | Acc(val) 0.5787 |
Epoch 00132 | Loss(train) 1.9717 | Acc(train) 0.5527 | Acc(val) 0.5798 |
Epoch 00133 | Loss(train) 1.9737 | Acc(train) 0.5455 | Acc(val) 0.5787 |
Epoch 00134 | Loss(train) 1.9816 | Acc(train) 0.5386 | Acc(val) 0.5793 |
Epoch 00135 | Loss(train) 1.9963 | Acc(train) 0.5364 | Acc(val) 0.5819 |*
Epoch 00136 | Loss(train) 1.9832 | Acc(train) 0.5343 | Acc(val) 0.5824 |*
Epoch 00137 | Loss(train) 1.9865 | Acc(train) 0.5436 | Acc(val) 0.5830 |*
Epoch 00138 | Loss(train) 2.0014 | Acc(train) 0.5449 | Acc(val) 0.5824 |
Epoch 00139 | Loss(train) 1.9690 | Acc(train) 0.5513 | Acc(val) 0.5814 |
Epoch 00140 | Loss(train) 1.9908 | Acc(train) 0.5380 | Acc(val) 0.5766 |
Epoch 00141 | Loss(train) 1.9862 | Acc(train) 0.5505 | Acc(val) 0.5755 |
Epoch 00142 | Loss(train) 1.9759 | Acc(train) 0.5505 | Acc(val) 0.5750 |
Epoch 00143 | Loss(train) 1.9692 | Acc(train) 0.5561 | Acc(val) 0.5782 |
Epoch 00144 | Loss(train) 1.9592 | Acc(train) 0.5521 | Acc(val) 0.5814 |
Epoch 00145 | Loss(train) 1.9852 | Acc(train) 0.5444 | Acc(val) 0.5819 |
Epoch 00146 | Loss(train) 1.9716 | Acc(train) 0.5460 | Acc(val) 0.5835 |*
Epoch 00147 | Loss(train) 1.9712 | Acc(train) 0.5495 | Acc(val) 0.5814 |
Epoch 00148 | Loss(train) 1.9711 | Acc(train) 0.5431 | Acc(val) 0.5793 |
Epoch 00149 | Loss(train) 1.9719 | Acc(train) 0.5473 | Acc(val) 0.5787 |
Epoch 00150 | Loss(train) 1.9860 | Acc(train) 0.5444 | Acc(val) 0.5766 |
Epoch 00151 | Loss(train) 1.9745 | Acc(train) 0.5465 | Acc(val) 0.5771 |
Epoch 00152 | Loss(train) 1.9740 | Acc(train) 0.5524 | Acc(val) 0.5782 |
Epoch 00153 | Loss(train) 1.9619 | Acc(train) 0.5481 | Acc(val) 0.5761 |
Epoch 00154 | Loss(train) 1.9388 | Acc(train) 0.5566 | Acc(val) 0.5745 |
Epoch 00155 | Loss(train) 1.9685 | Acc(train) 0.5500 | Acc(val) 0.5734 |
Epoch 00156 | Loss(train) 1.9712 | Acc(train) 0.5404 | Acc(val) 0.5766 |
Epoch 00157 | Loss(train) 1.9833 | Acc(train) 0.5364 | Acc(val) 0.5798 |
Epoch 00158 | Loss(train) 1.9693 | Acc(train) 0.5495 | Acc(val) 0.5782 |
Epoch 00159 | Loss(train) 1.9775 | Acc(train) 0.5449 | Acc(val) 0.5782 |
Epoch 00160 | Loss(train) 1.9554 | Acc(train) 0.5532 | Acc(val) 0.5793 |
Epoch 00161 | Loss(train) 1.9454 | Acc(train) 0.5561 | Acc(val) 0.5793 |
Epoch 00162 | Loss(train) 1.9635 | Acc(train) 0.5447 | Acc(val) 0.5798 |
Epoch 00163 | Loss(train) 1.9660 | Acc(train) 0.5487 | Acc(val) 0.5793 |
Epoch 00164 | Loss(train) 1.9653 | Acc(train) 0.5457 | Acc(val) 0.5803 |
Epoch 00165 | Loss(train) 1.9552 | Acc(train) 0.5553 | Acc(val) 0.5830 |
Epoch 00166 | Loss(train) 1.9683 | Acc(train) 0.5444 | Acc(val) 0.5846 |*
Epoch 00167 | Loss(train) 1.9496 | Acc(train) 0.5593 | Acc(val) 0.5851 |*
Epoch 00168 | Loss(train) 1.9468 | Acc(train) 0.5606 | Acc(val) 0.5840 |
Epoch 00169 | Loss(train) 1.9713 | Acc(train) 0.5489 | Acc(val) 0.5771 |
Epoch 00170 | Loss(train) 1.9508 | Acc(train) 0.5609 | Acc(val) 0.5793 |
Epoch 00171 | Loss(train) 1.9527 | Acc(train) 0.5601 | Acc(val) 0.5782 |
Epoch 00172 | Loss(train) 1.9487 | Acc(train) 0.5497 | Acc(val) 0.5777 |
Epoch 00173 | Loss(train) 1.9405 | Acc(train) 0.5590 | Acc(val) 0.5819 |
Epoch 00174 | Loss(train) 1.9637 | Acc(train) 0.5519 | Acc(val) 0.5819 |
Epoch 00175 | Loss(train) 1.9479 | Acc(train) 0.5481 | Acc(val) 0.5809 |
Epoch 00176 | Loss(train) 1.9582 | Acc(train) 0.5585 | Acc(val) 0.5782 |
Epoch 00177 | Loss(train) 1.9592 | Acc(train) 0.5495 | Acc(val) 0.5766 |
Epoch 00178 | Loss(train) 1.9164 | Acc(train) 0.5596 | Acc(val) 0.5777 |
Epoch 00179 | Loss(train) 1.9334 | Acc(train) 0.5580 | Acc(val) 0.5777 |
Epoch 00180 | Loss(train) 1.9594 | Acc(train) 0.5516 | Acc(val) 0.5782 |
Epoch 00181 | Loss(train) 1.9520 | Acc(train) 0.5436 | Acc(val) 0.5809 |
Epoch 00182 | Loss(train) 1.9643 | Acc(train) 0.5529 | Acc(val) 0.5819 |
Epoch 00183 | Loss(train) 1.9617 | Acc(train) 0.5543 | Acc(val) 0.5830 |
Epoch 00184 | Loss(train) 1.9645 | Acc(train) 0.5524 | Acc(val) 0.5851 |
Epoch 00185 | Loss(train) 1.9496 | Acc(train) 0.5564 | Acc(val) 0.5835 |
Epoch 00186 | Loss(train) 1.9426 | Acc(train) 0.5574 | Acc(val) 0.5793 |
Epoch 00187 | Loss(train) 1.9499 | Acc(train) 0.5460 | Acc(val) 0.5766 |
Epoch 00188 | Loss(train) 1.9764 | Acc(train) 0.5489 | Acc(val) 0.5782 |
Epoch 00189 | Loss(train) 1.9311 | Acc(train) 0.5665 | Acc(val) 0.5803 |
Epoch 00190 | Loss(train) 1.9202 | Acc(train) 0.5641 | Acc(val) 0.5814 |
Epoch 00191 | Loss(train) 1.9467 | Acc(train) 0.5527 | Acc(val) 0.5867 |*
Epoch 00192 | Loss(train) 1.9208 | Acc(train) 0.5628 | Acc(val) 0.5867 |
Epoch 00193 | Loss(train) 1.9532 | Acc(train) 0.5508 | Acc(val) 0.5878 |*
Epoch 00194 | Loss(train) 1.9418 | Acc(train) 0.5468 | Acc(val) 0.5846 |
Epoch 00195 | Loss(train) 1.9397 | Acc(train) 0.5527 | Acc(val) 0.5819 |
Epoch 00196 | Loss(train) 1.9297 | Acc(train) 0.5527 | Acc(val) 0.5819 |
Epoch 00197 | Loss(train) 1.9408 | Acc(train) 0.5545 | Acc(val) 0.5840 |
Epoch 00198 | Loss(train) 1.9303 | Acc(train) 0.5601 | Acc(val) 0.5856 |
Epoch 00199 | Loss(train) 1.9403 | Acc(train) 0.5580 | Acc(val) 0.5862 |
Epoch 00200 | Loss(train) 1.9492 | Acc(train) 0.5614 | Acc(val) 0.5899 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2486 | Acc(train) 0.0176 | Acc(val) 0.0718 |*
Epoch 00002 | Loss(train) 4.2200 | Acc(train) 0.0944 | Acc(val) 0.1250 |*
Epoch 00003 | Loss(train) 4.1807 | Acc(train) 0.1181 | Acc(val) 0.1053 |
Epoch 00004 | Loss(train) 4.1347 | Acc(train) 0.1215 | Acc(val) 0.0957 |
Epoch 00005 | Loss(train) 4.0851 | Acc(train) 0.1253 | Acc(val) 0.0973 |
Epoch 00006 | Loss(train) 4.0303 | Acc(train) 0.1149 | Acc(val) 0.0995 |
Epoch 00007 | Loss(train) 3.9774 | Acc(train) 0.1226 | Acc(val) 0.1122 |
Epoch 00008 | Loss(train) 3.9283 | Acc(train) 0.1173 | Acc(val) 0.1298 |*
Epoch 00009 | Loss(train) 3.8829 | Acc(train) 0.1199 | Acc(val) 0.1548 |*
Epoch 00010 | Loss(train) 3.8453 | Acc(train) 0.1301 | Acc(val) 0.1697 |*
Epoch 00011 | Loss(train) 3.8069 | Acc(train) 0.1356 | Acc(val) 0.1777 |*
Epoch 00012 | Loss(train) 3.7779 | Acc(train) 0.1394 | Acc(val) 0.1734 |
Epoch 00013 | Loss(train) 3.7447 | Acc(train) 0.1508 | Acc(val) 0.1803 |*
Epoch 00014 | Loss(train) 3.7093 | Acc(train) 0.1548 | Acc(val) 0.1824 |*
Epoch 00015 | Loss(train) 3.6685 | Acc(train) 0.1676 | Acc(val) 0.1862 |*
Epoch 00016 | Loss(train) 3.6333 | Acc(train) 0.1702 | Acc(val) 0.1931 |*
Epoch 00017 | Loss(train) 3.5877 | Acc(train) 0.1859 | Acc(val) 0.2043 |*
Epoch 00018 | Loss(train) 3.5599 | Acc(train) 0.1957 | Acc(val) 0.2090 |*
Epoch 00019 | Loss(train) 3.5201 | Acc(train) 0.2035 | Acc(val) 0.2207 |*
Epoch 00020 | Loss(train) 3.4769 | Acc(train) 0.2117 | Acc(val) 0.2303 |*
Epoch 00021 | Loss(train) 3.4352 | Acc(train) 0.2136 | Acc(val) 0.2404 |*
Epoch 00022 | Loss(train) 3.3988 | Acc(train) 0.2237 | Acc(val) 0.2505 |*
Epoch 00023 | Loss(train) 3.3458 | Acc(train) 0.2303 | Acc(val) 0.2707 |*
Epoch 00024 | Loss(train) 3.3144 | Acc(train) 0.2362 | Acc(val) 0.2819 |*
Epoch 00025 | Loss(train) 3.2774 | Acc(train) 0.2455 | Acc(val) 0.2920 |*
Epoch 00026 | Loss(train) 3.2263 | Acc(train) 0.2612 | Acc(val) 0.3069 |*
Epoch 00027 | Loss(train) 3.1950 | Acc(train) 0.2702 | Acc(val) 0.3229 |*
Epoch 00028 | Loss(train) 3.1493 | Acc(train) 0.2824 | Acc(val) 0.3340 |*
Epoch 00029 | Loss(train) 3.1227 | Acc(train) 0.3027 | Acc(val) 0.3479 |*
Epoch 00030 | Loss(train) 3.0731 | Acc(train) 0.3117 | Acc(val) 0.3612 |*
Epoch 00031 | Loss(train) 3.0484 | Acc(train) 0.3247 | Acc(val) 0.3697 |*
Epoch 00032 | Loss(train) 3.0107 | Acc(train) 0.3346 | Acc(val) 0.3814 |*
Epoch 00033 | Loss(train) 2.9712 | Acc(train) 0.3359 | Acc(val) 0.3894 |*
Epoch 00034 | Loss(train) 2.9458 | Acc(train) 0.3364 | Acc(val) 0.3968 |*
Epoch 00035 | Loss(train) 2.9006 | Acc(train) 0.3418 | Acc(val) 0.4027 |*
Epoch 00036 | Loss(train) 2.8694 | Acc(train) 0.3537 | Acc(val) 0.4133 |*
Epoch 00037 | Loss(train) 2.8398 | Acc(train) 0.3713 | Acc(val) 0.4223 |*
Epoch 00038 | Loss(train) 2.8294 | Acc(train) 0.3662 | Acc(val) 0.4309 |*
Epoch 00039 | Loss(train) 2.7803 | Acc(train) 0.3840 | Acc(val) 0.4346 |*
Epoch 00040 | Loss(train) 2.7369 | Acc(train) 0.3854 | Acc(val) 0.4404 |*
Epoch 00041 | Loss(train) 2.7263 | Acc(train) 0.3899 | Acc(val) 0.4452 |*
Epoch 00042 | Loss(train) 2.7038 | Acc(train) 0.4053 | Acc(val) 0.4511 |*
Epoch 00043 | Loss(train) 2.6651 | Acc(train) 0.4011 | Acc(val) 0.4532 |*
Epoch 00044 | Loss(train) 2.6294 | Acc(train) 0.4082 | Acc(val) 0.4564 |*
Epoch 00045 | Loss(train) 2.6191 | Acc(train) 0.4066 | Acc(val) 0.4622 |*
Epoch 00046 | Loss(train) 2.5973 | Acc(train) 0.4186 | Acc(val) 0.4676 |*
Epoch 00047 | Loss(train) 2.5824 | Acc(train) 0.4160 | Acc(val) 0.4723 |*
Epoch 00048 | Loss(train) 2.5486 | Acc(train) 0.4314 | Acc(val) 0.4766 |*
Epoch 00049 | Loss(train) 2.5429 | Acc(train) 0.4205 | Acc(val) 0.4809 |*
Epoch 00050 | Loss(train) 2.5006 | Acc(train) 0.4335 | Acc(val) 0.4851 |*
Epoch 00051 | Loss(train) 2.4915 | Acc(train) 0.4404 | Acc(val) 0.4867 |*
Epoch 00052 | Loss(train) 2.4599 | Acc(train) 0.4402 | Acc(val) 0.4915 |*
Epoch 00053 | Loss(train) 2.4567 | Acc(train) 0.4386 | Acc(val) 0.4973 |*
Epoch 00054 | Loss(train) 2.4400 | Acc(train) 0.4495 | Acc(val) 0.4984 |*
Epoch 00055 | Loss(train) 2.4041 | Acc(train) 0.4628 | Acc(val) 0.5021 |*
Epoch 00056 | Loss(train) 2.3944 | Acc(train) 0.4574 | Acc(val) 0.5069 |*
Epoch 00057 | Loss(train) 2.3890 | Acc(train) 0.4569 | Acc(val) 0.5101 |*
Epoch 00058 | Loss(train) 2.3632 | Acc(train) 0.4652 | Acc(val) 0.5154 |*
Epoch 00059 | Loss(train) 2.3731 | Acc(train) 0.4535 | Acc(val) 0.5207 |*
Epoch 00060 | Loss(train) 2.3395 | Acc(train) 0.4601 | Acc(val) 0.5234 |*
Epoch 00061 | Loss(train) 2.3316 | Acc(train) 0.4641 | Acc(val) 0.5239 |*
Epoch 00062 | Loss(train) 2.3028 | Acc(train) 0.4771 | Acc(val) 0.5261 |*
Epoch 00063 | Loss(train) 2.2994 | Acc(train) 0.4766 | Acc(val) 0.5261 |
Epoch 00064 | Loss(train) 2.2984 | Acc(train) 0.4729 | Acc(val) 0.5261 |
Epoch 00065 | Loss(train) 2.2853 | Acc(train) 0.4787 | Acc(val) 0.5271 |*
Epoch 00066 | Loss(train) 2.2496 | Acc(train) 0.4904 | Acc(val) 0.5314 |*
Epoch 00067 | Loss(train) 2.2460 | Acc(train) 0.4830 | Acc(val) 0.5346 |*
Epoch 00068 | Loss(train) 2.2604 | Acc(train) 0.4766 | Acc(val) 0.5351 |*
Epoch 00069 | Loss(train) 2.2364 | Acc(train) 0.4848 | Acc(val) 0.5383 |*
Epoch 00070 | Loss(train) 2.2091 | Acc(train) 0.4896 | Acc(val) 0.5399 |*
Epoch 00071 | Loss(train) 2.2180 | Acc(train) 0.4880 | Acc(val) 0.5399 |
Epoch 00072 | Loss(train) 2.2100 | Acc(train) 0.4910 | Acc(val) 0.5404 |*
Epoch 00073 | Loss(train) 2.2088 | Acc(train) 0.4811 | Acc(val) 0.5420 |*
Epoch 00074 | Loss(train) 2.2056 | Acc(train) 0.4912 | Acc(val) 0.5468 |*
Epoch 00075 | Loss(train) 2.1730 | Acc(train) 0.5045 | Acc(val) 0.5468 |
Epoch 00076 | Loss(train) 2.1796 | Acc(train) 0.4941 | Acc(val) 0.5441 |
Epoch 00077 | Loss(train) 2.1678 | Acc(train) 0.4960 | Acc(val) 0.5447 |
Epoch 00078 | Loss(train) 2.1465 | Acc(train) 0.5045 | Acc(val) 0.5495 |*
Epoch 00079 | Loss(train) 2.1528 | Acc(train) 0.5077 | Acc(val) 0.5511 |*
Epoch 00080 | Loss(train) 2.1764 | Acc(train) 0.4949 | Acc(val) 0.5489 |
Epoch 00081 | Loss(train) 2.1528 | Acc(train) 0.5069 | Acc(val) 0.5527 |*
Epoch 00082 | Loss(train) 2.1426 | Acc(train) 0.5029 | Acc(val) 0.5543 |*
Epoch 00083 | Loss(train) 2.1279 | Acc(train) 0.5154 | Acc(val) 0.5553 |*
Epoch 00084 | Loss(train) 2.1519 | Acc(train) 0.5019 | Acc(val) 0.5537 |
Epoch 00085 | Loss(train) 2.1283 | Acc(train) 0.5048 | Acc(val) 0.5543 |
Epoch 00086 | Loss(train) 2.1112 | Acc(train) 0.5205 | Acc(val) 0.5585 |*
Epoch 00087 | Loss(train) 2.1195 | Acc(train) 0.5109 | Acc(val) 0.5612 |*
Epoch 00088 | Loss(train) 2.0984 | Acc(train) 0.5173 | Acc(val) 0.5590 |
Epoch 00089 | Loss(train) 2.0859 | Acc(train) 0.5184 | Acc(val) 0.5622 |*
Epoch 00090 | Loss(train) 2.0817 | Acc(train) 0.5282 | Acc(val) 0.5612 |
Epoch 00091 | Loss(train) 2.1049 | Acc(train) 0.5090 | Acc(val) 0.5596 |
Epoch 00092 | Loss(train) 2.0963 | Acc(train) 0.5170 | Acc(val) 0.5628 |*
Epoch 00093 | Loss(train) 2.0929 | Acc(train) 0.5090 | Acc(val) 0.5628 |
Epoch 00094 | Loss(train) 2.0855 | Acc(train) 0.5199 | Acc(val) 0.5633 |*
Epoch 00095 | Loss(train) 2.0855 | Acc(train) 0.5191 | Acc(val) 0.5622 |
Epoch 00096 | Loss(train) 2.0817 | Acc(train) 0.5250 | Acc(val) 0.5633 |
Epoch 00097 | Loss(train) 2.0828 | Acc(train) 0.5093 | Acc(val) 0.5660 |*
Epoch 00098 | Loss(train) 2.0508 | Acc(train) 0.5338 | Acc(val) 0.5649 |
Epoch 00099 | Loss(train) 2.0732 | Acc(train) 0.5269 | Acc(val) 0.5681 |*
Epoch 00100 | Loss(train) 2.0741 | Acc(train) 0.5197 | Acc(val) 0.5654 |
Epoch 00101 | Loss(train) 2.0625 | Acc(train) 0.5197 | Acc(val) 0.5676 |
Epoch 00102 | Loss(train) 2.0562 | Acc(train) 0.5250 | Acc(val) 0.5686 |*
Epoch 00103 | Loss(train) 2.0564 | Acc(train) 0.5343 | Acc(val) 0.5665 |
Epoch 00104 | Loss(train) 2.0688 | Acc(train) 0.5207 | Acc(val) 0.5633 |
Epoch 00105 | Loss(train) 2.0543 | Acc(train) 0.5173 | Acc(val) 0.5644 |
Epoch 00106 | Loss(train) 2.0527 | Acc(train) 0.5231 | Acc(val) 0.5681 |
Epoch 00107 | Loss(train) 2.0484 | Acc(train) 0.5253 | Acc(val) 0.5660 |
Epoch 00108 | Loss(train) 2.0288 | Acc(train) 0.5306 | Acc(val) 0.5676 |
Epoch 00109 | Loss(train) 2.0538 | Acc(train) 0.5301 | Acc(val) 0.5681 |
Epoch 00110 | Loss(train) 2.0280 | Acc(train) 0.5388 | Acc(val) 0.5676 |
Epoch 00111 | Loss(train) 2.0435 | Acc(train) 0.5330 | Acc(val) 0.5681 |
Epoch 00112 | Loss(train) 2.0318 | Acc(train) 0.5271 | Acc(val) 0.5670 |
Epoch 00113 | Loss(train) 2.0187 | Acc(train) 0.5295 | Acc(val) 0.5676 |
Epoch 00114 | Loss(train) 2.0248 | Acc(train) 0.5319 | Acc(val) 0.5707 |*
Epoch 00115 | Loss(train) 2.0184 | Acc(train) 0.5364 | Acc(val) 0.5739 |*
Epoch 00116 | Loss(train) 2.0319 | Acc(train) 0.5388 | Acc(val) 0.5755 |*
Epoch 00117 | Loss(train) 2.0151 | Acc(train) 0.5314 | Acc(val) 0.5766 |*
Epoch 00118 | Loss(train) 2.0194 | Acc(train) 0.5367 | Acc(val) 0.5734 |
Epoch 00119 | Loss(train) 2.0101 | Acc(train) 0.5338 | Acc(val) 0.5723 |
Epoch 00120 | Loss(train) 2.0048 | Acc(train) 0.5436 | Acc(val) 0.5691 |
Epoch 00121 | Loss(train) 2.0159 | Acc(train) 0.5348 | Acc(val) 0.5713 |
Epoch 00122 | Loss(train) 2.0061 | Acc(train) 0.5404 | Acc(val) 0.5734 |
Epoch 00123 | Loss(train) 2.0149 | Acc(train) 0.5327 | Acc(val) 0.5766 |
Epoch 00124 | Loss(train) 2.0013 | Acc(train) 0.5420 | Acc(val) 0.5782 |*
Epoch 00125 | Loss(train) 2.0100 | Acc(train) 0.5394 | Acc(val) 0.5787 |*
Epoch 00126 | Loss(train) 2.0198 | Acc(train) 0.5359 | Acc(val) 0.5809 |*
Epoch 00127 | Loss(train) 2.0121 | Acc(train) 0.5436 | Acc(val) 0.5803 |
Epoch 00128 | Loss(train) 2.0169 | Acc(train) 0.5492 | Acc(val) 0.5809 |
Epoch 00129 | Loss(train) 2.0066 | Acc(train) 0.5418 | Acc(val) 0.5750 |
Epoch 00130 | Loss(train) 1.9856 | Acc(train) 0.5383 | Acc(val) 0.5734 |
Epoch 00131 | Loss(train) 2.0032 | Acc(train) 0.5434 | Acc(val) 0.5755 |
Epoch 00132 | Loss(train) 1.9958 | Acc(train) 0.5452 | Acc(val) 0.5771 |
Epoch 00133 | Loss(train) 2.0056 | Acc(train) 0.5436 | Acc(val) 0.5771 |
Epoch 00134 | Loss(train) 1.9893 | Acc(train) 0.5441 | Acc(val) 0.5729 |
Epoch 00135 | Loss(train) 1.9923 | Acc(train) 0.5465 | Acc(val) 0.5739 |
Epoch 00136 | Loss(train) 1.9698 | Acc(train) 0.5551 | Acc(val) 0.5755 |
Epoch 00137 | Loss(train) 1.9883 | Acc(train) 0.5316 | Acc(val) 0.5766 |
Epoch 00138 | Loss(train) 1.9934 | Acc(train) 0.5351 | Acc(val) 0.5766 |
Epoch 00139 | Loss(train) 2.0040 | Acc(train) 0.5487 | Acc(val) 0.5771 |
Epoch 00140 | Loss(train) 1.9826 | Acc(train) 0.5455 | Acc(val) 0.5782 |
Epoch 00141 | Loss(train) 1.9801 | Acc(train) 0.5476 | Acc(val) 0.5777 |
Epoch 00142 | Loss(train) 2.0131 | Acc(train) 0.5359 | Acc(val) 0.5755 |
Epoch 00143 | Loss(train) 1.9859 | Acc(train) 0.5439 | Acc(val) 0.5766 |
Epoch 00144 | Loss(train) 1.9854 | Acc(train) 0.5481 | Acc(val) 0.5787 |
Epoch 00145 | Loss(train) 1.9841 | Acc(train) 0.5346 | Acc(val) 0.5771 |
Epoch 00146 | Loss(train) 1.9905 | Acc(train) 0.5428 | Acc(val) 0.5809 |
Epoch 00147 | Loss(train) 1.9670 | Acc(train) 0.5532 | Acc(val) 0.5809 |
Epoch 00148 | Loss(train) 1.9595 | Acc(train) 0.5468 | Acc(val) 0.5809 |
Epoch 00149 | Loss(train) 1.9861 | Acc(train) 0.5439 | Acc(val) 0.5777 |
Epoch 00150 | Loss(train) 1.9659 | Acc(train) 0.5431 | Acc(val) 0.5766 |
Epoch 00151 | Loss(train) 1.9795 | Acc(train) 0.5420 | Acc(val) 0.5777 |
Epoch 00152 | Loss(train) 1.9853 | Acc(train) 0.5391 | Acc(val) 0.5798 |
Epoch 00153 | Loss(train) 1.9863 | Acc(train) 0.5468 | Acc(val) 0.5766 |
Epoch 00154 | Loss(train) 1.9701 | Acc(train) 0.5543 | Acc(val) 0.5803 |
Epoch 00155 | Loss(train) 1.9883 | Acc(train) 0.5471 | Acc(val) 0.5814 |*
Epoch 00156 | Loss(train) 1.9765 | Acc(train) 0.5420 | Acc(val) 0.5819 |*
Epoch 00157 | Loss(train) 1.9526 | Acc(train) 0.5511 | Acc(val) 0.5819 |
Epoch 00158 | Loss(train) 1.9722 | Acc(train) 0.5468 | Acc(val) 0.5809 |
Epoch 00159 | Loss(train) 1.9668 | Acc(train) 0.5407 | Acc(val) 0.5809 |
Epoch 00160 | Loss(train) 1.9727 | Acc(train) 0.5420 | Acc(val) 0.5824 |*
Epoch 00161 | Loss(train) 1.9801 | Acc(train) 0.5420 | Acc(val) 0.5830 |*
Epoch 00162 | Loss(train) 1.9572 | Acc(train) 0.5516 | Acc(val) 0.5814 |
Epoch 00163 | Loss(train) 1.9587 | Acc(train) 0.5553 | Acc(val) 0.5819 |
Epoch 00164 | Loss(train) 1.9562 | Acc(train) 0.5521 | Acc(val) 0.5824 |
Epoch 00165 | Loss(train) 1.9544 | Acc(train) 0.5606 | Acc(val) 0.5814 |
Epoch 00166 | Loss(train) 1.9504 | Acc(train) 0.5543 | Acc(val) 0.5814 |
Epoch 00167 | Loss(train) 1.9726 | Acc(train) 0.5412 | Acc(val) 0.5809 |
Epoch 00168 | Loss(train) 1.9706 | Acc(train) 0.5436 | Acc(val) 0.5803 |
Epoch 00169 | Loss(train) 1.9594 | Acc(train) 0.5524 | Acc(val) 0.5809 |
Epoch 00170 | Loss(train) 1.9653 | Acc(train) 0.5487 | Acc(val) 0.5835 |*
Epoch 00171 | Loss(train) 1.9832 | Acc(train) 0.5460 | Acc(val) 0.5824 |
Epoch 00172 | Loss(train) 1.9554 | Acc(train) 0.5508 | Acc(val) 0.5814 |
Epoch 00173 | Loss(train) 1.9524 | Acc(train) 0.5481 | Acc(val) 0.5814 |
Epoch 00174 | Loss(train) 1.9606 | Acc(train) 0.5484 | Acc(val) 0.5819 |
Epoch 00175 | Loss(train) 1.9425 | Acc(train) 0.5481 | Acc(val) 0.5824 |
Epoch 00176 | Loss(train) 1.9614 | Acc(train) 0.5561 | Acc(val) 0.5798 |
Epoch 00177 | Loss(train) 1.9598 | Acc(train) 0.5463 | Acc(val) 0.5819 |
Epoch 00178 | Loss(train) 1.9635 | Acc(train) 0.5500 | Acc(val) 0.5824 |
Epoch 00179 | Loss(train) 1.9532 | Acc(train) 0.5540 | Acc(val) 0.5824 |
Epoch 00180 | Loss(train) 1.9530 | Acc(train) 0.5521 | Acc(val) 0.5803 |
Epoch 00181 | Loss(train) 1.9503 | Acc(train) 0.5535 | Acc(val) 0.5793 |
Epoch 00182 | Loss(train) 1.9349 | Acc(train) 0.5564 | Acc(val) 0.5814 |
Epoch 00183 | Loss(train) 1.9617 | Acc(train) 0.5492 | Acc(val) 0.5809 |
Epoch 00184 | Loss(train) 1.9514 | Acc(train) 0.5566 | Acc(val) 0.5824 |
Epoch 00185 | Loss(train) 1.9692 | Acc(train) 0.5383 | Acc(val) 0.5851 |*
Epoch 00186 | Loss(train) 1.9425 | Acc(train) 0.5545 | Acc(val) 0.5862 |*
Epoch 00187 | Loss(train) 1.9597 | Acc(train) 0.5476 | Acc(val) 0.5867 |*
Epoch 00188 | Loss(train) 1.9562 | Acc(train) 0.5614 | Acc(val) 0.5830 |
Epoch 00189 | Loss(train) 1.9498 | Acc(train) 0.5577 | Acc(val) 0.5809 |
Epoch 00190 | Loss(train) 1.9764 | Acc(train) 0.5463 | Acc(val) 0.5819 |
Epoch 00191 | Loss(train) 1.9515 | Acc(train) 0.5500 | Acc(val) 0.5819 |
Epoch 00192 | Loss(train) 1.9577 | Acc(train) 0.5561 | Acc(val) 0.5846 |
Epoch 00193 | Loss(train) 1.9389 | Acc(train) 0.5500 | Acc(val) 0.5867 |
Epoch 00194 | Loss(train) 1.9667 | Acc(train) 0.5577 | Acc(val) 0.5867 |
Epoch 00195 | Loss(train) 1.9518 | Acc(train) 0.5505 | Acc(val) 0.5824 |
Epoch 00196 | Loss(train) 1.9550 | Acc(train) 0.5492 | Acc(val) 0.5835 |
Epoch 00197 | Loss(train) 1.9516 | Acc(train) 0.5582 | Acc(val) 0.5819 |
Epoch 00198 | Loss(train) 1.9612 | Acc(train) 0.5593 | Acc(val) 0.5787 |
Epoch 00199 | Loss(train) 1.9464 | Acc(train) 0.5516 | Acc(val) 0.5830 |
Epoch 00200 | Loss(train) 1.9382 | Acc(train) 0.5548 | Acc(val) 0.5862 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2487 | Acc(train) 0.0104 | Acc(val) 0.1920 |*
Epoch 00002 | Loss(train) 4.2221 | Acc(train) 0.1144 | Acc(val) 0.2372 |*
Epoch 00003 | Loss(train) 4.1853 | Acc(train) 0.1564 | Acc(val) 0.2266 |
Epoch 00004 | Loss(train) 4.1416 | Acc(train) 0.1612 | Acc(val) 0.2096 |
Epoch 00005 | Loss(train) 4.0897 | Acc(train) 0.1524 | Acc(val) 0.2005 |
Epoch 00006 | Loss(train) 4.0404 | Acc(train) 0.1484 | Acc(val) 0.2011 |
Epoch 00007 | Loss(train) 3.9855 | Acc(train) 0.1436 | Acc(val) 0.1989 |
Epoch 00008 | Loss(train) 3.9335 | Acc(train) 0.1436 | Acc(val) 0.1979 |
Epoch 00009 | Loss(train) 3.8766 | Acc(train) 0.1431 | Acc(val) 0.1963 |
Epoch 00010 | Loss(train) 3.8485 | Acc(train) 0.1441 | Acc(val) 0.1984 |
Epoch 00011 | Loss(train) 3.8023 | Acc(train) 0.1527 | Acc(val) 0.1989 |
Epoch 00012 | Loss(train) 3.7700 | Acc(train) 0.1492 | Acc(val) 0.1995 |
Epoch 00013 | Loss(train) 3.7426 | Acc(train) 0.1590 | Acc(val) 0.2000 |
Epoch 00014 | Loss(train) 3.6956 | Acc(train) 0.1660 | Acc(val) 0.2048 |
Epoch 00015 | Loss(train) 3.6730 | Acc(train) 0.1641 | Acc(val) 0.2117 |
Epoch 00016 | Loss(train) 3.6234 | Acc(train) 0.1769 | Acc(val) 0.2266 |
Epoch 00017 | Loss(train) 3.5887 | Acc(train) 0.1854 | Acc(val) 0.2378 |*
Epoch 00018 | Loss(train) 3.5450 | Acc(train) 0.2037 | Acc(val) 0.2484 |*
Epoch 00019 | Loss(train) 3.5062 | Acc(train) 0.2149 | Acc(val) 0.2601 |*
Epoch 00020 | Loss(train) 3.4709 | Acc(train) 0.2261 | Acc(val) 0.2665 |*
Epoch 00021 | Loss(train) 3.4338 | Acc(train) 0.2250 | Acc(val) 0.2702 |*
Epoch 00022 | Loss(train) 3.3941 | Acc(train) 0.2255 | Acc(val) 0.2745 |*
Epoch 00023 | Loss(train) 3.3537 | Acc(train) 0.2330 | Acc(val) 0.2782 |*
Epoch 00024 | Loss(train) 3.3103 | Acc(train) 0.2410 | Acc(val) 0.2904 |*
Epoch 00025 | Loss(train) 3.2700 | Acc(train) 0.2524 | Acc(val) 0.3037 |*
Epoch 00026 | Loss(train) 3.2313 | Acc(train) 0.2556 | Acc(val) 0.3090 |*
Epoch 00027 | Loss(train) 3.1928 | Acc(train) 0.2705 | Acc(val) 0.3223 |*
Epoch 00028 | Loss(train) 3.1612 | Acc(train) 0.2838 | Acc(val) 0.3324 |*
Epoch 00029 | Loss(train) 3.1115 | Acc(train) 0.2957 | Acc(val) 0.3479 |*
Epoch 00030 | Loss(train) 3.0801 | Acc(train) 0.3117 | Acc(val) 0.3612 |*
Epoch 00031 | Loss(train) 3.0558 | Acc(train) 0.3128 | Acc(val) 0.3718 |*
Epoch 00032 | Loss(train) 3.0135 | Acc(train) 0.3144 | Acc(val) 0.3809 |*
Epoch 00033 | Loss(train) 2.9619 | Acc(train) 0.3465 | Acc(val) 0.3941 |*
Epoch 00034 | Loss(train) 2.9339 | Acc(train) 0.3497 | Acc(val) 0.4059 |*
Epoch 00035 | Loss(train) 2.9042 | Acc(train) 0.3495 | Acc(val) 0.4117 |*
Epoch 00036 | Loss(train) 2.8645 | Acc(train) 0.3636 | Acc(val) 0.4186 |*
Epoch 00037 | Loss(train) 2.8316 | Acc(train) 0.3705 | Acc(val) 0.4245 |*
Epoch 00038 | Loss(train) 2.8230 | Acc(train) 0.3689 | Acc(val) 0.4298 |*
Epoch 00039 | Loss(train) 2.7755 | Acc(train) 0.3795 | Acc(val) 0.4404 |*
Epoch 00040 | Loss(train) 2.7419 | Acc(train) 0.3840 | Acc(val) 0.4484 |*
Epoch 00041 | Loss(train) 2.7075 | Acc(train) 0.3992 | Acc(val) 0.4585 |*
Epoch 00042 | Loss(train) 2.6830 | Acc(train) 0.3941 | Acc(val) 0.4638 |*
Epoch 00043 | Loss(train) 2.6586 | Acc(train) 0.4011 | Acc(val) 0.4670 |*
Epoch 00044 | Loss(train) 2.6338 | Acc(train) 0.4093 | Acc(val) 0.4723 |*
Epoch 00045 | Loss(train) 2.6028 | Acc(train) 0.4138 | Acc(val) 0.4755 |*
Epoch 00046 | Loss(train) 2.5746 | Acc(train) 0.4178 | Acc(val) 0.4793 |*
Epoch 00047 | Loss(train) 2.5418 | Acc(train) 0.4242 | Acc(val) 0.4830 |*
Epoch 00048 | Loss(train) 2.5302 | Acc(train) 0.4226 | Acc(val) 0.4878 |*
Epoch 00049 | Loss(train) 2.5085 | Acc(train) 0.4441 | Acc(val) 0.4910 |*
Epoch 00050 | Loss(train) 2.4882 | Acc(train) 0.4255 | Acc(val) 0.4936 |*
Epoch 00051 | Loss(train) 2.4760 | Acc(train) 0.4415 | Acc(val) 0.4995 |*
Epoch 00052 | Loss(train) 2.4533 | Acc(train) 0.4423 | Acc(val) 0.5011 |*
Epoch 00053 | Loss(train) 2.4286 | Acc(train) 0.4524 | Acc(val) 0.5043 |*
Epoch 00054 | Loss(train) 2.4246 | Acc(train) 0.4487 | Acc(val) 0.5101 |*
Epoch 00055 | Loss(train) 2.4051 | Acc(train) 0.4551 | Acc(val) 0.5133 |*
Epoch 00056 | Loss(train) 2.3729 | Acc(train) 0.4524 | Acc(val) 0.5170 |*
Epoch 00057 | Loss(train) 2.3738 | Acc(train) 0.4580 | Acc(val) 0.5181 |*
Epoch 00058 | Loss(train) 2.3634 | Acc(train) 0.4593 | Acc(val) 0.5181 |
Epoch 00059 | Loss(train) 2.3574 | Acc(train) 0.4580 | Acc(val) 0.5213 |*
Epoch 00060 | Loss(train) 2.3316 | Acc(train) 0.4660 | Acc(val) 0.5229 |*
Epoch 00061 | Loss(train) 2.3162 | Acc(train) 0.4771 | Acc(val) 0.5287 |*
Epoch 00062 | Loss(train) 2.3166 | Acc(train) 0.4731 | Acc(val) 0.5293 |*
Epoch 00063 | Loss(train) 2.2949 | Acc(train) 0.4702 | Acc(val) 0.5298 |*
Epoch 00064 | Loss(train) 2.2746 | Acc(train) 0.4790 | Acc(val) 0.5314 |*
Epoch 00065 | Loss(train) 2.2736 | Acc(train) 0.4673 | Acc(val) 0.5362 |*
Epoch 00066 | Loss(train) 2.2735 | Acc(train) 0.4731 | Acc(val) 0.5404 |*
Epoch 00067 | Loss(train) 2.2479 | Acc(train) 0.4830 | Acc(val) 0.5399 |
Epoch 00068 | Loss(train) 2.2560 | Acc(train) 0.4851 | Acc(val) 0.5431 |*
Epoch 00069 | Loss(train) 2.2364 | Acc(train) 0.4859 | Acc(val) 0.5441 |*
Epoch 00070 | Loss(train) 2.2211 | Acc(train) 0.4856 | Acc(val) 0.5452 |*
Epoch 00071 | Loss(train) 2.2320 | Acc(train) 0.4872 | Acc(val) 0.5463 |*
Epoch 00072 | Loss(train) 2.2187 | Acc(train) 0.4875 | Acc(val) 0.5447 |
Epoch 00073 | Loss(train) 2.2017 | Acc(train) 0.4981 | Acc(val) 0.5436 |
Epoch 00074 | Loss(train) 2.1986 | Acc(train) 0.4891 | Acc(val) 0.5431 |
Epoch 00075 | Loss(train) 2.1943 | Acc(train) 0.4944 | Acc(val) 0.5447 |
Epoch 00076 | Loss(train) 2.1844 | Acc(train) 0.4944 | Acc(val) 0.5468 |*
Epoch 00077 | Loss(train) 2.1563 | Acc(train) 0.4992 | Acc(val) 0.5484 |*
Epoch 00078 | Loss(train) 2.1632 | Acc(train) 0.5098 | Acc(val) 0.5521 |*
Epoch 00079 | Loss(train) 2.1607 | Acc(train) 0.5045 | Acc(val) 0.5543 |*
Epoch 00080 | Loss(train) 2.1615 | Acc(train) 0.5043 | Acc(val) 0.5553 |*
Epoch 00081 | Loss(train) 2.1551 | Acc(train) 0.5059 | Acc(val) 0.5553 |
Epoch 00082 | Loss(train) 2.1486 | Acc(train) 0.4973 | Acc(val) 0.5553 |
Epoch 00083 | Loss(train) 2.1405 | Acc(train) 0.4949 | Acc(val) 0.5553 |
Epoch 00084 | Loss(train) 2.1382 | Acc(train) 0.5016 | Acc(val) 0.5553 |
Epoch 00085 | Loss(train) 2.1341 | Acc(train) 0.5106 | Acc(val) 0.5564 |*
Epoch 00086 | Loss(train) 2.1235 | Acc(train) 0.5146 | Acc(val) 0.5590 |*
Epoch 00087 | Loss(train) 2.1217 | Acc(train) 0.5109 | Acc(val) 0.5574 |
Epoch 00088 | Loss(train) 2.1188 | Acc(train) 0.5162 | Acc(val) 0.5569 |
Epoch 00089 | Loss(train) 2.0994 | Acc(train) 0.5013 | Acc(val) 0.5628 |*
Epoch 00090 | Loss(train) 2.1041 | Acc(train) 0.5117 | Acc(val) 0.5660 |*
Epoch 00091 | Loss(train) 2.1143 | Acc(train) 0.5029 | Acc(val) 0.5649 |
Epoch 00092 | Loss(train) 2.1164 | Acc(train) 0.5149 | Acc(val) 0.5649 |
Epoch 00093 | Loss(train) 2.0986 | Acc(train) 0.5069 | Acc(val) 0.5633 |
Epoch 00094 | Loss(train) 2.1000 | Acc(train) 0.5085 | Acc(val) 0.5628 |
Epoch 00095 | Loss(train) 2.0986 | Acc(train) 0.5173 | Acc(val) 0.5628 |
Epoch 00096 | Loss(train) 2.0710 | Acc(train) 0.5215 | Acc(val) 0.5633 |
Epoch 00097 | Loss(train) 2.0848 | Acc(train) 0.5189 | Acc(val) 0.5654 |
Epoch 00098 | Loss(train) 2.0869 | Acc(train) 0.5215 | Acc(val) 0.5670 |*
Epoch 00099 | Loss(train) 2.1008 | Acc(train) 0.5141 | Acc(val) 0.5665 |
Epoch 00100 | Loss(train) 2.0745 | Acc(train) 0.5146 | Acc(val) 0.5665 |
Epoch 00101 | Loss(train) 2.0623 | Acc(train) 0.5189 | Acc(val) 0.5665 |
Epoch 00102 | Loss(train) 2.0620 | Acc(train) 0.5234 | Acc(val) 0.5654 |
Epoch 00103 | Loss(train) 2.0614 | Acc(train) 0.5255 | Acc(val) 0.5654 |
Epoch 00104 | Loss(train) 2.0388 | Acc(train) 0.5314 | Acc(val) 0.5686 |*
Epoch 00105 | Loss(train) 2.0808 | Acc(train) 0.5197 | Acc(val) 0.5681 |
Epoch 00106 | Loss(train) 2.0662 | Acc(train) 0.5234 | Acc(val) 0.5702 |*
Epoch 00107 | Loss(train) 2.0552 | Acc(train) 0.5316 | Acc(val) 0.5676 |
Epoch 00108 | Loss(train) 2.0568 | Acc(train) 0.5186 | Acc(val) 0.5691 |
Epoch 00109 | Loss(train) 2.0386 | Acc(train) 0.5378 | Acc(val) 0.5686 |
Epoch 00110 | Loss(train) 2.0572 | Acc(train) 0.5162 | Acc(val) 0.5723 |*
Epoch 00111 | Loss(train) 2.0659 | Acc(train) 0.5287 | Acc(val) 0.5761 |*
Epoch 00112 | Loss(train) 2.0587 | Acc(train) 0.5290 | Acc(val) 0.5755 |
Epoch 00113 | Loss(train) 2.0523 | Acc(train) 0.5237 | Acc(val) 0.5771 |*
Epoch 00114 | Loss(train) 2.0407 | Acc(train) 0.5279 | Acc(val) 0.5766 |
Epoch 00115 | Loss(train) 2.0262 | Acc(train) 0.5370 | Acc(val) 0.5755 |
Epoch 00116 | Loss(train) 2.0113 | Acc(train) 0.5391 | Acc(val) 0.5723 |
Epoch 00117 | Loss(train) 2.0304 | Acc(train) 0.5269 | Acc(val) 0.5707 |
Epoch 00118 | Loss(train) 2.0328 | Acc(train) 0.5298 | Acc(val) 0.5739 |
Epoch 00119 | Loss(train) 2.0247 | Acc(train) 0.5287 | Acc(val) 0.5777 |*
Epoch 00120 | Loss(train) 2.0348 | Acc(train) 0.5348 | Acc(val) 0.5793 |*
Epoch 00121 | Loss(train) 2.0315 | Acc(train) 0.5277 | Acc(val) 0.5787 |
Epoch 00122 | Loss(train) 2.0162 | Acc(train) 0.5346 | Acc(val) 0.5793 |
Epoch 00123 | Loss(train) 2.0202 | Acc(train) 0.5359 | Acc(val) 0.5787 |
Epoch 00124 | Loss(train) 2.0340 | Acc(train) 0.5322 | Acc(val) 0.5761 |
Epoch 00125 | Loss(train) 2.0195 | Acc(train) 0.5346 | Acc(val) 0.5766 |
Epoch 00126 | Loss(train) 2.0188 | Acc(train) 0.5346 | Acc(val) 0.5761 |
Epoch 00127 | Loss(train) 2.0200 | Acc(train) 0.5290 | Acc(val) 0.5777 |
Epoch 00128 | Loss(train) 2.0312 | Acc(train) 0.5354 | Acc(val) 0.5809 |*
Epoch 00129 | Loss(train) 2.0256 | Acc(train) 0.5298 | Acc(val) 0.5793 |
Epoch 00130 | Loss(train) 2.0166 | Acc(train) 0.5314 | Acc(val) 0.5814 |*
Epoch 00131 | Loss(train) 2.0037 | Acc(train) 0.5324 | Acc(val) 0.5793 |
Epoch 00132 | Loss(train) 2.0172 | Acc(train) 0.5311 | Acc(val) 0.5803 |
Epoch 00133 | Loss(train) 2.0196 | Acc(train) 0.5316 | Acc(val) 0.5803 |
Epoch 00134 | Loss(train) 2.0302 | Acc(train) 0.5303 | Acc(val) 0.5782 |
Epoch 00135 | Loss(train) 2.0015 | Acc(train) 0.5428 | Acc(val) 0.5809 |
Epoch 00136 | Loss(train) 2.0170 | Acc(train) 0.5372 | Acc(val) 0.5809 |
Epoch 00137 | Loss(train) 2.0232 | Acc(train) 0.5410 | Acc(val) 0.5803 |
Epoch 00138 | Loss(train) 1.9954 | Acc(train) 0.5396 | Acc(val) 0.5782 |
Epoch 00139 | Loss(train) 2.0060 | Acc(train) 0.5404 | Acc(val) 0.5771 |
Epoch 00140 | Loss(train) 2.0052 | Acc(train) 0.5335 | Acc(val) 0.5771 |
Epoch 00141 | Loss(train) 2.0125 | Acc(train) 0.5316 | Acc(val) 0.5798 |
Epoch 00142 | Loss(train) 2.0095 | Acc(train) 0.5311 | Acc(val) 0.5793 |
Epoch 00143 | Loss(train) 1.9930 | Acc(train) 0.5372 | Acc(val) 0.5787 |
Epoch 00144 | Loss(train) 1.9928 | Acc(train) 0.5418 | Acc(val) 0.5777 |
Epoch 00145 | Loss(train) 1.9950 | Acc(train) 0.5436 | Acc(val) 0.5793 |
Epoch 00146 | Loss(train) 2.0021 | Acc(train) 0.5346 | Acc(val) 0.5777 |
Epoch 00147 | Loss(train) 1.9853 | Acc(train) 0.5505 | Acc(val) 0.5766 |
Epoch 00148 | Loss(train) 1.9992 | Acc(train) 0.5370 | Acc(val) 0.5777 |
Epoch 00149 | Loss(train) 1.9886 | Acc(train) 0.5423 | Acc(val) 0.5739 |
Epoch 00150 | Loss(train) 1.9692 | Acc(train) 0.5479 | Acc(val) 0.5761 |
Epoch 00151 | Loss(train) 1.9929 | Acc(train) 0.5428 | Acc(val) 0.5777 |
Epoch 00152 | Loss(train) 1.9729 | Acc(train) 0.5428 | Acc(val) 0.5771 |
Epoch 00153 | Loss(train) 1.9733 | Acc(train) 0.5436 | Acc(val) 0.5809 |
Epoch 00154 | Loss(train) 1.9785 | Acc(train) 0.5449 | Acc(val) 0.5809 |
Epoch 00155 | Loss(train) 1.9830 | Acc(train) 0.5457 | Acc(val) 0.5777 |
Epoch 00156 | Loss(train) 1.9918 | Acc(train) 0.5473 | Acc(val) 0.5793 |
Epoch 00157 | Loss(train) 1.9813 | Acc(train) 0.5380 | Acc(val) 0.5782 |
Epoch 00158 | Loss(train) 1.9942 | Acc(train) 0.5431 | Acc(val) 0.5771 |
Epoch 00159 | Loss(train) 1.9952 | Acc(train) 0.5375 | Acc(val) 0.5814 |
Epoch 00160 | Loss(train) 1.9745 | Acc(train) 0.5434 | Acc(val) 0.5830 |*
Epoch 00161 | Loss(train) 1.9806 | Acc(train) 0.5436 | Acc(val) 0.5840 |*
Epoch 00162 | Loss(train) 1.9828 | Acc(train) 0.5436 | Acc(val) 0.5851 |*
Epoch 00163 | Loss(train) 1.9816 | Acc(train) 0.5428 | Acc(val) 0.5862 |*
Epoch 00164 | Loss(train) 1.9779 | Acc(train) 0.5423 | Acc(val) 0.5872 |*
Epoch 00165 | Loss(train) 1.9763 | Acc(train) 0.5378 | Acc(val) 0.5867 |
Epoch 00166 | Loss(train) 1.9901 | Acc(train) 0.5394 | Acc(val) 0.5840 |
Epoch 00167 | Loss(train) 1.9728 | Acc(train) 0.5370 | Acc(val) 0.5824 |
Epoch 00168 | Loss(train) 1.9572 | Acc(train) 0.5561 | Acc(val) 0.5830 |
Epoch 00169 | Loss(train) 1.9746 | Acc(train) 0.5418 | Acc(val) 0.5824 |
Epoch 00170 | Loss(train) 1.9886 | Acc(train) 0.5441 | Acc(val) 0.5851 |
Epoch 00171 | Loss(train) 1.9591 | Acc(train) 0.5378 | Acc(val) 0.5840 |
Epoch 00172 | Loss(train) 1.9700 | Acc(train) 0.5463 | Acc(val) 0.5830 |
Epoch 00173 | Loss(train) 1.9826 | Acc(train) 0.5372 | Acc(val) 0.5824 |
Epoch 00174 | Loss(train) 1.9609 | Acc(train) 0.5535 | Acc(val) 0.5856 |
Epoch 00175 | Loss(train) 1.9763 | Acc(train) 0.5420 | Acc(val) 0.5856 |
Epoch 00176 | Loss(train) 1.9595 | Acc(train) 0.5452 | Acc(val) 0.5846 |
Epoch 00177 | Loss(train) 1.9890 | Acc(train) 0.5426 | Acc(val) 0.5851 |
Epoch 00178 | Loss(train) 1.9885 | Acc(train) 0.5388 | Acc(val) 0.5856 |
Epoch 00179 | Loss(train) 1.9703 | Acc(train) 0.5431 | Acc(val) 0.5851 |
Epoch 00180 | Loss(train) 1.9727 | Acc(train) 0.5577 | Acc(val) 0.5824 |
Epoch 00181 | Loss(train) 1.9803 | Acc(train) 0.5439 | Acc(val) 0.5814 |
Epoch 00182 | Loss(train) 1.9594 | Acc(train) 0.5511 | Acc(val) 0.5819 |
Epoch 00183 | Loss(train) 1.9698 | Acc(train) 0.5487 | Acc(val) 0.5819 |
Epoch 00184 | Loss(train) 1.9512 | Acc(train) 0.5604 | Acc(val) 0.5830 |
Epoch 00185 | Loss(train) 1.9864 | Acc(train) 0.5508 | Acc(val) 0.5840 |
Epoch 00186 | Loss(train) 1.9792 | Acc(train) 0.5449 | Acc(val) 0.5846 |
Epoch 00187 | Loss(train) 1.9550 | Acc(train) 0.5431 | Acc(val) 0.5851 |
Epoch 00188 | Loss(train) 1.9702 | Acc(train) 0.5402 | Acc(val) 0.5840 |
Epoch 00189 | Loss(train) 1.9733 | Acc(train) 0.5500 | Acc(val) 0.5824 |
Epoch 00190 | Loss(train) 1.9553 | Acc(train) 0.5545 | Acc(val) 0.5840 |
Epoch 00191 | Loss(train) 1.9479 | Acc(train) 0.5593 | Acc(val) 0.5814 |
Epoch 00192 | Loss(train) 1.9666 | Acc(train) 0.5551 | Acc(val) 0.5830 |
Epoch 00193 | Loss(train) 1.9775 | Acc(train) 0.5468 | Acc(val) 0.5809 |
Epoch 00194 | Loss(train) 1.9682 | Acc(train) 0.5410 | Acc(val) 0.5819 |
Epoch 00195 | Loss(train) 1.9721 | Acc(train) 0.5420 | Acc(val) 0.5835 |
Epoch 00196 | Loss(train) 1.9658 | Acc(train) 0.5415 | Acc(val) 0.5846 |
Epoch 00197 | Loss(train) 1.9458 | Acc(train) 0.5489 | Acc(val) 0.5851 |
Epoch 00198 | Loss(train) 1.9561 | Acc(train) 0.5532 | Acc(val) 0.5888 |*
Epoch 00199 | Loss(train) 1.9611 | Acc(train) 0.5452 | Acc(val) 0.5888 |
Epoch 00200 | Loss(train) 1.9809 | Acc(train) 0.5476 | Acc(val) 0.5851 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2485 | Acc(train) 0.0160 | Acc(val) 0.1755 |*
Epoch 00002 | Loss(train) 4.2221 | Acc(train) 0.1229 | Acc(val) 0.1745 |
Epoch 00003 | Loss(train) 4.1851 | Acc(train) 0.1375 | Acc(val) 0.1702 |
Epoch 00004 | Loss(train) 4.1427 | Acc(train) 0.1343 | Acc(val) 0.1670 |
Epoch 00005 | Loss(train) 4.0903 | Acc(train) 0.1410 | Acc(val) 0.1633 |
Epoch 00006 | Loss(train) 4.0352 | Acc(train) 0.1399 | Acc(val) 0.1527 |
Epoch 00007 | Loss(train) 3.9839 | Acc(train) 0.1202 | Acc(val) 0.1447 |
Epoch 00008 | Loss(train) 3.9278 | Acc(train) 0.1173 | Acc(val) 0.1388 |
Epoch 00009 | Loss(train) 3.8818 | Acc(train) 0.1141 | Acc(val) 0.1372 |
Epoch 00010 | Loss(train) 3.8451 | Acc(train) 0.1170 | Acc(val) 0.1372 |
Epoch 00011 | Loss(train) 3.8094 | Acc(train) 0.1173 | Acc(val) 0.1415 |
Epoch 00012 | Loss(train) 3.7725 | Acc(train) 0.1290 | Acc(val) 0.1484 |
Epoch 00013 | Loss(train) 3.7397 | Acc(train) 0.1362 | Acc(val) 0.1553 |
Epoch 00014 | Loss(train) 3.7044 | Acc(train) 0.1476 | Acc(val) 0.1707 |
Epoch 00015 | Loss(train) 3.6624 | Acc(train) 0.1662 | Acc(val) 0.1809 |*
Epoch 00016 | Loss(train) 3.6203 | Acc(train) 0.1713 | Acc(val) 0.1963 |*
Epoch 00017 | Loss(train) 3.5914 | Acc(train) 0.1854 | Acc(val) 0.2069 |*
Epoch 00018 | Loss(train) 3.5526 | Acc(train) 0.1968 | Acc(val) 0.2202 |*
Epoch 00019 | Loss(train) 3.5038 | Acc(train) 0.2117 | Acc(val) 0.2277 |*
Epoch 00020 | Loss(train) 3.4729 | Acc(train) 0.2056 | Acc(val) 0.2340 |*
Epoch 00021 | Loss(train) 3.4292 | Acc(train) 0.2176 | Acc(val) 0.2383 |*
Epoch 00022 | Loss(train) 3.3853 | Acc(train) 0.2237 | Acc(val) 0.2495 |*
Epoch 00023 | Loss(train) 3.3434 | Acc(train) 0.2354 | Acc(val) 0.2596 |*
Epoch 00024 | Loss(train) 3.2959 | Acc(train) 0.2380 | Acc(val) 0.2739 |*
Epoch 00025 | Loss(train) 3.2650 | Acc(train) 0.2484 | Acc(val) 0.2920 |*
Epoch 00026 | Loss(train) 3.2110 | Acc(train) 0.2686 | Acc(val) 0.3122 |*
Epoch 00027 | Loss(train) 3.1724 | Acc(train) 0.2809 | Acc(val) 0.3388 |*
Epoch 00028 | Loss(train) 3.1322 | Acc(train) 0.3064 | Acc(val) 0.3537 |*
Epoch 00029 | Loss(train) 3.0933 | Acc(train) 0.3162 | Acc(val) 0.3644 |*
Epoch 00030 | Loss(train) 3.0461 | Acc(train) 0.3340 | Acc(val) 0.3734 |*
Epoch 00031 | Loss(train) 3.0205 | Acc(train) 0.3340 | Acc(val) 0.3872 |*
Epoch 00032 | Loss(train) 2.9764 | Acc(train) 0.3423 | Acc(val) 0.3952 |*
Epoch 00033 | Loss(train) 2.9449 | Acc(train) 0.3439 | Acc(val) 0.4005 |*
Epoch 00034 | Loss(train) 2.8994 | Acc(train) 0.3556 | Acc(val) 0.4090 |*
Epoch 00035 | Loss(train) 2.8728 | Acc(train) 0.3641 | Acc(val) 0.4165 |*
Epoch 00036 | Loss(train) 2.8405 | Acc(train) 0.3753 | Acc(val) 0.4250 |*
Epoch 00037 | Loss(train) 2.8079 | Acc(train) 0.3753 | Acc(val) 0.4356 |*
Epoch 00038 | Loss(train) 2.7706 | Acc(train) 0.3880 | Acc(val) 0.4452 |*
Epoch 00039 | Loss(train) 2.7430 | Acc(train) 0.3944 | Acc(val) 0.4537 |*
Epoch 00040 | Loss(train) 2.7044 | Acc(train) 0.4053 | Acc(val) 0.4553 |*
Epoch 00041 | Loss(train) 2.6725 | Acc(train) 0.4104 | Acc(val) 0.4585 |*
Epoch 00042 | Loss(train) 2.6464 | Acc(train) 0.4178 | Acc(val) 0.4596 |*
Epoch 00043 | Loss(train) 2.6353 | Acc(train) 0.4096 | Acc(val) 0.4670 |*
Epoch 00044 | Loss(train) 2.5929 | Acc(train) 0.4210 | Acc(val) 0.4729 |*
Epoch 00045 | Loss(train) 2.5772 | Acc(train) 0.4295 | Acc(val) 0.4761 |*
Epoch 00046 | Loss(train) 2.5556 | Acc(train) 0.4245 | Acc(val) 0.4803 |*
Epoch 00047 | Loss(train) 2.5148 | Acc(train) 0.4324 | Acc(val) 0.4840 |*
Epoch 00048 | Loss(train) 2.5009 | Acc(train) 0.4399 | Acc(val) 0.4894 |*
Epoch 00049 | Loss(train) 2.4859 | Acc(train) 0.4434 | Acc(val) 0.4995 |*
Epoch 00050 | Loss(train) 2.4545 | Acc(train) 0.4511 | Acc(val) 0.5037 |*
Epoch 00051 | Loss(train) 2.4528 | Acc(train) 0.4521 | Acc(val) 0.5059 |*
Epoch 00052 | Loss(train) 2.4225 | Acc(train) 0.4564 | Acc(val) 0.5032 |
Epoch 00053 | Loss(train) 2.4213 | Acc(train) 0.4559 | Acc(val) 0.5069 |*
Epoch 00054 | Loss(train) 2.3888 | Acc(train) 0.4577 | Acc(val) 0.5080 |*
Epoch 00055 | Loss(train) 2.3646 | Acc(train) 0.4511 | Acc(val) 0.5106 |*
Epoch 00056 | Loss(train) 2.3666 | Acc(train) 0.4590 | Acc(val) 0.5138 |*
Epoch 00057 | Loss(train) 2.3551 | Acc(train) 0.4516 | Acc(val) 0.5202 |*
Epoch 00058 | Loss(train) 2.3272 | Acc(train) 0.4654 | Acc(val) 0.5245 |*
Epoch 00059 | Loss(train) 2.3264 | Acc(train) 0.4652 | Acc(val) 0.5239 |
Epoch 00060 | Loss(train) 2.3234 | Acc(train) 0.4620 | Acc(val) 0.5245 |
Epoch 00061 | Loss(train) 2.3048 | Acc(train) 0.4739 | Acc(val) 0.5229 |
Epoch 00062 | Loss(train) 2.2807 | Acc(train) 0.4715 | Acc(val) 0.5186 |
Epoch 00063 | Loss(train) 2.2599 | Acc(train) 0.4928 | Acc(val) 0.5229 |
Epoch 00064 | Loss(train) 2.2581 | Acc(train) 0.4726 | Acc(val) 0.5277 |*
Epoch 00065 | Loss(train) 2.2479 | Acc(train) 0.4793 | Acc(val) 0.5340 |*
Epoch 00066 | Loss(train) 2.2461 | Acc(train) 0.4896 | Acc(val) 0.5335 |
Epoch 00067 | Loss(train) 2.2308 | Acc(train) 0.4798 | Acc(val) 0.5346 |*
Epoch 00068 | Loss(train) 2.2248 | Acc(train) 0.4957 | Acc(val) 0.5330 |
Epoch 00069 | Loss(train) 2.2034 | Acc(train) 0.4888 | Acc(val) 0.5346 |
Epoch 00070 | Loss(train) 2.2294 | Acc(train) 0.4830 | Acc(val) 0.5394 |*
Epoch 00071 | Loss(train) 2.2060 | Acc(train) 0.4949 | Acc(val) 0.5415 |*
Epoch 00072 | Loss(train) 2.1875 | Acc(train) 0.4955 | Acc(val) 0.5431 |*
Epoch 00073 | Loss(train) 2.1822 | Acc(train) 0.4939 | Acc(val) 0.5426 |
Epoch 00074 | Loss(train) 2.1622 | Acc(train) 0.5024 | Acc(val) 0.5441 |*
Epoch 00075 | Loss(train) 2.1542 | Acc(train) 0.4976 | Acc(val) 0.5484 |*
Epoch 00076 | Loss(train) 2.1482 | Acc(train) 0.5040 | Acc(val) 0.5473 |
Epoch 00077 | Loss(train) 2.1318 | Acc(train) 0.5133 | Acc(val) 0.5505 |*
Epoch 00078 | Loss(train) 2.1472 | Acc(train) 0.5008 | Acc(val) 0.5484 |
Epoch 00079 | Loss(train) 2.1556 | Acc(train) 0.5005 | Acc(val) 0.5516 |*
Epoch 00080 | Loss(train) 2.1426 | Acc(train) 0.5080 | Acc(val) 0.5553 |*
Epoch 00081 | Loss(train) 2.1283 | Acc(train) 0.5051 | Acc(val) 0.5548 |
Epoch 00082 | Loss(train) 2.1281 | Acc(train) 0.5141 | Acc(val) 0.5548 |
Epoch 00083 | Loss(train) 2.1138 | Acc(train) 0.5125 | Acc(val) 0.5553 |
Epoch 00084 | Loss(train) 2.1060 | Acc(train) 0.5160 | Acc(val) 0.5590 |*
Epoch 00085 | Loss(train) 2.1014 | Acc(train) 0.5162 | Acc(val) 0.5580 |
Epoch 00086 | Loss(train) 2.0918 | Acc(train) 0.5170 | Acc(val) 0.5580 |
Epoch 00087 | Loss(train) 2.0944 | Acc(train) 0.5173 | Acc(val) 0.5590 |
Epoch 00088 | Loss(train) 2.0954 | Acc(train) 0.5191 | Acc(val) 0.5590 |
Epoch 00089 | Loss(train) 2.0777 | Acc(train) 0.5181 | Acc(val) 0.5606 |*
Epoch 00090 | Loss(train) 2.0724 | Acc(train) 0.5184 | Acc(val) 0.5633 |*
Epoch 00091 | Loss(train) 2.0817 | Acc(train) 0.5303 | Acc(val) 0.5649 |*
Epoch 00092 | Loss(train) 2.0898 | Acc(train) 0.5231 | Acc(val) 0.5622 |
Epoch 00093 | Loss(train) 2.0827 | Acc(train) 0.5128 | Acc(val) 0.5628 |
Epoch 00094 | Loss(train) 2.0573 | Acc(train) 0.5162 | Acc(val) 0.5628 |
Epoch 00095 | Loss(train) 2.0666 | Acc(train) 0.5082 | Acc(val) 0.5644 |
Epoch 00096 | Loss(train) 2.0434 | Acc(train) 0.5263 | Acc(val) 0.5654 |*
Epoch 00097 | Loss(train) 2.0473 | Acc(train) 0.5316 | Acc(val) 0.5686 |*
Epoch 00098 | Loss(train) 2.0432 | Acc(train) 0.5160 | Acc(val) 0.5702 |*
Epoch 00099 | Loss(train) 2.0595 | Acc(train) 0.5253 | Acc(val) 0.5718 |*
Epoch 00100 | Loss(train) 2.0641 | Acc(train) 0.5234 | Acc(val) 0.5681 |
Epoch 00101 | Loss(train) 2.0375 | Acc(train) 0.5330 | Acc(val) 0.5681 |
Epoch 00102 | Loss(train) 2.0558 | Acc(train) 0.5269 | Acc(val) 0.5665 |
Epoch 00103 | Loss(train) 2.0423 | Acc(train) 0.5343 | Acc(val) 0.5707 |
Epoch 00104 | Loss(train) 2.0300 | Acc(train) 0.5303 | Acc(val) 0.5729 |*
Epoch 00105 | Loss(train) 2.0339 | Acc(train) 0.5285 | Acc(val) 0.5755 |*
Epoch 00106 | Loss(train) 2.0149 | Acc(train) 0.5298 | Acc(val) 0.5723 |
Epoch 00107 | Loss(train) 2.0365 | Acc(train) 0.5322 | Acc(val) 0.5729 |
Epoch 00108 | Loss(train) 2.0437 | Acc(train) 0.5295 | Acc(val) 0.5702 |
Epoch 00109 | Loss(train) 2.0371 | Acc(train) 0.5335 | Acc(val) 0.5718 |
Epoch 00110 | Loss(train) 2.0290 | Acc(train) 0.5311 | Acc(val) 0.5734 |
Epoch 00111 | Loss(train) 2.0088 | Acc(train) 0.5343 | Acc(val) 0.5755 |
Epoch 00112 | Loss(train) 2.0227 | Acc(train) 0.5298 | Acc(val) 0.5739 |
Epoch 00113 | Loss(train) 2.0239 | Acc(train) 0.5338 | Acc(val) 0.5739 |
Epoch 00114 | Loss(train) 2.0190 | Acc(train) 0.5271 | Acc(val) 0.5707 |
Epoch 00115 | Loss(train) 2.0263 | Acc(train) 0.5359 | Acc(val) 0.5707 |
Epoch 00116 | Loss(train) 2.0019 | Acc(train) 0.5362 | Acc(val) 0.5707 |
Epoch 00117 | Loss(train) 2.0057 | Acc(train) 0.5372 | Acc(val) 0.5723 |
Epoch 00118 | Loss(train) 2.0125 | Acc(train) 0.5354 | Acc(val) 0.5713 |
Epoch 00119 | Loss(train) 2.0180 | Acc(train) 0.5322 | Acc(val) 0.5729 |
Epoch 00120 | Loss(train) 2.0158 | Acc(train) 0.5346 | Acc(val) 0.5750 |
Epoch 00121 | Loss(train) 1.9966 | Acc(train) 0.5452 | Acc(val) 0.5739 |
Epoch 00122 | Loss(train) 1.9862 | Acc(train) 0.5476 | Acc(val) 0.5718 |
Epoch 00123 | Loss(train) 1.9899 | Acc(train) 0.5372 | Acc(val) 0.5745 |
Epoch 00124 | Loss(train) 1.9650 | Acc(train) 0.5511 | Acc(val) 0.5755 |
Epoch 00125 | Loss(train) 2.0188 | Acc(train) 0.5351 | Acc(val) 0.5755 |
Epoch 00126 | Loss(train) 2.0076 | Acc(train) 0.5391 | Acc(val) 0.5766 |*
Epoch 00127 | Loss(train) 1.9903 | Acc(train) 0.5383 | Acc(val) 0.5771 |*
Epoch 00128 | Loss(train) 1.9908 | Acc(train) 0.5492 | Acc(val) 0.5782 |*
Epoch 00129 | Loss(train) 1.9720 | Acc(train) 0.5508 | Acc(val) 0.5803 |*
Epoch 00130 | Loss(train) 1.9837 | Acc(train) 0.5436 | Acc(val) 0.5819 |*
Epoch 00131 | Loss(train) 1.9778 | Acc(train) 0.5457 | Acc(val) 0.5803 |
Epoch 00132 | Loss(train) 1.9951 | Acc(train) 0.5391 | Acc(val) 0.5819 |
Epoch 00133 | Loss(train) 1.9968 | Acc(train) 0.5364 | Acc(val) 0.5824 |*
Epoch 00134 | Loss(train) 1.9839 | Acc(train) 0.5439 | Acc(val) 0.5819 |
Epoch 00135 | Loss(train) 1.9762 | Acc(train) 0.5404 | Acc(val) 0.5803 |
Epoch 00136 | Loss(train) 1.9888 | Acc(train) 0.5407 | Acc(val) 0.5814 |
Epoch 00137 | Loss(train) 1.9824 | Acc(train) 0.5441 | Acc(val) 0.5803 |
Epoch 00138 | Loss(train) 1.9758 | Acc(train) 0.5426 | Acc(val) 0.5814 |
Epoch 00139 | Loss(train) 1.9704 | Acc(train) 0.5473 | Acc(val) 0.5814 |
Epoch 00140 | Loss(train) 1.9760 | Acc(train) 0.5519 | Acc(val) 0.5809 |
Epoch 00141 | Loss(train) 1.9850 | Acc(train) 0.5386 | Acc(val) 0.5787 |
Epoch 00142 | Loss(train) 1.9739 | Acc(train) 0.5460 | Acc(val) 0.5782 |
Epoch 00143 | Loss(train) 1.9720 | Acc(train) 0.5441 | Acc(val) 0.5798 |
Epoch 00144 | Loss(train) 1.9659 | Acc(train) 0.5588 | Acc(val) 0.5803 |
Epoch 00145 | Loss(train) 1.9782 | Acc(train) 0.5457 | Acc(val) 0.5840 |*
Epoch 00146 | Loss(train) 1.9586 | Acc(train) 0.5495 | Acc(val) 0.5851 |*
Epoch 00147 | Loss(train) 1.9741 | Acc(train) 0.5476 | Acc(val) 0.5819 |
Epoch 00148 | Loss(train) 1.9689 | Acc(train) 0.5423 | Acc(val) 0.5809 |
Epoch 00149 | Loss(train) 1.9610 | Acc(train) 0.5497 | Acc(val) 0.5814 |
Epoch 00150 | Loss(train) 1.9798 | Acc(train) 0.5492 | Acc(val) 0.5793 |
Epoch 00151 | Loss(train) 1.9693 | Acc(train) 0.5391 | Acc(val) 0.5809 |
Epoch 00152 | Loss(train) 1.9569 | Acc(train) 0.5543 | Acc(val) 0.5819 |
Epoch 00153 | Loss(train) 1.9517 | Acc(train) 0.5559 | Acc(val) 0.5819 |
Epoch 00154 | Loss(train) 1.9734 | Acc(train) 0.5537 | Acc(val) 0.5824 |
Epoch 00155 | Loss(train) 1.9653 | Acc(train) 0.5471 | Acc(val) 0.5835 |
Epoch 00156 | Loss(train) 1.9637 | Acc(train) 0.5495 | Acc(val) 0.5840 |
Epoch 00157 | Loss(train) 1.9591 | Acc(train) 0.5439 | Acc(val) 0.5835 |
Epoch 00158 | Loss(train) 1.9744 | Acc(train) 0.5447 | Acc(val) 0.5835 |
Epoch 00159 | Loss(train) 1.9589 | Acc(train) 0.5606 | Acc(val) 0.5824 |
Epoch 00160 | Loss(train) 1.9657 | Acc(train) 0.5479 | Acc(val) 0.5824 |
Epoch 00161 | Loss(train) 1.9689 | Acc(train) 0.5410 | Acc(val) 0.5830 |
Epoch 00162 | Loss(train) 1.9594 | Acc(train) 0.5524 | Acc(val) 0.5814 |
Epoch 00163 | Loss(train) 1.9617 | Acc(train) 0.5415 | Acc(val) 0.5814 |
Epoch 00164 | Loss(train) 1.9666 | Acc(train) 0.5503 | Acc(val) 0.5819 |
Epoch 00165 | Loss(train) 1.9461 | Acc(train) 0.5436 | Acc(val) 0.5824 |
Epoch 00166 | Loss(train) 1.9514 | Acc(train) 0.5524 | Acc(val) 0.5809 |
Epoch 00167 | Loss(train) 1.9525 | Acc(train) 0.5561 | Acc(val) 0.5835 |
Epoch 00168 | Loss(train) 1.9504 | Acc(train) 0.5529 | Acc(val) 0.5835 |
Epoch 00169 | Loss(train) 1.9683 | Acc(train) 0.5511 | Acc(val) 0.5830 |
Epoch 00170 | Loss(train) 1.9483 | Acc(train) 0.5527 | Acc(val) 0.5819 |
Epoch 00171 | Loss(train) 1.9441 | Acc(train) 0.5524 | Acc(val) 0.5809 |
Epoch 00172 | Loss(train) 1.9652 | Acc(train) 0.5484 | Acc(val) 0.5809 |
Epoch 00173 | Loss(train) 1.9511 | Acc(train) 0.5487 | Acc(val) 0.5824 |
Epoch 00174 | Loss(train) 1.9545 | Acc(train) 0.5484 | Acc(val) 0.5835 |
Epoch 00175 | Loss(train) 1.9278 | Acc(train) 0.5548 | Acc(val) 0.5851 |
Epoch 00176 | Loss(train) 1.9605 | Acc(train) 0.5532 | Acc(val) 0.5878 |*
Epoch 00177 | Loss(train) 1.9444 | Acc(train) 0.5548 | Acc(val) 0.5862 |
Epoch 00178 | Loss(train) 1.9653 | Acc(train) 0.5625 | Acc(val) 0.5872 |
Epoch 00179 | Loss(train) 1.9482 | Acc(train) 0.5580 | Acc(val) 0.5846 |
Epoch 00180 | Loss(train) 1.9574 | Acc(train) 0.5489 | Acc(val) 0.5819 |
Epoch 00181 | Loss(train) 1.9495 | Acc(train) 0.5559 | Acc(val) 0.5830 |
Epoch 00182 | Loss(train) 1.9572 | Acc(train) 0.5545 | Acc(val) 0.5835 |
Epoch 00183 | Loss(train) 1.9623 | Acc(train) 0.5535 | Acc(val) 0.5846 |
Epoch 00184 | Loss(train) 1.9312 | Acc(train) 0.5519 | Acc(val) 0.5840 |
Epoch 00185 | Loss(train) 1.9494 | Acc(train) 0.5492 | Acc(val) 0.5814 |
Epoch 00186 | Loss(train) 1.9512 | Acc(train) 0.5439 | Acc(val) 0.5814 |
Epoch 00187 | Loss(train) 1.9251 | Acc(train) 0.5660 | Acc(val) 0.5824 |
Epoch 00188 | Loss(train) 1.9540 | Acc(train) 0.5540 | Acc(val) 0.5830 |
Epoch 00189 | Loss(train) 1.9352 | Acc(train) 0.5545 | Acc(val) 0.5830 |
Epoch 00190 | Loss(train) 1.9467 | Acc(train) 0.5612 | Acc(val) 0.5840 |
Epoch 00191 | Loss(train) 1.9514 | Acc(train) 0.5543 | Acc(val) 0.5830 |
Epoch 00192 | Loss(train) 1.9414 | Acc(train) 0.5612 | Acc(val) 0.5793 |
Epoch 00193 | Loss(train) 1.9625 | Acc(train) 0.5543 | Acc(val) 0.5819 |
Epoch 00194 | Loss(train) 1.9287 | Acc(train) 0.5686 | Acc(val) 0.5819 |
Epoch 00195 | Loss(train) 1.9286 | Acc(train) 0.5633 | Acc(val) 0.5846 |
Epoch 00196 | Loss(train) 1.9422 | Acc(train) 0.5574 | Acc(val) 0.5851 |
Epoch 00197 | Loss(train) 1.9224 | Acc(train) 0.5723 | Acc(val) 0.5862 |
Epoch 00198 | Loss(train) 1.9354 | Acc(train) 0.5596 | Acc(val) 0.5856 |
Epoch 00199 | Loss(train) 1.9363 | Acc(train) 0.5588 | Acc(val) 0.5824 |
Epoch 00200 | Loss(train) 1.9413 | Acc(train) 0.5580 | Acc(val) 0.5809 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2483 | Acc(train) 0.0165 | Acc(val) 0.1101 |*
Epoch 00002 | Loss(train) 4.2197 | Acc(train) 0.0939 | Acc(val) 0.1074 |
Epoch 00003 | Loss(train) 4.1806 | Acc(train) 0.1059 | Acc(val) 0.1117 |*
Epoch 00004 | Loss(train) 4.1348 | Acc(train) 0.1090 | Acc(val) 0.1154 |*
Epoch 00005 | Loss(train) 4.0810 | Acc(train) 0.1112 | Acc(val) 0.1122 |
Epoch 00006 | Loss(train) 4.0273 | Acc(train) 0.1114 | Acc(val) 0.1112 |
Epoch 00007 | Loss(train) 3.9753 | Acc(train) 0.1077 | Acc(val) 0.1112 |
Epoch 00008 | Loss(train) 3.9252 | Acc(train) 0.1128 | Acc(val) 0.1138 |
Epoch 00009 | Loss(train) 3.8869 | Acc(train) 0.1056 | Acc(val) 0.1245 |*
Epoch 00010 | Loss(train) 3.8561 | Acc(train) 0.1136 | Acc(val) 0.1356 |*
Epoch 00011 | Loss(train) 3.8282 | Acc(train) 0.1191 | Acc(val) 0.1463 |*
Epoch 00012 | Loss(train) 3.7948 | Acc(train) 0.1306 | Acc(val) 0.1452 |
Epoch 00013 | Loss(train) 3.7571 | Acc(train) 0.1420 | Acc(val) 0.1521 |*
Epoch 00014 | Loss(train) 3.7205 | Acc(train) 0.1447 | Acc(val) 0.1601 |*
Epoch 00015 | Loss(train) 3.6952 | Acc(train) 0.1596 | Acc(val) 0.1654 |*
Epoch 00016 | Loss(train) 3.6479 | Acc(train) 0.1633 | Acc(val) 0.1777 |*
Epoch 00017 | Loss(train) 3.6189 | Acc(train) 0.1691 | Acc(val) 0.1862 |*
Epoch 00018 | Loss(train) 3.5800 | Acc(train) 0.1838 | Acc(val) 0.1957 |*
Epoch 00019 | Loss(train) 3.5327 | Acc(train) 0.1851 | Acc(val) 0.2048 |*
Epoch 00020 | Loss(train) 3.4945 | Acc(train) 0.1997 | Acc(val) 0.2117 |*
Epoch 00021 | Loss(train) 3.4587 | Acc(train) 0.1965 | Acc(val) 0.2223 |*
Epoch 00022 | Loss(train) 3.4081 | Acc(train) 0.2066 | Acc(val) 0.2372 |*
Epoch 00023 | Loss(train) 3.3641 | Acc(train) 0.2191 | Acc(val) 0.2559 |*
Epoch 00024 | Loss(train) 3.3067 | Acc(train) 0.2394 | Acc(val) 0.2697 |*
Epoch 00025 | Loss(train) 3.2782 | Acc(train) 0.2452 | Acc(val) 0.2867 |*
Epoch 00026 | Loss(train) 3.2320 | Acc(train) 0.2649 | Acc(val) 0.3000 |*
Epoch 00027 | Loss(train) 3.1853 | Acc(train) 0.2753 | Acc(val) 0.3202 |*
Epoch 00028 | Loss(train) 3.1565 | Acc(train) 0.2851 | Acc(val) 0.3378 |*
Epoch 00029 | Loss(train) 3.1092 | Acc(train) 0.3035 | Acc(val) 0.3495 |*
Epoch 00030 | Loss(train) 3.0684 | Acc(train) 0.3101 | Acc(val) 0.3606 |*
Epoch 00031 | Loss(train) 3.0329 | Acc(train) 0.3242 | Acc(val) 0.3691 |*
Epoch 00032 | Loss(train) 2.9876 | Acc(train) 0.3274 | Acc(val) 0.3872 |*
Epoch 00033 | Loss(train) 2.9474 | Acc(train) 0.3444 | Acc(val) 0.3968 |*
Epoch 00034 | Loss(train) 2.9220 | Acc(train) 0.3566 | Acc(val) 0.4043 |*
Epoch 00035 | Loss(train) 2.8852 | Acc(train) 0.3585 | Acc(val) 0.4165 |*
Epoch 00036 | Loss(train) 2.8514 | Acc(train) 0.3718 | Acc(val) 0.4298 |*
Epoch 00037 | Loss(train) 2.8140 | Acc(train) 0.3875 | Acc(val) 0.4351 |*
Epoch 00038 | Loss(train) 2.7939 | Acc(train) 0.3918 | Acc(val) 0.4399 |*
Epoch 00039 | Loss(train) 2.7647 | Acc(train) 0.3811 | Acc(val) 0.4431 |*
Epoch 00040 | Loss(train) 2.7246 | Acc(train) 0.4005 | Acc(val) 0.4505 |*
Epoch 00041 | Loss(train) 2.6905 | Acc(train) 0.4077 | Acc(val) 0.4548 |*
Epoch 00042 | Loss(train) 2.6768 | Acc(train) 0.4136 | Acc(val) 0.4574 |*
Epoch 00043 | Loss(train) 2.6392 | Acc(train) 0.4056 | Acc(val) 0.4585 |*
Epoch 00044 | Loss(train) 2.6113 | Acc(train) 0.4229 | Acc(val) 0.4596 |*
Epoch 00045 | Loss(train) 2.5829 | Acc(train) 0.4229 | Acc(val) 0.4681 |*
Epoch 00046 | Loss(train) 2.5663 | Acc(train) 0.4255 | Acc(val) 0.4734 |*
Epoch 00047 | Loss(train) 2.5479 | Acc(train) 0.4404 | Acc(val) 0.4777 |*
Epoch 00048 | Loss(train) 2.5082 | Acc(train) 0.4380 | Acc(val) 0.4840 |*
Epoch 00049 | Loss(train) 2.4842 | Acc(train) 0.4444 | Acc(val) 0.4878 |*
Epoch 00050 | Loss(train) 2.4656 | Acc(train) 0.4465 | Acc(val) 0.4910 |*
Epoch 00051 | Loss(train) 2.4513 | Acc(train) 0.4487 | Acc(val) 0.4931 |*
Epoch 00052 | Loss(train) 2.4354 | Acc(train) 0.4500 | Acc(val) 0.4973 |*
Epoch 00053 | Loss(train) 2.4100 | Acc(train) 0.4513 | Acc(val) 0.4989 |*
Epoch 00054 | Loss(train) 2.3963 | Acc(train) 0.4548 | Acc(val) 0.5037 |*
Epoch 00055 | Loss(train) 2.3818 | Acc(train) 0.4670 | Acc(val) 0.5059 |*
Epoch 00056 | Loss(train) 2.3527 | Acc(train) 0.4535 | Acc(val) 0.5122 |*
Epoch 00057 | Loss(train) 2.3546 | Acc(train) 0.4620 | Acc(val) 0.5154 |*
Epoch 00058 | Loss(train) 2.3306 | Acc(train) 0.4726 | Acc(val) 0.5165 |*
Epoch 00059 | Loss(train) 2.3195 | Acc(train) 0.4777 | Acc(val) 0.5176 |*
Epoch 00060 | Loss(train) 2.2953 | Acc(train) 0.4859 | Acc(val) 0.5186 |*
Epoch 00061 | Loss(train) 2.2843 | Acc(train) 0.4779 | Acc(val) 0.5213 |*
Epoch 00062 | Loss(train) 2.2772 | Acc(train) 0.4795 | Acc(val) 0.5218 |*
Epoch 00063 | Loss(train) 2.2718 | Acc(train) 0.4766 | Acc(val) 0.5250 |*
Epoch 00064 | Loss(train) 2.2561 | Acc(train) 0.4862 | Acc(val) 0.5261 |*
Epoch 00065 | Loss(train) 2.2604 | Acc(train) 0.4811 | Acc(val) 0.5282 |*
Epoch 00066 | Loss(train) 2.2340 | Acc(train) 0.4896 | Acc(val) 0.5319 |*
Epoch 00067 | Loss(train) 2.2178 | Acc(train) 0.4896 | Acc(val) 0.5351 |*
Epoch 00068 | Loss(train) 2.2234 | Acc(train) 0.4981 | Acc(val) 0.5330 |
Epoch 00069 | Loss(train) 2.2028 | Acc(train) 0.4984 | Acc(val) 0.5324 |
Epoch 00070 | Loss(train) 2.1907 | Acc(train) 0.5040 | Acc(val) 0.5319 |
Epoch 00071 | Loss(train) 2.1847 | Acc(train) 0.5059 | Acc(val) 0.5335 |
Epoch 00072 | Loss(train) 2.2049 | Acc(train) 0.4899 | Acc(val) 0.5362 |*
Epoch 00073 | Loss(train) 2.1678 | Acc(train) 0.5048 | Acc(val) 0.5367 |*
Epoch 00074 | Loss(train) 2.1766 | Acc(train) 0.4968 | Acc(val) 0.5394 |*
Epoch 00075 | Loss(train) 2.1573 | Acc(train) 0.5021 | Acc(val) 0.5420 |*
Epoch 00076 | Loss(train) 2.1414 | Acc(train) 0.5061 | Acc(val) 0.5463 |*
Epoch 00077 | Loss(train) 2.1256 | Acc(train) 0.5162 | Acc(val) 0.5484 |*
Epoch 00078 | Loss(train) 2.1631 | Acc(train) 0.4992 | Acc(val) 0.5484 |
Epoch 00079 | Loss(train) 2.1434 | Acc(train) 0.5013 | Acc(val) 0.5489 |*
Epoch 00080 | Loss(train) 2.1234 | Acc(train) 0.5128 | Acc(val) 0.5479 |
Epoch 00081 | Loss(train) 2.1230 | Acc(train) 0.5104 | Acc(val) 0.5484 |
Epoch 00082 | Loss(train) 2.1202 | Acc(train) 0.5059 | Acc(val) 0.5489 |
Epoch 00083 | Loss(train) 2.1020 | Acc(train) 0.5149 | Acc(val) 0.5505 |*
Epoch 00084 | Loss(train) 2.1010 | Acc(train) 0.5133 | Acc(val) 0.5521 |*
Epoch 00085 | Loss(train) 2.0994 | Acc(train) 0.5096 | Acc(val) 0.5543 |*
Epoch 00086 | Loss(train) 2.0891 | Acc(train) 0.5218 | Acc(val) 0.5564 |*
Epoch 00087 | Loss(train) 2.0767 | Acc(train) 0.5181 | Acc(val) 0.5590 |*
Epoch 00088 | Loss(train) 2.0659 | Acc(train) 0.5274 | Acc(val) 0.5569 |
Epoch 00089 | Loss(train) 2.0663 | Acc(train) 0.5247 | Acc(val) 0.5564 |
Epoch 00090 | Loss(train) 2.0842 | Acc(train) 0.5170 | Acc(val) 0.5559 |
Epoch 00091 | Loss(train) 2.0828 | Acc(train) 0.5146 | Acc(val) 0.5574 |
Epoch 00092 | Loss(train) 2.0685 | Acc(train) 0.5184 | Acc(val) 0.5606 |*
Epoch 00093 | Loss(train) 2.0681 | Acc(train) 0.5160 | Acc(val) 0.5633 |*
Epoch 00094 | Loss(train) 2.0691 | Acc(train) 0.5173 | Acc(val) 0.5649 |*
Epoch 00095 | Loss(train) 2.0646 | Acc(train) 0.5186 | Acc(val) 0.5670 |*
Epoch 00096 | Loss(train) 2.0472 | Acc(train) 0.5277 | Acc(val) 0.5665 |
Epoch 00097 | Loss(train) 2.0568 | Acc(train) 0.5282 | Acc(val) 0.5649 |
Epoch 00098 | Loss(train) 2.0419 | Acc(train) 0.5269 | Acc(val) 0.5676 |*
Epoch 00099 | Loss(train) 2.0379 | Acc(train) 0.5303 | Acc(val) 0.5686 |*
Epoch 00100 | Loss(train) 2.0312 | Acc(train) 0.5351 | Acc(val) 0.5702 |*
Epoch 00101 | Loss(train) 2.0413 | Acc(train) 0.5290 | Acc(val) 0.5707 |*
Epoch 00102 | Loss(train) 2.0390 | Acc(train) 0.5301 | Acc(val) 0.5713 |*
Epoch 00103 | Loss(train) 2.0595 | Acc(train) 0.5234 | Acc(val) 0.5729 |*
Epoch 00104 | Loss(train) 2.0236 | Acc(train) 0.5431 | Acc(val) 0.5718 |
Epoch 00105 | Loss(train) 2.0430 | Acc(train) 0.5266 | Acc(val) 0.5739 |*
Epoch 00106 | Loss(train) 2.0356 | Acc(train) 0.5306 | Acc(val) 0.5729 |
Epoch 00107 | Loss(train) 2.0255 | Acc(train) 0.5324 | Acc(val) 0.5734 |
Epoch 00108 | Loss(train) 2.0275 | Acc(train) 0.5378 | Acc(val) 0.5766 |*
Epoch 00109 | Loss(train) 2.0357 | Acc(train) 0.5253 | Acc(val) 0.5750 |
Epoch 00110 | Loss(train) 2.0205 | Acc(train) 0.5338 | Acc(val) 0.5761 |
Epoch 00111 | Loss(train) 2.0201 | Acc(train) 0.5335 | Acc(val) 0.5793 |*
Epoch 00112 | Loss(train) 2.0138 | Acc(train) 0.5263 | Acc(val) 0.5793 |
Epoch 00113 | Loss(train) 2.0212 | Acc(train) 0.5338 | Acc(val) 0.5814 |*
Epoch 00114 | Loss(train) 2.0284 | Acc(train) 0.5351 | Acc(val) 0.5761 |
Epoch 00115 | Loss(train) 2.0166 | Acc(train) 0.5269 | Acc(val) 0.5755 |
Epoch 00116 | Loss(train) 2.0047 | Acc(train) 0.5426 | Acc(val) 0.5771 |
Epoch 00117 | Loss(train) 2.0045 | Acc(train) 0.5418 | Acc(val) 0.5793 |
Epoch 00118 | Loss(train) 2.0137 | Acc(train) 0.5444 | Acc(val) 0.5777 |
Epoch 00119 | Loss(train) 2.0047 | Acc(train) 0.5378 | Acc(val) 0.5782 |
Epoch 00120 | Loss(train) 2.0038 | Acc(train) 0.5415 | Acc(val) 0.5761 |
Epoch 00121 | Loss(train) 2.0149 | Acc(train) 0.5404 | Acc(val) 0.5750 |
Epoch 00122 | Loss(train) 1.9854 | Acc(train) 0.5386 | Acc(val) 0.5777 |
Epoch 00123 | Loss(train) 2.0141 | Acc(train) 0.5293 | Acc(val) 0.5777 |
Epoch 00124 | Loss(train) 1.9940 | Acc(train) 0.5404 | Acc(val) 0.5777 |
Epoch 00125 | Loss(train) 1.9766 | Acc(train) 0.5513 | Acc(val) 0.5803 |
Epoch 00126 | Loss(train) 1.9825 | Acc(train) 0.5516 | Acc(val) 0.5809 |
Epoch 00127 | Loss(train) 1.9812 | Acc(train) 0.5375 | Acc(val) 0.5803 |
Epoch 00128 | Loss(train) 1.9774 | Acc(train) 0.5473 | Acc(val) 0.5809 |
Epoch 00129 | Loss(train) 1.9974 | Acc(train) 0.5582 | Acc(val) 0.5830 |*
Epoch 00130 | Loss(train) 1.9852 | Acc(train) 0.5402 | Acc(val) 0.5840 |*
Epoch 00131 | Loss(train) 1.9567 | Acc(train) 0.5596 | Acc(val) 0.5840 |
Epoch 00132 | Loss(train) 1.9895 | Acc(train) 0.5394 | Acc(val) 0.5830 |
Epoch 00133 | Loss(train) 1.9795 | Acc(train) 0.5423 | Acc(val) 0.5840 |
Epoch 00134 | Loss(train) 1.9858 | Acc(train) 0.5426 | Acc(val) 0.5840 |
Epoch 00135 | Loss(train) 1.9952 | Acc(train) 0.5428 | Acc(val) 0.5824 |
Epoch 00136 | Loss(train) 1.9855 | Acc(train) 0.5407 | Acc(val) 0.5824 |
Epoch 00137 | Loss(train) 1.9821 | Acc(train) 0.5444 | Acc(val) 0.5840 |
Epoch 00138 | Loss(train) 1.9682 | Acc(train) 0.5476 | Acc(val) 0.5851 |*
Epoch 00139 | Loss(train) 1.9932 | Acc(train) 0.5489 | Acc(val) 0.5856 |*
Epoch 00140 | Loss(train) 1.9701 | Acc(train) 0.5460 | Acc(val) 0.5867 |*
Epoch 00141 | Loss(train) 1.9796 | Acc(train) 0.5559 | Acc(val) 0.5803 |
Epoch 00142 | Loss(train) 1.9491 | Acc(train) 0.5511 | Acc(val) 0.5803 |
Epoch 00143 | Loss(train) 1.9789 | Acc(train) 0.5388 | Acc(val) 0.5803 |
Epoch 00144 | Loss(train) 1.9851 | Acc(train) 0.5444 | Acc(val) 0.5798 |
Epoch 00145 | Loss(train) 1.9782 | Acc(train) 0.5375 | Acc(val) 0.5814 |
Epoch 00146 | Loss(train) 1.9629 | Acc(train) 0.5492 | Acc(val) 0.5824 |
Epoch 00147 | Loss(train) 1.9610 | Acc(train) 0.5511 | Acc(val) 0.5840 |
Epoch 00148 | Loss(train) 1.9820 | Acc(train) 0.5484 | Acc(val) 0.5862 |
Epoch 00149 | Loss(train) 1.9724 | Acc(train) 0.5508 | Acc(val) 0.5835 |
Epoch 00150 | Loss(train) 1.9545 | Acc(train) 0.5444 | Acc(val) 0.5809 |
Epoch 00151 | Loss(train) 1.9678 | Acc(train) 0.5465 | Acc(val) 0.5793 |
Epoch 00152 | Loss(train) 1.9718 | Acc(train) 0.5505 | Acc(val) 0.5787 |
Epoch 00153 | Loss(train) 1.9521 | Acc(train) 0.5513 | Acc(val) 0.5787 |
Epoch 00154 | Loss(train) 1.9575 | Acc(train) 0.5444 | Acc(val) 0.5793 |
Epoch 00155 | Loss(train) 1.9506 | Acc(train) 0.5471 | Acc(val) 0.5814 |
Epoch 00156 | Loss(train) 1.9636 | Acc(train) 0.5505 | Acc(val) 0.5824 |
Epoch 00157 | Loss(train) 1.9839 | Acc(train) 0.5500 | Acc(val) 0.5840 |
Epoch 00158 | Loss(train) 1.9435 | Acc(train) 0.5508 | Acc(val) 0.5856 |
Epoch 00159 | Loss(train) 1.9483 | Acc(train) 0.5559 | Acc(val) 0.5862 |
Epoch 00160 | Loss(train) 1.9696 | Acc(train) 0.5521 | Acc(val) 0.5872 |*
Epoch 00161 | Loss(train) 1.9632 | Acc(train) 0.5489 | Acc(val) 0.5862 |
Epoch 00162 | Loss(train) 1.9542 | Acc(train) 0.5455 | Acc(val) 0.5840 |
Epoch 00163 | Loss(train) 1.9542 | Acc(train) 0.5537 | Acc(val) 0.5814 |
Epoch 00164 | Loss(train) 1.9513 | Acc(train) 0.5508 | Acc(val) 0.5819 |
Epoch 00165 | Loss(train) 1.9636 | Acc(train) 0.5484 | Acc(val) 0.5830 |
Epoch 00166 | Loss(train) 1.9529 | Acc(train) 0.5673 | Acc(val) 0.5867 |
Epoch 00167 | Loss(train) 1.9344 | Acc(train) 0.5644 | Acc(val) 0.5872 |
Epoch 00168 | Loss(train) 1.9606 | Acc(train) 0.5495 | Acc(val) 0.5872 |
Epoch 00169 | Loss(train) 1.9499 | Acc(train) 0.5505 | Acc(val) 0.5840 |
Epoch 00170 | Loss(train) 1.9765 | Acc(train) 0.5439 | Acc(val) 0.5862 |
Epoch 00171 | Loss(train) 1.9580 | Acc(train) 0.5503 | Acc(val) 0.5856 |
Epoch 00172 | Loss(train) 1.9669 | Acc(train) 0.5463 | Acc(val) 0.5835 |
Epoch 00173 | Loss(train) 1.9551 | Acc(train) 0.5500 | Acc(val) 0.5851 |
Epoch 00174 | Loss(train) 1.9534 | Acc(train) 0.5492 | Acc(val) 0.5883 |*
Epoch 00175 | Loss(train) 1.9548 | Acc(train) 0.5484 | Acc(val) 0.5846 |
Epoch 00176 | Loss(train) 1.9619 | Acc(train) 0.5457 | Acc(val) 0.5835 |
Epoch 00177 | Loss(train) 1.9607 | Acc(train) 0.5460 | Acc(val) 0.5840 |
Epoch 00178 | Loss(train) 1.9627 | Acc(train) 0.5524 | Acc(val) 0.5830 |
Epoch 00179 | Loss(train) 1.9355 | Acc(train) 0.5524 | Acc(val) 0.5840 |
Epoch 00180 | Loss(train) 1.9503 | Acc(train) 0.5543 | Acc(val) 0.5856 |
Epoch 00181 | Loss(train) 1.9332 | Acc(train) 0.5620 | Acc(val) 0.5830 |
Epoch 00182 | Loss(train) 1.9686 | Acc(train) 0.5436 | Acc(val) 0.5846 |
Epoch 00183 | Loss(train) 1.9326 | Acc(train) 0.5657 | Acc(val) 0.5846 |
Epoch 00184 | Loss(train) 1.9392 | Acc(train) 0.5590 | Acc(val) 0.5851 |
Epoch 00185 | Loss(train) 1.9514 | Acc(train) 0.5564 | Acc(val) 0.5851 |
Epoch 00186 | Loss(train) 1.9454 | Acc(train) 0.5566 | Acc(val) 0.5835 |
Epoch 00187 | Loss(train) 1.9454 | Acc(train) 0.5484 | Acc(val) 0.5830 |
Epoch 00188 | Loss(train) 1.9576 | Acc(train) 0.5537 | Acc(val) 0.5830 |
Epoch 00189 | Loss(train) 1.9391 | Acc(train) 0.5513 | Acc(val) 0.5846 |
Epoch 00190 | Loss(train) 1.9501 | Acc(train) 0.5532 | Acc(val) 0.5872 |
Epoch 00191 | Loss(train) 1.9354 | Acc(train) 0.5561 | Acc(val) 0.5872 |
Epoch 00192 | Loss(train) 1.9508 | Acc(train) 0.5484 | Acc(val) 0.5840 |
Epoch 00193 | Loss(train) 1.9580 | Acc(train) 0.5465 | Acc(val) 0.5851 |
Epoch 00194 | Loss(train) 1.9491 | Acc(train) 0.5548 | Acc(val) 0.5867 |
Epoch 00195 | Loss(train) 1.9443 | Acc(train) 0.5468 | Acc(val) 0.5883 |
Epoch 00196 | Loss(train) 1.9568 | Acc(train) 0.5569 | Acc(val) 0.5883 |
Epoch 00197 | Loss(train) 1.9646 | Acc(train) 0.5441 | Acc(val) 0.5883 |
Epoch 00198 | Loss(train) 1.9481 | Acc(train) 0.5471 | Acc(val) 0.5867 |
Epoch 00199 | Loss(train) 1.9308 | Acc(train) 0.5545 | Acc(val) 0.5814 |
Epoch 00200 | Loss(train) 1.9511 | Acc(train) 0.5532 | Acc(val) 0.5840 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 4.2488 | Acc(train) 0.0122 | Acc(val) 0.1867 |*
Epoch 00002 | Loss(train) 4.2204 | Acc(train) 0.1316 | Acc(val) 0.2691 |*
Epoch 00003 | Loss(train) 4.1818 | Acc(train) 0.1633 | Acc(val) 0.2649 |
Epoch 00004 | Loss(train) 4.1370 | Acc(train) 0.1654 | Acc(val) 0.2564 |
Epoch 00005 | Loss(train) 4.0864 | Acc(train) 0.1750 | Acc(val) 0.2457 |
Epoch 00006 | Loss(train) 4.0232 | Acc(train) 0.1806 | Acc(val) 0.2351 |
Epoch 00007 | Loss(train) 3.9755 | Acc(train) 0.1572 | Acc(val) 0.2346 |
Epoch 00008 | Loss(train) 3.9142 | Acc(train) 0.1803 | Acc(val) 0.2330 |
Epoch 00009 | Loss(train) 3.8681 | Acc(train) 0.1633 | Acc(val) 0.2330 |
Epoch 00010 | Loss(train) 3.8261 | Acc(train) 0.1731 | Acc(val) 0.2298 |
Epoch 00011 | Loss(train) 3.7941 | Acc(train) 0.1747 | Acc(val) 0.2234 |
Epoch 00012 | Loss(train) 3.7493 | Acc(train) 0.1832 | Acc(val) 0.2149 |
Epoch 00013 | Loss(train) 3.7122 | Acc(train) 0.1801 | Acc(val) 0.2027 |
Epoch 00014 | Loss(train) 3.6727 | Acc(train) 0.1816 | Acc(val) 0.1995 |
Epoch 00015 | Loss(train) 3.6356 | Acc(train) 0.1830 | Acc(val) 0.2011 |
Epoch 00016 | Loss(train) 3.5978 | Acc(train) 0.1886 | Acc(val) 0.2069 |
Epoch 00017 | Loss(train) 3.5652 | Acc(train) 0.1926 | Acc(val) 0.2117 |
Epoch 00018 | Loss(train) 3.5254 | Acc(train) 0.1960 | Acc(val) 0.2170 |
Epoch 00019 | Loss(train) 3.4849 | Acc(train) 0.2035 | Acc(val) 0.2255 |
Epoch 00020 | Loss(train) 3.4473 | Acc(train) 0.2106 | Acc(val) 0.2356 |
Epoch 00021 | Loss(train) 3.4121 | Acc(train) 0.2138 | Acc(val) 0.2415 |
Epoch 00022 | Loss(train) 3.3640 | Acc(train) 0.2213 | Acc(val) 0.2511 |
Epoch 00023 | Loss(train) 3.3280 | Acc(train) 0.2247 | Acc(val) 0.2606 |
Epoch 00024 | Loss(train) 3.2863 | Acc(train) 0.2303 | Acc(val) 0.2691 |
Epoch 00025 | Loss(train) 3.2522 | Acc(train) 0.2396 | Acc(val) 0.2840 |*
Epoch 00026 | Loss(train) 3.2133 | Acc(train) 0.2569 | Acc(val) 0.3037 |*
Epoch 00027 | Loss(train) 3.1738 | Acc(train) 0.2665 | Acc(val) 0.3202 |*
Epoch 00028 | Loss(train) 3.1411 | Acc(train) 0.2846 | Acc(val) 0.3410 |*
Epoch 00029 | Loss(train) 3.0909 | Acc(train) 0.2984 | Acc(val) 0.3574 |*
Epoch 00030 | Loss(train) 3.0526 | Acc(train) 0.3205 | Acc(val) 0.3681 |*
Epoch 00031 | Loss(train) 3.0290 | Acc(train) 0.3136 | Acc(val) 0.3729 |*
Epoch 00032 | Loss(train) 2.9993 | Acc(train) 0.3301 | Acc(val) 0.3814 |*
Epoch 00033 | Loss(train) 2.9564 | Acc(train) 0.3338 | Acc(val) 0.3867 |*
Epoch 00034 | Loss(train) 2.9313 | Acc(train) 0.3463 | Acc(val) 0.3957 |*
Epoch 00035 | Loss(train) 2.9042 | Acc(train) 0.3476 | Acc(val) 0.4053 |*
Epoch 00036 | Loss(train) 2.8519 | Acc(train) 0.3585 | Acc(val) 0.4191 |*
Epoch 00037 | Loss(train) 2.8169 | Acc(train) 0.3699 | Acc(val) 0.4239 |*
Epoch 00038 | Loss(train) 2.8013 | Acc(train) 0.3715 | Acc(val) 0.4330 |*
Epoch 00039 | Loss(train) 2.7781 | Acc(train) 0.3840 | Acc(val) 0.4383 |*
Epoch 00040 | Loss(train) 2.7369 | Acc(train) 0.3952 | Acc(val) 0.4426 |*
Epoch 00041 | Loss(train) 2.6964 | Acc(train) 0.4016 | Acc(val) 0.4436 |*
Epoch 00042 | Loss(train) 2.6779 | Acc(train) 0.4019 | Acc(val) 0.4447 |*
Epoch 00043 | Loss(train) 2.6585 | Acc(train) 0.4011 | Acc(val) 0.4441 |
Epoch 00044 | Loss(train) 2.6348 | Acc(train) 0.4051 | Acc(val) 0.4473 |*
Epoch 00045 | Loss(train) 2.6166 | Acc(train) 0.4035 | Acc(val) 0.4532 |*
Epoch 00046 | Loss(train) 2.5785 | Acc(train) 0.4154 | Acc(val) 0.4612 |*
Epoch 00047 | Loss(train) 2.5634 | Acc(train) 0.4189 | Acc(val) 0.4660 |*
Epoch 00048 | Loss(train) 2.5244 | Acc(train) 0.4237 | Acc(val) 0.4707 |*
Epoch 00049 | Loss(train) 2.5233 | Acc(train) 0.4245 | Acc(val) 0.4723 |*
Epoch 00050 | Loss(train) 2.4881 | Acc(train) 0.4351 | Acc(val) 0.4755 |*
Epoch 00051 | Loss(train) 2.4793 | Acc(train) 0.4423 | Acc(val) 0.4819 |*
Epoch 00052 | Loss(train) 2.4686 | Acc(train) 0.4338 | Acc(val) 0.4846 |*
Epoch 00053 | Loss(train) 2.4528 | Acc(train) 0.4391 | Acc(val) 0.4867 |*
Epoch 00054 | Loss(train) 2.4398 | Acc(train) 0.4375 | Acc(val) 0.4904 |*
Epoch 00055 | Loss(train) 2.4165 | Acc(train) 0.4479 | Acc(val) 0.4915 |*
Epoch 00056 | Loss(train) 2.3827 | Acc(train) 0.4383 | Acc(val) 0.4947 |*
Epoch 00057 | Loss(train) 2.3825 | Acc(train) 0.4521 | Acc(val) 0.4979 |*
Epoch 00058 | Loss(train) 2.3576 | Acc(train) 0.4588 | Acc(val) 0.5011 |*
Epoch 00059 | Loss(train) 2.3478 | Acc(train) 0.4577 | Acc(val) 0.5053 |*
Epoch 00060 | Loss(train) 2.3395 | Acc(train) 0.4553 | Acc(val) 0.5085 |*
Epoch 00061 | Loss(train) 2.3354 | Acc(train) 0.4630 | Acc(val) 0.5096 |*
Epoch 00062 | Loss(train) 2.3191 | Acc(train) 0.4705 | Acc(val) 0.5106 |*
Epoch 00063 | Loss(train) 2.2888 | Acc(train) 0.4737 | Acc(val) 0.5133 |*
Epoch 00064 | Loss(train) 2.2915 | Acc(train) 0.4686 | Acc(val) 0.5128 |
Epoch 00065 | Loss(train) 2.2834 | Acc(train) 0.4662 | Acc(val) 0.5176 |*
Epoch 00066 | Loss(train) 2.2961 | Acc(train) 0.4681 | Acc(val) 0.5197 |*
Epoch 00067 | Loss(train) 2.2679 | Acc(train) 0.4737 | Acc(val) 0.5234 |*
Epoch 00068 | Loss(train) 2.2498 | Acc(train) 0.4875 | Acc(val) 0.5234 |
Epoch 00069 | Loss(train) 2.2419 | Acc(train) 0.4798 | Acc(val) 0.5277 |*
Epoch 00070 | Loss(train) 2.2364 | Acc(train) 0.4822 | Acc(val) 0.5261 |
Epoch 00071 | Loss(train) 2.2041 | Acc(train) 0.4891 | Acc(val) 0.5287 |*
Epoch 00072 | Loss(train) 2.2099 | Acc(train) 0.4843 | Acc(val) 0.5330 |*
Epoch 00073 | Loss(train) 2.2089 | Acc(train) 0.4910 | Acc(val) 0.5346 |*
Epoch 00074 | Loss(train) 2.1994 | Acc(train) 0.4886 | Acc(val) 0.5367 |*
Epoch 00075 | Loss(train) 2.1911 | Acc(train) 0.4846 | Acc(val) 0.5404 |*
Epoch 00076 | Loss(train) 2.1784 | Acc(train) 0.4955 | Acc(val) 0.5420 |*
Epoch 00077 | Loss(train) 2.1934 | Acc(train) 0.4960 | Acc(val) 0.5426 |*
Epoch 00078 | Loss(train) 2.1705 | Acc(train) 0.5011 | Acc(val) 0.5415 |
Epoch 00079 | Loss(train) 2.1835 | Acc(train) 0.4955 | Acc(val) 0.5404 |
Epoch 00080 | Loss(train) 2.1638 | Acc(train) 0.5019 | Acc(val) 0.5441 |*
Epoch 00081 | Loss(train) 2.1339 | Acc(train) 0.5128 | Acc(val) 0.5463 |*
Epoch 00082 | Loss(train) 2.1651 | Acc(train) 0.4955 | Acc(val) 0.5484 |*
Epoch 00083 | Loss(train) 2.1506 | Acc(train) 0.5152 | Acc(val) 0.5521 |*
Epoch 00084 | Loss(train) 2.1515 | Acc(train) 0.5133 | Acc(val) 0.5532 |*
Epoch 00085 | Loss(train) 2.1192 | Acc(train) 0.5019 | Acc(val) 0.5511 |
Epoch 00086 | Loss(train) 2.1123 | Acc(train) 0.5128 | Acc(val) 0.5516 |
Epoch 00087 | Loss(train) 2.1238 | Acc(train) 0.5029 | Acc(val) 0.5532 |
Epoch 00088 | Loss(train) 2.1146 | Acc(train) 0.5074 | Acc(val) 0.5559 |*
Epoch 00089 | Loss(train) 2.1208 | Acc(train) 0.5168 | Acc(val) 0.5564 |*
Epoch 00090 | Loss(train) 2.1202 | Acc(train) 0.5059 | Acc(val) 0.5590 |*
Epoch 00091 | Loss(train) 2.1005 | Acc(train) 0.5191 | Acc(val) 0.5606 |*
Epoch 00092 | Loss(train) 2.1034 | Acc(train) 0.5101 | Acc(val) 0.5601 |
Epoch 00093 | Loss(train) 2.1046 | Acc(train) 0.5144 | Acc(val) 0.5580 |
Epoch 00094 | Loss(train) 2.0874 | Acc(train) 0.5223 | Acc(val) 0.5569 |
Epoch 00095 | Loss(train) 2.0856 | Acc(train) 0.5085 | Acc(val) 0.5590 |
Epoch 00096 | Loss(train) 2.0846 | Acc(train) 0.5141 | Acc(val) 0.5617 |*
Epoch 00097 | Loss(train) 2.0721 | Acc(train) 0.5191 | Acc(val) 0.5644 |*
Epoch 00098 | Loss(train) 2.0970 | Acc(train) 0.5146 | Acc(val) 0.5660 |*
Epoch 00099 | Loss(train) 2.0635 | Acc(train) 0.5181 | Acc(val) 0.5681 |*
Epoch 00100 | Loss(train) 2.0839 | Acc(train) 0.5138 | Acc(val) 0.5670 |
Epoch 00101 | Loss(train) 2.0560 | Acc(train) 0.5285 | Acc(val) 0.5649 |
Epoch 00102 | Loss(train) 2.0688 | Acc(train) 0.5234 | Acc(val) 0.5681 |
Epoch 00103 | Loss(train) 2.0713 | Acc(train) 0.5239 | Acc(val) 0.5691 |*
Epoch 00104 | Loss(train) 2.0651 | Acc(train) 0.5239 | Acc(val) 0.5686 |
Epoch 00105 | Loss(train) 2.0488 | Acc(train) 0.5346 | Acc(val) 0.5697 |*
Epoch 00106 | Loss(train) 2.0505 | Acc(train) 0.5295 | Acc(val) 0.5702 |*
Epoch 00107 | Loss(train) 2.0557 | Acc(train) 0.5290 | Acc(val) 0.5718 |*
Epoch 00108 | Loss(train) 2.0708 | Acc(train) 0.5112 | Acc(val) 0.5713 |
Epoch 00109 | Loss(train) 2.0351 | Acc(train) 0.5303 | Acc(val) 0.5697 |
Epoch 00110 | Loss(train) 2.0462 | Acc(train) 0.5189 | Acc(val) 0.5697 |
Epoch 00111 | Loss(train) 2.0329 | Acc(train) 0.5327 | Acc(val) 0.5713 |
Epoch 00112 | Loss(train) 2.0388 | Acc(train) 0.5293 | Acc(val) 0.5723 |*
Epoch 00113 | Loss(train) 2.0577 | Acc(train) 0.5271 | Acc(val) 0.5734 |*
Epoch 00114 | Loss(train) 2.0544 | Acc(train) 0.5242 | Acc(val) 0.5755 |*
Epoch 00115 | Loss(train) 2.0257 | Acc(train) 0.5402 | Acc(val) 0.5761 |*
Epoch 00116 | Loss(train) 2.0390 | Acc(train) 0.5261 | Acc(val) 0.5739 |
Epoch 00117 | Loss(train) 2.0463 | Acc(train) 0.5199 | Acc(val) 0.5729 |
Epoch 00118 | Loss(train) 2.0445 | Acc(train) 0.5231 | Acc(val) 0.5729 |
Epoch 00119 | Loss(train) 2.0397 | Acc(train) 0.5314 | Acc(val) 0.5745 |
Epoch 00120 | Loss(train) 2.0416 | Acc(train) 0.5407 | Acc(val) 0.5745 |
Epoch 00121 | Loss(train) 2.0156 | Acc(train) 0.5495 | Acc(val) 0.5755 |
Epoch 00122 | Loss(train) 2.0205 | Acc(train) 0.5439 | Acc(val) 0.5739 |
Epoch 00123 | Loss(train) 2.0156 | Acc(train) 0.5391 | Acc(val) 0.5745 |
Epoch 00124 | Loss(train) 2.0207 | Acc(train) 0.5367 | Acc(val) 0.5750 |
Epoch 00125 | Loss(train) 2.0158 | Acc(train) 0.5253 | Acc(val) 0.5761 |
Epoch 00126 | Loss(train) 2.0228 | Acc(train) 0.5370 | Acc(val) 0.5761 |
Epoch 00127 | Loss(train) 2.0207 | Acc(train) 0.5237 | Acc(val) 0.5766 |*
Epoch 00128 | Loss(train) 2.0013 | Acc(train) 0.5402 | Acc(val) 0.5755 |
Epoch 00129 | Loss(train) 2.0109 | Acc(train) 0.5426 | Acc(val) 0.5761 |
Epoch 00130 | Loss(train) 2.0247 | Acc(train) 0.5388 | Acc(val) 0.5745 |
Epoch 00131 | Loss(train) 2.0200 | Acc(train) 0.5354 | Acc(val) 0.5739 |
Epoch 00132 | Loss(train) 2.0156 | Acc(train) 0.5362 | Acc(val) 0.5739 |
Epoch 00133 | Loss(train) 1.9951 | Acc(train) 0.5399 | Acc(val) 0.5729 |
Epoch 00134 | Loss(train) 1.9981 | Acc(train) 0.5367 | Acc(val) 0.5750 |
Epoch 00135 | Loss(train) 2.0020 | Acc(train) 0.5324 | Acc(val) 0.5750 |
Epoch 00136 | Loss(train) 1.9996 | Acc(train) 0.5423 | Acc(val) 0.5755 |
Epoch 00137 | Loss(train) 2.0166 | Acc(train) 0.5362 | Acc(val) 0.5777 |*
Epoch 00138 | Loss(train) 1.9991 | Acc(train) 0.5338 | Acc(val) 0.5782 |*
Epoch 00139 | Loss(train) 2.0106 | Acc(train) 0.5348 | Acc(val) 0.5793 |*
Epoch 00140 | Loss(train) 2.0049 | Acc(train) 0.5340 | Acc(val) 0.5793 |
Epoch 00141 | Loss(train) 1.9967 | Acc(train) 0.5423 | Acc(val) 0.5803 |*
Epoch 00142 | Loss(train) 1.9984 | Acc(train) 0.5426 | Acc(val) 0.5782 |
Epoch 00143 | Loss(train) 2.0260 | Acc(train) 0.5277 | Acc(val) 0.5761 |
Epoch 00144 | Loss(train) 2.0041 | Acc(train) 0.5359 | Acc(val) 0.5761 |
Epoch 00145 | Loss(train) 2.0013 | Acc(train) 0.5404 | Acc(val) 0.5734 |
Epoch 00146 | Loss(train) 1.9942 | Acc(train) 0.5383 | Acc(val) 0.5761 |
Epoch 00147 | Loss(train) 2.0034 | Acc(train) 0.5386 | Acc(val) 0.5809 |*
Epoch 00148 | Loss(train) 2.0013 | Acc(train) 0.5396 | Acc(val) 0.5771 |
Epoch 00149 | Loss(train) 2.0144 | Acc(train) 0.5327 | Acc(val) 0.5766 |
Epoch 00150 | Loss(train) 1.9920 | Acc(train) 0.5354 | Acc(val) 0.5761 |
Epoch 00151 | Loss(train) 1.9914 | Acc(train) 0.5471 | Acc(val) 0.5761 |
Epoch 00152 | Loss(train) 2.0033 | Acc(train) 0.5410 | Acc(val) 0.5745 |
Epoch 00153 | Loss(train) 1.9604 | Acc(train) 0.5582 | Acc(val) 0.5761 |
Epoch 00154 | Loss(train) 2.0127 | Acc(train) 0.5285 | Acc(val) 0.5782 |
Epoch 00155 | Loss(train) 1.9922 | Acc(train) 0.5324 | Acc(val) 0.5809 |
Epoch 00156 | Loss(train) 1.9807 | Acc(train) 0.5473 | Acc(val) 0.5814 |*
Epoch 00157 | Loss(train) 1.9861 | Acc(train) 0.5370 | Acc(val) 0.5803 |
Epoch 00158 | Loss(train) 2.0000 | Acc(train) 0.5418 | Acc(val) 0.5798 |
Epoch 00159 | Loss(train) 1.9763 | Acc(train) 0.5471 | Acc(val) 0.5755 |
Epoch 00160 | Loss(train) 1.9909 | Acc(train) 0.5378 | Acc(val) 0.5771 |
Epoch 00161 | Loss(train) 1.9769 | Acc(train) 0.5473 | Acc(val) 0.5782 |
Epoch 00162 | Loss(train) 1.9894 | Acc(train) 0.5489 | Acc(val) 0.5782 |
Epoch 00163 | Loss(train) 1.9614 | Acc(train) 0.5463 | Acc(val) 0.5798 |
Epoch 00164 | Loss(train) 1.9841 | Acc(train) 0.5407 | Acc(val) 0.5787 |
Epoch 00165 | Loss(train) 1.9627 | Acc(train) 0.5516 | Acc(val) 0.5782 |
Epoch 00166 | Loss(train) 1.9767 | Acc(train) 0.5500 | Acc(val) 0.5766 |
Epoch 00167 | Loss(train) 1.9752 | Acc(train) 0.5439 | Acc(val) 0.5761 |
Epoch 00168 | Loss(train) 1.9744 | Acc(train) 0.5447 | Acc(val) 0.5777 |
Epoch 00169 | Loss(train) 1.9813 | Acc(train) 0.5319 | Acc(val) 0.5787 |
Epoch 00170 | Loss(train) 1.9766 | Acc(train) 0.5394 | Acc(val) 0.5809 |
Epoch 00171 | Loss(train) 1.9803 | Acc(train) 0.5415 | Acc(val) 0.5803 |
Epoch 00172 | Loss(train) 1.9592 | Acc(train) 0.5577 | Acc(val) 0.5787 |
Epoch 00173 | Loss(train) 1.9677 | Acc(train) 0.5479 | Acc(val) 0.5782 |
Epoch 00174 | Loss(train) 1.9975 | Acc(train) 0.5394 | Acc(val) 0.5782 |
Epoch 00175 | Loss(train) 1.9693 | Acc(train) 0.5447 | Acc(val) 0.5782 |
Epoch 00176 | Loss(train) 1.9571 | Acc(train) 0.5508 | Acc(val) 0.5803 |
Epoch 00177 | Loss(train) 1.9683 | Acc(train) 0.5447 | Acc(val) 0.5819 |*
Epoch 00178 | Loss(train) 1.9823 | Acc(train) 0.5335 | Acc(val) 0.5819 |
Epoch 00179 | Loss(train) 1.9797 | Acc(train) 0.5582 | Acc(val) 0.5803 |
Epoch 00180 | Loss(train) 1.9581 | Acc(train) 0.5519 | Acc(val) 0.5787 |
Epoch 00181 | Loss(train) 1.9578 | Acc(train) 0.5471 | Acc(val) 0.5777 |
Epoch 00182 | Loss(train) 1.9808 | Acc(train) 0.5441 | Acc(val) 0.5771 |
Epoch 00183 | Loss(train) 1.9494 | Acc(train) 0.5540 | Acc(val) 0.5782 |
Epoch 00184 | Loss(train) 1.9743 | Acc(train) 0.5505 | Acc(val) 0.5787 |
Epoch 00185 | Loss(train) 1.9696 | Acc(train) 0.5519 | Acc(val) 0.5793 |
Epoch 00186 | Loss(train) 1.9838 | Acc(train) 0.5423 | Acc(val) 0.5809 |
Epoch 00187 | Loss(train) 1.9576 | Acc(train) 0.5511 | Acc(val) 0.5809 |
Epoch 00188 | Loss(train) 1.9590 | Acc(train) 0.5516 | Acc(val) 0.5819 |
Epoch 00189 | Loss(train) 1.9752 | Acc(train) 0.5343 | Acc(val) 0.5814 |
Epoch 00190 | Loss(train) 1.9498 | Acc(train) 0.5596 | Acc(val) 0.5814 |
Epoch 00191 | Loss(train) 1.9590 | Acc(train) 0.5426 | Acc(val) 0.5803 |
Epoch 00192 | Loss(train) 1.9736 | Acc(train) 0.5431 | Acc(val) 0.5793 |
Epoch 00193 | Loss(train) 1.9638 | Acc(train) 0.5612 | Acc(val) 0.5798 |
Epoch 00194 | Loss(train) 1.9590 | Acc(train) 0.5460 | Acc(val) 0.5787 |
Epoch 00195 | Loss(train) 1.9675 | Acc(train) 0.5511 | Acc(val) 0.5761 |
Epoch 00196 | Loss(train) 1.9581 | Acc(train) 0.5460 | Acc(val) 0.5798 |
Epoch 00197 | Loss(train) 1.9276 | Acc(train) 0.5529 | Acc(val) 0.5809 |
Epoch 00198 | Loss(train) 1.9605 | Acc(train) 0.5479 | Acc(val) 0.5803 |
Epoch 00199 | Loss(train) 1.9662 | Acc(train) 0.5500 | Acc(val) 0.5809 |
Epoch 00200 | Loss(train) 1.9614 | Acc(train) 0.5495 | Acc(val) 0.5809 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 128}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 8710, 'out_dim': 70}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 705.20 MB
GPU Memory Reserved: 1382.00 MB
All runs:
Uncalibrated Test Accuracy: 58.82 ± 0.20
Uncalibrated Difference: 28.94 ± 0.19
Calibrated Test Accuracy: 58.82 ± 0.20
Calibrated Difference: 2.04 ± 0.24
