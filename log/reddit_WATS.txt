Dataset: reddit | #Nodes: 232965 | #Edges: 114848857 | #Classes: 41 |#Features: 602
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7269 | Acc(train) 0.0083 | Acc(val) 0.0365 |*
Epoch 00002 | Loss(train) 3.4959 | Acc(train) 0.0384 | Acc(val) 0.1965 |*
Epoch 00003 | Loss(train) 3.3077 | Acc(train) 0.1958 | Acc(val) 0.3054 |*
Epoch 00004 | Loss(train) 3.1372 | Acc(train) 0.2979 | Acc(val) 0.4166 |*
Epoch 00005 | Loss(train) 2.9750 | Acc(train) 0.4084 | Acc(val) 0.4627 |*
Epoch 00006 | Loss(train) 2.8199 | Acc(train) 0.4530 | Acc(val) 0.5026 |*
Epoch 00007 | Loss(train) 2.6605 | Acc(train) 0.4953 | Acc(val) 0.5379 |*
Epoch 00008 | Loss(train) 2.5058 | Acc(train) 0.5276 | Acc(val) 0.5455 |*
Epoch 00009 | Loss(train) 2.3503 | Acc(train) 0.5398 | Acc(val) 0.5695 |*
Epoch 00010 | Loss(train) 2.2083 | Acc(train) 0.5573 | Acc(val) 0.5891 |*
Epoch 00011 | Loss(train) 2.0768 | Acc(train) 0.5822 | Acc(val) 0.6117 |*
Epoch 00012 | Loss(train) 1.9547 | Acc(train) 0.6033 | Acc(val) 0.6346 |*
Epoch 00013 | Loss(train) 1.8467 | Acc(train) 0.6241 | Acc(val) 0.6481 |*
Epoch 00014 | Loss(train) 1.7474 | Acc(train) 0.6399 | Acc(val) 0.6615 |*
Epoch 00015 | Loss(train) 1.6582 | Acc(train) 0.6484 | Acc(val) 0.6741 |*
Epoch 00016 | Loss(train) 1.5741 | Acc(train) 0.6610 | Acc(val) 0.6942 |*
Epoch 00017 | Loss(train) 1.5039 | Acc(train) 0.6816 | Acc(val) 0.7165 |*
Epoch 00018 | Loss(train) 1.4320 | Acc(train) 0.7085 | Acc(val) 0.7360 |*
Epoch 00019 | Loss(train) 1.3669 | Acc(train) 0.7258 | Acc(val) 0.7421 |*
Epoch 00020 | Loss(train) 1.3037 | Acc(train) 0.7300 | Acc(val) 0.7410 |
Epoch 00021 | Loss(train) 1.2402 | Acc(train) 0.7306 | Acc(val) 0.7478 |*
Epoch 00022 | Loss(train) 1.1898 | Acc(train) 0.7296 | Acc(val) 0.7661 |*
Epoch 00023 | Loss(train) 1.1414 | Acc(train) 0.7495 | Acc(val) 0.7863 |*
Epoch 00024 | Loss(train) 1.0962 | Acc(train) 0.7739 | Acc(val) 0.8087 |*
Epoch 00025 | Loss(train) 1.0561 | Acc(train) 0.7935 | Acc(val) 0.8242 |*
Epoch 00026 | Loss(train) 1.0275 | Acc(train) 0.8063 | Acc(val) 0.8381 |*
Epoch 00027 | Loss(train) 0.9866 | Acc(train) 0.8227 | Acc(val) 0.8480 |*
Epoch 00028 | Loss(train) 0.9548 | Acc(train) 0.8304 | Acc(val) 0.8556 |*
Epoch 00029 | Loss(train) 0.9219 | Acc(train) 0.8430 | Acc(val) 0.8577 |*
Epoch 00030 | Loss(train) 0.9005 | Acc(train) 0.8436 | Acc(val) 0.8582 |*
Epoch 00031 | Loss(train) 0.8670 | Acc(train) 0.8427 | Acc(val) 0.8620 |*
Epoch 00032 | Loss(train) 0.8451 | Acc(train) 0.8460 | Acc(val) 0.8635 |*
Epoch 00033 | Loss(train) 0.8275 | Acc(train) 0.8491 | Acc(val) 0.8654 |*
Epoch 00034 | Loss(train) 0.7990 | Acc(train) 0.8501 | Acc(val) 0.8689 |*
Epoch 00035 | Loss(train) 0.7809 | Acc(train) 0.8532 | Acc(val) 0.8723 |*
Epoch 00036 | Loss(train) 0.7663 | Acc(train) 0.8559 | Acc(val) 0.8774 |*
Epoch 00037 | Loss(train) 0.7445 | Acc(train) 0.8585 | Acc(val) 0.8823 |*
Epoch 00038 | Loss(train) 0.7315 | Acc(train) 0.8660 | Acc(val) 0.8862 |*
Epoch 00039 | Loss(train) 0.7113 | Acc(train) 0.8697 | Acc(val) 0.8892 |*
Epoch 00040 | Loss(train) 0.7013 | Acc(train) 0.8750 | Acc(val) 0.8914 |*
Epoch 00041 | Loss(train) 0.6891 | Acc(train) 0.8770 | Acc(val) 0.8940 |*
Epoch 00042 | Loss(train) 0.6741 | Acc(train) 0.8789 | Acc(val) 0.8963 |*
Epoch 00043 | Loss(train) 0.6666 | Acc(train) 0.8786 | Acc(val) 0.8969 |*
Epoch 00044 | Loss(train) 0.6524 | Acc(train) 0.8815 | Acc(val) 0.8996 |*
Epoch 00045 | Loss(train) 0.6424 | Acc(train) 0.8831 | Acc(val) 0.9015 |*
Epoch 00046 | Loss(train) 0.6288 | Acc(train) 0.8870 | Acc(val) 0.9033 |*
Epoch 00047 | Loss(train) 0.6234 | Acc(train) 0.8870 | Acc(val) 0.9050 |*
Epoch 00048 | Loss(train) 0.6171 | Acc(train) 0.8894 | Acc(val) 0.9060 |*
Epoch 00049 | Loss(train) 0.6101 | Acc(train) 0.8909 | Acc(val) 0.9072 |*
Epoch 00050 | Loss(train) 0.5988 | Acc(train) 0.8923 | Acc(val) 0.9075 |*
Epoch 00051 | Loss(train) 0.5940 | Acc(train) 0.8937 | Acc(val) 0.9083 |*
Epoch 00052 | Loss(train) 0.5873 | Acc(train) 0.8944 | Acc(val) 0.9087 |*
Epoch 00053 | Loss(train) 0.5819 | Acc(train) 0.8960 | Acc(val) 0.9089 |*
Epoch 00054 | Loss(train) 0.5745 | Acc(train) 0.8966 | Acc(val) 0.9100 |*
Epoch 00055 | Loss(train) 0.5688 | Acc(train) 0.8969 | Acc(val) 0.9106 |*
Epoch 00056 | Loss(train) 0.5630 | Acc(train) 0.8973 | Acc(val) 0.9114 |*
Epoch 00057 | Loss(train) 0.5601 | Acc(train) 0.8980 | Acc(val) 0.9123 |*
Epoch 00058 | Loss(train) 0.5515 | Acc(train) 0.8997 | Acc(val) 0.9128 |*
Epoch 00059 | Loss(train) 0.5456 | Acc(train) 0.9003 | Acc(val) 0.9135 |*
Epoch 00060 | Loss(train) 0.5403 | Acc(train) 0.9000 | Acc(val) 0.9135 |
Epoch 00061 | Loss(train) 0.5368 | Acc(train) 0.9000 | Acc(val) 0.9142 |*
Epoch 00062 | Loss(train) 0.5320 | Acc(train) 0.9021 | Acc(val) 0.9149 |*
Epoch 00063 | Loss(train) 0.5277 | Acc(train) 0.9028 | Acc(val) 0.9156 |*
Epoch 00064 | Loss(train) 0.5224 | Acc(train) 0.9029 | Acc(val) 0.9163 |*
Epoch 00065 | Loss(train) 0.5203 | Acc(train) 0.9035 | Acc(val) 0.9171 |*
Epoch 00066 | Loss(train) 0.5183 | Acc(train) 0.9039 | Acc(val) 0.9180 |*
Epoch 00067 | Loss(train) 0.5163 | Acc(train) 0.9056 | Acc(val) 0.9187 |*
Epoch 00068 | Loss(train) 0.5130 | Acc(train) 0.9051 | Acc(val) 0.9189 |*
Epoch 00069 | Loss(train) 0.5111 | Acc(train) 0.9055 | Acc(val) 0.9190 |*
Epoch 00070 | Loss(train) 0.5097 | Acc(train) 0.9066 | Acc(val) 0.9190 |
Epoch 00071 | Loss(train) 0.5064 | Acc(train) 0.9070 | Acc(val) 0.9190 |
Epoch 00072 | Loss(train) 0.5015 | Acc(train) 0.9058 | Acc(val) 0.9193 |*
Epoch 00073 | Loss(train) 0.4974 | Acc(train) 0.9069 | Acc(val) 0.9197 |*
Epoch 00074 | Loss(train) 0.4968 | Acc(train) 0.9084 | Acc(val) 0.9202 |*
Epoch 00075 | Loss(train) 0.4974 | Acc(train) 0.9078 | Acc(val) 0.9203 |*
Epoch 00076 | Loss(train) 0.4912 | Acc(train) 0.9086 | Acc(val) 0.9206 |*
Epoch 00077 | Loss(train) 0.4885 | Acc(train) 0.9075 | Acc(val) 0.9211 |*
Epoch 00078 | Loss(train) 0.4855 | Acc(train) 0.9095 | Acc(val) 0.9214 |*
Epoch 00079 | Loss(train) 0.4838 | Acc(train) 0.9081 | Acc(val) 0.9219 |*
Epoch 00080 | Loss(train) 0.4811 | Acc(train) 0.9096 | Acc(val) 0.9220 |*
Epoch 00081 | Loss(train) 0.4819 | Acc(train) 0.9105 | Acc(val) 0.9221 |*
Epoch 00082 | Loss(train) 0.4804 | Acc(train) 0.9100 | Acc(val) 0.9226 |*
Epoch 00083 | Loss(train) 0.4766 | Acc(train) 0.9103 | Acc(val) 0.9229 |*
Epoch 00084 | Loss(train) 0.4723 | Acc(train) 0.9111 | Acc(val) 0.9228 |
Epoch 00085 | Loss(train) 0.4689 | Acc(train) 0.9122 | Acc(val) 0.9230 |*
Epoch 00086 | Loss(train) 0.4633 | Acc(train) 0.9116 | Acc(val) 0.9231 |*
Epoch 00087 | Loss(train) 0.4709 | Acc(train) 0.9106 | Acc(val) 0.9232 |*
Epoch 00088 | Loss(train) 0.4692 | Acc(train) 0.9108 | Acc(val) 0.9233 |*
Epoch 00089 | Loss(train) 0.4673 | Acc(train) 0.9122 | Acc(val) 0.9232 |
Epoch 00090 | Loss(train) 0.4650 | Acc(train) 0.9122 | Acc(val) 0.9235 |*
Epoch 00091 | Loss(train) 0.4671 | Acc(train) 0.9112 | Acc(val) 0.9236 |*
Epoch 00092 | Loss(train) 0.4589 | Acc(train) 0.9128 | Acc(val) 0.9236 |*
Epoch 00093 | Loss(train) 0.4578 | Acc(train) 0.9122 | Acc(val) 0.9239 |*
Epoch 00094 | Loss(train) 0.4524 | Acc(train) 0.9131 | Acc(val) 0.9239 |
Epoch 00095 | Loss(train) 0.4561 | Acc(train) 0.9127 | Acc(val) 0.9242 |*
Epoch 00096 | Loss(train) 0.4524 | Acc(train) 0.9134 | Acc(val) 0.9243 |*
Epoch 00097 | Loss(train) 0.4577 | Acc(train) 0.9138 | Acc(val) 0.9244 |*
Epoch 00098 | Loss(train) 0.4520 | Acc(train) 0.9143 | Acc(val) 0.9244 |
Epoch 00099 | Loss(train) 0.4499 | Acc(train) 0.9123 | Acc(val) 0.9245 |*
Epoch 00100 | Loss(train) 0.4537 | Acc(train) 0.9131 | Acc(val) 0.9246 |*
Epoch 00101 | Loss(train) 0.4488 | Acc(train) 0.9141 | Acc(val) 0.9250 |*
Epoch 00102 | Loss(train) 0.4466 | Acc(train) 0.9146 | Acc(val) 0.9251 |*
Epoch 00103 | Loss(train) 0.4459 | Acc(train) 0.9142 | Acc(val) 0.9253 |*
Epoch 00104 | Loss(train) 0.4448 | Acc(train) 0.9149 | Acc(val) 0.9256 |*
Epoch 00105 | Loss(train) 0.4433 | Acc(train) 0.9159 | Acc(val) 0.9256 |
Epoch 00106 | Loss(train) 0.4407 | Acc(train) 0.9157 | Acc(val) 0.9258 |*
Epoch 00107 | Loss(train) 0.4403 | Acc(train) 0.9161 | Acc(val) 0.9257 |
Epoch 00108 | Loss(train) 0.4410 | Acc(train) 0.9155 | Acc(val) 0.9260 |*
Epoch 00109 | Loss(train) 0.4391 | Acc(train) 0.9150 | Acc(val) 0.9260 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00110 | Loss(train) 0.4371 | Acc(train) 0.9163 | Acc(val) 0.9262 |*
Epoch 00111 | Loss(train) 0.4368 | Acc(train) 0.9158 | Acc(val) 0.9262 |
Epoch 00112 | Loss(train) 0.4369 | Acc(train) 0.9156 | Acc(val) 0.9263 |*
Epoch 00113 | Loss(train) 0.4322 | Acc(train) 0.9161 | Acc(val) 0.9263 |
Epoch 00114 | Loss(train) 0.4302 | Acc(train) 0.9152 | Acc(val) 0.9263 |
Epoch 00115 | Loss(train) 0.4300 | Acc(train) 0.9157 | Acc(val) 0.9265 |*
Epoch 00116 | Loss(train) 0.4302 | Acc(train) 0.9150 | Acc(val) 0.9266 |*
Epoch 00117 | Loss(train) 0.4330 | Acc(train) 0.9162 | Acc(val) 0.9268 |*
Epoch 00118 | Loss(train) 0.4333 | Acc(train) 0.9158 | Acc(val) 0.9267 |
Epoch 00119 | Loss(train) 0.4247 | Acc(train) 0.9183 | Acc(val) 0.9271 |*
Epoch 00120 | Loss(train) 0.4291 | Acc(train) 0.9169 | Acc(val) 0.9271 |*
Epoch 00121 | Loss(train) 0.4265 | Acc(train) 0.9172 | Acc(val) 0.9273 |*
Epoch 00122 | Loss(train) 0.4216 | Acc(train) 0.9175 | Acc(val) 0.9275 |*
Epoch 00123 | Loss(train) 0.4241 | Acc(train) 0.9176 | Acc(val) 0.9274 |
Epoch 00124 | Loss(train) 0.4262 | Acc(train) 0.9171 | Acc(val) 0.9272 |
Epoch 00125 | Loss(train) 0.4218 | Acc(train) 0.9182 | Acc(val) 0.9269 |
Epoch 00126 | Loss(train) 0.4239 | Acc(train) 0.9169 | Acc(val) 0.9270 |
Epoch 00127 | Loss(train) 0.4209 | Acc(train) 0.9174 | Acc(val) 0.9274 |
Epoch 00128 | Loss(train) 0.4236 | Acc(train) 0.9180 | Acc(val) 0.9274 |
Epoch 00129 | Loss(train) 0.4205 | Acc(train) 0.9187 | Acc(val) 0.9278 |*
Epoch 00130 | Loss(train) 0.4210 | Acc(train) 0.9172 | Acc(val) 0.9281 |*
Epoch 00131 | Loss(train) 0.4152 | Acc(train) 0.9188 | Acc(val) 0.9283 |*
Epoch 00132 | Loss(train) 0.4148 | Acc(train) 0.9193 | Acc(val) 0.9283 |*
Epoch 00133 | Loss(train) 0.4202 | Acc(train) 0.9182 | Acc(val) 0.9281 |
Epoch 00134 | Loss(train) 0.4112 | Acc(train) 0.9189 | Acc(val) 0.9284 |*
Epoch 00135 | Loss(train) 0.4168 | Acc(train) 0.9177 | Acc(val) 0.9284 |
Epoch 00136 | Loss(train) 0.4174 | Acc(train) 0.9170 | Acc(val) 0.9283 |
Epoch 00137 | Loss(train) 0.4154 | Acc(train) 0.9181 | Acc(val) 0.9281 |
Epoch 00138 | Loss(train) 0.4153 | Acc(train) 0.9188 | Acc(val) 0.9281 |
Epoch 00139 | Loss(train) 0.4103 | Acc(train) 0.9196 | Acc(val) 0.9283 |
Epoch 00140 | Loss(train) 0.4112 | Acc(train) 0.9181 | Acc(val) 0.9284 |
Epoch 00141 | Loss(train) 0.4089 | Acc(train) 0.9188 | Acc(val) 0.9287 |*
Epoch 00142 | Loss(train) 0.4094 | Acc(train) 0.9178 | Acc(val) 0.9287 |*
Epoch 00143 | Loss(train) 0.4114 | Acc(train) 0.9192 | Acc(val) 0.9287 |*
Epoch 00144 | Loss(train) 0.4088 | Acc(train) 0.9189 | Acc(val) 0.9287 |
Epoch 00145 | Loss(train) 0.4045 | Acc(train) 0.9203 | Acc(val) 0.9286 |
Epoch 00146 | Loss(train) 0.4080 | Acc(train) 0.9195 | Acc(val) 0.9286 |
Epoch 00147 | Loss(train) 0.4073 | Acc(train) 0.9201 | Acc(val) 0.9284 |
Epoch 00148 | Loss(train) 0.4074 | Acc(train) 0.9193 | Acc(val) 0.9284 |
Epoch 00149 | Loss(train) 0.4034 | Acc(train) 0.9189 | Acc(val) 0.9286 |
Epoch 00150 | Loss(train) 0.4048 | Acc(train) 0.9204 | Acc(val) 0.9288 |*
Epoch 00151 | Loss(train) 0.4061 | Acc(train) 0.9191 | Acc(val) 0.9290 |*
Epoch 00152 | Loss(train) 0.3991 | Acc(train) 0.9195 | Acc(val) 0.9290 |
Epoch 00153 | Loss(train) 0.4030 | Acc(train) 0.9205 | Acc(val) 0.9290 |
Epoch 00154 | Loss(train) 0.3987 | Acc(train) 0.9208 | Acc(val) 0.9291 |*
Epoch 00155 | Loss(train) 0.4012 | Acc(train) 0.9203 | Acc(val) 0.9292 |*
Epoch 00156 | Loss(train) 0.4015 | Acc(train) 0.9201 | Acc(val) 0.9294 |*
Epoch 00157 | Loss(train) 0.4033 | Acc(train) 0.9194 | Acc(val) 0.9295 |*
Epoch 00158 | Loss(train) 0.3990 | Acc(train) 0.9205 | Acc(val) 0.9295 |
Epoch 00159 | Loss(train) 0.3998 | Acc(train) 0.9208 | Acc(val) 0.9295 |
Epoch 00160 | Loss(train) 0.4003 | Acc(train) 0.9193 | Acc(val) 0.9295 |
Epoch 00161 | Loss(train) 0.4005 | Acc(train) 0.9204 | Acc(val) 0.9295 |
Epoch 00162 | Loss(train) 0.3996 | Acc(train) 0.9201 | Acc(val) 0.9294 |
Epoch 00163 | Loss(train) 0.3960 | Acc(train) 0.9204 | Acc(val) 0.9295 |
Epoch 00164 | Loss(train) 0.3958 | Acc(train) 0.9210 | Acc(val) 0.9294 |
Epoch 00165 | Loss(train) 0.3976 | Acc(train) 0.9205 | Acc(val) 0.9294 |
Epoch 00166 | Loss(train) 0.3961 | Acc(train) 0.9205 | Acc(val) 0.9294 |
Epoch 00167 | Loss(train) 0.3983 | Acc(train) 0.9199 | Acc(val) 0.9295 |
Epoch 00168 | Loss(train) 0.3951 | Acc(train) 0.9203 | Acc(val) 0.9294 |
Epoch 00169 | Loss(train) 0.3992 | Acc(train) 0.9197 | Acc(val) 0.9296 |*
Epoch 00170 | Loss(train) 0.3899 | Acc(train) 0.9210 | Acc(val) 0.9296 |
Epoch 00171 | Loss(train) 0.3928 | Acc(train) 0.9216 | Acc(val) 0.9299 |*
Epoch 00172 | Loss(train) 0.3954 | Acc(train) 0.9209 | Acc(val) 0.9298 |
Epoch 00173 | Loss(train) 0.3920 | Acc(train) 0.9211 | Acc(val) 0.9299 |*
Epoch 00174 | Loss(train) 0.3944 | Acc(train) 0.9210 | Acc(val) 0.9297 |
Epoch 00175 | Loss(train) 0.3902 | Acc(train) 0.9222 | Acc(val) 0.9297 |
Epoch 00176 | Loss(train) 0.3893 | Acc(train) 0.9219 | Acc(val) 0.9297 |
Epoch 00177 | Loss(train) 0.3904 | Acc(train) 0.9205 | Acc(val) 0.9301 |*
Epoch 00178 | Loss(train) 0.3895 | Acc(train) 0.9210 | Acc(val) 0.9299 |
Epoch 00179 | Loss(train) 0.3884 | Acc(train) 0.9219 | Acc(val) 0.9300 |
Epoch 00180 | Loss(train) 0.3911 | Acc(train) 0.9205 | Acc(val) 0.9299 |
Epoch 00181 | Loss(train) 0.3877 | Acc(train) 0.9221 | Acc(val) 0.9302 |*
Epoch 00182 | Loss(train) 0.3865 | Acc(train) 0.9205 | Acc(val) 0.9304 |*
Epoch 00183 | Loss(train) 0.3860 | Acc(train) 0.9222 | Acc(val) 0.9302 |
Epoch 00184 | Loss(train) 0.3878 | Acc(train) 0.9219 | Acc(val) 0.9303 |
Epoch 00185 | Loss(train) 0.3866 | Acc(train) 0.9223 | Acc(val) 0.9303 |
Epoch 00186 | Loss(train) 0.3862 | Acc(train) 0.9211 | Acc(val) 0.9303 |
Epoch 00187 | Loss(train) 0.3869 | Acc(train) 0.9218 | Acc(val) 0.9302 |
Epoch 00188 | Loss(train) 0.3842 | Acc(train) 0.9222 | Acc(val) 0.9300 |
Epoch 00189 | Loss(train) 0.3844 | Acc(train) 0.9223 | Acc(val) 0.9302 |
Epoch 00190 | Loss(train) 0.3886 | Acc(train) 0.9221 | Acc(val) 0.9298 |
Epoch 00191 | Loss(train) 0.3858 | Acc(train) 0.9231 | Acc(val) 0.9299 |
Epoch 00192 | Loss(train) 0.3855 | Acc(train) 0.9211 | Acc(val) 0.9301 |
Epoch 00193 | Loss(train) 0.3833 | Acc(train) 0.9230 | Acc(val) 0.9301 |
Epoch 00194 | Loss(train) 0.3844 | Acc(train) 0.9221 | Acc(val) 0.9302 |
Epoch 00195 | Loss(train) 0.3814 | Acc(train) 0.9226 | Acc(val) 0.9304 |
Epoch 00196 | Loss(train) 0.3817 | Acc(train) 0.9223 | Acc(val) 0.9305 |*
Epoch 00197 | Loss(train) 0.3818 | Acc(train) 0.9228 | Acc(val) 0.9306 |*
Epoch 00198 | Loss(train) 0.3770 | Acc(train) 0.9236 | Acc(val) 0.9304 |
Epoch 00199 | Loss(train) 0.3804 | Acc(train) 0.9239 | Acc(val) 0.9304 |
Epoch 00200 | Loss(train) 0.3777 | Acc(train) 0.9233 | Acc(val) 0.9303 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7647 | Acc(train) 0.0290 | Acc(val) 0.1171 |*
Epoch 00002 | Loss(train) 3.4772 | Acc(train) 0.1130 | Acc(val) 0.3189 |*
Epoch 00003 | Loss(train) 3.2731 | Acc(train) 0.3132 | Acc(val) 0.3289 |*
Epoch 00004 | Loss(train) 3.0692 | Acc(train) 0.3247 | Acc(val) 0.3452 |*
Epoch 00005 | Loss(train) 2.8876 | Acc(train) 0.3401 | Acc(val) 0.3722 |*
Epoch 00006 | Loss(train) 2.7248 | Acc(train) 0.3678 | Acc(val) 0.3946 |*
Epoch 00007 | Loss(train) 2.5831 | Acc(train) 0.3908 | Acc(val) 0.4158 |*
Epoch 00008 | Loss(train) 2.4657 | Acc(train) 0.4074 | Acc(val) 0.4228 |*
Epoch 00009 | Loss(train) 2.3503 | Acc(train) 0.4167 | Acc(val) 0.4337 |*
Epoch 00010 | Loss(train) 2.2422 | Acc(train) 0.4279 | Acc(val) 0.4484 |*
Epoch 00011 | Loss(train) 2.1357 | Acc(train) 0.4453 | Acc(val) 0.5074 |*
Epoch 00012 | Loss(train) 2.0292 | Acc(train) 0.5039 | Acc(val) 0.5517 |*
Epoch 00013 | Loss(train) 1.9302 | Acc(train) 0.5511 | Acc(val) 0.6126 |*
Epoch 00014 | Loss(train) 1.8421 | Acc(train) 0.6060 | Acc(val) 0.6674 |*
Epoch 00015 | Loss(train) 1.7482 | Acc(train) 0.6578 | Acc(val) 0.6930 |*
Epoch 00016 | Loss(train) 1.6645 | Acc(train) 0.6858 | Acc(val) 0.7080 |*
Epoch 00017 | Loss(train) 1.5903 | Acc(train) 0.6936 | Acc(val) 0.7178 |*
Epoch 00018 | Loss(train) 1.5155 | Acc(train) 0.7031 | Acc(val) 0.7283 |*
Epoch 00019 | Loss(train) 1.4449 | Acc(train) 0.7135 | Acc(val) 0.7405 |*
Epoch 00020 | Loss(train) 1.3833 | Acc(train) 0.7255 | Acc(val) 0.7505 |*
Epoch 00021 | Loss(train) 1.3215 | Acc(train) 0.7349 | Acc(val) 0.7663 |*
Epoch 00022 | Loss(train) 1.2649 | Acc(train) 0.7516 | Acc(val) 0.7837 |*
Epoch 00023 | Loss(train) 1.2131 | Acc(train) 0.7679 | Acc(val) 0.7920 |*
Epoch 00024 | Loss(train) 1.1666 | Acc(train) 0.7747 | Acc(val) 0.7992 |*
Epoch 00025 | Loss(train) 1.1259 | Acc(train) 0.7821 | Acc(val) 0.8053 |*
Epoch 00026 | Loss(train) 1.0823 | Acc(train) 0.7874 | Acc(val) 0.8099 |*
Epoch 00027 | Loss(train) 1.0433 | Acc(train) 0.7927 | Acc(val) 0.8178 |*
Epoch 00028 | Loss(train) 1.0044 | Acc(train) 0.7995 | Acc(val) 0.8269 |*
Epoch 00029 | Loss(train) 0.9658 | Acc(train) 0.8129 | Acc(val) 0.8326 |*
Epoch 00030 | Loss(train) 0.9347 | Acc(train) 0.8181 | Acc(val) 0.8395 |*
Epoch 00031 | Loss(train) 0.9066 | Acc(train) 0.8200 | Acc(val) 0.8455 |*
Epoch 00032 | Loss(train) 0.8813 | Acc(train) 0.8315 | Acc(val) 0.8493 |*
Epoch 00033 | Loss(train) 0.8576 | Acc(train) 0.8361 | Acc(val) 0.8540 |*
Epoch 00034 | Loss(train) 0.8293 | Acc(train) 0.8397 | Acc(val) 0.8617 |*
Epoch 00035 | Loss(train) 0.8049 | Acc(train) 0.8470 | Acc(val) 0.8697 |*
Epoch 00036 | Loss(train) 0.7857 | Acc(train) 0.8551 | Acc(val) 0.8800 |*
Epoch 00037 | Loss(train) 0.7669 | Acc(train) 0.8620 | Acc(val) 0.8857 |*
Epoch 00038 | Loss(train) 0.7480 | Acc(train) 0.8692 | Acc(val) 0.8896 |*
Epoch 00039 | Loss(train) 0.7328 | Acc(train) 0.8735 | Acc(val) 0.8933 |*
Epoch 00040 | Loss(train) 0.7162 | Acc(train) 0.8781 | Acc(val) 0.8967 |*
Epoch 00041 | Loss(train) 0.7043 | Acc(train) 0.8821 | Acc(val) 0.8982 |*
Epoch 00042 | Loss(train) 0.6858 | Acc(train) 0.8848 | Acc(val) 0.9000 |*
Epoch 00043 | Loss(train) 0.6762 | Acc(train) 0.8854 | Acc(val) 0.9013 |*
Epoch 00044 | Loss(train) 0.6636 | Acc(train) 0.8876 | Acc(val) 0.9020 |*
Epoch 00045 | Loss(train) 0.6521 | Acc(train) 0.8885 | Acc(val) 0.9029 |*
Epoch 00046 | Loss(train) 0.6420 | Acc(train) 0.8882 | Acc(val) 0.9038 |*
Epoch 00047 | Loss(train) 0.6312 | Acc(train) 0.8893 | Acc(val) 0.9051 |*
Epoch 00048 | Loss(train) 0.6194 | Acc(train) 0.8897 | Acc(val) 0.9064 |*
Epoch 00049 | Loss(train) 0.6128 | Acc(train) 0.8922 | Acc(val) 0.9076 |*
Epoch 00050 | Loss(train) 0.6040 | Acc(train) 0.8922 | Acc(val) 0.9089 |*
Epoch 00051 | Loss(train) 0.5963 | Acc(train) 0.8957 | Acc(val) 0.9090 |*
Epoch 00052 | Loss(train) 0.5865 | Acc(train) 0.8957 | Acc(val) 0.9101 |*
Epoch 00053 | Loss(train) 0.5848 | Acc(train) 0.8964 | Acc(val) 0.9102 |*
Epoch 00054 | Loss(train) 0.5792 | Acc(train) 0.8964 | Acc(val) 0.9100 |
Epoch 00055 | Loss(train) 0.5712 | Acc(train) 0.8976 | Acc(val) 0.9101 |
Epoch 00056 | Loss(train) 0.5625 | Acc(train) 0.8981 | Acc(val) 0.9107 |*
Epoch 00057 | Loss(train) 0.5571 | Acc(train) 0.8981 | Acc(val) 0.9113 |*
Epoch 00058 | Loss(train) 0.5573 | Acc(train) 0.8988 | Acc(val) 0.9118 |*
Epoch 00059 | Loss(train) 0.5531 | Acc(train) 0.9000 | Acc(val) 0.9128 |*
Epoch 00060 | Loss(train) 0.5438 | Acc(train) 0.9005 | Acc(val) 0.9137 |*
Epoch 00061 | Loss(train) 0.5439 | Acc(train) 0.9000 | Acc(val) 0.9146 |*
Epoch 00062 | Loss(train) 0.5304 | Acc(train) 0.9025 | Acc(val) 0.9150 |*
Epoch 00063 | Loss(train) 0.5341 | Acc(train) 0.9020 | Acc(val) 0.9153 |*
Epoch 00064 | Loss(train) 0.5271 | Acc(train) 0.9020 | Acc(val) 0.9154 |*
Epoch 00065 | Loss(train) 0.5236 | Acc(train) 0.9039 | Acc(val) 0.9157 |*
Epoch 00066 | Loss(train) 0.5244 | Acc(train) 0.9031 | Acc(val) 0.9159 |*
Epoch 00067 | Loss(train) 0.5198 | Acc(train) 0.9040 | Acc(val) 0.9163 |*
Epoch 00068 | Loss(train) 0.5180 | Acc(train) 0.9028 | Acc(val) 0.9166 |*
Epoch 00069 | Loss(train) 0.5185 | Acc(train) 0.9033 | Acc(val) 0.9168 |*
Epoch 00070 | Loss(train) 0.5085 | Acc(train) 0.9048 | Acc(val) 0.9173 |*
Epoch 00071 | Loss(train) 0.5056 | Acc(train) 0.9043 | Acc(val) 0.9181 |*
Epoch 00072 | Loss(train) 0.5081 | Acc(train) 0.9046 | Acc(val) 0.9185 |*
Epoch 00073 | Loss(train) 0.5016 | Acc(train) 0.9063 | Acc(val) 0.9187 |*
Epoch 00074 | Loss(train) 0.5036 | Acc(train) 0.9058 | Acc(val) 0.9189 |*
Epoch 00075 | Loss(train) 0.5033 | Acc(train) 0.9059 | Acc(val) 0.9193 |*
Epoch 00076 | Loss(train) 0.4973 | Acc(train) 0.9067 | Acc(val) 0.9193 |
Epoch 00077 | Loss(train) 0.4885 | Acc(train) 0.9070 | Acc(val) 0.9192 |
Epoch 00078 | Loss(train) 0.4880 | Acc(train) 0.9070 | Acc(val) 0.9193 |*
Epoch 00079 | Loss(train) 0.4830 | Acc(train) 0.9082 | Acc(val) 0.9193 |
Epoch 00080 | Loss(train) 0.4895 | Acc(train) 0.9086 | Acc(val) 0.9195 |*
Epoch 00081 | Loss(train) 0.4866 | Acc(train) 0.9082 | Acc(val) 0.9197 |*
Epoch 00082 | Loss(train) 0.4815 | Acc(train) 0.9095 | Acc(val) 0.9200 |*
Epoch 00083 | Loss(train) 0.4794 | Acc(train) 0.9078 | Acc(val) 0.9203 |*
Epoch 00084 | Loss(train) 0.4780 | Acc(train) 0.9080 | Acc(val) 0.9208 |*
Epoch 00085 | Loss(train) 0.4775 | Acc(train) 0.9084 | Acc(val) 0.9210 |*
Epoch 00086 | Loss(train) 0.4755 | Acc(train) 0.9094 | Acc(val) 0.9211 |*
Epoch 00087 | Loss(train) 0.4694 | Acc(train) 0.9092 | Acc(val) 0.9214 |*
Epoch 00088 | Loss(train) 0.4724 | Acc(train) 0.9097 | Acc(val) 0.9215 |*
Epoch 00089 | Loss(train) 0.4688 | Acc(train) 0.9096 | Acc(val) 0.9217 |*
Epoch 00090 | Loss(train) 0.4681 | Acc(train) 0.9106 | Acc(val) 0.9218 |*
Epoch 00091 | Loss(train) 0.4676 | Acc(train) 0.9098 | Acc(val) 0.9218 |*
Epoch 00092 | Loss(train) 0.4675 | Acc(train) 0.9096 | Acc(val) 0.9219 |*
Epoch 00093 | Loss(train) 0.4604 | Acc(train) 0.9105 | Acc(val) 0.9221 |*
Epoch 00094 | Loss(train) 0.4638 | Acc(train) 0.9095 | Acc(val) 0.9223 |*
Epoch 00095 | Loss(train) 0.4614 | Acc(train) 0.9100 | Acc(val) 0.9222 |
Epoch 00096 | Loss(train) 0.4615 | Acc(train) 0.9111 | Acc(val) 0.9223 |
Epoch 00097 | Loss(train) 0.4562 | Acc(train) 0.9119 | Acc(val) 0.9225 |*
Epoch 00098 | Loss(train) 0.4562 | Acc(train) 0.9105 | Acc(val) 0.9228 |*
Epoch 00099 | Loss(train) 0.4525 | Acc(train) 0.9122 | Acc(val) 0.9226 |
Epoch 00100 | Loss(train) 0.4480 | Acc(train) 0.9133 | Acc(val) 0.9227 |
Epoch 00101 | Loss(train) 0.4509 | Acc(train) 0.9120 | Acc(val) 0.9229 |*
Epoch 00102 | Loss(train) 0.4532 | Acc(train) 0.9125 | Acc(val) 0.9228 |
Epoch 00103 | Loss(train) 0.4504 | Acc(train) 0.9126 | Acc(val) 0.9229 |*
Epoch 00104 | Loss(train) 0.4493 | Acc(train) 0.9135 | Acc(val) 0.9232 |*
Epoch 00105 | Loss(train) 0.4446 | Acc(train) 0.9120 | Acc(val) 0.9233 |*
Epoch 00106 | Loss(train) 0.4494 | Acc(train) 0.9125 | Acc(val) 0.9235 |*
Epoch 00107 | Loss(train) 0.4457 | Acc(train) 0.9125 | Acc(val) 0.9236 |*
Epoch 00108 | Loss(train) 0.4463 | Acc(train) 0.9131 | Acc(val) 0.9237 |*
Epoch 00109 | Loss(train) 0.4440 | Acc(train) 0.9128 | Acc(val) 0.9241 |*
Epoch 00110 | Loss(train) 0.4448 | Acc(train) 0.9125 | Acc(val) 0.9242 |*
Epoch 00111 | Loss(train) 0.4435 | Acc(train) 0.9132 | Acc(val) 0.9242 |
Epoch 00112 | Loss(train) 0.4386 | Acc(train) 0.9138 | Acc(val) 0.9242 |*
Epoch 00113 | Loss(train) 0.4405 | Acc(train) 0.9134 | Acc(val) 0.9242 |
Epoch 00114 | Loss(train) 0.4380 | Acc(train) 0.9131 | Acc(val) 0.9242 |*
Epoch 00115 | Loss(train) 0.4386 | Acc(train) 0.9145 | Acc(val) 0.9241 |
Epoch 00116 | Loss(train) 0.4376 | Acc(train) 0.9140 | Acc(val) 0.9244 |*
Epoch 00117 | Loss(train) 0.4352 | Acc(train) 0.9149 | Acc(val) 0.9246 |*
Epoch 00118 | Loss(train) 0.4333 | Acc(train) 0.9144 | Acc(val) 0.9245 |
Epoch 00119 | Loss(train) 0.4340 | Acc(train) 0.9131 | Acc(val) 0.9246 |
Epoch 00120 | Loss(train) 0.4329 | Acc(train) 0.9150 | Acc(val) 0.9245 |
Epoch 00121 | Loss(train) 0.4293 | Acc(train) 0.9153 | Acc(val) 0.9248 |*
Epoch 00122 | Loss(train) 0.4275 | Acc(train) 0.9158 | Acc(val) 0.9250 |*
Epoch 00123 | Loss(train) 0.4302 | Acc(train) 0.9147 | Acc(val) 0.9250 |
Epoch 00124 | Loss(train) 0.4290 | Acc(train) 0.9163 | Acc(val) 0.9251 |*
Epoch 00125 | Loss(train) 0.4278 | Acc(train) 0.9165 | Acc(val) 0.9252 |*
Epoch 00126 | Loss(train) 0.4243 | Acc(train) 0.9157 | Acc(val) 0.9256 |*
Epoch 00127 | Loss(train) 0.4254 | Acc(train) 0.9152 | Acc(val) 0.9256 |
Epoch 00128 | Loss(train) 0.4208 | Acc(train) 0.9168 | Acc(val) 0.9256 |*
Epoch 00129 | Loss(train) 0.4221 | Acc(train) 0.9160 | Acc(val) 0.9255 |
Epoch 00130 | Loss(train) 0.4263 | Acc(train) 0.9165 | Acc(val) 0.9257 |*
Epoch 00131 | Loss(train) 0.4196 | Acc(train) 0.9168 | Acc(val) 0.9260 |*
Epoch 00132 | Loss(train) 0.4209 | Acc(train) 0.9175 | Acc(val) 0.9261 |*
Epoch 00133 | Loss(train) 0.4209 | Acc(train) 0.9161 | Acc(val) 0.9263 |*
Epoch 00134 | Loss(train) 0.4216 | Acc(train) 0.9164 | Acc(val) 0.9262 |
Epoch 00135 | Loss(train) 0.4189 | Acc(train) 0.9174 | Acc(val) 0.9262 |
Epoch 00136 | Loss(train) 0.4221 | Acc(train) 0.9164 | Acc(val) 0.9262 |
Epoch 00137 | Loss(train) 0.4217 | Acc(train) 0.9159 | Acc(val) 0.9261 |
Epoch 00138 | Loss(train) 0.4200 | Acc(train) 0.9173 | Acc(val) 0.9261 |
Epoch 00139 | Loss(train) 0.4141 | Acc(train) 0.9170 | Acc(val) 0.9262 |
Epoch 00140 | Loss(train) 0.4172 | Acc(train) 0.9179 | Acc(val) 0.9263 |*
Epoch 00141 | Loss(train) 0.4127 | Acc(train) 0.9181 | Acc(val) 0.9264 |*
Epoch 00142 | Loss(train) 0.4158 | Acc(train) 0.9174 | Acc(val) 0.9267 |*
Epoch 00143 | Loss(train) 0.4102 | Acc(train) 0.9184 | Acc(val) 0.9266 |
Epoch 00144 | Loss(train) 0.4132 | Acc(train) 0.9181 | Acc(val) 0.9268 |*
Epoch 00145 | Loss(train) 0.4132 | Acc(train) 0.9170 | Acc(val) 0.9270 |*
Epoch 00146 | Loss(train) 0.4126 | Acc(train) 0.9175 | Acc(val) 0.9268 |
Epoch 00147 | Loss(train) 0.4053 | Acc(train) 0.9193 | Acc(val) 0.9269 |
Epoch 00148 | Loss(train) 0.4080 | Acc(train) 0.9198 | Acc(val) 0.9270 |
Epoch 00149 | Loss(train) 0.4054 | Acc(train) 0.9192 | Acc(val) 0.9272 |*
Epoch 00150 | Loss(train) 0.4085 | Acc(train) 0.9179 | Acc(val) 0.9271 |
Epoch 00151 | Loss(train) 0.4099 | Acc(train) 0.9182 | Acc(val) 0.9272 |*
Epoch 00152 | Loss(train) 0.4081 | Acc(train) 0.9193 | Acc(val) 0.9272 |
Epoch 00153 | Loss(train) 0.4095 | Acc(train) 0.9175 | Acc(val) 0.9273 |*
Epoch 00154 | Loss(train) 0.4038 | Acc(train) 0.9195 | Acc(val) 0.9272 |
Epoch 00155 | Loss(train) 0.4080 | Acc(train) 0.9180 | Acc(val) 0.9271 |
Epoch 00156 | Loss(train) 0.4059 | Acc(train) 0.9190 | Acc(val) 0.9273 |
Epoch 00157 | Loss(train) 0.4049 | Acc(train) 0.9198 | Acc(val) 0.9272 |
Epoch 00158 | Loss(train) 0.4032 | Acc(train) 0.9199 | Acc(val) 0.9273 |
Epoch 00159 | Loss(train) 0.4014 | Acc(train) 0.9195 | Acc(val) 0.9272 |
Epoch 00160 | Loss(train) 0.4005 | Acc(train) 0.9214 | Acc(val) 0.9272 |
Epoch 00161 | Loss(train) 0.4035 | Acc(train) 0.9189 | Acc(val) 0.9272 |
Epoch 00162 | Loss(train) 0.4047 | Acc(train) 0.9191 | Acc(val) 0.9274 |*
Epoch 00163 | Loss(train) 0.4002 | Acc(train) 0.9199 | Acc(val) 0.9275 |*
Epoch 00164 | Loss(train) 0.4010 | Acc(train) 0.9200 | Acc(val) 0.9276 |*
Epoch 00165 | Loss(train) 0.3983 | Acc(train) 0.9200 | Acc(val) 0.9280 |*
Epoch 00166 | Loss(train) 0.3995 | Acc(train) 0.9198 | Acc(val) 0.9280 |*
Epoch 00167 | Loss(train) 0.3973 | Acc(train) 0.9194 | Acc(val) 0.9281 |*
Epoch 00168 | Loss(train) 0.3979 | Acc(train) 0.9197 | Acc(val) 0.9282 |*
Epoch 00169 | Loss(train) 0.3993 | Acc(train) 0.9195 | Acc(val) 0.9281 |
Epoch 00170 | Loss(train) 0.3980 | Acc(train) 0.9210 | Acc(val) 0.9282 |*
Epoch 00171 | Loss(train) 0.3991 | Acc(train) 0.9192 | Acc(val) 0.9282 |
Epoch 00172 | Loss(train) 0.3944 | Acc(train) 0.9192 | Acc(val) 0.9283 |*
Epoch 00173 | Loss(train) 0.3955 | Acc(train) 0.9203 | Acc(val) 0.9282 |
Epoch 00174 | Loss(train) 0.3972 | Acc(train) 0.9203 | Acc(val) 0.9283 |*
Epoch 00175 | Loss(train) 0.3926 | Acc(train) 0.9201 | Acc(val) 0.9284 |*
Epoch 00176 | Loss(train) 0.3926 | Acc(train) 0.9205 | Acc(val) 0.9285 |*
Epoch 00177 | Loss(train) 0.3924 | Acc(train) 0.9209 | Acc(val) 0.9288 |*
Epoch 00178 | Loss(train) 0.3928 | Acc(train) 0.9208 | Acc(val) 0.9290 |*
Epoch 00179 | Loss(train) 0.3948 | Acc(train) 0.9197 | Acc(val) 0.9290 |*
Epoch 00180 | Loss(train) 0.3916 | Acc(train) 0.9204 | Acc(val) 0.9288 |
Epoch 00181 | Loss(train) 0.3905 | Acc(train) 0.9204 | Acc(val) 0.9285 |
Epoch 00182 | Loss(train) 0.3912 | Acc(train) 0.9210 | Acc(val) 0.9284 |
Epoch 00183 | Loss(train) 0.3895 | Acc(train) 0.9209 | Acc(val) 0.9285 |
Epoch 00184 | Loss(train) 0.3886 | Acc(train) 0.9206 | Acc(val) 0.9286 |
Epoch 00185 | Loss(train) 0.3886 | Acc(train) 0.9213 | Acc(val) 0.9287 |
Epoch 00186 | Loss(train) 0.3859 | Acc(train) 0.9231 | Acc(val) 0.9290 |
Epoch 00187 | Loss(train) 0.3858 | Acc(train) 0.9211 | Acc(val) 0.9292 |*
Epoch 00188 | Loss(train) 0.3871 | Acc(train) 0.9215 | Acc(val) 0.9292 |
Epoch 00189 | Loss(train) 0.3889 | Acc(train) 0.9212 | Acc(val) 0.9290 |
Epoch 00190 | Loss(train) 0.3854 | Acc(train) 0.9220 | Acc(val) 0.9291 |
Epoch 00191 | Loss(train) 0.3845 | Acc(train) 0.9216 | Acc(val) 0.9291 |
Epoch 00192 | Loss(train) 0.3846 | Acc(train) 0.9215 | Acc(val) 0.9293 |*
Epoch 00193 | Loss(train) 0.3841 | Acc(train) 0.9216 | Acc(val) 0.9296 |*
Epoch 00194 | Loss(train) 0.3862 | Acc(train) 0.9207 | Acc(val) 0.9297 |*
Epoch 00195 | Loss(train) 0.3860 | Acc(train) 0.9217 | Acc(val) 0.9299 |*
Epoch 00196 | Loss(train) 0.3842 | Acc(train) 0.9213 | Acc(val) 0.9301 |*
Epoch 00197 | Loss(train) 0.3808 | Acc(train) 0.9221 | Acc(val) 0.9303 |*
Epoch 00198 | Loss(train) 0.3819 | Acc(train) 0.9218 | Acc(val) 0.9299 |
Epoch 00199 | Loss(train) 0.3785 | Acc(train) 0.9226 | Acc(val) 0.9298 |
Epoch 00200 | Loss(train) 0.3835 | Acc(train) 0.9212 | Acc(val) 0.9298 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7853 | Acc(train) 0.0028 | Acc(val) 0.1520 |*
Epoch 00002 | Loss(train) 3.4847 | Acc(train) 0.1500 | Acc(val) 0.1673 |*
Epoch 00003 | Loss(train) 3.3246 | Acc(train) 0.1681 | Acc(val) 0.1992 |*
Epoch 00004 | Loss(train) 3.2057 | Acc(train) 0.2008 | Acc(val) 0.2195 |*
Epoch 00005 | Loss(train) 3.0866 | Acc(train) 0.2192 | Acc(val) 0.2445 |*
Epoch 00006 | Loss(train) 2.9646 | Acc(train) 0.2440 | Acc(val) 0.2754 |*
Epoch 00007 | Loss(train) 2.8483 | Acc(train) 0.2808 | Acc(val) 0.3772 |*
Epoch 00008 | Loss(train) 2.7364 | Acc(train) 0.3759 | Acc(val) 0.4021 |*
Epoch 00009 | Loss(train) 2.6268 | Acc(train) 0.3977 | Acc(val) 0.4479 |*
Epoch 00010 | Loss(train) 2.5192 | Acc(train) 0.4421 | Acc(val) 0.4744 |*
Epoch 00011 | Loss(train) 2.4165 | Acc(train) 0.4700 | Acc(val) 0.5045 |*
Epoch 00012 | Loss(train) 2.3143 | Acc(train) 0.5003 | Acc(val) 0.5193 |*
Epoch 00013 | Loss(train) 2.2166 | Acc(train) 0.5114 | Acc(val) 0.5513 |*
Epoch 00014 | Loss(train) 2.1183 | Acc(train) 0.5448 | Acc(val) 0.5856 |*
Epoch 00015 | Loss(train) 2.0282 | Acc(train) 0.5765 | Acc(val) 0.6165 |*
Epoch 00016 | Loss(train) 1.9382 | Acc(train) 0.6059 | Acc(val) 0.6332 |*
Epoch 00017 | Loss(train) 1.8551 | Acc(train) 0.6207 | Acc(val) 0.6476 |*
Epoch 00018 | Loss(train) 1.7739 | Acc(train) 0.6384 | Acc(val) 0.6615 |*
Epoch 00019 | Loss(train) 1.6976 | Acc(train) 0.6507 | Acc(val) 0.6723 |*
Epoch 00020 | Loss(train) 1.6185 | Acc(train) 0.6611 | Acc(val) 0.6878 |*
Epoch 00021 | Loss(train) 1.5477 | Acc(train) 0.6775 | Acc(val) 0.7112 |*
Epoch 00022 | Loss(train) 1.4766 | Acc(train) 0.7016 | Acc(val) 0.7336 |*
Epoch 00023 | Loss(train) 1.4106 | Acc(train) 0.7214 | Acc(val) 0.7466 |*
Epoch 00024 | Loss(train) 1.3499 | Acc(train) 0.7345 | Acc(val) 0.7540 |*
Epoch 00025 | Loss(train) 1.2897 | Acc(train) 0.7411 | Acc(val) 0.7609 |*
Epoch 00026 | Loss(train) 1.2386 | Acc(train) 0.7456 | Acc(val) 0.7701 |*
Epoch 00027 | Loss(train) 1.1891 | Acc(train) 0.7576 | Acc(val) 0.7856 |*
Epoch 00028 | Loss(train) 1.1455 | Acc(train) 0.7734 | Acc(val) 0.8045 |*
Epoch 00029 | Loss(train) 1.1009 | Acc(train) 0.7922 | Acc(val) 0.8224 |*
Epoch 00030 | Loss(train) 1.0617 | Acc(train) 0.8103 | Acc(val) 0.8392 |*
Epoch 00031 | Loss(train) 1.0227 | Acc(train) 0.8220 | Acc(val) 0.8470 |*
Epoch 00032 | Loss(train) 0.9877 | Acc(train) 0.8335 | Acc(val) 0.8514 |*
Epoch 00033 | Loss(train) 0.9492 | Acc(train) 0.8365 | Acc(val) 0.8518 |*
Epoch 00034 | Loss(train) 0.9179 | Acc(train) 0.8374 | Acc(val) 0.8525 |*
Epoch 00035 | Loss(train) 0.8904 | Acc(train) 0.8360 | Acc(val) 0.8549 |*
Epoch 00036 | Loss(train) 0.8604 | Acc(train) 0.8403 | Acc(val) 0.8582 |*
Epoch 00037 | Loss(train) 0.8385 | Acc(train) 0.8444 | Acc(val) 0.8613 |*
Epoch 00038 | Loss(train) 0.8090 | Acc(train) 0.8497 | Acc(val) 0.8642 |*
Epoch 00039 | Loss(train) 0.7927 | Acc(train) 0.8500 | Acc(val) 0.8683 |*
Epoch 00040 | Loss(train) 0.7712 | Acc(train) 0.8539 | Acc(val) 0.8723 |*
Epoch 00041 | Loss(train) 0.7455 | Acc(train) 0.8589 | Acc(val) 0.8792 |*
Epoch 00042 | Loss(train) 0.7317 | Acc(train) 0.8657 | Acc(val) 0.8854 |*
Epoch 00043 | Loss(train) 0.7097 | Acc(train) 0.8738 | Acc(val) 0.8883 |*
Epoch 00044 | Loss(train) 0.7004 | Acc(train) 0.8748 | Acc(val) 0.8906 |*
Epoch 00045 | Loss(train) 0.6870 | Acc(train) 0.8779 | Acc(val) 0.8923 |*
Epoch 00046 | Loss(train) 0.6755 | Acc(train) 0.8809 | Acc(val) 0.8943 |*
Epoch 00047 | Loss(train) 0.6634 | Acc(train) 0.8818 | Acc(val) 0.8965 |*
Epoch 00048 | Loss(train) 0.6476 | Acc(train) 0.8835 | Acc(val) 0.8987 |*
Epoch 00049 | Loss(train) 0.6439 | Acc(train) 0.8853 | Acc(val) 0.9015 |*
Epoch 00050 | Loss(train) 0.6308 | Acc(train) 0.8884 | Acc(val) 0.9035 |*
Epoch 00051 | Loss(train) 0.6158 | Acc(train) 0.8906 | Acc(val) 0.9049 |*
Epoch 00052 | Loss(train) 0.6081 | Acc(train) 0.8917 | Acc(val) 0.9060 |*
Epoch 00053 | Loss(train) 0.6063 | Acc(train) 0.8927 | Acc(val) 0.9069 |*
Epoch 00054 | Loss(train) 0.5953 | Acc(train) 0.8940 | Acc(val) 0.9077 |*
Epoch 00055 | Loss(train) 0.5875 | Acc(train) 0.8960 | Acc(val) 0.9084 |*
Epoch 00056 | Loss(train) 0.5794 | Acc(train) 0.8966 | Acc(val) 0.9092 |*
Epoch 00057 | Loss(train) 0.5685 | Acc(train) 0.8973 | Acc(val) 0.9096 |*
Epoch 00058 | Loss(train) 0.5660 | Acc(train) 0.8989 | Acc(val) 0.9108 |*
Epoch 00059 | Loss(train) 0.5613 | Acc(train) 0.8989 | Acc(val) 0.9117 |*
Epoch 00060 | Loss(train) 0.5570 | Acc(train) 0.9009 | Acc(val) 0.9124 |*
Epoch 00061 | Loss(train) 0.5497 | Acc(train) 0.9019 | Acc(val) 0.9131 |*
Epoch 00062 | Loss(train) 0.5419 | Acc(train) 0.9017 | Acc(val) 0.9138 |*
Epoch 00063 | Loss(train) 0.5358 | Acc(train) 0.9032 | Acc(val) 0.9142 |*
Epoch 00064 | Loss(train) 0.5352 | Acc(train) 0.9020 | Acc(val) 0.9143 |*
Epoch 00065 | Loss(train) 0.5330 | Acc(train) 0.9030 | Acc(val) 0.9147 |*
Epoch 00066 | Loss(train) 0.5276 | Acc(train) 0.9035 | Acc(val) 0.9152 |*
Epoch 00067 | Loss(train) 0.5273 | Acc(train) 0.9053 | Acc(val) 0.9150 |
Epoch 00068 | Loss(train) 0.5191 | Acc(train) 0.9052 | Acc(val) 0.9156 |*
Epoch 00069 | Loss(train) 0.5135 | Acc(train) 0.9054 | Acc(val) 0.9158 |*
Epoch 00070 | Loss(train) 0.5091 | Acc(train) 0.9064 | Acc(val) 0.9165 |*
Epoch 00071 | Loss(train) 0.5055 | Acc(train) 0.9080 | Acc(val) 0.9169 |*
Epoch 00072 | Loss(train) 0.5044 | Acc(train) 0.9076 | Acc(val) 0.9172 |*
Epoch 00073 | Loss(train) 0.5029 | Acc(train) 0.9074 | Acc(val) 0.9175 |*
Epoch 00074 | Loss(train) 0.5002 | Acc(train) 0.9079 | Acc(val) 0.9177 |*
Epoch 00075 | Loss(train) 0.4990 | Acc(train) 0.9083 | Acc(val) 0.9178 |*
Epoch 00076 | Loss(train) 0.4930 | Acc(train) 0.9078 | Acc(val) 0.9180 |*
Epoch 00077 | Loss(train) 0.4906 | Acc(train) 0.9087 | Acc(val) 0.9184 |*
Epoch 00078 | Loss(train) 0.4860 | Acc(train) 0.9092 | Acc(val) 0.9185 |*
Epoch 00079 | Loss(train) 0.4889 | Acc(train) 0.9087 | Acc(val) 0.9185 |
Epoch 00080 | Loss(train) 0.4845 | Acc(train) 0.9098 | Acc(val) 0.9187 |*
Epoch 00081 | Loss(train) 0.4799 | Acc(train) 0.9101 | Acc(val) 0.9190 |*
Epoch 00082 | Loss(train) 0.4765 | Acc(train) 0.9107 | Acc(val) 0.9190 |
Epoch 00083 | Loss(train) 0.4776 | Acc(train) 0.9107 | Acc(val) 0.9192 |*
Epoch 00084 | Loss(train) 0.4773 | Acc(train) 0.9105 | Acc(val) 0.9193 |*
Epoch 00085 | Loss(train) 0.4697 | Acc(train) 0.9110 | Acc(val) 0.9196 |*
Epoch 00086 | Loss(train) 0.4724 | Acc(train) 0.9094 | Acc(val) 0.9199 |*
Epoch 00087 | Loss(train) 0.4685 | Acc(train) 0.9113 | Acc(val) 0.9203 |*
Epoch 00088 | Loss(train) 0.4687 | Acc(train) 0.9121 | Acc(val) 0.9202 |
Epoch 00089 | Loss(train) 0.4657 | Acc(train) 0.9123 | Acc(val) 0.9205 |*
Epoch 00090 | Loss(train) 0.4629 | Acc(train) 0.9130 | Acc(val) 0.9207 |*
Epoch 00091 | Loss(train) 0.4644 | Acc(train) 0.9117 | Acc(val) 0.9205 |
Epoch 00092 | Loss(train) 0.4592 | Acc(train) 0.9131 | Acc(val) 0.9208 |*
Epoch 00093 | Loss(train) 0.4608 | Acc(train) 0.9117 | Acc(val) 0.9208 |
Epoch 00094 | Loss(train) 0.4573 | Acc(train) 0.9123 | Acc(val) 0.9211 |*
Epoch 00095 | Loss(train) 0.4548 | Acc(train) 0.9122 | Acc(val) 0.9214 |*
Epoch 00096 | Loss(train) 0.4532 | Acc(train) 0.9140 | Acc(val) 0.9216 |*
Epoch 00097 | Loss(train) 0.4526 | Acc(train) 0.9139 | Acc(val) 0.9218 |*
Epoch 00098 | Loss(train) 0.4509 | Acc(train) 0.9142 | Acc(val) 0.9220 |*
Epoch 00099 | Loss(train) 0.4526 | Acc(train) 0.9139 | Acc(val) 0.9223 |*
Epoch 00100 | Loss(train) 0.4509 | Acc(train) 0.9146 | Acc(val) 0.9225 |*
Epoch 00101 | Loss(train) 0.4517 | Acc(train) 0.9140 | Acc(val) 0.9229 |*
Epoch 00102 | Loss(train) 0.4463 | Acc(train) 0.9142 | Acc(val) 0.9231 |*
Epoch 00103 | Loss(train) 0.4448 | Acc(train) 0.9144 | Acc(val) 0.9231 |
Epoch 00104 | Loss(train) 0.4468 | Acc(train) 0.9145 | Acc(val) 0.9232 |*
Epoch 00105 | Loss(train) 0.4432 | Acc(train) 0.9145 | Acc(val) 0.9234 |*
Epoch 00106 | Loss(train) 0.4439 | Acc(train) 0.9149 | Acc(val) 0.9235 |*
Epoch 00107 | Loss(train) 0.4397 | Acc(train) 0.9146 | Acc(val) 0.9235 |
Epoch 00108 | Loss(train) 0.4372 | Acc(train) 0.9152 | Acc(val) 0.9236 |*
Epoch 00109 | Loss(train) 0.4372 | Acc(train) 0.9149 | Acc(val) 0.9240 |*
Epoch 00110 | Loss(train) 0.4365 | Acc(train) 0.9160 | Acc(val) 0.9240 |
Epoch 00111 | Loss(train) 0.4375 | Acc(train) 0.9151 | Acc(val) 0.9238 |
Epoch 00112 | Loss(train) 0.4332 | Acc(train) 0.9161 | Acc(val) 0.9239 |
Epoch 00113 | Loss(train) 0.4302 | Acc(train) 0.9169 | Acc(val) 0.9242 |*
Epoch 00114 | Loss(train) 0.4292 | Acc(train) 0.9170 | Acc(val) 0.9242 |
Epoch 00115 | Loss(train) 0.4290 | Acc(train) 0.9163 | Acc(val) 0.9245 |*
Epoch 00116 | Loss(train) 0.4294 | Acc(train) 0.9156 | Acc(val) 0.9249 |*
Epoch 00117 | Loss(train) 0.4266 | Acc(train) 0.9167 | Acc(val) 0.9249 |*
Epoch 00118 | Loss(train) 0.4228 | Acc(train) 0.9173 | Acc(val) 0.9251 |*
Epoch 00119 | Loss(train) 0.4312 | Acc(train) 0.9159 | Acc(val) 0.9252 |*
Epoch 00120 | Loss(train) 0.4253 | Acc(train) 0.9165 | Acc(val) 0.9256 |*
Epoch 00121 | Loss(train) 0.4268 | Acc(train) 0.9172 | Acc(val) 0.9257 |*
Epoch 00122 | Loss(train) 0.4229 | Acc(train) 0.9164 | Acc(val) 0.9257 |*
Epoch 00123 | Loss(train) 0.4258 | Acc(train) 0.9172 | Acc(val) 0.9259 |*
Epoch 00124 | Loss(train) 0.4209 | Acc(train) 0.9177 | Acc(val) 0.9261 |*
Epoch 00125 | Loss(train) 0.4188 | Acc(train) 0.9171 | Acc(val) 0.9262 |*
Epoch 00126 | Loss(train) 0.4202 | Acc(train) 0.9178 | Acc(val) 0.9265 |*
Epoch 00127 | Loss(train) 0.4175 | Acc(train) 0.9183 | Acc(val) 0.9267 |*
Epoch 00128 | Loss(train) 0.4164 | Acc(train) 0.9184 | Acc(val) 0.9267 |
Epoch 00129 | Loss(train) 0.4174 | Acc(train) 0.9187 | Acc(val) 0.9266 |
Epoch 00130 | Loss(train) 0.4158 | Acc(train) 0.9177 | Acc(val) 0.9267 |
Epoch 00131 | Loss(train) 0.4171 | Acc(train) 0.9173 | Acc(val) 0.9270 |*
Epoch 00132 | Loss(train) 0.4149 | Acc(train) 0.9182 | Acc(val) 0.9269 |
Epoch 00133 | Loss(train) 0.4149 | Acc(train) 0.9190 | Acc(val) 0.9271 |*
Epoch 00134 | Loss(train) 0.4138 | Acc(train) 0.9190 | Acc(val) 0.9271 |
Epoch 00135 | Loss(train) 0.4104 | Acc(train) 0.9191 | Acc(val) 0.9271 |
Epoch 00136 | Loss(train) 0.4096 | Acc(train) 0.9188 | Acc(val) 0.9272 |*
Epoch 00137 | Loss(train) 0.4127 | Acc(train) 0.9186 | Acc(val) 0.9274 |*
Epoch 00138 | Loss(train) 0.4065 | Acc(train) 0.9185 | Acc(val) 0.9275 |*
Epoch 00139 | Loss(train) 0.4090 | Acc(train) 0.9193 | Acc(val) 0.9276 |*
Epoch 00140 | Loss(train) 0.4086 | Acc(train) 0.9193 | Acc(val) 0.9276 |*
Epoch 00141 | Loss(train) 0.4087 | Acc(train) 0.9197 | Acc(val) 0.9281 |*
Epoch 00142 | Loss(train) 0.4063 | Acc(train) 0.9188 | Acc(val) 0.9280 |
Epoch 00143 | Loss(train) 0.4086 | Acc(train) 0.9187 | Acc(val) 0.9278 |
Epoch 00144 | Loss(train) 0.4066 | Acc(train) 0.9199 | Acc(val) 0.9279 |
Epoch 00145 | Loss(train) 0.4045 | Acc(train) 0.9190 | Acc(val) 0.9278 |
Epoch 00146 | Loss(train) 0.4042 | Acc(train) 0.9202 | Acc(val) 0.9276 |
Epoch 00147 | Loss(train) 0.4064 | Acc(train) 0.9204 | Acc(val) 0.9278 |
Epoch 00148 | Loss(train) 0.4026 | Acc(train) 0.9199 | Acc(val) 0.9278 |
Epoch 00149 | Loss(train) 0.3991 | Acc(train) 0.9207 | Acc(val) 0.9282 |*
Epoch 00150 | Loss(train) 0.3976 | Acc(train) 0.9209 | Acc(val) 0.9286 |*
Epoch 00151 | Loss(train) 0.3993 | Acc(train) 0.9199 | Acc(val) 0.9286 |
Epoch 00152 | Loss(train) 0.3998 | Acc(train) 0.9204 | Acc(val) 0.9286 |
Epoch 00153 | Loss(train) 0.3988 | Acc(train) 0.9207 | Acc(val) 0.9286 |
Epoch 00154 | Loss(train) 0.3981 | Acc(train) 0.9202 | Acc(val) 0.9287 |*
Epoch 00155 | Loss(train) 0.4019 | Acc(train) 0.9205 | Acc(val) 0.9290 |*
Epoch 00156 | Loss(train) 0.3959 | Acc(train) 0.9209 | Acc(val) 0.9289 |
Epoch 00157 | Loss(train) 0.3931 | Acc(train) 0.9206 | Acc(val) 0.9287 |
Epoch 00158 | Loss(train) 0.3956 | Acc(train) 0.9211 | Acc(val) 0.9285 |
Epoch 00159 | Loss(train) 0.3958 | Acc(train) 0.9210 | Acc(val) 0.9287 |
Epoch 00160 | Loss(train) 0.3919 | Acc(train) 0.9205 | Acc(val) 0.9289 |
Epoch 00161 | Loss(train) 0.3927 | Acc(train) 0.9207 | Acc(val) 0.9291 |*
Epoch 00162 | Loss(train) 0.3938 | Acc(train) 0.9206 | Acc(val) 0.9293 |*
Epoch 00163 | Loss(train) 0.3915 | Acc(train) 0.9210 | Acc(val) 0.9290 |
Epoch 00164 | Loss(train) 0.3933 | Acc(train) 0.9212 | Acc(val) 0.9292 |
Epoch 00165 | Loss(train) 0.3902 | Acc(train) 0.9220 | Acc(val) 0.9292 |
Epoch 00166 | Loss(train) 0.3896 | Acc(train) 0.9214 | Acc(val) 0.9294 |*
Epoch 00167 | Loss(train) 0.3918 | Acc(train) 0.9205 | Acc(val) 0.9292 |
Epoch 00168 | Loss(train) 0.3883 | Acc(train) 0.9217 | Acc(val) 0.9290 |
Epoch 00169 | Loss(train) 0.3887 | Acc(train) 0.9210 | Acc(val) 0.9293 |
Epoch 00170 | Loss(train) 0.3918 | Acc(train) 0.9207 | Acc(val) 0.9296 |*
Epoch 00171 | Loss(train) 0.3858 | Acc(train) 0.9217 | Acc(val) 0.9295 |
Epoch 00172 | Loss(train) 0.3860 | Acc(train) 0.9214 | Acc(val) 0.9296 |
Epoch 00173 | Loss(train) 0.3871 | Acc(train) 0.9218 | Acc(val) 0.9299 |*
Epoch 00174 | Loss(train) 0.3852 | Acc(train) 0.9223 | Acc(val) 0.9301 |*
Epoch 00175 | Loss(train) 0.3846 | Acc(train) 0.9220 | Acc(val) 0.9301 |
Epoch 00176 | Loss(train) 0.3825 | Acc(train) 0.9231 | Acc(val) 0.9301 |
Epoch 00177 | Loss(train) 0.3827 | Acc(train) 0.9227 | Acc(val) 0.9297 |
Epoch 00178 | Loss(train) 0.3828 | Acc(train) 0.9217 | Acc(val) 0.9296 |
Epoch 00179 | Loss(train) 0.3834 | Acc(train) 0.9227 | Acc(val) 0.9297 |
Epoch 00180 | Loss(train) 0.3832 | Acc(train) 0.9222 | Acc(val) 0.9298 |
Epoch 00181 | Loss(train) 0.3844 | Acc(train) 0.9216 | Acc(val) 0.9299 |
Epoch 00182 | Loss(train) 0.3816 | Acc(train) 0.9234 | Acc(val) 0.9299 |
Epoch 00183 | Loss(train) 0.3813 | Acc(train) 0.9228 | Acc(val) 0.9301 |
Epoch 00184 | Loss(train) 0.3794 | Acc(train) 0.9232 | Acc(val) 0.9304 |*
Epoch 00185 | Loss(train) 0.3824 | Acc(train) 0.9221 | Acc(val) 0.9305 |*
Epoch 00186 | Loss(train) 0.3807 | Acc(train) 0.9225 | Acc(val) 0.9304 |
Epoch 00187 | Loss(train) 0.3800 | Acc(train) 0.9224 | Acc(val) 0.9304 |
Epoch 00188 | Loss(train) 0.3772 | Acc(train) 0.9229 | Acc(val) 0.9302 |
Epoch 00189 | Loss(train) 0.3813 | Acc(train) 0.9224 | Acc(val) 0.9305 |*
Epoch 00190 | Loss(train) 0.3802 | Acc(train) 0.9222 | Acc(val) 0.9304 |
Epoch 00191 | Loss(train) 0.3788 | Acc(train) 0.9222 | Acc(val) 0.9302 |
Epoch 00192 | Loss(train) 0.3792 | Acc(train) 0.9224 | Acc(val) 0.9304 |
Epoch 00193 | Loss(train) 0.3751 | Acc(train) 0.9232 | Acc(val) 0.9307 |*
Epoch 00194 | Loss(train) 0.3762 | Acc(train) 0.9234 | Acc(val) 0.9305 |
Epoch 00195 | Loss(train) 0.3761 | Acc(train) 0.9235 | Acc(val) 0.9306 |
Epoch 00196 | Loss(train) 0.3762 | Acc(train) 0.9226 | Acc(val) 0.9305 |
Epoch 00197 | Loss(train) 0.3763 | Acc(train) 0.9235 | Acc(val) 0.9308 |*
Epoch 00198 | Loss(train) 0.3756 | Acc(train) 0.9231 | Acc(val) 0.9308 |
Epoch 00199 | Loss(train) 0.3755 | Acc(train) 0.9240 | Acc(val) 0.9309 |*
Epoch 00200 | Loss(train) 0.3717 | Acc(train) 0.9240 | Acc(val) 0.9306 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7534 | Acc(train) 0.0280 | Acc(val) 0.1230 |*
Epoch 00002 | Loss(train) 3.4385 | Acc(train) 0.1245 | Acc(val) 0.1640 |*
Epoch 00003 | Loss(train) 3.2978 | Acc(train) 0.1716 | Acc(val) 0.3029 |*
Epoch 00004 | Loss(train) 3.1799 | Acc(train) 0.2961 | Acc(val) 0.4189 |*
Epoch 00005 | Loss(train) 3.0563 | Acc(train) 0.4141 | Acc(val) 0.4517 |*
Epoch 00006 | Loss(train) 2.9289 | Acc(train) 0.4444 | Acc(val) 0.4991 |*
Epoch 00007 | Loss(train) 2.8034 | Acc(train) 0.4891 | Acc(val) 0.5396 |*
Epoch 00008 | Loss(train) 2.6762 | Acc(train) 0.5305 | Acc(val) 0.5531 |*
Epoch 00009 | Loss(train) 2.5484 | Acc(train) 0.5441 | Acc(val) 0.5618 |*
Epoch 00010 | Loss(train) 2.4244 | Acc(train) 0.5553 | Acc(val) 0.5684 |*
Epoch 00011 | Loss(train) 2.3040 | Acc(train) 0.5612 | Acc(val) 0.5736 |*
Epoch 00012 | Loss(train) 2.1820 | Acc(train) 0.5660 | Acc(val) 0.5849 |*
Epoch 00013 | Loss(train) 2.0748 | Acc(train) 0.5786 | Acc(val) 0.5969 |*
Epoch 00014 | Loss(train) 1.9779 | Acc(train) 0.5900 | Acc(val) 0.6096 |*
Epoch 00015 | Loss(train) 1.8846 | Acc(train) 0.6025 | Acc(val) 0.6351 |*
Epoch 00016 | Loss(train) 1.7992 | Acc(train) 0.6270 | Acc(val) 0.6623 |*
Epoch 00017 | Loss(train) 1.7227 | Acc(train) 0.6502 | Acc(val) 0.6800 |*
Epoch 00018 | Loss(train) 1.6430 | Acc(train) 0.6670 | Acc(val) 0.6904 |*
Epoch 00019 | Loss(train) 1.5760 | Acc(train) 0.6763 | Acc(val) 0.6980 |*
Epoch 00020 | Loss(train) 1.5081 | Acc(train) 0.6856 | Acc(val) 0.7094 |*
Epoch 00021 | Loss(train) 1.4423 | Acc(train) 0.6966 | Acc(val) 0.7223 |*
Epoch 00022 | Loss(train) 1.3829 | Acc(train) 0.7120 | Acc(val) 0.7361 |*
Epoch 00023 | Loss(train) 1.3235 | Acc(train) 0.7246 | Acc(val) 0.7475 |*
Epoch 00024 | Loss(train) 1.2726 | Acc(train) 0.7328 | Acc(val) 0.7560 |*
Epoch 00025 | Loss(train) 1.2232 | Acc(train) 0.7419 | Acc(val) 0.7657 |*
Epoch 00026 | Loss(train) 1.1752 | Acc(train) 0.7520 | Acc(val) 0.7808 |*
Epoch 00027 | Loss(train) 1.1332 | Acc(train) 0.7657 | Acc(val) 0.7944 |*
Epoch 00028 | Loss(train) 1.0915 | Acc(train) 0.7813 | Acc(val) 0.8085 |*
Epoch 00029 | Loss(train) 1.0535 | Acc(train) 0.7945 | Acc(val) 0.8207 |*
Epoch 00030 | Loss(train) 1.0167 | Acc(train) 0.8095 | Acc(val) 0.8318 |*
Epoch 00031 | Loss(train) 0.9879 | Acc(train) 0.8187 | Acc(val) 0.8399 |*
Epoch 00032 | Loss(train) 0.9470 | Acc(train) 0.8264 | Acc(val) 0.8477 |*
Epoch 00033 | Loss(train) 0.9219 | Acc(train) 0.8304 | Acc(val) 0.8553 |*
Epoch 00034 | Loss(train) 0.8908 | Acc(train) 0.8402 | Acc(val) 0.8607 |*
Epoch 00035 | Loss(train) 0.8640 | Acc(train) 0.8452 | Acc(val) 0.8626 |*
Epoch 00036 | Loss(train) 0.8422 | Acc(train) 0.8471 | Acc(val) 0.8641 |*
Epoch 00037 | Loss(train) 0.8195 | Acc(train) 0.8481 | Acc(val) 0.8721 |*
Epoch 00038 | Loss(train) 0.7971 | Acc(train) 0.8529 | Acc(val) 0.8748 |*
Epoch 00039 | Loss(train) 0.7772 | Acc(train) 0.8576 | Acc(val) 0.8785 |*
Epoch 00040 | Loss(train) 0.7618 | Acc(train) 0.8609 | Acc(val) 0.8813 |*
Epoch 00041 | Loss(train) 0.7468 | Acc(train) 0.8647 | Acc(val) 0.8828 |*
Epoch 00042 | Loss(train) 0.7231 | Acc(train) 0.8669 | Acc(val) 0.8847 |*
Epoch 00043 | Loss(train) 0.7064 | Acc(train) 0.8681 | Acc(val) 0.8865 |*
Epoch 00044 | Loss(train) 0.6952 | Acc(train) 0.8705 | Acc(val) 0.8883 |*
Epoch 00045 | Loss(train) 0.6851 | Acc(train) 0.8734 | Acc(val) 0.8905 |*
Epoch 00046 | Loss(train) 0.6718 | Acc(train) 0.8749 | Acc(val) 0.8938 |*
Epoch 00047 | Loss(train) 0.6610 | Acc(train) 0.8771 | Acc(val) 0.8965 |*
Epoch 00048 | Loss(train) 0.6523 | Acc(train) 0.8800 | Acc(val) 0.8987 |*
Epoch 00049 | Loss(train) 0.6343 | Acc(train) 0.8825 | Acc(val) 0.9011 |*
Epoch 00050 | Loss(train) 0.6227 | Acc(train) 0.8858 | Acc(val) 0.9028 |*
Epoch 00051 | Loss(train) 0.6193 | Acc(train) 0.8875 | Acc(val) 0.9050 |*
Epoch 00052 | Loss(train) 0.6090 | Acc(train) 0.8912 | Acc(val) 0.9067 |*
Epoch 00053 | Loss(train) 0.5981 | Acc(train) 0.8913 | Acc(val) 0.9078 |*
Epoch 00054 | Loss(train) 0.5936 | Acc(train) 0.8927 | Acc(val) 0.9089 |*
Epoch 00055 | Loss(train) 0.5880 | Acc(train) 0.8953 | Acc(val) 0.9100 |*
Epoch 00056 | Loss(train) 0.5771 | Acc(train) 0.8965 | Acc(val) 0.9103 |*
Epoch 00057 | Loss(train) 0.5708 | Acc(train) 0.8963 | Acc(val) 0.9108 |*
Epoch 00058 | Loss(train) 0.5678 | Acc(train) 0.8975 | Acc(val) 0.9114 |*
Epoch 00059 | Loss(train) 0.5638 | Acc(train) 0.8981 | Acc(val) 0.9120 |*
Epoch 00060 | Loss(train) 0.5505 | Acc(train) 0.8991 | Acc(val) 0.9128 |*
Epoch 00061 | Loss(train) 0.5519 | Acc(train) 0.9000 | Acc(val) 0.9135 |*
Epoch 00062 | Loss(train) 0.5477 | Acc(train) 0.8996 | Acc(val) 0.9144 |*
Epoch 00063 | Loss(train) 0.5362 | Acc(train) 0.9019 | Acc(val) 0.9154 |*
Epoch 00064 | Loss(train) 0.5296 | Acc(train) 0.9024 | Acc(val) 0.9162 |*
Epoch 00065 | Loss(train) 0.5268 | Acc(train) 0.9041 | Acc(val) 0.9169 |*
Epoch 00066 | Loss(train) 0.5236 | Acc(train) 0.9033 | Acc(val) 0.9176 |*
Epoch 00067 | Loss(train) 0.5244 | Acc(train) 0.9042 | Acc(val) 0.9178 |*
Epoch 00068 | Loss(train) 0.5187 | Acc(train) 0.9047 | Acc(val) 0.9182 |*
Epoch 00069 | Loss(train) 0.5129 | Acc(train) 0.9062 | Acc(val) 0.9187 |*
Epoch 00070 | Loss(train) 0.5075 | Acc(train) 0.9069 | Acc(val) 0.9189 |*
Epoch 00071 | Loss(train) 0.5101 | Acc(train) 0.9064 | Acc(val) 0.9194 |*
Epoch 00072 | Loss(train) 0.5032 | Acc(train) 0.9077 | Acc(val) 0.9195 |*
Epoch 00073 | Loss(train) 0.5002 | Acc(train) 0.9073 | Acc(val) 0.9197 |*
Epoch 00074 | Loss(train) 0.4976 | Acc(train) 0.9078 | Acc(val) 0.9200 |*
Epoch 00075 | Loss(train) 0.4980 | Acc(train) 0.9065 | Acc(val) 0.9202 |*
Epoch 00076 | Loss(train) 0.4917 | Acc(train) 0.9094 | Acc(val) 0.9203 |*
Epoch 00077 | Loss(train) 0.4907 | Acc(train) 0.9072 | Acc(val) 0.9205 |*
Epoch 00078 | Loss(train) 0.4896 | Acc(train) 0.9081 | Acc(val) 0.9208 |*
Epoch 00079 | Loss(train) 0.4830 | Acc(train) 0.9098 | Acc(val) 0.9212 |*
Epoch 00080 | Loss(train) 0.4859 | Acc(train) 0.9098 | Acc(val) 0.9217 |*
Epoch 00081 | Loss(train) 0.4780 | Acc(train) 0.9104 | Acc(val) 0.9220 |*
Epoch 00082 | Loss(train) 0.4781 | Acc(train) 0.9102 | Acc(val) 0.9221 |*
Epoch 00083 | Loss(train) 0.4753 | Acc(train) 0.9101 | Acc(val) 0.9226 |*
Epoch 00084 | Loss(train) 0.4733 | Acc(train) 0.9095 | Acc(val) 0.9228 |*
Epoch 00085 | Loss(train) 0.4732 | Acc(train) 0.9111 | Acc(val) 0.9231 |*
Epoch 00086 | Loss(train) 0.4698 | Acc(train) 0.9114 | Acc(val) 0.9230 |
Epoch 00087 | Loss(train) 0.4691 | Acc(train) 0.9124 | Acc(val) 0.9230 |
Epoch 00088 | Loss(train) 0.4662 | Acc(train) 0.9113 | Acc(val) 0.9233 |*
Epoch 00089 | Loss(train) 0.4660 | Acc(train) 0.9106 | Acc(val) 0.9238 |*
Epoch 00090 | Loss(train) 0.4649 | Acc(train) 0.9112 | Acc(val) 0.9238 |
Epoch 00091 | Loss(train) 0.4613 | Acc(train) 0.9109 | Acc(val) 0.9241 |*
Epoch 00092 | Loss(train) 0.4552 | Acc(train) 0.9135 | Acc(val) 0.9243 |*
Epoch 00093 | Loss(train) 0.4560 | Acc(train) 0.9130 | Acc(val) 0.9242 |
Epoch 00094 | Loss(train) 0.4573 | Acc(train) 0.9139 | Acc(val) 0.9245 |*
Epoch 00095 | Loss(train) 0.4576 | Acc(train) 0.9131 | Acc(val) 0.9245 |
Epoch 00096 | Loss(train) 0.4489 | Acc(train) 0.9136 | Acc(val) 0.9245 |*
Epoch 00097 | Loss(train) 0.4506 | Acc(train) 0.9139 | Acc(val) 0.9250 |*
Epoch 00098 | Loss(train) 0.4491 | Acc(train) 0.9139 | Acc(val) 0.9251 |*
Epoch 00099 | Loss(train) 0.4462 | Acc(train) 0.9141 | Acc(val) 0.9252 |*
Epoch 00100 | Loss(train) 0.4511 | Acc(train) 0.9140 | Acc(val) 0.9255 |*
Epoch 00101 | Loss(train) 0.4434 | Acc(train) 0.9150 | Acc(val) 0.9257 |*
Epoch 00102 | Loss(train) 0.4421 | Acc(train) 0.9149 | Acc(val) 0.9257 |
Epoch 00103 | Loss(train) 0.4436 | Acc(train) 0.9144 | Acc(val) 0.9259 |*
Epoch 00104 | Loss(train) 0.4445 | Acc(train) 0.9156 | Acc(val) 0.9260 |*
Epoch 00105 | Loss(train) 0.4393 | Acc(train) 0.9143 | Acc(val) 0.9262 |*
Epoch 00106 | Loss(train) 0.4371 | Acc(train) 0.9154 | Acc(val) 0.9262 |*
Epoch 00107 | Loss(train) 0.4348 | Acc(train) 0.9161 | Acc(val) 0.9265 |*
Epoch 00108 | Loss(train) 0.4332 | Acc(train) 0.9162 | Acc(val) 0.9265 |*
Epoch 00109 | Loss(train) 0.4343 | Acc(train) 0.9158 | Acc(val) 0.9264 |
Epoch 00110 | Loss(train) 0.4336 | Acc(train) 0.9160 | Acc(val) 0.9265 |
Epoch 00111 | Loss(train) 0.4272 | Acc(train) 0.9168 | Acc(val) 0.9265 |
Epoch 00112 | Loss(train) 0.4246 | Acc(train) 0.9163 | Acc(val) 0.9265 |
Epoch 00113 | Loss(train) 0.4345 | Acc(train) 0.9161 | Acc(val) 0.9266 |*
Epoch 00114 | Loss(train) 0.4313 | Acc(train) 0.9161 | Acc(val) 0.9268 |*
Epoch 00115 | Loss(train) 0.4308 | Acc(train) 0.9164 | Acc(val) 0.9270 |*
Epoch 00116 | Loss(train) 0.4291 | Acc(train) 0.9168 | Acc(val) 0.9270 |*
Epoch 00117 | Loss(train) 0.4317 | Acc(train) 0.9157 | Acc(val) 0.9272 |*
Epoch 00118 | Loss(train) 0.4246 | Acc(train) 0.9170 | Acc(val) 0.9274 |*
Epoch 00119 | Loss(train) 0.4229 | Acc(train) 0.9177 | Acc(val) 0.9275 |*
Epoch 00120 | Loss(train) 0.4281 | Acc(train) 0.9167 | Acc(val) 0.9275 |*
Epoch 00121 | Loss(train) 0.4240 | Acc(train) 0.9184 | Acc(val) 0.9275 |
Epoch 00122 | Loss(train) 0.4215 | Acc(train) 0.9170 | Acc(val) 0.9275 |
Epoch 00123 | Loss(train) 0.4244 | Acc(train) 0.9171 | Acc(val) 0.9275 |
Epoch 00124 | Loss(train) 0.4176 | Acc(train) 0.9178 | Acc(val) 0.9275 |
Epoch 00125 | Loss(train) 0.4188 | Acc(train) 0.9187 | Acc(val) 0.9277 |*
Epoch 00126 | Loss(train) 0.4174 | Acc(train) 0.9184 | Acc(val) 0.9278 |*
Epoch 00127 | Loss(train) 0.4163 | Acc(train) 0.9192 | Acc(val) 0.9280 |*
Epoch 00128 | Loss(train) 0.4136 | Acc(train) 0.9189 | Acc(val) 0.9281 |*
Epoch 00129 | Loss(train) 0.4167 | Acc(train) 0.9171 | Acc(val) 0.9282 |*
Epoch 00130 | Loss(train) 0.4144 | Acc(train) 0.9198 | Acc(val) 0.9283 |*
Epoch 00131 | Loss(train) 0.4159 | Acc(train) 0.9187 | Acc(val) 0.9284 |*
Epoch 00132 | Loss(train) 0.4136 | Acc(train) 0.9186 | Acc(val) 0.9284 |*
Epoch 00133 | Loss(train) 0.4172 | Acc(train) 0.9193 | Acc(val) 0.9285 |*
Epoch 00134 | Loss(train) 0.4138 | Acc(train) 0.9189 | Acc(val) 0.9285 |*
Epoch 00135 | Loss(train) 0.4108 | Acc(train) 0.9182 | Acc(val) 0.9286 |*
Epoch 00136 | Loss(train) 0.4122 | Acc(train) 0.9197 | Acc(val) 0.9285 |
Epoch 00137 | Loss(train) 0.4075 | Acc(train) 0.9186 | Acc(val) 0.9287 |*
Epoch 00138 | Loss(train) 0.4113 | Acc(train) 0.9186 | Acc(val) 0.9287 |
Epoch 00139 | Loss(train) 0.4107 | Acc(train) 0.9187 | Acc(val) 0.9291 |*
Epoch 00140 | Loss(train) 0.4127 | Acc(train) 0.9185 | Acc(val) 0.9293 |*
Epoch 00141 | Loss(train) 0.4061 | Acc(train) 0.9196 | Acc(val) 0.9293 |*
Epoch 00142 | Loss(train) 0.4063 | Acc(train) 0.9201 | Acc(val) 0.9293 |
Epoch 00143 | Loss(train) 0.4075 | Acc(train) 0.9194 | Acc(val) 0.9292 |
Epoch 00144 | Loss(train) 0.4071 | Acc(train) 0.9192 | Acc(val) 0.9294 |*
Epoch 00145 | Loss(train) 0.4053 | Acc(train) 0.9196 | Acc(val) 0.9292 |
Epoch 00146 | Loss(train) 0.4054 | Acc(train) 0.9198 | Acc(val) 0.9290 |
Epoch 00147 | Loss(train) 0.4051 | Acc(train) 0.9196 | Acc(val) 0.9290 |
Epoch 00148 | Loss(train) 0.4021 | Acc(train) 0.9193 | Acc(val) 0.9293 |
Epoch 00149 | Loss(train) 0.4013 | Acc(train) 0.9205 | Acc(val) 0.9297 |*
Epoch 00150 | Loss(train) 0.4028 | Acc(train) 0.9199 | Acc(val) 0.9295 |
Epoch 00151 | Loss(train) 0.4025 | Acc(train) 0.9198 | Acc(val) 0.9296 |
Epoch 00152 | Loss(train) 0.4013 | Acc(train) 0.9201 | Acc(val) 0.9298 |*
Epoch 00153 | Loss(train) 0.4031 | Acc(train) 0.9206 | Acc(val) 0.9297 |
Epoch 00154 | Loss(train) 0.4027 | Acc(train) 0.9189 | Acc(val) 0.9299 |*
Epoch 00155 | Loss(train) 0.4023 | Acc(train) 0.9212 | Acc(val) 0.9297 |
Epoch 00156 | Loss(train) 0.3968 | Acc(train) 0.9209 | Acc(val) 0.9298 |
Epoch 00157 | Loss(train) 0.4011 | Acc(train) 0.9204 | Acc(val) 0.9299 |
Epoch 00158 | Loss(train) 0.3973 | Acc(train) 0.9202 | Acc(val) 0.9297 |
Epoch 00159 | Loss(train) 0.3952 | Acc(train) 0.9217 | Acc(val) 0.9297 |
Epoch 00160 | Loss(train) 0.3943 | Acc(train) 0.9209 | Acc(val) 0.9299 |
Epoch 00161 | Loss(train) 0.3918 | Acc(train) 0.9222 | Acc(val) 0.9300 |*
Epoch 00162 | Loss(train) 0.3916 | Acc(train) 0.9213 | Acc(val) 0.9303 |*
Epoch 00163 | Loss(train) 0.3934 | Acc(train) 0.9209 | Acc(val) 0.9302 |
Epoch 00164 | Loss(train) 0.3907 | Acc(train) 0.9216 | Acc(val) 0.9304 |*
Epoch 00165 | Loss(train) 0.3876 | Acc(train) 0.9219 | Acc(val) 0.9305 |*
Epoch 00166 | Loss(train) 0.3915 | Acc(train) 0.9217 | Acc(val) 0.9304 |
Epoch 00167 | Loss(train) 0.3973 | Acc(train) 0.9208 | Acc(val) 0.9302 |
Epoch 00168 | Loss(train) 0.3937 | Acc(train) 0.9218 | Acc(val) 0.9301 |
Epoch 00169 | Loss(train) 0.3892 | Acc(train) 0.9217 | Acc(val) 0.9302 |
Epoch 00170 | Loss(train) 0.3899 | Acc(train) 0.9212 | Acc(val) 0.9306 |*
Epoch 00171 | Loss(train) 0.3886 | Acc(train) 0.9221 | Acc(val) 0.9307 |*
Epoch 00172 | Loss(train) 0.3860 | Acc(train) 0.9223 | Acc(val) 0.9308 |*
Epoch 00173 | Loss(train) 0.3900 | Acc(train) 0.9222 | Acc(val) 0.9308 |
Epoch 00174 | Loss(train) 0.3882 | Acc(train) 0.9213 | Acc(val) 0.9309 |*
Epoch 00175 | Loss(train) 0.3858 | Acc(train) 0.9220 | Acc(val) 0.9309 |*
Epoch 00176 | Loss(train) 0.3841 | Acc(train) 0.9216 | Acc(val) 0.9308 |
Epoch 00177 | Loss(train) 0.3860 | Acc(train) 0.9224 | Acc(val) 0.9306 |
Epoch 00178 | Loss(train) 0.3848 | Acc(train) 0.9227 | Acc(val) 0.9306 |
Epoch 00179 | Loss(train) 0.3852 | Acc(train) 0.9230 | Acc(val) 0.9304 |
Epoch 00180 | Loss(train) 0.3860 | Acc(train) 0.9220 | Acc(val) 0.9305 |
Epoch 00181 | Loss(train) 0.3841 | Acc(train) 0.9219 | Acc(val) 0.9308 |
Epoch 00182 | Loss(train) 0.3828 | Acc(train) 0.9222 | Acc(val) 0.9310 |*
Epoch 00183 | Loss(train) 0.3834 | Acc(train) 0.9228 | Acc(val) 0.9311 |*
Epoch 00184 | Loss(train) 0.3831 | Acc(train) 0.9227 | Acc(val) 0.9311 |*
Epoch 00185 | Loss(train) 0.3815 | Acc(train) 0.9227 | Acc(val) 0.9311 |
Epoch 00186 | Loss(train) 0.3825 | Acc(train) 0.9225 | Acc(val) 0.9311 |
Epoch 00187 | Loss(train) 0.3817 | Acc(train) 0.9230 | Acc(val) 0.9310 |
Epoch 00188 | Loss(train) 0.3820 | Acc(train) 0.9222 | Acc(val) 0.9309 |
Epoch 00189 | Loss(train) 0.3794 | Acc(train) 0.9235 | Acc(val) 0.9306 |
Epoch 00190 | Loss(train) 0.3779 | Acc(train) 0.9225 | Acc(val) 0.9308 |
Epoch 00191 | Loss(train) 0.3794 | Acc(train) 0.9221 | Acc(val) 0.9312 |*
Epoch 00192 | Loss(train) 0.3783 | Acc(train) 0.9240 | Acc(val) 0.9312 |
Epoch 00193 | Loss(train) 0.3776 | Acc(train) 0.9226 | Acc(val) 0.9311 |
Epoch 00194 | Loss(train) 0.3782 | Acc(train) 0.9225 | Acc(val) 0.9312 |
Epoch 00195 | Loss(train) 0.3795 | Acc(train) 0.9231 | Acc(val) 0.9312 |*
Epoch 00196 | Loss(train) 0.3750 | Acc(train) 0.9241 | Acc(val) 0.9313 |*
Epoch 00197 | Loss(train) 0.3749 | Acc(train) 0.9241 | Acc(val) 0.9314 |*
Epoch 00198 | Loss(train) 0.3768 | Acc(train) 0.9233 | Acc(val) 0.9312 |
Epoch 00199 | Loss(train) 0.3748 | Acc(train) 0.9239 | Acc(val) 0.9313 |
Epoch 00200 | Loss(train) 0.3778 | Acc(train) 0.9220 | Acc(val) 0.9313 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.6883 | Acc(train) 0.0107 | Acc(val) 0.2583 |*
Epoch 00002 | Loss(train) 3.4247 | Acc(train) 0.2536 | Acc(val) 0.2875 |*
Epoch 00003 | Loss(train) 3.2006 | Acc(train) 0.2821 | Acc(val) 0.3094 |*
Epoch 00004 | Loss(train) 3.0116 | Acc(train) 0.3049 | Acc(val) 0.3221 |*
Epoch 00005 | Loss(train) 2.8265 | Acc(train) 0.3160 | Acc(val) 0.3655 |*
Epoch 00006 | Loss(train) 2.6566 | Acc(train) 0.3664 | Acc(val) 0.4757 |*
Epoch 00007 | Loss(train) 2.5035 | Acc(train) 0.4669 | Acc(val) 0.5236 |*
Epoch 00008 | Loss(train) 2.3608 | Acc(train) 0.5158 | Acc(val) 0.5650 |*
Epoch 00009 | Loss(train) 2.2282 | Acc(train) 0.5592 | Acc(val) 0.5901 |*
Epoch 00010 | Loss(train) 2.1150 | Acc(train) 0.5820 | Acc(val) 0.6057 |*
Epoch 00011 | Loss(train) 2.0107 | Acc(train) 0.5947 | Acc(val) 0.6148 |*
Epoch 00012 | Loss(train) 1.9184 | Acc(train) 0.6056 | Acc(val) 0.6314 |*
Epoch 00013 | Loss(train) 1.8283 | Acc(train) 0.6211 | Acc(val) 0.6403 |*
Epoch 00014 | Loss(train) 1.7532 | Acc(train) 0.6316 | Acc(val) 0.6502 |*
Epoch 00015 | Loss(train) 1.6794 | Acc(train) 0.6417 | Acc(val) 0.6682 |*
Epoch 00016 | Loss(train) 1.6037 | Acc(train) 0.6613 | Acc(val) 0.6769 |*
Epoch 00017 | Loss(train) 1.5382 | Acc(train) 0.6690 | Acc(val) 0.6886 |*
Epoch 00018 | Loss(train) 1.4716 | Acc(train) 0.6829 | Acc(val) 0.7021 |*
Epoch 00019 | Loss(train) 1.4060 | Acc(train) 0.6939 | Acc(val) 0.7201 |*
Epoch 00020 | Loss(train) 1.3470 | Acc(train) 0.7117 | Acc(val) 0.7386 |*
Epoch 00021 | Loss(train) 1.2881 | Acc(train) 0.7290 | Acc(val) 0.7625 |*
Epoch 00022 | Loss(train) 1.2342 | Acc(train) 0.7490 | Acc(val) 0.7846 |*
Epoch 00023 | Loss(train) 1.1836 | Acc(train) 0.7710 | Acc(val) 0.8022 |*
Epoch 00024 | Loss(train) 1.1346 | Acc(train) 0.7895 | Acc(val) 0.8145 |*
Epoch 00025 | Loss(train) 1.0916 | Acc(train) 0.7997 | Acc(val) 0.8194 |*
Epoch 00026 | Loss(train) 1.0482 | Acc(train) 0.8030 | Acc(val) 0.8271 |*
Epoch 00027 | Loss(train) 1.0115 | Acc(train) 0.8150 | Acc(val) 0.8383 |*
Epoch 00028 | Loss(train) 0.9689 | Acc(train) 0.8241 | Acc(val) 0.8462 |*
Epoch 00029 | Loss(train) 0.9390 | Acc(train) 0.8345 | Acc(val) 0.8536 |*
Epoch 00030 | Loss(train) 0.9099 | Acc(train) 0.8415 | Acc(val) 0.8562 |*
Epoch 00031 | Loss(train) 0.8809 | Acc(train) 0.8441 | Acc(val) 0.8600 |*
Epoch 00032 | Loss(train) 0.8552 | Acc(train) 0.8478 | Acc(val) 0.8639 |*
Epoch 00033 | Loss(train) 0.8349 | Acc(train) 0.8497 | Acc(val) 0.8692 |*
Epoch 00034 | Loss(train) 0.8075 | Acc(train) 0.8583 | Acc(val) 0.8767 |*
Epoch 00035 | Loss(train) 0.7868 | Acc(train) 0.8635 | Acc(val) 0.8815 |*
Epoch 00036 | Loss(train) 0.7694 | Acc(train) 0.8675 | Acc(val) 0.8856 |*
Epoch 00037 | Loss(train) 0.7507 | Acc(train) 0.8705 | Acc(val) 0.8869 |*
Epoch 00038 | Loss(train) 0.7328 | Acc(train) 0.8708 | Acc(val) 0.8894 |*
Epoch 00039 | Loss(train) 0.7187 | Acc(train) 0.8740 | Acc(val) 0.8905 |*
Epoch 00040 | Loss(train) 0.7095 | Acc(train) 0.8770 | Acc(val) 0.8924 |*
Epoch 00041 | Loss(train) 0.6981 | Acc(train) 0.8756 | Acc(val) 0.8938 |*
Epoch 00042 | Loss(train) 0.6814 | Acc(train) 0.8795 | Acc(val) 0.8956 |*
Epoch 00043 | Loss(train) 0.6666 | Acc(train) 0.8823 | Acc(val) 0.8978 |*
Epoch 00044 | Loss(train) 0.6631 | Acc(train) 0.8831 | Acc(val) 0.8993 |*
Epoch 00045 | Loss(train) 0.6466 | Acc(train) 0.8867 | Acc(val) 0.9002 |*
Epoch 00046 | Loss(train) 0.6340 | Acc(train) 0.8877 | Acc(val) 0.9017 |*
Epoch 00047 | Loss(train) 0.6273 | Acc(train) 0.8888 | Acc(val) 0.9037 |*
Epoch 00048 | Loss(train) 0.6197 | Acc(train) 0.8892 | Acc(val) 0.9049 |*
Epoch 00049 | Loss(train) 0.6143 | Acc(train) 0.8918 | Acc(val) 0.9059 |*
Epoch 00050 | Loss(train) 0.5971 | Acc(train) 0.8944 | Acc(val) 0.9067 |*
Epoch 00051 | Loss(train) 0.5999 | Acc(train) 0.8933 | Acc(val) 0.9072 |*
Epoch 00052 | Loss(train) 0.5899 | Acc(train) 0.8938 | Acc(val) 0.9076 |*
Epoch 00053 | Loss(train) 0.5753 | Acc(train) 0.8961 | Acc(val) 0.9087 |*
Epoch 00054 | Loss(train) 0.5788 | Acc(train) 0.8962 | Acc(val) 0.9095 |*
Epoch 00055 | Loss(train) 0.5663 | Acc(train) 0.8980 | Acc(val) 0.9099 |*
Epoch 00056 | Loss(train) 0.5653 | Acc(train) 0.8984 | Acc(val) 0.9108 |*
Epoch 00057 | Loss(train) 0.5527 | Acc(train) 0.8986 | Acc(val) 0.9119 |*
Epoch 00058 | Loss(train) 0.5493 | Acc(train) 0.8992 | Acc(val) 0.9123 |*
Epoch 00059 | Loss(train) 0.5509 | Acc(train) 0.8994 | Acc(val) 0.9130 |*
Epoch 00060 | Loss(train) 0.5409 | Acc(train) 0.8994 | Acc(val) 0.9135 |*
Epoch 00061 | Loss(train) 0.5422 | Acc(train) 0.9019 | Acc(val) 0.9143 |*
Epoch 00062 | Loss(train) 0.5349 | Acc(train) 0.9028 | Acc(val) 0.9145 |*
Epoch 00063 | Loss(train) 0.5272 | Acc(train) 0.9041 | Acc(val) 0.9150 |*
Epoch 00064 | Loss(train) 0.5230 | Acc(train) 0.9042 | Acc(val) 0.9155 |*
Epoch 00065 | Loss(train) 0.5213 | Acc(train) 0.9017 | Acc(val) 0.9163 |*
Epoch 00066 | Loss(train) 0.5180 | Acc(train) 0.9034 | Acc(val) 0.9164 |*
Epoch 00067 | Loss(train) 0.5155 | Acc(train) 0.9046 | Acc(val) 0.9167 |*
Epoch 00068 | Loss(train) 0.5114 | Acc(train) 0.9056 | Acc(val) 0.9172 |*
Epoch 00069 | Loss(train) 0.5049 | Acc(train) 0.9060 | Acc(val) 0.9173 |*
Epoch 00070 | Loss(train) 0.5070 | Acc(train) 0.9057 | Acc(val) 0.9173 |
Epoch 00071 | Loss(train) 0.5041 | Acc(train) 0.9067 | Acc(val) 0.9175 |*
Epoch 00072 | Loss(train) 0.5015 | Acc(train) 0.9058 | Acc(val) 0.9179 |*
Epoch 00073 | Loss(train) 0.4999 | Acc(train) 0.9057 | Acc(val) 0.9184 |*
Epoch 00074 | Loss(train) 0.4914 | Acc(train) 0.9066 | Acc(val) 0.9189 |*
Epoch 00075 | Loss(train) 0.4892 | Acc(train) 0.9069 | Acc(val) 0.9190 |*
Epoch 00076 | Loss(train) 0.4881 | Acc(train) 0.9074 | Acc(val) 0.9194 |*
Epoch 00077 | Loss(train) 0.4859 | Acc(train) 0.9091 | Acc(val) 0.9196 |*
Epoch 00078 | Loss(train) 0.4890 | Acc(train) 0.9073 | Acc(val) 0.9196 |*
Epoch 00079 | Loss(train) 0.4832 | Acc(train) 0.9097 | Acc(val) 0.9199 |*
Epoch 00080 | Loss(train) 0.4782 | Acc(train) 0.9081 | Acc(val) 0.9201 |*
Epoch 00081 | Loss(train) 0.4764 | Acc(train) 0.9094 | Acc(val) 0.9204 |*
Epoch 00082 | Loss(train) 0.4773 | Acc(train) 0.9096 | Acc(val) 0.9205 |*
Epoch 00083 | Loss(train) 0.4780 | Acc(train) 0.9094 | Acc(val) 0.9207 |*
Epoch 00084 | Loss(train) 0.4740 | Acc(train) 0.9091 | Acc(val) 0.9209 |*
Epoch 00085 | Loss(train) 0.4713 | Acc(train) 0.9097 | Acc(val) 0.9209 |
Epoch 00086 | Loss(train) 0.4716 | Acc(train) 0.9103 | Acc(val) 0.9208 |
Epoch 00087 | Loss(train) 0.4687 | Acc(train) 0.9108 | Acc(val) 0.9213 |*
Epoch 00088 | Loss(train) 0.4632 | Acc(train) 0.9109 | Acc(val) 0.9215 |*
Epoch 00089 | Loss(train) 0.4630 | Acc(train) 0.9105 | Acc(val) 0.9220 |*
Epoch 00090 | Loss(train) 0.4630 | Acc(train) 0.9124 | Acc(val) 0.9219 |
Epoch 00091 | Loss(train) 0.4609 | Acc(train) 0.9107 | Acc(val) 0.9220 |*
Epoch 00092 | Loss(train) 0.4590 | Acc(train) 0.9119 | Acc(val) 0.9223 |*
Epoch 00093 | Loss(train) 0.4581 | Acc(train) 0.9121 | Acc(val) 0.9221 |
Epoch 00094 | Loss(train) 0.4565 | Acc(train) 0.9121 | Acc(val) 0.9223 |
Epoch 00095 | Loss(train) 0.4528 | Acc(train) 0.9131 | Acc(val) 0.9224 |*
Epoch 00096 | Loss(train) 0.4540 | Acc(train) 0.9132 | Acc(val) 0.9223 |
Epoch 00097 | Loss(train) 0.4549 | Acc(train) 0.9127 | Acc(val) 0.9226 |*
Epoch 00098 | Loss(train) 0.4491 | Acc(train) 0.9131 | Acc(val) 0.9224 |
Epoch 00099 | Loss(train) 0.4474 | Acc(train) 0.9124 | Acc(val) 0.9227 |*
Epoch 00100 | Loss(train) 0.4488 | Acc(train) 0.9130 | Acc(val) 0.9231 |*
Epoch 00101 | Loss(train) 0.4457 | Acc(train) 0.9133 | Acc(val) 0.9232 |*
Epoch 00102 | Loss(train) 0.4467 | Acc(train) 0.9134 | Acc(val) 0.9234 |*
Epoch 00103 | Loss(train) 0.4428 | Acc(train) 0.9140 | Acc(val) 0.9235 |*
Epoch 00104 | Loss(train) 0.4412 | Acc(train) 0.9138 | Acc(val) 0.9232 |
Epoch 00105 | Loss(train) 0.4428 | Acc(train) 0.9137 | Acc(val) 0.9236 |*
Epoch 00106 | Loss(train) 0.4398 | Acc(train) 0.9147 | Acc(val) 0.9237 |*
Epoch 00107 | Loss(train) 0.4376 | Acc(train) 0.9151 | Acc(val) 0.9240 |*
Epoch 00108 | Loss(train) 0.4387 | Acc(train) 0.9145 | Acc(val) 0.9239 |
Epoch 00109 | Loss(train) 0.4369 | Acc(train) 0.9146 | Acc(val) 0.9242 |*
Epoch 00110 | Loss(train) 0.4303 | Acc(train) 0.9143 | Acc(val) 0.9242 |*
Epoch 00111 | Loss(train) 0.4372 | Acc(train) 0.9152 | Acc(val) 0.9245 |*
Epoch 00112 | Loss(train) 0.4338 | Acc(train) 0.9153 | Acc(val) 0.9244 |
Epoch 00113 | Loss(train) 0.4377 | Acc(train) 0.9143 | Acc(val) 0.9245 |*
Epoch 00114 | Loss(train) 0.4268 | Acc(train) 0.9170 | Acc(val) 0.9246 |*
Epoch 00115 | Loss(train) 0.4307 | Acc(train) 0.9159 | Acc(val) 0.9246 |
Epoch 00116 | Loss(train) 0.4313 | Acc(train) 0.9157 | Acc(val) 0.9247 |*
Epoch 00117 | Loss(train) 0.4244 | Acc(train) 0.9169 | Acc(val) 0.9246 |
Epoch 00118 | Loss(train) 0.4269 | Acc(train) 0.9157 | Acc(val) 0.9248 |*
Epoch 00119 | Loss(train) 0.4297 | Acc(train) 0.9171 | Acc(val) 0.9248 |
Epoch 00120 | Loss(train) 0.4270 | Acc(train) 0.9159 | Acc(val) 0.9249 |*
Epoch 00121 | Loss(train) 0.4284 | Acc(train) 0.9157 | Acc(val) 0.9249 |*
Epoch 00122 | Loss(train) 0.4242 | Acc(train) 0.9169 | Acc(val) 0.9250 |*
Epoch 00123 | Loss(train) 0.4253 | Acc(train) 0.9173 | Acc(val) 0.9248 |
Epoch 00124 | Loss(train) 0.4223 | Acc(train) 0.9172 | Acc(val) 0.9251 |*
Epoch 00125 | Loss(train) 0.4171 | Acc(train) 0.9172 | Acc(val) 0.9251 |
Epoch 00126 | Loss(train) 0.4227 | Acc(train) 0.9181 | Acc(val) 0.9252 |*
Epoch 00127 | Loss(train) 0.4187 | Acc(train) 0.9176 | Acc(val) 0.9253 |*
Epoch 00128 | Loss(train) 0.4190 | Acc(train) 0.9165 | Acc(val) 0.9256 |*
Epoch 00129 | Loss(train) 0.4165 | Acc(train) 0.9177 | Acc(val) 0.9259 |*
Epoch 00130 | Loss(train) 0.4197 | Acc(train) 0.9182 | Acc(val) 0.9259 |*
Epoch 00131 | Loss(train) 0.4154 | Acc(train) 0.9180 | Acc(val) 0.9259 |
Epoch 00132 | Loss(train) 0.4205 | Acc(train) 0.9177 | Acc(val) 0.9260 |*
Epoch 00133 | Loss(train) 0.4130 | Acc(train) 0.9181 | Acc(val) 0.9262 |*
Epoch 00134 | Loss(train) 0.4134 | Acc(train) 0.9184 | Acc(val) 0.9265 |*
Epoch 00135 | Loss(train) 0.4127 | Acc(train) 0.9180 | Acc(val) 0.9265 |*
Epoch 00136 | Loss(train) 0.4141 | Acc(train) 0.9186 | Acc(val) 0.9267 |*
Epoch 00137 | Loss(train) 0.4090 | Acc(train) 0.9185 | Acc(val) 0.9268 |*
Epoch 00138 | Loss(train) 0.4105 | Acc(train) 0.9191 | Acc(val) 0.9267 |
Epoch 00139 | Loss(train) 0.4109 | Acc(train) 0.9182 | Acc(val) 0.9267 |
Epoch 00140 | Loss(train) 0.4117 | Acc(train) 0.9181 | Acc(val) 0.9268 |
Epoch 00141 | Loss(train) 0.4083 | Acc(train) 0.9190 | Acc(val) 0.9269 |*
Epoch 00142 | Loss(train) 0.4049 | Acc(train) 0.9188 | Acc(val) 0.9271 |*
Epoch 00143 | Loss(train) 0.4088 | Acc(train) 0.9187 | Acc(val) 0.9272 |*
Epoch 00144 | Loss(train) 0.4088 | Acc(train) 0.9192 | Acc(val) 0.9272 |
Epoch 00145 | Loss(train) 0.4051 | Acc(train) 0.9186 | Acc(val) 0.9272 |
Epoch 00146 | Loss(train) 0.4043 | Acc(train) 0.9192 | Acc(val) 0.9270 |
Epoch 00147 | Loss(train) 0.4065 | Acc(train) 0.9192 | Acc(val) 0.9270 |
Epoch 00148 | Loss(train) 0.4043 | Acc(train) 0.9196 | Acc(val) 0.9272 |
Epoch 00149 | Loss(train) 0.4008 | Acc(train) 0.9201 | Acc(val) 0.9272 |
Epoch 00150 | Loss(train) 0.4079 | Acc(train) 0.9185 | Acc(val) 0.9275 |*
Epoch 00151 | Loss(train) 0.4026 | Acc(train) 0.9203 | Acc(val) 0.9276 |*
Epoch 00152 | Loss(train) 0.4029 | Acc(train) 0.9189 | Acc(val) 0.9277 |*
Epoch 00153 | Loss(train) 0.3978 | Acc(train) 0.9208 | Acc(val) 0.9278 |*
Epoch 00154 | Loss(train) 0.4022 | Acc(train) 0.9196 | Acc(val) 0.9278 |*
Epoch 00155 | Loss(train) 0.4047 | Acc(train) 0.9198 | Acc(val) 0.9277 |
Epoch 00156 | Loss(train) 0.3990 | Acc(train) 0.9201 | Acc(val) 0.9275 |
Epoch 00157 | Loss(train) 0.3944 | Acc(train) 0.9208 | Acc(val) 0.9275 |
Epoch 00158 | Loss(train) 0.3998 | Acc(train) 0.9196 | Acc(val) 0.9277 |
Epoch 00159 | Loss(train) 0.3965 | Acc(train) 0.9205 | Acc(val) 0.9278 |
Epoch 00160 | Loss(train) 0.3975 | Acc(train) 0.9197 | Acc(val) 0.9280 |*
Epoch 00161 | Loss(train) 0.3971 | Acc(train) 0.9199 | Acc(val) 0.9281 |*
Epoch 00162 | Loss(train) 0.3954 | Acc(train) 0.9202 | Acc(val) 0.9281 |*
Epoch 00163 | Loss(train) 0.3985 | Acc(train) 0.9202 | Acc(val) 0.9281 |*
Epoch 00164 | Loss(train) 0.3919 | Acc(train) 0.9214 | Acc(val) 0.9280 |
Epoch 00165 | Loss(train) 0.3942 | Acc(train) 0.9215 | Acc(val) 0.9281 |
Epoch 00166 | Loss(train) 0.3983 | Acc(train) 0.9208 | Acc(val) 0.9281 |
Epoch 00167 | Loss(train) 0.3933 | Acc(train) 0.9200 | Acc(val) 0.9281 |
Epoch 00168 | Loss(train) 0.3928 | Acc(train) 0.9207 | Acc(val) 0.9281 |
Epoch 00169 | Loss(train) 0.3940 | Acc(train) 0.9201 | Acc(val) 0.9283 |*
Epoch 00170 | Loss(train) 0.3905 | Acc(train) 0.9206 | Acc(val) 0.9284 |*
Epoch 00171 | Loss(train) 0.3912 | Acc(train) 0.9206 | Acc(val) 0.9284 |
Epoch 00172 | Loss(train) 0.3916 | Acc(train) 0.9199 | Acc(val) 0.9284 |*
Epoch 00173 | Loss(train) 0.3907 | Acc(train) 0.9209 | Acc(val) 0.9287 |*
Epoch 00174 | Loss(train) 0.3894 | Acc(train) 0.9208 | Acc(val) 0.9289 |*
Epoch 00175 | Loss(train) 0.3875 | Acc(train) 0.9207 | Acc(val) 0.9291 |*
Epoch 00176 | Loss(train) 0.3887 | Acc(train) 0.9213 | Acc(val) 0.9289 |
Epoch 00177 | Loss(train) 0.3866 | Acc(train) 0.9228 | Acc(val) 0.9290 |
Epoch 00178 | Loss(train) 0.3895 | Acc(train) 0.9211 | Acc(val) 0.9289 |
Epoch 00179 | Loss(train) 0.3874 | Acc(train) 0.9207 | Acc(val) 0.9290 |
Epoch 00180 | Loss(train) 0.3866 | Acc(train) 0.9216 | Acc(val) 0.9293 |*
Epoch 00181 | Loss(train) 0.3844 | Acc(train) 0.9212 | Acc(val) 0.9294 |*
Epoch 00182 | Loss(train) 0.3874 | Acc(train) 0.9210 | Acc(val) 0.9293 |
Epoch 00183 | Loss(train) 0.3891 | Acc(train) 0.9213 | Acc(val) 0.9294 |
Epoch 00184 | Loss(train) 0.3864 | Acc(train) 0.9209 | Acc(val) 0.9294 |
Epoch 00185 | Loss(train) 0.3831 | Acc(train) 0.9216 | Acc(val) 0.9297 |*
Epoch 00186 | Loss(train) 0.3842 | Acc(train) 0.9220 | Acc(val) 0.9296 |
Epoch 00187 | Loss(train) 0.3847 | Acc(train) 0.9212 | Acc(val) 0.9296 |
Epoch 00188 | Loss(train) 0.3816 | Acc(train) 0.9222 | Acc(val) 0.9296 |
Epoch 00189 | Loss(train) 0.3832 | Acc(train) 0.9220 | Acc(val) 0.9296 |
Epoch 00190 | Loss(train) 0.3825 | Acc(train) 0.9214 | Acc(val) 0.9295 |
Epoch 00191 | Loss(train) 0.3795 | Acc(train) 0.9221 | Acc(val) 0.9294 |
Epoch 00192 | Loss(train) 0.3813 | Acc(train) 0.9216 | Acc(val) 0.9295 |
Epoch 00193 | Loss(train) 0.3812 | Acc(train) 0.9222 | Acc(val) 0.9298 |*
Epoch 00194 | Loss(train) 0.3803 | Acc(train) 0.9226 | Acc(val) 0.9301 |*
Epoch 00195 | Loss(train) 0.3824 | Acc(train) 0.9217 | Acc(val) 0.9302 |*
Epoch 00196 | Loss(train) 0.3785 | Acc(train) 0.9233 | Acc(val) 0.9302 |
Epoch 00197 | Loss(train) 0.3860 | Acc(train) 0.9214 | Acc(val) 0.9302 |*
Epoch 00198 | Loss(train) 0.3775 | Acc(train) 0.9221 | Acc(val) 0.9302 |*
Epoch 00199 | Loss(train) 0.3811 | Acc(train) 0.9216 | Acc(val) 0.9301 |
Epoch 00200 | Loss(train) 0.3786 | Acc(train) 0.9225 | Acc(val) 0.9300 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7884 | Acc(train) 0.0033 | Acc(val) 0.1327 |*
Epoch 00002 | Loss(train) 3.5291 | Acc(train) 0.1271 | Acc(val) 0.2149 |*
Epoch 00003 | Loss(train) 3.3266 | Acc(train) 0.2059 | Acc(val) 0.3447 |*
Epoch 00004 | Loss(train) 3.1269 | Acc(train) 0.3432 | Acc(val) 0.3947 |*
Epoch 00005 | Loss(train) 2.9457 | Acc(train) 0.3908 | Acc(val) 0.4093 |*
Epoch 00006 | Loss(train) 2.7766 | Acc(train) 0.4060 | Acc(val) 0.4460 |*
Epoch 00007 | Loss(train) 2.6213 | Acc(train) 0.4380 | Acc(val) 0.4991 |*
Epoch 00008 | Loss(train) 2.4708 | Acc(train) 0.4916 | Acc(val) 0.4935 |
Epoch 00009 | Loss(train) 2.3316 | Acc(train) 0.4891 | Acc(val) 0.4920 |
Epoch 00010 | Loss(train) 2.2073 | Acc(train) 0.4868 | Acc(val) 0.5049 |*
Epoch 00011 | Loss(train) 2.0954 | Acc(train) 0.5001 | Acc(val) 0.5338 |*
Epoch 00012 | Loss(train) 1.9924 | Acc(train) 0.5298 | Acc(val) 0.5915 |*
Epoch 00013 | Loss(train) 1.8943 | Acc(train) 0.5849 | Acc(val) 0.6287 |*
Epoch 00014 | Loss(train) 1.8027 | Acc(train) 0.6178 | Acc(val) 0.6499 |*
Epoch 00015 | Loss(train) 1.7158 | Acc(train) 0.6402 | Acc(val) 0.6778 |*
Epoch 00016 | Loss(train) 1.6304 | Acc(train) 0.6676 | Acc(val) 0.7041 |*
Epoch 00017 | Loss(train) 1.5577 | Acc(train) 0.6931 | Acc(val) 0.7274 |*
Epoch 00018 | Loss(train) 1.4861 | Acc(train) 0.7147 | Acc(val) 0.7449 |*
Epoch 00019 | Loss(train) 1.4213 | Acc(train) 0.7280 | Acc(val) 0.7571 |*
Epoch 00020 | Loss(train) 1.3557 | Acc(train) 0.7422 | Acc(val) 0.7619 |*
Epoch 00021 | Loss(train) 1.2982 | Acc(train) 0.7456 | Acc(val) 0.7661 |*
Epoch 00022 | Loss(train) 1.2407 | Acc(train) 0.7518 | Acc(val) 0.7708 |*
Epoch 00023 | Loss(train) 1.1904 | Acc(train) 0.7558 | Acc(val) 0.7776 |*
Epoch 00024 | Loss(train) 1.1355 | Acc(train) 0.7648 | Acc(val) 0.7896 |*
Epoch 00025 | Loss(train) 1.0950 | Acc(train) 0.7758 | Acc(val) 0.7992 |*
Epoch 00026 | Loss(train) 1.0508 | Acc(train) 0.7848 | Acc(val) 0.8092 |*
Epoch 00027 | Loss(train) 1.0067 | Acc(train) 0.7956 | Acc(val) 0.8187 |*
Epoch 00028 | Loss(train) 0.9742 | Acc(train) 0.8084 | Acc(val) 0.8265 |*
Epoch 00029 | Loss(train) 0.9409 | Acc(train) 0.8143 | Acc(val) 0.8335 |*
Epoch 00030 | Loss(train) 0.9084 | Acc(train) 0.8198 | Acc(val) 0.8401 |*
Epoch 00031 | Loss(train) 0.8812 | Acc(train) 0.8228 | Acc(val) 0.8477 |*
Epoch 00032 | Loss(train) 0.8541 | Acc(train) 0.8296 | Acc(val) 0.8564 |*
Epoch 00033 | Loss(train) 0.8292 | Acc(train) 0.8420 | Acc(val) 0.8647 |*
Epoch 00034 | Loss(train) 0.8072 | Acc(train) 0.8510 | Acc(val) 0.8715 |*
Epoch 00035 | Loss(train) 0.7888 | Acc(train) 0.8614 | Acc(val) 0.8761 |*
Epoch 00036 | Loss(train) 0.7643 | Acc(train) 0.8642 | Acc(val) 0.8785 |*
Epoch 00037 | Loss(train) 0.7514 | Acc(train) 0.8666 | Acc(val) 0.8810 |*
Epoch 00038 | Loss(train) 0.7336 | Acc(train) 0.8685 | Acc(val) 0.8848 |*
Epoch 00039 | Loss(train) 0.7154 | Acc(train) 0.8745 | Acc(val) 0.8893 |*
Epoch 00040 | Loss(train) 0.6968 | Acc(train) 0.8786 | Acc(val) 0.8922 |*
Epoch 00041 | Loss(train) 0.6878 | Acc(train) 0.8796 | Acc(val) 0.8939 |*
Epoch 00042 | Loss(train) 0.6733 | Acc(train) 0.8834 | Acc(val) 0.8950 |*
Epoch 00043 | Loss(train) 0.6628 | Acc(train) 0.8835 | Acc(val) 0.8962 |*
Epoch 00044 | Loss(train) 0.6546 | Acc(train) 0.8832 | Acc(val) 0.8973 |*
Epoch 00045 | Loss(train) 0.6450 | Acc(train) 0.8847 | Acc(val) 0.8990 |*
Epoch 00046 | Loss(train) 0.6324 | Acc(train) 0.8852 | Acc(val) 0.9004 |*
Epoch 00047 | Loss(train) 0.6168 | Acc(train) 0.8877 | Acc(val) 0.9016 |*
Epoch 00048 | Loss(train) 0.6098 | Acc(train) 0.8898 | Acc(val) 0.9026 |*
Epoch 00049 | Loss(train) 0.6053 | Acc(train) 0.8905 | Acc(val) 0.9036 |*
Epoch 00050 | Loss(train) 0.5993 | Acc(train) 0.8905 | Acc(val) 0.9046 |*
Epoch 00051 | Loss(train) 0.5915 | Acc(train) 0.8928 | Acc(val) 0.9058 |*
Epoch 00052 | Loss(train) 0.5784 | Acc(train) 0.8952 | Acc(val) 0.9070 |*
Epoch 00053 | Loss(train) 0.5746 | Acc(train) 0.8954 | Acc(val) 0.9085 |*
Epoch 00054 | Loss(train) 0.5703 | Acc(train) 0.8981 | Acc(val) 0.9093 |*
Epoch 00055 | Loss(train) 0.5608 | Acc(train) 0.8982 | Acc(val) 0.9107 |*
Epoch 00056 | Loss(train) 0.5570 | Acc(train) 0.8995 | Acc(val) 0.9121 |*
Epoch 00057 | Loss(train) 0.5494 | Acc(train) 0.9016 | Acc(val) 0.9129 |*
Epoch 00058 | Loss(train) 0.5454 | Acc(train) 0.9007 | Acc(val) 0.9135 |*
Epoch 00059 | Loss(train) 0.5403 | Acc(train) 0.9022 | Acc(val) 0.9140 |*
Epoch 00060 | Loss(train) 0.5328 | Acc(train) 0.9029 | Acc(val) 0.9144 |*
Epoch 00061 | Loss(train) 0.5244 | Acc(train) 0.9027 | Acc(val) 0.9149 |*
Epoch 00062 | Loss(train) 0.5294 | Acc(train) 0.9027 | Acc(val) 0.9154 |*
Epoch 00063 | Loss(train) 0.5215 | Acc(train) 0.9043 | Acc(val) 0.9159 |*
Epoch 00064 | Loss(train) 0.5207 | Acc(train) 0.9037 | Acc(val) 0.9166 |*
Epoch 00065 | Loss(train) 0.5139 | Acc(train) 0.9055 | Acc(val) 0.9171 |*
Epoch 00066 | Loss(train) 0.5121 | Acc(train) 0.9058 | Acc(val) 0.9172 |*
Epoch 00067 | Loss(train) 0.5102 | Acc(train) 0.9063 | Acc(val) 0.9173 |*
Epoch 00068 | Loss(train) 0.5078 | Acc(train) 0.9079 | Acc(val) 0.9179 |*
Epoch 00069 | Loss(train) 0.5050 | Acc(train) 0.9072 | Acc(val) 0.9182 |*
Epoch 00070 | Loss(train) 0.4997 | Acc(train) 0.9073 | Acc(val) 0.9183 |*
Epoch 00071 | Loss(train) 0.4945 | Acc(train) 0.9077 | Acc(val) 0.9184 |*
Epoch 00072 | Loss(train) 0.4980 | Acc(train) 0.9079 | Acc(val) 0.9185 |*
Epoch 00073 | Loss(train) 0.4932 | Acc(train) 0.9074 | Acc(val) 0.9187 |*
Epoch 00074 | Loss(train) 0.4898 | Acc(train) 0.9087 | Acc(val) 0.9192 |*
Epoch 00075 | Loss(train) 0.4889 | Acc(train) 0.9090 | Acc(val) 0.9194 |*
Epoch 00076 | Loss(train) 0.4854 | Acc(train) 0.9100 | Acc(val) 0.9198 |*
Epoch 00077 | Loss(train) 0.4800 | Acc(train) 0.9084 | Acc(val) 0.9202 |*
Epoch 00078 | Loss(train) 0.4810 | Acc(train) 0.9110 | Acc(val) 0.9205 |*
Epoch 00079 | Loss(train) 0.4751 | Acc(train) 0.9105 | Acc(val) 0.9207 |*
Epoch 00080 | Loss(train) 0.4741 | Acc(train) 0.9111 | Acc(val) 0.9212 |*
Epoch 00081 | Loss(train) 0.4776 | Acc(train) 0.9102 | Acc(val) 0.9214 |*
Epoch 00082 | Loss(train) 0.4750 | Acc(train) 0.9109 | Acc(val) 0.9216 |*
Epoch 00083 | Loss(train) 0.4692 | Acc(train) 0.9110 | Acc(val) 0.9218 |*
Epoch 00084 | Loss(train) 0.4679 | Acc(train) 0.9109 | Acc(val) 0.9221 |*
Epoch 00085 | Loss(train) 0.4651 | Acc(train) 0.9128 | Acc(val) 0.9221 |
Epoch 00086 | Loss(train) 0.4621 | Acc(train) 0.9123 | Acc(val) 0.9222 |*
Epoch 00087 | Loss(train) 0.4622 | Acc(train) 0.9111 | Acc(val) 0.9222 |*
Epoch 00088 | Loss(train) 0.4568 | Acc(train) 0.9131 | Acc(val) 0.9223 |*
Epoch 00089 | Loss(train) 0.4589 | Acc(train) 0.9131 | Acc(val) 0.9225 |*
Epoch 00090 | Loss(train) 0.4541 | Acc(train) 0.9139 | Acc(val) 0.9227 |*
Epoch 00091 | Loss(train) 0.4559 | Acc(train) 0.9137 | Acc(val) 0.9228 |*
Epoch 00092 | Loss(train) 0.4509 | Acc(train) 0.9141 | Acc(val) 0.9230 |*
Epoch 00093 | Loss(train) 0.4488 | Acc(train) 0.9137 | Acc(val) 0.9232 |*
Epoch 00094 | Loss(train) 0.4491 | Acc(train) 0.9135 | Acc(val) 0.9234 |*
Epoch 00095 | Loss(train) 0.4489 | Acc(train) 0.9139 | Acc(val) 0.9236 |*
Epoch 00096 | Loss(train) 0.4423 | Acc(train) 0.9153 | Acc(val) 0.9239 |*
Epoch 00097 | Loss(train) 0.4499 | Acc(train) 0.9146 | Acc(val) 0.9242 |*
Epoch 00098 | Loss(train) 0.4460 | Acc(train) 0.9160 | Acc(val) 0.9242 |
Epoch 00099 | Loss(train) 0.4445 | Acc(train) 0.9142 | Acc(val) 0.9247 |*
Epoch 00100 | Loss(train) 0.4417 | Acc(train) 0.9146 | Acc(val) 0.9247 |
Epoch 00101 | Loss(train) 0.4438 | Acc(train) 0.9149 | Acc(val) 0.9250 |*
Epoch 00102 | Loss(train) 0.4393 | Acc(train) 0.9158 | Acc(val) 0.9251 |*
Epoch 00103 | Loss(train) 0.4404 | Acc(train) 0.9155 | Acc(val) 0.9255 |*
Epoch 00104 | Loss(train) 0.4360 | Acc(train) 0.9164 | Acc(val) 0.9254 |
Epoch 00105 | Loss(train) 0.4375 | Acc(train) 0.9151 | Acc(val) 0.9256 |*
Epoch 00106 | Loss(train) 0.4338 | Acc(train) 0.9160 | Acc(val) 0.9256 |
Epoch 00107 | Loss(train) 0.4375 | Acc(train) 0.9166 | Acc(val) 0.9257 |*
Epoch 00108 | Loss(train) 0.4342 | Acc(train) 0.9170 | Acc(val) 0.9258 |*
Epoch 00109 | Loss(train) 0.4328 | Acc(train) 0.9169 | Acc(val) 0.9259 |*
Epoch 00110 | Loss(train) 0.4298 | Acc(train) 0.9179 | Acc(val) 0.9261 |*
Epoch 00111 | Loss(train) 0.4278 | Acc(train) 0.9166 | Acc(val) 0.9261 |*
Epoch 00112 | Loss(train) 0.4283 | Acc(train) 0.9171 | Acc(val) 0.9263 |*
Epoch 00113 | Loss(train) 0.4234 | Acc(train) 0.9182 | Acc(val) 0.9263 |*
Epoch 00114 | Loss(train) 0.4286 | Acc(train) 0.9170 | Acc(val) 0.9264 |*
Epoch 00115 | Loss(train) 0.4272 | Acc(train) 0.9182 | Acc(val) 0.9267 |*
Epoch 00116 | Loss(train) 0.4215 | Acc(train) 0.9169 | Acc(val) 0.9266 |
Epoch 00117 | Loss(train) 0.4255 | Acc(train) 0.9191 | Acc(val) 0.9267 |
Epoch 00118 | Loss(train) 0.4233 | Acc(train) 0.9178 | Acc(val) 0.9270 |*
Epoch 00119 | Loss(train) 0.4210 | Acc(train) 0.9177 | Acc(val) 0.9272 |*
Epoch 00120 | Loss(train) 0.4250 | Acc(train) 0.9169 | Acc(val) 0.9271 |
Epoch 00121 | Loss(train) 0.4195 | Acc(train) 0.9190 | Acc(val) 0.9271 |
Epoch 00122 | Loss(train) 0.4237 | Acc(train) 0.9182 | Acc(val) 0.9273 |*
Epoch 00123 | Loss(train) 0.4200 | Acc(train) 0.9190 | Acc(val) 0.9272 |
Epoch 00124 | Loss(train) 0.4188 | Acc(train) 0.9183 | Acc(val) 0.9272 |
Epoch 00125 | Loss(train) 0.4162 | Acc(train) 0.9188 | Acc(val) 0.9273 |*
Epoch 00126 | Loss(train) 0.4148 | Acc(train) 0.9186 | Acc(val) 0.9274 |*
Epoch 00127 | Loss(train) 0.4161 | Acc(train) 0.9179 | Acc(val) 0.9276 |*
Epoch 00128 | Loss(train) 0.4183 | Acc(train) 0.9189 | Acc(val) 0.9275 |
Epoch 00129 | Loss(train) 0.4142 | Acc(train) 0.9194 | Acc(val) 0.9277 |*
Epoch 00130 | Loss(train) 0.4097 | Acc(train) 0.9185 | Acc(val) 0.9278 |*
Epoch 00131 | Loss(train) 0.4124 | Acc(train) 0.9197 | Acc(val) 0.9278 |
Epoch 00132 | Loss(train) 0.4145 | Acc(train) 0.9182 | Acc(val) 0.9279 |*
Epoch 00133 | Loss(train) 0.4155 | Acc(train) 0.9196 | Acc(val) 0.9278 |
Epoch 00134 | Loss(train) 0.4122 | Acc(train) 0.9195 | Acc(val) 0.9281 |*
Epoch 00135 | Loss(train) 0.4088 | Acc(train) 0.9191 | Acc(val) 0.9282 |*
Epoch 00136 | Loss(train) 0.4151 | Acc(train) 0.9185 | Acc(val) 0.9282 |
Epoch 00137 | Loss(train) 0.4065 | Acc(train) 0.9191 | Acc(val) 0.9281 |
Epoch 00138 | Loss(train) 0.4085 | Acc(train) 0.9198 | Acc(val) 0.9284 |*
Epoch 00139 | Loss(train) 0.4079 | Acc(train) 0.9194 | Acc(val) 0.9285 |*
Epoch 00140 | Loss(train) 0.4088 | Acc(train) 0.9193 | Acc(val) 0.9285 |*
Epoch 00141 | Loss(train) 0.4079 | Acc(train) 0.9190 | Acc(val) 0.9287 |*
Epoch 00142 | Loss(train) 0.4062 | Acc(train) 0.9205 | Acc(val) 0.9285 |
Epoch 00143 | Loss(train) 0.4072 | Acc(train) 0.9195 | Acc(val) 0.9285 |
Epoch 00144 | Loss(train) 0.4045 | Acc(train) 0.9202 | Acc(val) 0.9285 |
Epoch 00145 | Loss(train) 0.4047 | Acc(train) 0.9200 | Acc(val) 0.9287 |
Epoch 00146 | Loss(train) 0.4035 | Acc(train) 0.9209 | Acc(val) 0.9288 |*
Epoch 00147 | Loss(train) 0.4018 | Acc(train) 0.9208 | Acc(val) 0.9287 |
Epoch 00148 | Loss(train) 0.4039 | Acc(train) 0.9207 | Acc(val) 0.9288 |
Epoch 00149 | Loss(train) 0.3999 | Acc(train) 0.9216 | Acc(val) 0.9289 |*
Epoch 00150 | Loss(train) 0.4027 | Acc(train) 0.9194 | Acc(val) 0.9290 |*
Epoch 00151 | Loss(train) 0.4024 | Acc(train) 0.9211 | Acc(val) 0.9291 |*
Epoch 00152 | Loss(train) 0.3984 | Acc(train) 0.9200 | Acc(val) 0.9292 |*
Epoch 00153 | Loss(train) 0.3977 | Acc(train) 0.9224 | Acc(val) 0.9292 |*
Epoch 00154 | Loss(train) 0.3992 | Acc(train) 0.9211 | Acc(val) 0.9292 |
Epoch 00155 | Loss(train) 0.4008 | Acc(train) 0.9211 | Acc(val) 0.9293 |*
Epoch 00156 | Loss(train) 0.4008 | Acc(train) 0.9201 | Acc(val) 0.9292 |
Epoch 00157 | Loss(train) 0.3952 | Acc(train) 0.9201 | Acc(val) 0.9291 |
Epoch 00158 | Loss(train) 0.3970 | Acc(train) 0.9217 | Acc(val) 0.9293 |*
Epoch 00159 | Loss(train) 0.3987 | Acc(train) 0.9207 | Acc(val) 0.9293 |
Epoch 00160 | Loss(train) 0.4003 | Acc(train) 0.9199 | Acc(val) 0.9293 |*
Epoch 00161 | Loss(train) 0.3968 | Acc(train) 0.9207 | Acc(val) 0.9295 |*
Epoch 00162 | Loss(train) 0.3941 | Acc(train) 0.9216 | Acc(val) 0.9295 |*
Epoch 00163 | Loss(train) 0.3956 | Acc(train) 0.9209 | Acc(val) 0.9298 |*
Epoch 00164 | Loss(train) 0.3953 | Acc(train) 0.9212 | Acc(val) 0.9302 |*
Epoch 00165 | Loss(train) 0.3943 | Acc(train) 0.9211 | Acc(val) 0.9302 |*
Epoch 00166 | Loss(train) 0.3917 | Acc(train) 0.9218 | Acc(val) 0.9302 |
Epoch 00167 | Loss(train) 0.3919 | Acc(train) 0.9221 | Acc(val) 0.9302 |
Epoch 00168 | Loss(train) 0.3946 | Acc(train) 0.9220 | Acc(val) 0.9302 |
Epoch 00169 | Loss(train) 0.3896 | Acc(train) 0.9220 | Acc(val) 0.9302 |
Epoch 00170 | Loss(train) 0.3917 | Acc(train) 0.9213 | Acc(val) 0.9303 |*
Epoch 00171 | Loss(train) 0.3882 | Acc(train) 0.9207 | Acc(val) 0.9300 |
Epoch 00172 | Loss(train) 0.3921 | Acc(train) 0.9208 | Acc(val) 0.9301 |
Epoch 00173 | Loss(train) 0.3875 | Acc(train) 0.9214 | Acc(val) 0.9302 |
Epoch 00174 | Loss(train) 0.3883 | Acc(train) 0.9218 | Acc(val) 0.9302 |
Epoch 00175 | Loss(train) 0.3893 | Acc(train) 0.9214 | Acc(val) 0.9301 |
Epoch 00176 | Loss(train) 0.3877 | Acc(train) 0.9223 | Acc(val) 0.9300 |
Epoch 00177 | Loss(train) 0.3860 | Acc(train) 0.9224 | Acc(val) 0.9299 |
Epoch 00178 | Loss(train) 0.3874 | Acc(train) 0.9223 | Acc(val) 0.9303 |
Epoch 00179 | Loss(train) 0.3834 | Acc(train) 0.9220 | Acc(val) 0.9305 |*
Epoch 00180 | Loss(train) 0.3857 | Acc(train) 0.9221 | Acc(val) 0.9306 |*
Epoch 00181 | Loss(train) 0.3842 | Acc(train) 0.9226 | Acc(val) 0.9308 |*
Epoch 00182 | Loss(train) 0.3875 | Acc(train) 0.9218 | Acc(val) 0.9308 |*
Epoch 00183 | Loss(train) 0.3879 | Acc(train) 0.9222 | Acc(val) 0.9307 |
Epoch 00184 | Loss(train) 0.3820 | Acc(train) 0.9227 | Acc(val) 0.9306 |
Epoch 00185 | Loss(train) 0.3806 | Acc(train) 0.9231 | Acc(val) 0.9308 |
Epoch 00186 | Loss(train) 0.3845 | Acc(train) 0.9224 | Acc(val) 0.9308 |
Epoch 00187 | Loss(train) 0.3838 | Acc(train) 0.9228 | Acc(val) 0.9306 |
Epoch 00188 | Loss(train) 0.3831 | Acc(train) 0.9215 | Acc(val) 0.9306 |
Epoch 00189 | Loss(train) 0.3830 | Acc(train) 0.9233 | Acc(val) 0.9306 |
Epoch 00190 | Loss(train) 0.3807 | Acc(train) 0.9219 | Acc(val) 0.9306 |
Epoch 00191 | Loss(train) 0.3808 | Acc(train) 0.9231 | Acc(val) 0.9308 |
Epoch 00192 | Loss(train) 0.3816 | Acc(train) 0.9231 | Acc(val) 0.9309 |*
Epoch 00193 | Loss(train) 0.3781 | Acc(train) 0.9236 | Acc(val) 0.9308 |
Epoch 00194 | Loss(train) 0.3785 | Acc(train) 0.9237 | Acc(val) 0.9312 |*
Epoch 00195 | Loss(train) 0.3782 | Acc(train) 0.9242 | Acc(val) 0.9311 |
Epoch 00196 | Loss(train) 0.3804 | Acc(train) 0.9241 | Acc(val) 0.9311 |
Epoch 00197 | Loss(train) 0.3799 | Acc(train) 0.9220 | Acc(val) 0.9312 |
Epoch 00198 | Loss(train) 0.3789 | Acc(train) 0.9230 | Acc(val) 0.9311 |
Epoch 00199 | Loss(train) 0.3775 | Acc(train) 0.9228 | Acc(val) 0.9310 |
Epoch 00200 | Loss(train) 0.3753 | Acc(train) 0.9229 | Acc(val) 0.9311 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7407 | Acc(train) 0.0073 | Acc(val) 0.1804 |*
Epoch 00002 | Loss(train) 3.4303 | Acc(train) 0.1835 | Acc(val) 0.3278 |*
Epoch 00003 | Loss(train) 3.2265 | Acc(train) 0.3222 | Acc(val) 0.3475 |*
Epoch 00004 | Loss(train) 3.0670 | Acc(train) 0.3397 | Acc(val) 0.3897 |*
Epoch 00005 | Loss(train) 2.9174 | Acc(train) 0.3818 | Acc(val) 0.4197 |*
Epoch 00006 | Loss(train) 2.7761 | Acc(train) 0.4118 | Acc(val) 0.4578 |*
Epoch 00007 | Loss(train) 2.6442 | Acc(train) 0.4517 | Acc(val) 0.4702 |*
Epoch 00008 | Loss(train) 2.5155 | Acc(train) 0.4653 | Acc(val) 0.4970 |*
Epoch 00009 | Loss(train) 2.3958 | Acc(train) 0.4945 | Acc(val) 0.5253 |*
Epoch 00010 | Loss(train) 2.2790 | Acc(train) 0.5227 | Acc(val) 0.5379 |*
Epoch 00011 | Loss(train) 2.1754 | Acc(train) 0.5339 | Acc(val) 0.5535 |*
Epoch 00012 | Loss(train) 2.0766 | Acc(train) 0.5473 | Acc(val) 0.5661 |*
Epoch 00013 | Loss(train) 1.9797 | Acc(train) 0.5591 | Acc(val) 0.5871 |*
Epoch 00014 | Loss(train) 1.8871 | Acc(train) 0.5822 | Acc(val) 0.6098 |*
Epoch 00015 | Loss(train) 1.8032 | Acc(train) 0.6008 | Acc(val) 0.6381 |*
Epoch 00016 | Loss(train) 1.7232 | Acc(train) 0.6253 | Acc(val) 0.6650 |*
Epoch 00017 | Loss(train) 1.6465 | Acc(train) 0.6517 | Acc(val) 0.6863 |*
Epoch 00018 | Loss(train) 1.5711 | Acc(train) 0.6718 | Acc(val) 0.7051 |*
Epoch 00019 | Loss(train) 1.5000 | Acc(train) 0.6898 | Acc(val) 0.7172 |*
Epoch 00020 | Loss(train) 1.4408 | Acc(train) 0.6970 | Acc(val) 0.7248 |*
Epoch 00021 | Loss(train) 1.3825 | Acc(train) 0.7072 | Acc(val) 0.7312 |*
Epoch 00022 | Loss(train) 1.3256 | Acc(train) 0.7117 | Acc(val) 0.7446 |*
Epoch 00023 | Loss(train) 1.2755 | Acc(train) 0.7310 | Acc(val) 0.7621 |*
Epoch 00024 | Loss(train) 1.2286 | Acc(train) 0.7483 | Acc(val) 0.7752 |*
Epoch 00025 | Loss(train) 1.1795 | Acc(train) 0.7605 | Acc(val) 0.7865 |*
Epoch 00026 | Loss(train) 1.1362 | Acc(train) 0.7729 | Acc(val) 0.7979 |*
Epoch 00027 | Loss(train) 1.0907 | Acc(train) 0.7835 | Acc(val) 0.8024 |*
Epoch 00028 | Loss(train) 1.0551 | Acc(train) 0.7881 | Acc(val) 0.8055 |*
Epoch 00029 | Loss(train) 1.0157 | Acc(train) 0.7910 | Acc(val) 0.8113 |*
Epoch 00030 | Loss(train) 0.9831 | Acc(train) 0.7963 | Acc(val) 0.8174 |*
Epoch 00031 | Loss(train) 0.9556 | Acc(train) 0.8051 | Acc(val) 0.8279 |*
Epoch 00032 | Loss(train) 0.9236 | Acc(train) 0.8139 | Acc(val) 0.8331 |*
Epoch 00033 | Loss(train) 0.8999 | Acc(train) 0.8189 | Acc(val) 0.8371 |*
Epoch 00034 | Loss(train) 0.8713 | Acc(train) 0.8238 | Acc(val) 0.8410 |*
Epoch 00035 | Loss(train) 0.8526 | Acc(train) 0.8240 | Acc(val) 0.8488 |*
Epoch 00036 | Loss(train) 0.8273 | Acc(train) 0.8304 | Acc(val) 0.8548 |*
Epoch 00037 | Loss(train) 0.7994 | Acc(train) 0.8354 | Acc(val) 0.8601 |*
Epoch 00038 | Loss(train) 0.7774 | Acc(train) 0.8486 | Acc(val) 0.8692 |*
Epoch 00039 | Loss(train) 0.7589 | Acc(train) 0.8577 | Acc(val) 0.8724 |*
Epoch 00040 | Loss(train) 0.7441 | Acc(train) 0.8576 | Acc(val) 0.8774 |*
Epoch 00041 | Loss(train) 0.7321 | Acc(train) 0.8629 | Acc(val) 0.8826 |*
Epoch 00042 | Loss(train) 0.7175 | Acc(train) 0.8639 | Acc(val) 0.8886 |*
Epoch 00043 | Loss(train) 0.6934 | Acc(train) 0.8744 | Acc(val) 0.8929 |*
Epoch 00044 | Loss(train) 0.6839 | Acc(train) 0.8784 | Acc(val) 0.8953 |*
Epoch 00045 | Loss(train) 0.6711 | Acc(train) 0.8774 | Acc(val) 0.8967 |*
Epoch 00046 | Loss(train) 0.6567 | Acc(train) 0.8816 | Acc(val) 0.8980 |*
Epoch 00047 | Loss(train) 0.6516 | Acc(train) 0.8812 | Acc(val) 0.8991 |*
Epoch 00048 | Loss(train) 0.6353 | Acc(train) 0.8855 | Acc(val) 0.9007 |*
Epoch 00049 | Loss(train) 0.6233 | Acc(train) 0.8867 | Acc(val) 0.9020 |*
Epoch 00050 | Loss(train) 0.6216 | Acc(train) 0.8892 | Acc(val) 0.9036 |*
Epoch 00051 | Loss(train) 0.6113 | Acc(train) 0.8904 | Acc(val) 0.9048 |*
Epoch 00052 | Loss(train) 0.6034 | Acc(train) 0.8903 | Acc(val) 0.9066 |*
Epoch 00053 | Loss(train) 0.5900 | Acc(train) 0.8915 | Acc(val) 0.9078 |*
Epoch 00054 | Loss(train) 0.5902 | Acc(train) 0.8929 | Acc(val) 0.9091 |*
Epoch 00055 | Loss(train) 0.5805 | Acc(train) 0.8933 | Acc(val) 0.9108 |*
Epoch 00056 | Loss(train) 0.5684 | Acc(train) 0.8973 | Acc(val) 0.9117 |*
Epoch 00057 | Loss(train) 0.5696 | Acc(train) 0.8973 | Acc(val) 0.9127 |*
Epoch 00058 | Loss(train) 0.5557 | Acc(train) 0.9008 | Acc(val) 0.9133 |*
Epoch 00059 | Loss(train) 0.5554 | Acc(train) 0.8996 | Acc(val) 0.9136 |*
Epoch 00060 | Loss(train) 0.5448 | Acc(train) 0.9017 | Acc(val) 0.9144 |*
Epoch 00061 | Loss(train) 0.5474 | Acc(train) 0.9005 | Acc(val) 0.9148 |*
Epoch 00062 | Loss(train) 0.5384 | Acc(train) 0.9028 | Acc(val) 0.9155 |*
Epoch 00063 | Loss(train) 0.5332 | Acc(train) 0.9039 | Acc(val) 0.9163 |*
Epoch 00064 | Loss(train) 0.5298 | Acc(train) 0.9036 | Acc(val) 0.9169 |*
Epoch 00065 | Loss(train) 0.5263 | Acc(train) 0.9042 | Acc(val) 0.9174 |*
Epoch 00066 | Loss(train) 0.5240 | Acc(train) 0.9054 | Acc(val) 0.9181 |*
Epoch 00067 | Loss(train) 0.5192 | Acc(train) 0.9048 | Acc(val) 0.9191 |*
Epoch 00068 | Loss(train) 0.5136 | Acc(train) 0.9046 | Acc(val) 0.9192 |*
Epoch 00069 | Loss(train) 0.5116 | Acc(train) 0.9049 | Acc(val) 0.9189 |
Epoch 00070 | Loss(train) 0.5100 | Acc(train) 0.9050 | Acc(val) 0.9193 |*
Epoch 00071 | Loss(train) 0.5089 | Acc(train) 0.9053 | Acc(val) 0.9195 |*
Epoch 00072 | Loss(train) 0.4987 | Acc(train) 0.9063 | Acc(val) 0.9198 |*
Epoch 00073 | Loss(train) 0.5001 | Acc(train) 0.9064 | Acc(val) 0.9202 |*
Epoch 00074 | Loss(train) 0.4972 | Acc(train) 0.9070 | Acc(val) 0.9206 |*
Epoch 00075 | Loss(train) 0.4947 | Acc(train) 0.9072 | Acc(val) 0.9209 |*
Epoch 00076 | Loss(train) 0.4921 | Acc(train) 0.9089 | Acc(val) 0.9212 |*
Epoch 00077 | Loss(train) 0.4935 | Acc(train) 0.9072 | Acc(val) 0.9213 |*
Epoch 00078 | Loss(train) 0.4873 | Acc(train) 0.9093 | Acc(val) 0.9216 |*
Epoch 00079 | Loss(train) 0.4872 | Acc(train) 0.9095 | Acc(val) 0.9216 |*
Epoch 00080 | Loss(train) 0.4819 | Acc(train) 0.9096 | Acc(val) 0.9220 |*
Epoch 00081 | Loss(train) 0.4751 | Acc(train) 0.9099 | Acc(val) 0.9218 |
Epoch 00082 | Loss(train) 0.4728 | Acc(train) 0.9095 | Acc(val) 0.9217 |
Epoch 00083 | Loss(train) 0.4774 | Acc(train) 0.9086 | Acc(val) 0.9223 |*
Epoch 00084 | Loss(train) 0.4729 | Acc(train) 0.9094 | Acc(val) 0.9228 |*
Epoch 00085 | Loss(train) 0.4750 | Acc(train) 0.9099 | Acc(val) 0.9230 |*
Epoch 00086 | Loss(train) 0.4706 | Acc(train) 0.9114 | Acc(val) 0.9233 |*
Epoch 00087 | Loss(train) 0.4700 | Acc(train) 0.9108 | Acc(val) 0.9236 |*
Epoch 00088 | Loss(train) 0.4608 | Acc(train) 0.9118 | Acc(val) 0.9238 |*
Epoch 00089 | Loss(train) 0.4697 | Acc(train) 0.9111 | Acc(val) 0.9239 |*
Epoch 00090 | Loss(train) 0.4618 | Acc(train) 0.9123 | Acc(val) 0.9239 |
Epoch 00091 | Loss(train) 0.4633 | Acc(train) 0.9120 | Acc(val) 0.9241 |*
Epoch 00092 | Loss(train) 0.4653 | Acc(train) 0.9119 | Acc(val) 0.9244 |*
Epoch 00093 | Loss(train) 0.4607 | Acc(train) 0.9108 | Acc(val) 0.9245 |*
Epoch 00094 | Loss(train) 0.4542 | Acc(train) 0.9133 | Acc(val) 0.9246 |*
Epoch 00095 | Loss(train) 0.4592 | Acc(train) 0.9122 | Acc(val) 0.9248 |*
Epoch 00096 | Loss(train) 0.4507 | Acc(train) 0.9146 | Acc(val) 0.9250 |*
Epoch 00097 | Loss(train) 0.4549 | Acc(train) 0.9128 | Acc(val) 0.9251 |*
Epoch 00098 | Loss(train) 0.4505 | Acc(train) 0.9129 | Acc(val) 0.9252 |*
Epoch 00099 | Loss(train) 0.4507 | Acc(train) 0.9140 | Acc(val) 0.9253 |*
Epoch 00100 | Loss(train) 0.4420 | Acc(train) 0.9146 | Acc(val) 0.9252 |
Epoch 00101 | Loss(train) 0.4453 | Acc(train) 0.9141 | Acc(val) 0.9253 |
Epoch 00102 | Loss(train) 0.4478 | Acc(train) 0.9137 | Acc(val) 0.9256 |*
Epoch 00103 | Loss(train) 0.4424 | Acc(train) 0.9147 | Acc(val) 0.9258 |*
Epoch 00104 | Loss(train) 0.4420 | Acc(train) 0.9140 | Acc(val) 0.9259 |*
Epoch 00105 | Loss(train) 0.4417 | Acc(train) 0.9138 | Acc(val) 0.9263 |*
Epoch 00106 | Loss(train) 0.4496 | Acc(train) 0.9144 | Acc(val) 0.9265 |*
Epoch 00107 | Loss(train) 0.4371 | Acc(train) 0.9154 | Acc(val) 0.9266 |*
Epoch 00108 | Loss(train) 0.4378 | Acc(train) 0.9151 | Acc(val) 0.9267 |*
Epoch 00109 | Loss(train) 0.4349 | Acc(train) 0.9160 | Acc(val) 0.9267 |
Epoch 00110 | Loss(train) 0.4331 | Acc(train) 0.9165 | Acc(val) 0.9270 |*
Epoch 00111 | Loss(train) 0.4338 | Acc(train) 0.9153 | Acc(val) 0.9271 |*
Epoch 00112 | Loss(train) 0.4321 | Acc(train) 0.9155 | Acc(val) 0.9273 |*
Epoch 00113 | Loss(train) 0.4309 | Acc(train) 0.9164 | Acc(val) 0.9274 |*
Epoch 00114 | Loss(train) 0.4320 | Acc(train) 0.9152 | Acc(val) 0.9275 |*
Epoch 00115 | Loss(train) 0.4339 | Acc(train) 0.9163 | Acc(val) 0.9277 |*
Epoch 00116 | Loss(train) 0.4335 | Acc(train) 0.9159 | Acc(val) 0.9279 |*
Epoch 00117 | Loss(train) 0.4259 | Acc(train) 0.9169 | Acc(val) 0.9282 |*
Epoch 00118 | Loss(train) 0.4280 | Acc(train) 0.9158 | Acc(val) 0.9283 |*
Epoch 00119 | Loss(train) 0.4242 | Acc(train) 0.9176 | Acc(val) 0.9284 |*
Epoch 00120 | Loss(train) 0.4262 | Acc(train) 0.9160 | Acc(val) 0.9283 |
Epoch 00121 | Loss(train) 0.4269 | Acc(train) 0.9163 | Acc(val) 0.9283 |
Epoch 00122 | Loss(train) 0.4198 | Acc(train) 0.9174 | Acc(val) 0.9283 |
Epoch 00123 | Loss(train) 0.4236 | Acc(train) 0.9176 | Acc(val) 0.9282 |
Epoch 00124 | Loss(train) 0.4202 | Acc(train) 0.9173 | Acc(val) 0.9286 |*
Epoch 00125 | Loss(train) 0.4225 | Acc(train) 0.9175 | Acc(val) 0.9287 |*
Epoch 00126 | Loss(train) 0.4198 | Acc(train) 0.9178 | Acc(val) 0.9287 |*
Epoch 00127 | Loss(train) 0.4203 | Acc(train) 0.9177 | Acc(val) 0.9287 |
Epoch 00128 | Loss(train) 0.4179 | Acc(train) 0.9189 | Acc(val) 0.9290 |*
Epoch 00129 | Loss(train) 0.4228 | Acc(train) 0.9170 | Acc(val) 0.9290 |*
Epoch 00130 | Loss(train) 0.4158 | Acc(train) 0.9187 | Acc(val) 0.9289 |
Epoch 00131 | Loss(train) 0.4144 | Acc(train) 0.9182 | Acc(val) 0.9291 |*
Epoch 00132 | Loss(train) 0.4151 | Acc(train) 0.9185 | Acc(val) 0.9290 |
Epoch 00133 | Loss(train) 0.4154 | Acc(train) 0.9182 | Acc(val) 0.9291 |*
Epoch 00134 | Loss(train) 0.4149 | Acc(train) 0.9180 | Acc(val) 0.9293 |*
Epoch 00135 | Loss(train) 0.4146 | Acc(train) 0.9185 | Acc(val) 0.9293 |
Epoch 00136 | Loss(train) 0.4149 | Acc(train) 0.9178 | Acc(val) 0.9296 |*
Epoch 00137 | Loss(train) 0.4147 | Acc(train) 0.9184 | Acc(val) 0.9295 |
Epoch 00138 | Loss(train) 0.4088 | Acc(train) 0.9193 | Acc(val) 0.9296 |*
Epoch 00139 | Loss(train) 0.4086 | Acc(train) 0.9188 | Acc(val) 0.9296 |*
Epoch 00140 | Loss(train) 0.4114 | Acc(train) 0.9194 | Acc(val) 0.9296 |
Epoch 00141 | Loss(train) 0.4111 | Acc(train) 0.9186 | Acc(val) 0.9297 |*
Epoch 00142 | Loss(train) 0.4104 | Acc(train) 0.9188 | Acc(val) 0.9296 |
Epoch 00143 | Loss(train) 0.4101 | Acc(train) 0.9187 | Acc(val) 0.9297 |
Epoch 00144 | Loss(train) 0.4089 | Acc(train) 0.9199 | Acc(val) 0.9297 |
Epoch 00145 | Loss(train) 0.4074 | Acc(train) 0.9187 | Acc(val) 0.9297 |
Epoch 00146 | Loss(train) 0.4062 | Acc(train) 0.9189 | Acc(val) 0.9299 |*
Epoch 00147 | Loss(train) 0.4059 | Acc(train) 0.9207 | Acc(val) 0.9300 |*
Epoch 00148 | Loss(train) 0.4059 | Acc(train) 0.9199 | Acc(val) 0.9299 |
Epoch 00149 | Loss(train) 0.4055 | Acc(train) 0.9189 | Acc(val) 0.9298 |
Epoch 00150 | Loss(train) 0.4031 | Acc(train) 0.9193 | Acc(val) 0.9296 |
Epoch 00151 | Loss(train) 0.4037 | Acc(train) 0.9193 | Acc(val) 0.9295 |
Epoch 00152 | Loss(train) 0.4029 | Acc(train) 0.9201 | Acc(val) 0.9296 |
Epoch 00153 | Loss(train) 0.4025 | Acc(train) 0.9203 | Acc(val) 0.9298 |
Epoch 00154 | Loss(train) 0.3999 | Acc(train) 0.9206 | Acc(val) 0.9297 |
Epoch 00155 | Loss(train) 0.4003 | Acc(train) 0.9201 | Acc(val) 0.9302 |*
Epoch 00156 | Loss(train) 0.4038 | Acc(train) 0.9205 | Acc(val) 0.9302 |*
Epoch 00157 | Loss(train) 0.4009 | Acc(train) 0.9200 | Acc(val) 0.9306 |*
Epoch 00158 | Loss(train) 0.3993 | Acc(train) 0.9211 | Acc(val) 0.9304 |
Epoch 00159 | Loss(train) 0.3978 | Acc(train) 0.9198 | Acc(val) 0.9305 |
Epoch 00160 | Loss(train) 0.4008 | Acc(train) 0.9204 | Acc(val) 0.9304 |
Epoch 00161 | Loss(train) 0.3946 | Acc(train) 0.9214 | Acc(val) 0.9302 |
Epoch 00162 | Loss(train) 0.3968 | Acc(train) 0.9203 | Acc(val) 0.9303 |
Epoch 00163 | Loss(train) 0.3946 | Acc(train) 0.9208 | Acc(val) 0.9303 |
Epoch 00164 | Loss(train) 0.3969 | Acc(train) 0.9204 | Acc(val) 0.9303 |
Epoch 00165 | Loss(train) 0.3947 | Acc(train) 0.9205 | Acc(val) 0.9300 |
Epoch 00166 | Loss(train) 0.3916 | Acc(train) 0.9217 | Acc(val) 0.9301 |
Epoch 00167 | Loss(train) 0.3954 | Acc(train) 0.9214 | Acc(val) 0.9304 |
Epoch 00168 | Loss(train) 0.3892 | Acc(train) 0.9208 | Acc(val) 0.9308 |*
Epoch 00169 | Loss(train) 0.3919 | Acc(train) 0.9210 | Acc(val) 0.9308 |*
Epoch 00170 | Loss(train) 0.3893 | Acc(train) 0.9221 | Acc(val) 0.9308 |
Epoch 00171 | Loss(train) 0.3907 | Acc(train) 0.9216 | Acc(val) 0.9307 |
Epoch 00172 | Loss(train) 0.3935 | Acc(train) 0.9208 | Acc(val) 0.9305 |
Epoch 00173 | Loss(train) 0.3926 | Acc(train) 0.9209 | Acc(val) 0.9304 |
Epoch 00174 | Loss(train) 0.3904 | Acc(train) 0.9214 | Acc(val) 0.9306 |
Epoch 00175 | Loss(train) 0.3913 | Acc(train) 0.9224 | Acc(val) 0.9307 |
Epoch 00176 | Loss(train) 0.3884 | Acc(train) 0.9223 | Acc(val) 0.9308 |
Epoch 00177 | Loss(train) 0.3891 | Acc(train) 0.9214 | Acc(val) 0.9307 |
Epoch 00178 | Loss(train) 0.3894 | Acc(train) 0.9220 | Acc(val) 0.9309 |*
Epoch 00179 | Loss(train) 0.3881 | Acc(train) 0.9222 | Acc(val) 0.9310 |*
Epoch 00180 | Loss(train) 0.3892 | Acc(train) 0.9209 | Acc(val) 0.9311 |*
Epoch 00181 | Loss(train) 0.3859 | Acc(train) 0.9214 | Acc(val) 0.9308 |
Epoch 00182 | Loss(train) 0.3863 | Acc(train) 0.9229 | Acc(val) 0.9306 |
Epoch 00183 | Loss(train) 0.3840 | Acc(train) 0.9219 | Acc(val) 0.9310 |
Epoch 00184 | Loss(train) 0.3847 | Acc(train) 0.9226 | Acc(val) 0.9311 |
Epoch 00185 | Loss(train) 0.3851 | Acc(train) 0.9211 | Acc(val) 0.9311 |
Epoch 00186 | Loss(train) 0.3825 | Acc(train) 0.9227 | Acc(val) 0.9311 |
Epoch 00187 | Loss(train) 0.3841 | Acc(train) 0.9233 | Acc(val) 0.9313 |*
Epoch 00188 | Loss(train) 0.3802 | Acc(train) 0.9233 | Acc(val) 0.9313 |
Epoch 00189 | Loss(train) 0.3805 | Acc(train) 0.9234 | Acc(val) 0.9313 |
Epoch 00190 | Loss(train) 0.3806 | Acc(train) 0.9230 | Acc(val) 0.9312 |
Epoch 00191 | Loss(train) 0.3804 | Acc(train) 0.9233 | Acc(val) 0.9314 |*
Epoch 00192 | Loss(train) 0.3799 | Acc(train) 0.9229 | Acc(val) 0.9316 |*
Epoch 00193 | Loss(train) 0.3810 | Acc(train) 0.9223 | Acc(val) 0.9316 |
Epoch 00194 | Loss(train) 0.3821 | Acc(train) 0.9222 | Acc(val) 0.9318 |*
Epoch 00195 | Loss(train) 0.3801 | Acc(train) 0.9220 | Acc(val) 0.9318 |*
Epoch 00196 | Loss(train) 0.3806 | Acc(train) 0.9229 | Acc(val) 0.9320 |*
Epoch 00197 | Loss(train) 0.3759 | Acc(train) 0.9234 | Acc(val) 0.9320 |
Epoch 00198 | Loss(train) 0.3788 | Acc(train) 0.9240 | Acc(val) 0.9319 |
Epoch 00199 | Loss(train) 0.3784 | Acc(train) 0.9228 | Acc(val) 0.9320 |
Epoch 00200 | Loss(train) 0.3770 | Acc(train) 0.9240 | Acc(val) 0.9318 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7221 | Acc(train) 0.0136 | Acc(val) 0.3000 |*
Epoch 00002 | Loss(train) 3.4057 | Acc(train) 0.2981 | Acc(val) 0.3074 |*
Epoch 00003 | Loss(train) 3.1506 | Acc(train) 0.3077 | Acc(val) 0.3388 |*
Epoch 00004 | Loss(train) 2.9650 | Acc(train) 0.3399 | Acc(val) 0.3503 |*
Epoch 00005 | Loss(train) 2.8037 | Acc(train) 0.3520 | Acc(val) 0.3925 |*
Epoch 00006 | Loss(train) 2.6608 | Acc(train) 0.3918 | Acc(val) 0.4203 |*
Epoch 00007 | Loss(train) 2.5340 | Acc(train) 0.4224 | Acc(val) 0.4491 |*
Epoch 00008 | Loss(train) 2.4192 | Acc(train) 0.4504 | Acc(val) 0.4738 |*
Epoch 00009 | Loss(train) 2.3194 | Acc(train) 0.4730 | Acc(val) 0.5074 |*
Epoch 00010 | Loss(train) 2.2289 | Acc(train) 0.5019 | Acc(val) 0.5256 |*
Epoch 00011 | Loss(train) 2.1446 | Acc(train) 0.5210 | Acc(val) 0.5367 |*
Epoch 00012 | Loss(train) 2.0617 | Acc(train) 0.5291 | Acc(val) 0.5625 |*
Epoch 00013 | Loss(train) 1.9839 | Acc(train) 0.5541 | Acc(val) 0.6034 |*
Epoch 00014 | Loss(train) 1.9056 | Acc(train) 0.5889 | Acc(val) 0.6190 |*
Epoch 00015 | Loss(train) 1.8294 | Acc(train) 0.6076 | Acc(val) 0.6408 |*
Epoch 00016 | Loss(train) 1.7552 | Acc(train) 0.6282 | Acc(val) 0.6605 |*
Epoch 00017 | Loss(train) 1.6830 | Acc(train) 0.6429 | Acc(val) 0.6732 |*
Epoch 00018 | Loss(train) 1.6146 | Acc(train) 0.6604 | Acc(val) 0.6815 |*
Epoch 00019 | Loss(train) 1.5470 | Acc(train) 0.6686 | Acc(val) 0.6960 |*
Epoch 00020 | Loss(train) 1.4889 | Acc(train) 0.6816 | Acc(val) 0.7165 |*
Epoch 00021 | Loss(train) 1.4232 | Acc(train) 0.7026 | Acc(val) 0.7319 |*
Epoch 00022 | Loss(train) 1.3733 | Acc(train) 0.7176 | Acc(val) 0.7488 |*
Epoch 00023 | Loss(train) 1.3176 | Acc(train) 0.7357 | Acc(val) 0.7660 |*
Epoch 00024 | Loss(train) 1.2720 | Acc(train) 0.7506 | Acc(val) 0.7737 |*
Epoch 00025 | Loss(train) 1.2192 | Acc(train) 0.7562 | Acc(val) 0.7786 |*
Epoch 00026 | Loss(train) 1.1771 | Acc(train) 0.7617 | Acc(val) 0.7815 |*
Epoch 00027 | Loss(train) 1.1361 | Acc(train) 0.7610 | Acc(val) 0.7863 |*
Epoch 00028 | Loss(train) 1.0949 | Acc(train) 0.7662 | Acc(val) 0.8016 |*
Epoch 00029 | Loss(train) 1.0536 | Acc(train) 0.7839 | Acc(val) 0.8188 |*
Epoch 00030 | Loss(train) 1.0154 | Acc(train) 0.8034 | Acc(val) 0.8329 |*
Epoch 00031 | Loss(train) 0.9833 | Acc(train) 0.8139 | Acc(val) 0.8477 |*
Epoch 00032 | Loss(train) 0.9612 | Acc(train) 0.8285 | Acc(val) 0.8578 |*
Epoch 00033 | Loss(train) 0.9229 | Acc(train) 0.8386 | Acc(val) 0.8640 |*
Epoch 00034 | Loss(train) 0.8932 | Acc(train) 0.8461 | Acc(val) 0.8692 |*
Epoch 00035 | Loss(train) 0.8716 | Acc(train) 0.8498 | Acc(val) 0.8722 |*
Epoch 00036 | Loss(train) 0.8466 | Acc(train) 0.8527 | Acc(val) 0.8732 |*
Epoch 00037 | Loss(train) 0.8212 | Acc(train) 0.8538 | Acc(val) 0.8744 |*
Epoch 00038 | Loss(train) 0.8052 | Acc(train) 0.8561 | Acc(val) 0.8771 |*
Epoch 00039 | Loss(train) 0.7787 | Acc(train) 0.8608 | Acc(val) 0.8813 |*
Epoch 00040 | Loss(train) 0.7641 | Acc(train) 0.8647 | Acc(val) 0.8862 |*
Epoch 00041 | Loss(train) 0.7471 | Acc(train) 0.8711 | Acc(val) 0.8906 |*
Epoch 00042 | Loss(train) 0.7257 | Acc(train) 0.8745 | Acc(val) 0.8938 |*
Epoch 00043 | Loss(train) 0.7177 | Acc(train) 0.8768 | Acc(val) 0.8965 |*
Epoch 00044 | Loss(train) 0.6969 | Acc(train) 0.8808 | Acc(val) 0.8985 |*
Epoch 00045 | Loss(train) 0.6752 | Acc(train) 0.8852 | Acc(val) 0.8994 |*
Epoch 00046 | Loss(train) 0.6649 | Acc(train) 0.8859 | Acc(val) 0.9009 |*
Epoch 00047 | Loss(train) 0.6582 | Acc(train) 0.8889 | Acc(val) 0.9023 |*
Epoch 00048 | Loss(train) 0.6401 | Acc(train) 0.8884 | Acc(val) 0.9036 |*
Epoch 00049 | Loss(train) 0.6300 | Acc(train) 0.8889 | Acc(val) 0.9047 |*
Epoch 00050 | Loss(train) 0.6241 | Acc(train) 0.8898 | Acc(val) 0.9066 |*
Epoch 00051 | Loss(train) 0.6176 | Acc(train) 0.8917 | Acc(val) 0.9073 |*
Epoch 00052 | Loss(train) 0.6084 | Acc(train) 0.8947 | Acc(val) 0.9084 |*
Epoch 00053 | Loss(train) 0.5984 | Acc(train) 0.8956 | Acc(val) 0.9096 |*
Epoch 00054 | Loss(train) 0.5922 | Acc(train) 0.8957 | Acc(val) 0.9105 |*
Epoch 00055 | Loss(train) 0.5805 | Acc(train) 0.8954 | Acc(val) 0.9110 |*
Epoch 00056 | Loss(train) 0.5766 | Acc(train) 0.8978 | Acc(val) 0.9114 |*
Epoch 00057 | Loss(train) 0.5660 | Acc(train) 0.8983 | Acc(val) 0.9127 |*
Epoch 00058 | Loss(train) 0.5554 | Acc(train) 0.8996 | Acc(val) 0.9136 |*
Epoch 00059 | Loss(train) 0.5565 | Acc(train) 0.9007 | Acc(val) 0.9145 |*
Epoch 00060 | Loss(train) 0.5528 | Acc(train) 0.9015 | Acc(val) 0.9150 |*
Epoch 00061 | Loss(train) 0.5431 | Acc(train) 0.9020 | Acc(val) 0.9155 |*
Epoch 00062 | Loss(train) 0.5439 | Acc(train) 0.9016 | Acc(val) 0.9155 |
Epoch 00063 | Loss(train) 0.5426 | Acc(train) 0.9035 | Acc(val) 0.9162 |*
Epoch 00064 | Loss(train) 0.5329 | Acc(train) 0.9036 | Acc(val) 0.9166 |*
Epoch 00065 | Loss(train) 0.5277 | Acc(train) 0.9036 | Acc(val) 0.9172 |*
Epoch 00066 | Loss(train) 0.5213 | Acc(train) 0.9039 | Acc(val) 0.9175 |*
Epoch 00067 | Loss(train) 0.5121 | Acc(train) 0.9041 | Acc(val) 0.9179 |*
Epoch 00068 | Loss(train) 0.5121 | Acc(train) 0.9065 | Acc(val) 0.9184 |*
Epoch 00069 | Loss(train) 0.5075 | Acc(train) 0.9059 | Acc(val) 0.9190 |*
Epoch 00070 | Loss(train) 0.5069 | Acc(train) 0.9069 | Acc(val) 0.9199 |*
Epoch 00071 | Loss(train) 0.5024 | Acc(train) 0.9072 | Acc(val) 0.9196 |
Epoch 00072 | Loss(train) 0.5019 | Acc(train) 0.9070 | Acc(val) 0.9195 |
Epoch 00073 | Loss(train) 0.4942 | Acc(train) 0.9088 | Acc(val) 0.9198 |
Epoch 00074 | Loss(train) 0.4940 | Acc(train) 0.9079 | Acc(val) 0.9199 |
Epoch 00075 | Loss(train) 0.4912 | Acc(train) 0.9088 | Acc(val) 0.9202 |*
Epoch 00076 | Loss(train) 0.4856 | Acc(train) 0.9092 | Acc(val) 0.9202 |
Epoch 00077 | Loss(train) 0.4828 | Acc(train) 0.9095 | Acc(val) 0.9202 |
Epoch 00078 | Loss(train) 0.4820 | Acc(train) 0.9092 | Acc(val) 0.9203 |*
Epoch 00079 | Loss(train) 0.4814 | Acc(train) 0.9091 | Acc(val) 0.9206 |*
Epoch 00080 | Loss(train) 0.4838 | Acc(train) 0.9099 | Acc(val) 0.9212 |*
Epoch 00081 | Loss(train) 0.4763 | Acc(train) 0.9104 | Acc(val) 0.9214 |*
Epoch 00082 | Loss(train) 0.4778 | Acc(train) 0.9112 | Acc(val) 0.9217 |*
Epoch 00083 | Loss(train) 0.4724 | Acc(train) 0.9113 | Acc(val) 0.9221 |*
Epoch 00084 | Loss(train) 0.4673 | Acc(train) 0.9117 | Acc(val) 0.9226 |*
Epoch 00085 | Loss(train) 0.4669 | Acc(train) 0.9111 | Acc(val) 0.9230 |*
Epoch 00086 | Loss(train) 0.4653 | Acc(train) 0.9123 | Acc(val) 0.9231 |*
Epoch 00087 | Loss(train) 0.4642 | Acc(train) 0.9127 | Acc(val) 0.9233 |*
Epoch 00088 | Loss(train) 0.4634 | Acc(train) 0.9134 | Acc(val) 0.9235 |*
Epoch 00089 | Loss(train) 0.4618 | Acc(train) 0.9124 | Acc(val) 0.9235 |*
Epoch 00090 | Loss(train) 0.4619 | Acc(train) 0.9110 | Acc(val) 0.9235 |
Epoch 00091 | Loss(train) 0.4604 | Acc(train) 0.9130 | Acc(val) 0.9235 |
Epoch 00092 | Loss(train) 0.4549 | Acc(train) 0.9140 | Acc(val) 0.9237 |*
Epoch 00093 | Loss(train) 0.4532 | Acc(train) 0.9132 | Acc(val) 0.9238 |*
Epoch 00094 | Loss(train) 0.4522 | Acc(train) 0.9125 | Acc(val) 0.9238 |
Epoch 00095 | Loss(train) 0.4507 | Acc(train) 0.9132 | Acc(val) 0.9240 |*
Epoch 00096 | Loss(train) 0.4527 | Acc(train) 0.9143 | Acc(val) 0.9246 |*
Epoch 00097 | Loss(train) 0.4476 | Acc(train) 0.9149 | Acc(val) 0.9250 |*
Epoch 00098 | Loss(train) 0.4487 | Acc(train) 0.9143 | Acc(val) 0.9253 |*
Epoch 00099 | Loss(train) 0.4504 | Acc(train) 0.9147 | Acc(val) 0.9256 |*
Epoch 00100 | Loss(train) 0.4444 | Acc(train) 0.9148 | Acc(val) 0.9260 |*
Epoch 00101 | Loss(train) 0.4404 | Acc(train) 0.9160 | Acc(val) 0.9262 |*
Epoch 00102 | Loss(train) 0.4456 | Acc(train) 0.9158 | Acc(val) 0.9264 |*
Epoch 00103 | Loss(train) 0.4399 | Acc(train) 0.9161 | Acc(val) 0.9265 |*
Epoch 00104 | Loss(train) 0.4418 | Acc(train) 0.9160 | Acc(val) 0.9265 |*
Epoch 00105 | Loss(train) 0.4431 | Acc(train) 0.9154 | Acc(val) 0.9266 |*
Epoch 00106 | Loss(train) 0.4390 | Acc(train) 0.9166 | Acc(val) 0.9267 |*
Epoch 00107 | Loss(train) 0.4411 | Acc(train) 0.9157 | Acc(val) 0.9269 |*
Epoch 00108 | Loss(train) 0.4353 | Acc(train) 0.9159 | Acc(val) 0.9271 |*
Epoch 00109 | Loss(train) 0.4373 | Acc(train) 0.9154 | Acc(val) 0.9271 |
Epoch 00110 | Loss(train) 0.4335 | Acc(train) 0.9169 | Acc(val) 0.9270 |
Epoch 00111 | Loss(train) 0.4367 | Acc(train) 0.9153 | Acc(val) 0.9276 |*
Epoch 00112 | Loss(train) 0.4316 | Acc(train) 0.9170 | Acc(val) 0.9278 |*
Epoch 00113 | Loss(train) 0.4325 | Acc(train) 0.9168 | Acc(val) 0.9279 |*
Epoch 00114 | Loss(train) 0.4283 | Acc(train) 0.9171 | Acc(val) 0.9280 |*
Epoch 00115 | Loss(train) 0.4287 | Acc(train) 0.9181 | Acc(val) 0.9281 |*
Epoch 00116 | Loss(train) 0.4268 | Acc(train) 0.9172 | Acc(val) 0.9281 |
Epoch 00117 | Loss(train) 0.4270 | Acc(train) 0.9181 | Acc(val) 0.9280 |
Epoch 00118 | Loss(train) 0.4286 | Acc(train) 0.9174 | Acc(val) 0.9281 |*
Epoch 00119 | Loss(train) 0.4245 | Acc(train) 0.9172 | Acc(val) 0.9281 |*
Epoch 00120 | Loss(train) 0.4218 | Acc(train) 0.9176 | Acc(val) 0.9282 |*
Epoch 00121 | Loss(train) 0.4215 | Acc(train) 0.9177 | Acc(val) 0.9284 |*
Epoch 00122 | Loss(train) 0.4237 | Acc(train) 0.9187 | Acc(val) 0.9285 |*
Epoch 00123 | Loss(train) 0.4205 | Acc(train) 0.9188 | Acc(val) 0.9286 |*
Epoch 00124 | Loss(train) 0.4179 | Acc(train) 0.9190 | Acc(val) 0.9286 |
Epoch 00125 | Loss(train) 0.4204 | Acc(train) 0.9190 | Acc(val) 0.9285 |
Epoch 00126 | Loss(train) 0.4176 | Acc(train) 0.9198 | Acc(val) 0.9284 |
Epoch 00127 | Loss(train) 0.4146 | Acc(train) 0.9196 | Acc(val) 0.9284 |
Epoch 00128 | Loss(train) 0.4152 | Acc(train) 0.9196 | Acc(val) 0.9287 |*
Epoch 00129 | Loss(train) 0.4160 | Acc(train) 0.9189 | Acc(val) 0.9290 |*
Epoch 00130 | Loss(train) 0.4123 | Acc(train) 0.9202 | Acc(val) 0.9290 |
Epoch 00131 | Loss(train) 0.4085 | Acc(train) 0.9198 | Acc(val) 0.9293 |*
Epoch 00132 | Loss(train) 0.4127 | Acc(train) 0.9192 | Acc(val) 0.9295 |*
Epoch 00133 | Loss(train) 0.4131 | Acc(train) 0.9192 | Acc(val) 0.9294 |
Epoch 00134 | Loss(train) 0.4110 | Acc(train) 0.9200 | Acc(val) 0.9294 |
Epoch 00135 | Loss(train) 0.4115 | Acc(train) 0.9201 | Acc(val) 0.9297 |*
Epoch 00136 | Loss(train) 0.4098 | Acc(train) 0.9197 | Acc(val) 0.9296 |
Epoch 00137 | Loss(train) 0.4045 | Acc(train) 0.9208 | Acc(val) 0.9297 |
Epoch 00138 | Loss(train) 0.4076 | Acc(train) 0.9201 | Acc(val) 0.9296 |
Epoch 00139 | Loss(train) 0.4091 | Acc(train) 0.9198 | Acc(val) 0.9295 |
Epoch 00140 | Loss(train) 0.4068 | Acc(train) 0.9208 | Acc(val) 0.9295 |
Epoch 00141 | Loss(train) 0.4067 | Acc(train) 0.9195 | Acc(val) 0.9294 |
Epoch 00142 | Loss(train) 0.4022 | Acc(train) 0.9207 | Acc(val) 0.9297 |
Epoch 00143 | Loss(train) 0.4070 | Acc(train) 0.9202 | Acc(val) 0.9298 |*
Epoch 00144 | Loss(train) 0.4027 | Acc(train) 0.9209 | Acc(val) 0.9299 |*
Epoch 00145 | Loss(train) 0.4030 | Acc(train) 0.9216 | Acc(val) 0.9299 |*
Epoch 00146 | Loss(train) 0.4040 | Acc(train) 0.9202 | Acc(val) 0.9301 |*
Epoch 00147 | Loss(train) 0.4026 | Acc(train) 0.9201 | Acc(val) 0.9301 |*
Epoch 00148 | Loss(train) 0.4037 | Acc(train) 0.9214 | Acc(val) 0.9303 |*
Epoch 00149 | Loss(train) 0.4027 | Acc(train) 0.9211 | Acc(val) 0.9305 |*
Epoch 00150 | Loss(train) 0.3960 | Acc(train) 0.9211 | Acc(val) 0.9305 |
Epoch 00151 | Loss(train) 0.3993 | Acc(train) 0.9214 | Acc(val) 0.9305 |*
Epoch 00152 | Loss(train) 0.3958 | Acc(train) 0.9203 | Acc(val) 0.9304 |
Epoch 00153 | Loss(train) 0.3968 | Acc(train) 0.9217 | Acc(val) 0.9305 |
Epoch 00154 | Loss(train) 0.3982 | Acc(train) 0.9219 | Acc(val) 0.9307 |*
Epoch 00155 | Loss(train) 0.3979 | Acc(train) 0.9216 | Acc(val) 0.9308 |*
Epoch 00156 | Loss(train) 0.3924 | Acc(train) 0.9221 | Acc(val) 0.9308 |
Epoch 00157 | Loss(train) 0.3965 | Acc(train) 0.9212 | Acc(val) 0.9308 |
Epoch 00158 | Loss(train) 0.3939 | Acc(train) 0.9216 | Acc(val) 0.9308 |
Epoch 00159 | Loss(train) 0.3982 | Acc(train) 0.9214 | Acc(val) 0.9309 |*
Epoch 00160 | Loss(train) 0.3934 | Acc(train) 0.9221 | Acc(val) 0.9309 |
Epoch 00161 | Loss(train) 0.3943 | Acc(train) 0.9220 | Acc(val) 0.9308 |
Epoch 00162 | Loss(train) 0.3929 | Acc(train) 0.9212 | Acc(val) 0.9309 |
Epoch 00163 | Loss(train) 0.3915 | Acc(train) 0.9220 | Acc(val) 0.9309 |
Epoch 00164 | Loss(train) 0.3926 | Acc(train) 0.9215 | Acc(val) 0.9311 |*
Epoch 00165 | Loss(train) 0.3915 | Acc(train) 0.9216 | Acc(val) 0.9312 |*
Epoch 00166 | Loss(train) 0.3886 | Acc(train) 0.9222 | Acc(val) 0.9314 |*
Epoch 00167 | Loss(train) 0.3905 | Acc(train) 0.9221 | Acc(val) 0.9317 |*
Epoch 00168 | Loss(train) 0.3868 | Acc(train) 0.9228 | Acc(val) 0.9315 |
Epoch 00169 | Loss(train) 0.3885 | Acc(train) 0.9225 | Acc(val) 0.9316 |
Epoch 00170 | Loss(train) 0.3842 | Acc(train) 0.9225 | Acc(val) 0.9315 |
Epoch 00171 | Loss(train) 0.3906 | Acc(train) 0.9225 | Acc(val) 0.9314 |
Epoch 00172 | Loss(train) 0.3899 | Acc(train) 0.9227 | Acc(val) 0.9314 |
Epoch 00173 | Loss(train) 0.3897 | Acc(train) 0.9221 | Acc(val) 0.9315 |
Epoch 00174 | Loss(train) 0.3882 | Acc(train) 0.9222 | Acc(val) 0.9316 |
Epoch 00175 | Loss(train) 0.3858 | Acc(train) 0.9226 | Acc(val) 0.9314 |
Epoch 00176 | Loss(train) 0.3851 | Acc(train) 0.9228 | Acc(val) 0.9318 |*
Epoch 00177 | Loss(train) 0.3879 | Acc(train) 0.9231 | Acc(val) 0.9319 |*
Epoch 00178 | Loss(train) 0.3864 | Acc(train) 0.9227 | Acc(val) 0.9320 |*
Epoch 00179 | Loss(train) 0.3860 | Acc(train) 0.9217 | Acc(val) 0.9321 |*
Epoch 00180 | Loss(train) 0.3833 | Acc(train) 0.9225 | Acc(val) 0.9323 |*
Epoch 00181 | Loss(train) 0.3847 | Acc(train) 0.9230 | Acc(val) 0.9319 |
Epoch 00182 | Loss(train) 0.3837 | Acc(train) 0.9236 | Acc(val) 0.9318 |
Epoch 00183 | Loss(train) 0.3809 | Acc(train) 0.9242 | Acc(val) 0.9316 |
Epoch 00184 | Loss(train) 0.3848 | Acc(train) 0.9233 | Acc(val) 0.9318 |
Epoch 00185 | Loss(train) 0.3828 | Acc(train) 0.9227 | Acc(val) 0.9320 |
Epoch 00186 | Loss(train) 0.3837 | Acc(train) 0.9225 | Acc(val) 0.9318 |
Epoch 00187 | Loss(train) 0.3828 | Acc(train) 0.9232 | Acc(val) 0.9321 |
Epoch 00188 | Loss(train) 0.3817 | Acc(train) 0.9233 | Acc(val) 0.9321 |
Epoch 00189 | Loss(train) 0.3792 | Acc(train) 0.9229 | Acc(val) 0.9322 |
Epoch 00190 | Loss(train) 0.3790 | Acc(train) 0.9243 | Acc(val) 0.9321 |
Epoch 00191 | Loss(train) 0.3778 | Acc(train) 0.9236 | Acc(val) 0.9322 |
Epoch 00192 | Loss(train) 0.3801 | Acc(train) 0.9234 | Acc(val) 0.9322 |
Epoch 00193 | Loss(train) 0.3770 | Acc(train) 0.9242 | Acc(val) 0.9322 |
Epoch 00194 | Loss(train) 0.3795 | Acc(train) 0.9226 | Acc(val) 0.9323 |*
Epoch 00195 | Loss(train) 0.3796 | Acc(train) 0.9241 | Acc(val) 0.9324 |*
Epoch 00196 | Loss(train) 0.3752 | Acc(train) 0.9233 | Acc(val) 0.9323 |
Epoch 00197 | Loss(train) 0.3790 | Acc(train) 0.9243 | Acc(val) 0.9322 |
Epoch 00198 | Loss(train) 0.3778 | Acc(train) 0.9241 | Acc(val) 0.9324 |
Epoch 00199 | Loss(train) 0.3761 | Acc(train) 0.9236 | Acc(val) 0.9325 |*
Epoch 00200 | Loss(train) 0.3760 | Acc(train) 0.9232 | Acc(val) 0.9326 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7218 | Acc(train) 0.0211 | Acc(val) 0.1659 |*
Epoch 00002 | Loss(train) 3.4587 | Acc(train) 0.1649 | Acc(val) 0.3011 |*
Epoch 00003 | Loss(train) 3.2219 | Acc(train) 0.2876 | Acc(val) 0.4183 |*
Epoch 00004 | Loss(train) 3.0107 | Acc(train) 0.4133 | Acc(val) 0.4808 |*
Epoch 00005 | Loss(train) 2.7989 | Acc(train) 0.4769 | Acc(val) 0.4811 |*
Epoch 00006 | Loss(train) 2.6122 | Acc(train) 0.4758 | Acc(val) 0.4832 |*
Epoch 00007 | Loss(train) 2.4461 | Acc(train) 0.4779 | Acc(val) 0.4852 |*
Epoch 00008 | Loss(train) 2.3123 | Acc(train) 0.4803 | Acc(val) 0.4889 |*
Epoch 00009 | Loss(train) 2.1951 | Acc(train) 0.4835 | Acc(val) 0.5030 |*
Epoch 00010 | Loss(train) 2.0929 | Acc(train) 0.4995 | Acc(val) 0.5470 |*
Epoch 00011 | Loss(train) 1.9873 | Acc(train) 0.5386 | Acc(val) 0.5725 |*
Epoch 00012 | Loss(train) 1.9002 | Acc(train) 0.5657 | Acc(val) 0.5859 |*
Epoch 00013 | Loss(train) 1.8087 | Acc(train) 0.5806 | Acc(val) 0.5989 |*
Epoch 00014 | Loss(train) 1.7201 | Acc(train) 0.5925 | Acc(val) 0.6189 |*
Epoch 00015 | Loss(train) 1.6439 | Acc(train) 0.6111 | Acc(val) 0.6382 |*
Epoch 00016 | Loss(train) 1.5699 | Acc(train) 0.6277 | Acc(val) 0.6629 |*
Epoch 00017 | Loss(train) 1.4986 | Acc(train) 0.6489 | Acc(val) 0.7011 |*
Epoch 00018 | Loss(train) 1.4298 | Acc(train) 0.6911 | Acc(val) 0.7355 |*
Epoch 00019 | Loss(train) 1.3672 | Acc(train) 0.7212 | Acc(val) 0.7526 |*
Epoch 00020 | Loss(train) 1.3077 | Acc(train) 0.7410 | Acc(val) 0.7687 |*
Epoch 00021 | Loss(train) 1.2504 | Acc(train) 0.7539 | Acc(val) 0.7839 |*
Epoch 00022 | Loss(train) 1.2009 | Acc(train) 0.7718 | Acc(val) 0.7970 |*
Epoch 00023 | Loss(train) 1.1531 | Acc(train) 0.7801 | Acc(val) 0.8075 |*
Epoch 00024 | Loss(train) 1.1068 | Acc(train) 0.7915 | Acc(val) 0.8163 |*
Epoch 00025 | Loss(train) 1.0590 | Acc(train) 0.8015 | Acc(val) 0.8276 |*
Epoch 00026 | Loss(train) 1.0208 | Acc(train) 0.8139 | Acc(val) 0.8371 |*
Epoch 00027 | Loss(train) 0.9819 | Acc(train) 0.8214 | Acc(val) 0.8449 |*
Epoch 00028 | Loss(train) 0.9513 | Acc(train) 0.8309 | Acc(val) 0.8504 |*
Epoch 00029 | Loss(train) 0.9190 | Acc(train) 0.8375 | Acc(val) 0.8566 |*
Epoch 00030 | Loss(train) 0.8904 | Acc(train) 0.8431 | Acc(val) 0.8621 |*
Epoch 00031 | Loss(train) 0.8591 | Acc(train) 0.8501 | Acc(val) 0.8671 |*
Epoch 00032 | Loss(train) 0.8389 | Acc(train) 0.8517 | Acc(val) 0.8707 |*
Epoch 00033 | Loss(train) 0.8187 | Acc(train) 0.8553 | Acc(val) 0.8733 |*
Epoch 00034 | Loss(train) 0.7936 | Acc(train) 0.8593 | Acc(val) 0.8776 |*
Epoch 00035 | Loss(train) 0.7722 | Acc(train) 0.8637 | Acc(val) 0.8807 |*
Epoch 00036 | Loss(train) 0.7546 | Acc(train) 0.8651 | Acc(val) 0.8829 |*
Epoch 00037 | Loss(train) 0.7335 | Acc(train) 0.8686 | Acc(val) 0.8849 |*
Epoch 00038 | Loss(train) 0.7161 | Acc(train) 0.8710 | Acc(val) 0.8872 |*
Epoch 00039 | Loss(train) 0.7057 | Acc(train) 0.8729 | Acc(val) 0.8893 |*
Epoch 00040 | Loss(train) 0.6907 | Acc(train) 0.8758 | Acc(val) 0.8912 |*
Epoch 00041 | Loss(train) 0.6770 | Acc(train) 0.8789 | Acc(val) 0.8937 |*
Epoch 00042 | Loss(train) 0.6632 | Acc(train) 0.8808 | Acc(val) 0.8965 |*
Epoch 00043 | Loss(train) 0.6518 | Acc(train) 0.8872 | Acc(val) 0.8990 |*
Epoch 00044 | Loss(train) 0.6432 | Acc(train) 0.8862 | Acc(val) 0.9009 |*
Epoch 00045 | Loss(train) 0.6292 | Acc(train) 0.8891 | Acc(val) 0.9016 |*
Epoch 00046 | Loss(train) 0.6237 | Acc(train) 0.8888 | Acc(val) 0.9020 |*
Epoch 00047 | Loss(train) 0.6120 | Acc(train) 0.8898 | Acc(val) 0.9040 |*
Epoch 00048 | Loss(train) 0.6042 | Acc(train) 0.8927 | Acc(val) 0.9054 |*
Epoch 00049 | Loss(train) 0.5936 | Acc(train) 0.8922 | Acc(val) 0.9065 |*
Epoch 00050 | Loss(train) 0.5911 | Acc(train) 0.8926 | Acc(val) 0.9085 |*
Epoch 00051 | Loss(train) 0.5746 | Acc(train) 0.8962 | Acc(val) 0.9104 |*
Epoch 00052 | Loss(train) 0.5767 | Acc(train) 0.8974 | Acc(val) 0.9110 |*
Epoch 00053 | Loss(train) 0.5672 | Acc(train) 0.8982 | Acc(val) 0.9114 |*
Epoch 00054 | Loss(train) 0.5607 | Acc(train) 0.8984 | Acc(val) 0.9119 |*
Epoch 00055 | Loss(train) 0.5586 | Acc(train) 0.8990 | Acc(val) 0.9125 |*
Epoch 00056 | Loss(train) 0.5533 | Acc(train) 0.8981 | Acc(val) 0.9129 |*
Epoch 00057 | Loss(train) 0.5471 | Acc(train) 0.9009 | Acc(val) 0.9138 |*
Epoch 00058 | Loss(train) 0.5448 | Acc(train) 0.9011 | Acc(val) 0.9146 |*
Epoch 00059 | Loss(train) 0.5395 | Acc(train) 0.9014 | Acc(val) 0.9150 |*
Epoch 00060 | Loss(train) 0.5343 | Acc(train) 0.9022 | Acc(val) 0.9155 |*
Epoch 00061 | Loss(train) 0.5326 | Acc(train) 0.9019 | Acc(val) 0.9166 |*
Epoch 00062 | Loss(train) 0.5266 | Acc(train) 0.9033 | Acc(val) 0.9166 |*
Epoch 00063 | Loss(train) 0.5188 | Acc(train) 0.9040 | Acc(val) 0.9170 |*
Epoch 00064 | Loss(train) 0.5191 | Acc(train) 0.9044 | Acc(val) 0.9177 |*
Epoch 00065 | Loss(train) 0.5126 | Acc(train) 0.9055 | Acc(val) 0.9183 |*
Epoch 00066 | Loss(train) 0.5071 | Acc(train) 0.9059 | Acc(val) 0.9190 |*
Epoch 00067 | Loss(train) 0.5074 | Acc(train) 0.9064 | Acc(val) 0.9196 |*
Epoch 00068 | Loss(train) 0.5056 | Acc(train) 0.9064 | Acc(val) 0.9198 |*
Epoch 00069 | Loss(train) 0.5032 | Acc(train) 0.9070 | Acc(val) 0.9198 |
Epoch 00070 | Loss(train) 0.4958 | Acc(train) 0.9082 | Acc(val) 0.9203 |*
Epoch 00071 | Loss(train) 0.4967 | Acc(train) 0.9082 | Acc(val) 0.9202 |
Epoch 00072 | Loss(train) 0.4928 | Acc(train) 0.9094 | Acc(val) 0.9204 |*
Epoch 00073 | Loss(train) 0.4881 | Acc(train) 0.9099 | Acc(val) 0.9206 |*
Epoch 00074 | Loss(train) 0.4863 | Acc(train) 0.9093 | Acc(val) 0.9205 |
Epoch 00075 | Loss(train) 0.4866 | Acc(train) 0.9084 | Acc(val) 0.9206 |*
Epoch 00076 | Loss(train) 0.4773 | Acc(train) 0.9097 | Acc(val) 0.9211 |*
Epoch 00077 | Loss(train) 0.4848 | Acc(train) 0.9094 | Acc(val) 0.9215 |*
Epoch 00078 | Loss(train) 0.4777 | Acc(train) 0.9101 | Acc(val) 0.9217 |*
Epoch 00079 | Loss(train) 0.4758 | Acc(train) 0.9114 | Acc(val) 0.9226 |*
Epoch 00080 | Loss(train) 0.4734 | Acc(train) 0.9108 | Acc(val) 0.9228 |*
Epoch 00081 | Loss(train) 0.4676 | Acc(train) 0.9119 | Acc(val) 0.9231 |*
Epoch 00082 | Loss(train) 0.4729 | Acc(train) 0.9112 | Acc(val) 0.9232 |*
Epoch 00083 | Loss(train) 0.4657 | Acc(train) 0.9125 | Acc(val) 0.9235 |*
Epoch 00084 | Loss(train) 0.4628 | Acc(train) 0.9116 | Acc(val) 0.9233 |
Epoch 00085 | Loss(train) 0.4682 | Acc(train) 0.9118 | Acc(val) 0.9233 |
Epoch 00086 | Loss(train) 0.4597 | Acc(train) 0.9132 | Acc(val) 0.9233 |
Epoch 00087 | Loss(train) 0.4589 | Acc(train) 0.9134 | Acc(val) 0.9234 |
Epoch 00088 | Loss(train) 0.4582 | Acc(train) 0.9132 | Acc(val) 0.9239 |*
Epoch 00089 | Loss(train) 0.4577 | Acc(train) 0.9139 | Acc(val) 0.9241 |*
Epoch 00090 | Loss(train) 0.4559 | Acc(train) 0.9133 | Acc(val) 0.9242 |*
Epoch 00091 | Loss(train) 0.4528 | Acc(train) 0.9132 | Acc(val) 0.9245 |*
Epoch 00092 | Loss(train) 0.4485 | Acc(train) 0.9145 | Acc(val) 0.9246 |*
Epoch 00093 | Loss(train) 0.4502 | Acc(train) 0.9140 | Acc(val) 0.9247 |*
Epoch 00094 | Loss(train) 0.4502 | Acc(train) 0.9138 | Acc(val) 0.9248 |*
Epoch 00095 | Loss(train) 0.4494 | Acc(train) 0.9141 | Acc(val) 0.9252 |*
Epoch 00096 | Loss(train) 0.4448 | Acc(train) 0.9138 | Acc(val) 0.9256 |*
Epoch 00097 | Loss(train) 0.4457 | Acc(train) 0.9143 | Acc(val) 0.9255 |
Epoch 00098 | Loss(train) 0.4462 | Acc(train) 0.9146 | Acc(val) 0.9255 |
Epoch 00099 | Loss(train) 0.4406 | Acc(train) 0.9163 | Acc(val) 0.9254 |
Epoch 00100 | Loss(train) 0.4392 | Acc(train) 0.9162 | Acc(val) 0.9257 |*
Epoch 00101 | Loss(train) 0.4404 | Acc(train) 0.9159 | Acc(val) 0.9255 |
Epoch 00102 | Loss(train) 0.4404 | Acc(train) 0.9157 | Acc(val) 0.9257 |
Epoch 00103 | Loss(train) 0.4378 | Acc(train) 0.9154 | Acc(val) 0.9257 |*
Epoch 00104 | Loss(train) 0.4355 | Acc(train) 0.9171 | Acc(val) 0.9262 |*
Epoch 00105 | Loss(train) 0.4377 | Acc(train) 0.9164 | Acc(val) 0.9264 |*
Epoch 00106 | Loss(train) 0.4352 | Acc(train) 0.9162 | Acc(val) 0.9266 |*
Epoch 00107 | Loss(train) 0.4313 | Acc(train) 0.9173 | Acc(val) 0.9272 |*
Epoch 00108 | Loss(train) 0.4329 | Acc(train) 0.9174 | Acc(val) 0.9273 |*
Epoch 00109 | Loss(train) 0.4263 | Acc(train) 0.9178 | Acc(val) 0.9274 |*
Epoch 00110 | Loss(train) 0.4298 | Acc(train) 0.9177 | Acc(val) 0.9274 |
Epoch 00111 | Loss(train) 0.4278 | Acc(train) 0.9167 | Acc(val) 0.9273 |
Epoch 00112 | Loss(train) 0.4271 | Acc(train) 0.9176 | Acc(val) 0.9273 |
Epoch 00113 | Loss(train) 0.4270 | Acc(train) 0.9174 | Acc(val) 0.9275 |*
Epoch 00114 | Loss(train) 0.4288 | Acc(train) 0.9156 | Acc(val) 0.9274 |
Epoch 00115 | Loss(train) 0.4272 | Acc(train) 0.9175 | Acc(val) 0.9275 |*
Epoch 00116 | Loss(train) 0.4241 | Acc(train) 0.9177 | Acc(val) 0.9275 |
Epoch 00117 | Loss(train) 0.4216 | Acc(train) 0.9181 | Acc(val) 0.9277 |*
Epoch 00118 | Loss(train) 0.4223 | Acc(train) 0.9179 | Acc(val) 0.9279 |*
Epoch 00119 | Loss(train) 0.4191 | Acc(train) 0.9182 | Acc(val) 0.9280 |*
Epoch 00120 | Loss(train) 0.4234 | Acc(train) 0.9187 | Acc(val) 0.9279 |
Epoch 00121 | Loss(train) 0.4190 | Acc(train) 0.9181 | Acc(val) 0.9278 |
Epoch 00122 | Loss(train) 0.4171 | Acc(train) 0.9187 | Acc(val) 0.9277 |
Epoch 00123 | Loss(train) 0.4177 | Acc(train) 0.9181 | Acc(val) 0.9279 |
Epoch 00124 | Loss(train) 0.4140 | Acc(train) 0.9188 | Acc(val) 0.9280 |
Epoch 00125 | Loss(train) 0.4156 | Acc(train) 0.9179 | Acc(val) 0.9283 |*
Epoch 00126 | Loss(train) 0.4125 | Acc(train) 0.9194 | Acc(val) 0.9285 |*
Epoch 00127 | Loss(train) 0.4134 | Acc(train) 0.9193 | Acc(val) 0.9286 |*
Epoch 00128 | Loss(train) 0.4101 | Acc(train) 0.9200 | Acc(val) 0.9286 |
Epoch 00129 | Loss(train) 0.4097 | Acc(train) 0.9193 | Acc(val) 0.9286 |
Epoch 00130 | Loss(train) 0.4085 | Acc(train) 0.9202 | Acc(val) 0.9287 |*
Epoch 00131 | Loss(train) 0.4112 | Acc(train) 0.9202 | Acc(val) 0.9287 |*
Epoch 00132 | Loss(train) 0.4100 | Acc(train) 0.9197 | Acc(val) 0.9289 |*
Epoch 00133 | Loss(train) 0.4065 | Acc(train) 0.9199 | Acc(val) 0.9287 |
Epoch 00134 | Loss(train) 0.4111 | Acc(train) 0.9197 | Acc(val) 0.9287 |
Epoch 00135 | Loss(train) 0.4074 | Acc(train) 0.9187 | Acc(val) 0.9288 |
Epoch 00136 | Loss(train) 0.4076 | Acc(train) 0.9201 | Acc(val) 0.9291 |*
Epoch 00137 | Loss(train) 0.4103 | Acc(train) 0.9193 | Acc(val) 0.9291 |
Epoch 00138 | Loss(train) 0.4041 | Acc(train) 0.9201 | Acc(val) 0.9294 |*
Epoch 00139 | Loss(train) 0.4032 | Acc(train) 0.9191 | Acc(val) 0.9295 |*
Epoch 00140 | Loss(train) 0.4031 | Acc(train) 0.9197 | Acc(val) 0.9296 |*
Epoch 00141 | Loss(train) 0.4023 | Acc(train) 0.9207 | Acc(val) 0.9296 |
Epoch 00142 | Loss(train) 0.4033 | Acc(train) 0.9199 | Acc(val) 0.9294 |
Epoch 00143 | Loss(train) 0.4026 | Acc(train) 0.9208 | Acc(val) 0.9296 |
Epoch 00144 | Loss(train) 0.3985 | Acc(train) 0.9211 | Acc(val) 0.9296 |
Epoch 00145 | Loss(train) 0.3975 | Acc(train) 0.9211 | Acc(val) 0.9297 |*
Epoch 00146 | Loss(train) 0.4008 | Acc(train) 0.9206 | Acc(val) 0.9298 |*
Epoch 00147 | Loss(train) 0.3987 | Acc(train) 0.9216 | Acc(val) 0.9301 |*
Epoch 00148 | Loss(train) 0.3981 | Acc(train) 0.9203 | Acc(val) 0.9300 |
Epoch 00149 | Loss(train) 0.3980 | Acc(train) 0.9212 | Acc(val) 0.9297 |
Epoch 00150 | Loss(train) 0.3938 | Acc(train) 0.9223 | Acc(val) 0.9297 |
Epoch 00151 | Loss(train) 0.3978 | Acc(train) 0.9214 | Acc(val) 0.9297 |
Epoch 00152 | Loss(train) 0.3945 | Acc(train) 0.9206 | Acc(val) 0.9299 |
Epoch 00153 | Loss(train) 0.3974 | Acc(train) 0.9196 | Acc(val) 0.9302 |*
Epoch 00154 | Loss(train) 0.3965 | Acc(train) 0.9207 | Acc(val) 0.9305 |*
Epoch 00155 | Loss(train) 0.3942 | Acc(train) 0.9217 | Acc(val) 0.9305 |
Epoch 00156 | Loss(train) 0.3930 | Acc(train) 0.9219 | Acc(val) 0.9305 |
Epoch 00157 | Loss(train) 0.3965 | Acc(train) 0.9210 | Acc(val) 0.9305 |
Epoch 00158 | Loss(train) 0.3920 | Acc(train) 0.9222 | Acc(val) 0.9305 |*
Epoch 00159 | Loss(train) 0.3893 | Acc(train) 0.9222 | Acc(val) 0.9304 |
Epoch 00160 | Loss(train) 0.3920 | Acc(train) 0.9207 | Acc(val) 0.9305 |
Epoch 00161 | Loss(train) 0.3903 | Acc(train) 0.9212 | Acc(val) 0.9303 |
Epoch 00162 | Loss(train) 0.3915 | Acc(train) 0.9208 | Acc(val) 0.9302 |
Epoch 00163 | Loss(train) 0.3905 | Acc(train) 0.9211 | Acc(val) 0.9306 |*
Epoch 00164 | Loss(train) 0.3918 | Acc(train) 0.9221 | Acc(val) 0.9305 |
Epoch 00165 | Loss(train) 0.3904 | Acc(train) 0.9222 | Acc(val) 0.9305 |
Epoch 00166 | Loss(train) 0.3905 | Acc(train) 0.9217 | Acc(val) 0.9307 |*
Epoch 00167 | Loss(train) 0.3871 | Acc(train) 0.9218 | Acc(val) 0.9307 |
Epoch 00168 | Loss(train) 0.3900 | Acc(train) 0.9219 | Acc(val) 0.9308 |*
Epoch 00169 | Loss(train) 0.3865 | Acc(train) 0.9221 | Acc(val) 0.9308 |
Epoch 00170 | Loss(train) 0.3841 | Acc(train) 0.9221 | Acc(val) 0.9305 |
Epoch 00171 | Loss(train) 0.3875 | Acc(train) 0.9222 | Acc(val) 0.9305 |
Epoch 00172 | Loss(train) 0.3843 | Acc(train) 0.9236 | Acc(val) 0.9308 |
Epoch 00173 | Loss(train) 0.3846 | Acc(train) 0.9222 | Acc(val) 0.9308 |
Epoch 00174 | Loss(train) 0.3817 | Acc(train) 0.9225 | Acc(val) 0.9308 |
Epoch 00175 | Loss(train) 0.3836 | Acc(train) 0.9233 | Acc(val) 0.9305 |
Epoch 00176 | Loss(train) 0.3842 | Acc(train) 0.9221 | Acc(val) 0.9305 |
Epoch 00177 | Loss(train) 0.3859 | Acc(train) 0.9218 | Acc(val) 0.9305 |
Epoch 00178 | Loss(train) 0.3838 | Acc(train) 0.9225 | Acc(val) 0.9305 |
Epoch 00179 | Loss(train) 0.3801 | Acc(train) 0.9221 | Acc(val) 0.9306 |
Epoch 00180 | Loss(train) 0.3846 | Acc(train) 0.9213 | Acc(val) 0.9306 |
Epoch 00181 | Loss(train) 0.3785 | Acc(train) 0.9220 | Acc(val) 0.9309 |*
Epoch 00182 | Loss(train) 0.3792 | Acc(train) 0.9233 | Acc(val) 0.9310 |*
Epoch 00183 | Loss(train) 0.3799 | Acc(train) 0.9225 | Acc(val) 0.9311 |*
Epoch 00184 | Loss(train) 0.3797 | Acc(train) 0.9230 | Acc(val) 0.9311 |
Epoch 00185 | Loss(train) 0.3775 | Acc(train) 0.9228 | Acc(val) 0.9311 |
Epoch 00186 | Loss(train) 0.3774 | Acc(train) 0.9237 | Acc(val) 0.9312 |*
Epoch 00187 | Loss(train) 0.3795 | Acc(train) 0.9224 | Acc(val) 0.9311 |
Epoch 00188 | Loss(train) 0.3767 | Acc(train) 0.9219 | Acc(val) 0.9308 |
Epoch 00189 | Loss(train) 0.3775 | Acc(train) 0.9230 | Acc(val) 0.9307 |
Epoch 00190 | Loss(train) 0.3776 | Acc(train) 0.9225 | Acc(val) 0.9307 |
Epoch 00191 | Loss(train) 0.3774 | Acc(train) 0.9229 | Acc(val) 0.9308 |
Epoch 00192 | Loss(train) 0.3734 | Acc(train) 0.9226 | Acc(val) 0.9309 |
Epoch 00193 | Loss(train) 0.3745 | Acc(train) 0.9244 | Acc(val) 0.9310 |
Epoch 00194 | Loss(train) 0.3779 | Acc(train) 0.9224 | Acc(val) 0.9312 |*
Epoch 00195 | Loss(train) 0.3777 | Acc(train) 0.9226 | Acc(val) 0.9314 |*
Epoch 00196 | Loss(train) 0.3749 | Acc(train) 0.9226 | Acc(val) 0.9313 |
Epoch 00197 | Loss(train) 0.3756 | Acc(train) 0.9236 | Acc(val) 0.9311 |
Epoch 00198 | Loss(train) 0.3731 | Acc(train) 0.9244 | Acc(val) 0.9307 |
Epoch 00199 | Loss(train) 0.3725 | Acc(train) 0.9234 | Acc(val) 0.9307 |
Epoch 00200 | Loss(train) 0.3724 | Acc(train) 0.9234 | Acc(val) 0.9308 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 3.7945 | Acc(train) 0.0171 | Acc(val) 0.1093 |*
Epoch 00002 | Loss(train) 3.5145 | Acc(train) 0.1077 | Acc(val) 0.2501 |*
Epoch 00003 | Loss(train) 3.3028 | Acc(train) 0.2422 | Acc(val) 0.3597 |*
Epoch 00004 | Loss(train) 3.0855 | Acc(train) 0.3541 | Acc(val) 0.4601 |*
Epoch 00005 | Loss(train) 2.8778 | Acc(train) 0.4502 | Acc(val) 0.4797 |*
Epoch 00006 | Loss(train) 2.6951 | Acc(train) 0.4694 | Acc(val) 0.5008 |*
Epoch 00007 | Loss(train) 2.5318 | Acc(train) 0.4955 | Acc(val) 0.5220 |*
Epoch 00008 | Loss(train) 2.3923 | Acc(train) 0.5157 | Acc(val) 0.5355 |*
Epoch 00009 | Loss(train) 2.2712 | Acc(train) 0.5274 | Acc(val) 0.5413 |*
Epoch 00010 | Loss(train) 2.1606 | Acc(train) 0.5346 | Acc(val) 0.5557 |*
Epoch 00011 | Loss(train) 2.0559 | Acc(train) 0.5516 | Acc(val) 0.5820 |*
Epoch 00012 | Loss(train) 1.9587 | Acc(train) 0.5752 | Acc(val) 0.6004 |*
Epoch 00013 | Loss(train) 1.8621 | Acc(train) 0.5935 | Acc(val) 0.6171 |*
Epoch 00014 | Loss(train) 1.7762 | Acc(train) 0.6077 | Acc(val) 0.6465 |*
Epoch 00015 | Loss(train) 1.6894 | Acc(train) 0.6363 | Acc(val) 0.6912 |*
Epoch 00016 | Loss(train) 1.6094 | Acc(train) 0.6791 | Acc(val) 0.7033 |*
Epoch 00017 | Loss(train) 1.5361 | Acc(train) 0.6891 | Acc(val) 0.7185 |*
Epoch 00018 | Loss(train) 1.4647 | Acc(train) 0.7062 | Acc(val) 0.7434 |*
Epoch 00019 | Loss(train) 1.3980 | Acc(train) 0.7319 | Acc(val) 0.7643 |*
Epoch 00020 | Loss(train) 1.3417 | Acc(train) 0.7484 | Acc(val) 0.7754 |*
Epoch 00021 | Loss(train) 1.2869 | Acc(train) 0.7596 | Acc(val) 0.7840 |*
Epoch 00022 | Loss(train) 1.2289 | Acc(train) 0.7704 | Acc(val) 0.7927 |*
Epoch 00023 | Loss(train) 1.1763 | Acc(train) 0.7792 | Acc(val) 0.7947 |*
Epoch 00024 | Loss(train) 1.1300 | Acc(train) 0.7818 | Acc(val) 0.8003 |*
Epoch 00025 | Loss(train) 1.0844 | Acc(train) 0.7898 | Acc(val) 0.8056 |*
Epoch 00026 | Loss(train) 1.0408 | Acc(train) 0.7946 | Acc(val) 0.8138 |*
Epoch 00027 | Loss(train) 1.0057 | Acc(train) 0.8004 | Acc(val) 0.8237 |*
Epoch 00028 | Loss(train) 0.9686 | Acc(train) 0.8126 | Acc(val) 0.8332 |*
Epoch 00029 | Loss(train) 0.9396 | Acc(train) 0.8182 | Acc(val) 0.8460 |*
Epoch 00030 | Loss(train) 0.9054 | Acc(train) 0.8305 | Acc(val) 0.8498 |*
Epoch 00031 | Loss(train) 0.8825 | Acc(train) 0.8363 | Acc(val) 0.8516 |*
Epoch 00032 | Loss(train) 0.8601 | Acc(train) 0.8369 | Acc(val) 0.8553 |*
Epoch 00033 | Loss(train) 0.8296 | Acc(train) 0.8427 | Acc(val) 0.8620 |*
Epoch 00034 | Loss(train) 0.8116 | Acc(train) 0.8466 | Acc(val) 0.8688 |*
Epoch 00035 | Loss(train) 0.7924 | Acc(train) 0.8544 | Acc(val) 0.8724 |*
Epoch 00036 | Loss(train) 0.7654 | Acc(train) 0.8561 | Acc(val) 0.8732 |*
Epoch 00037 | Loss(train) 0.7504 | Acc(train) 0.8581 | Acc(val) 0.8745 |*
Epoch 00038 | Loss(train) 0.7316 | Acc(train) 0.8613 | Acc(val) 0.8774 |*
Epoch 00039 | Loss(train) 0.7196 | Acc(train) 0.8639 | Acc(val) 0.8812 |*
Epoch 00040 | Loss(train) 0.7014 | Acc(train) 0.8705 | Acc(val) 0.8863 |*
Epoch 00041 | Loss(train) 0.6854 | Acc(train) 0.8740 | Acc(val) 0.8894 |*
Epoch 00042 | Loss(train) 0.6733 | Acc(train) 0.8762 | Acc(val) 0.8911 |*
Epoch 00043 | Loss(train) 0.6629 | Acc(train) 0.8779 | Acc(val) 0.8907 |
Epoch 00044 | Loss(train) 0.6539 | Acc(train) 0.8785 | Acc(val) 0.8911 |
Epoch 00045 | Loss(train) 0.6380 | Acc(train) 0.8793 | Acc(val) 0.8916 |*
Epoch 00046 | Loss(train) 0.6265 | Acc(train) 0.8786 | Acc(val) 0.8928 |*
Epoch 00047 | Loss(train) 0.6188 | Acc(train) 0.8800 | Acc(val) 0.8942 |*
Epoch 00048 | Loss(train) 0.6171 | Acc(train) 0.8816 | Acc(val) 0.8969 |*
Epoch 00049 | Loss(train) 0.6040 | Acc(train) 0.8847 | Acc(val) 0.9008 |*
Epoch 00050 | Loss(train) 0.5943 | Acc(train) 0.8886 | Acc(val) 0.9043 |*
Epoch 00051 | Loss(train) 0.5874 | Acc(train) 0.8902 | Acc(val) 0.9068 |*
Epoch 00052 | Loss(train) 0.5793 | Acc(train) 0.8945 | Acc(val) 0.9084 |*
Epoch 00053 | Loss(train) 0.5734 | Acc(train) 0.8951 | Acc(val) 0.9091 |*
Epoch 00054 | Loss(train) 0.5663 | Acc(train) 0.8977 | Acc(val) 0.9095 |*
Epoch 00055 | Loss(train) 0.5560 | Acc(train) 0.8983 | Acc(val) 0.9100 |*
Epoch 00056 | Loss(train) 0.5543 | Acc(train) 0.8980 | Acc(val) 0.9103 |*
Epoch 00057 | Loss(train) 0.5535 | Acc(train) 0.8979 | Acc(val) 0.9108 |*
Epoch 00058 | Loss(train) 0.5517 | Acc(train) 0.8983 | Acc(val) 0.9113 |*
Epoch 00059 | Loss(train) 0.5352 | Acc(train) 0.8991 | Acc(val) 0.9126 |*
Epoch 00060 | Loss(train) 0.5331 | Acc(train) 0.9000 | Acc(val) 0.9132 |*
Epoch 00061 | Loss(train) 0.5297 | Acc(train) 0.9004 | Acc(val) 0.9138 |*
Epoch 00062 | Loss(train) 0.5253 | Acc(train) 0.9013 | Acc(val) 0.9144 |*
Epoch 00063 | Loss(train) 0.5219 | Acc(train) 0.9028 | Acc(val) 0.9151 |*
Epoch 00064 | Loss(train) 0.5204 | Acc(train) 0.9040 | Acc(val) 0.9161 |*
Epoch 00065 | Loss(train) 0.5148 | Acc(train) 0.9028 | Acc(val) 0.9164 |*
Epoch 00066 | Loss(train) 0.5152 | Acc(train) 0.9032 | Acc(val) 0.9164 |*
Epoch 00067 | Loss(train) 0.5058 | Acc(train) 0.9046 | Acc(val) 0.9163 |
Epoch 00068 | Loss(train) 0.5034 | Acc(train) 0.9039 | Acc(val) 0.9169 |*
Epoch 00069 | Loss(train) 0.4984 | Acc(train) 0.9060 | Acc(val) 0.9172 |*
Epoch 00070 | Loss(train) 0.5020 | Acc(train) 0.9056 | Acc(val) 0.9176 |*
Epoch 00071 | Loss(train) 0.4975 | Acc(train) 0.9064 | Acc(val) 0.9179 |*
Epoch 00072 | Loss(train) 0.4935 | Acc(train) 0.9062 | Acc(val) 0.9184 |*
Epoch 00073 | Loss(train) 0.4848 | Acc(train) 0.9079 | Acc(val) 0.9185 |*
Epoch 00074 | Loss(train) 0.4904 | Acc(train) 0.9063 | Acc(val) 0.9189 |*
Epoch 00075 | Loss(train) 0.4845 | Acc(train) 0.9072 | Acc(val) 0.9190 |*
Epoch 00076 | Loss(train) 0.4814 | Acc(train) 0.9078 | Acc(val) 0.9192 |*
Epoch 00077 | Loss(train) 0.4833 | Acc(train) 0.9080 | Acc(val) 0.9193 |*
Epoch 00078 | Loss(train) 0.4759 | Acc(train) 0.9076 | Acc(val) 0.9196 |*
Epoch 00079 | Loss(train) 0.4779 | Acc(train) 0.9081 | Acc(val) 0.9200 |*
Epoch 00080 | Loss(train) 0.4707 | Acc(train) 0.9098 | Acc(val) 0.9204 |*
Epoch 00081 | Loss(train) 0.4686 | Acc(train) 0.9107 | Acc(val) 0.9204 |
Epoch 00082 | Loss(train) 0.4677 | Acc(train) 0.9087 | Acc(val) 0.9206 |*
Epoch 00083 | Loss(train) 0.4643 | Acc(train) 0.9106 | Acc(val) 0.9209 |*
Epoch 00084 | Loss(train) 0.4665 | Acc(train) 0.9104 | Acc(val) 0.9210 |*
Epoch 00085 | Loss(train) 0.4642 | Acc(train) 0.9108 | Acc(val) 0.9210 |*
Epoch 00086 | Loss(train) 0.4599 | Acc(train) 0.9104 | Acc(val) 0.9210 |
Epoch 00087 | Loss(train) 0.4603 | Acc(train) 0.9102 | Acc(val) 0.9212 |*
Epoch 00088 | Loss(train) 0.4585 | Acc(train) 0.9111 | Acc(val) 0.9214 |*
Epoch 00089 | Loss(train) 0.4538 | Acc(train) 0.9117 | Acc(val) 0.9219 |*
Epoch 00090 | Loss(train) 0.4571 | Acc(train) 0.9113 | Acc(val) 0.9226 |*
Epoch 00091 | Loss(train) 0.4503 | Acc(train) 0.9125 | Acc(val) 0.9228 |*
Epoch 00092 | Loss(train) 0.4529 | Acc(train) 0.9124 | Acc(val) 0.9230 |*
Epoch 00093 | Loss(train) 0.4524 | Acc(train) 0.9125 | Acc(val) 0.9234 |*
Epoch 00094 | Loss(train) 0.4499 | Acc(train) 0.9128 | Acc(val) 0.9234 |*
Epoch 00095 | Loss(train) 0.4452 | Acc(train) 0.9142 | Acc(val) 0.9236 |*
Epoch 00096 | Loss(train) 0.4462 | Acc(train) 0.9141 | Acc(val) 0.9234 |
Epoch 00097 | Loss(train) 0.4485 | Acc(train) 0.9139 | Acc(val) 0.9238 |*
Epoch 00098 | Loss(train) 0.4448 | Acc(train) 0.9138 | Acc(val) 0.9240 |*
Epoch 00099 | Loss(train) 0.4441 | Acc(train) 0.9150 | Acc(val) 0.9238 |
Epoch 00100 | Loss(train) 0.4406 | Acc(train) 0.9142 | Acc(val) 0.9238 |
Epoch 00101 | Loss(train) 0.4428 | Acc(train) 0.9127 | Acc(val) 0.9241 |*
Epoch 00102 | Loss(train) 0.4391 | Acc(train) 0.9153 | Acc(val) 0.9245 |*
Epoch 00103 | Loss(train) 0.4378 | Acc(train) 0.9146 | Acc(val) 0.9246 |*
Epoch 00104 | Loss(train) 0.4314 | Acc(train) 0.9146 | Acc(val) 0.9246 |
Epoch 00105 | Loss(train) 0.4357 | Acc(train) 0.9152 | Acc(val) 0.9246 |*
Epoch 00106 | Loss(train) 0.4343 | Acc(train) 0.9147 | Acc(val) 0.9248 |*
Epoch 00107 | Loss(train) 0.4324 | Acc(train) 0.9161 | Acc(val) 0.9251 |*
Epoch 00108 | Loss(train) 0.4329 | Acc(train) 0.9159 | Acc(val) 0.9255 |*
Epoch 00109 | Loss(train) 0.4309 | Acc(train) 0.9159 | Acc(val) 0.9258 |*
Epoch 00110 | Loss(train) 0.4303 | Acc(train) 0.9158 | Acc(val) 0.9259 |*
Epoch 00111 | Loss(train) 0.4311 | Acc(train) 0.9168 | Acc(val) 0.9261 |*
Epoch 00112 | Loss(train) 0.4240 | Acc(train) 0.9165 | Acc(val) 0.9264 |*
Epoch 00113 | Loss(train) 0.4251 | Acc(train) 0.9160 | Acc(val) 0.9265 |*
Epoch 00114 | Loss(train) 0.4267 | Acc(train) 0.9157 | Acc(val) 0.9265 |*
Epoch 00115 | Loss(train) 0.4272 | Acc(train) 0.9171 | Acc(val) 0.9268 |*
Epoch 00116 | Loss(train) 0.4259 | Acc(train) 0.9168 | Acc(val) 0.9266 |
Epoch 00117 | Loss(train) 0.4277 | Acc(train) 0.9163 | Acc(val) 0.9268 |
Epoch 00118 | Loss(train) 0.4213 | Acc(train) 0.9175 | Acc(val) 0.9269 |*
Epoch 00119 | Loss(train) 0.4190 | Acc(train) 0.9177 | Acc(val) 0.9272 |*
Epoch 00120 | Loss(train) 0.4202 | Acc(train) 0.9178 | Acc(val) 0.9274 |*
Epoch 00121 | Loss(train) 0.4216 | Acc(train) 0.9179 | Acc(val) 0.9270 |
Epoch 00122 | Loss(train) 0.4172 | Acc(train) 0.9179 | Acc(val) 0.9272 |
Epoch 00123 | Loss(train) 0.4214 | Acc(train) 0.9172 | Acc(val) 0.9273 |
Epoch 00124 | Loss(train) 0.4166 | Acc(train) 0.9169 | Acc(val) 0.9274 |*
Epoch 00125 | Loss(train) 0.4185 | Acc(train) 0.9175 | Acc(val) 0.9275 |*
Epoch 00126 | Loss(train) 0.4150 | Acc(train) 0.9177 | Acc(val) 0.9278 |*
Epoch 00127 | Loss(train) 0.4144 | Acc(train) 0.9186 | Acc(val) 0.9278 |
Epoch 00128 | Loss(train) 0.4151 | Acc(train) 0.9181 | Acc(val) 0.9279 |*
Epoch 00129 | Loss(train) 0.4135 | Acc(train) 0.9182 | Acc(val) 0.9281 |*
Epoch 00130 | Loss(train) 0.4155 | Acc(train) 0.9182 | Acc(val) 0.9282 |*
Epoch 00131 | Loss(train) 0.4142 | Acc(train) 0.9188 | Acc(val) 0.9281 |
Epoch 00132 | Loss(train) 0.4120 | Acc(train) 0.9186 | Acc(val) 0.9281 |
Epoch 00133 | Loss(train) 0.4098 | Acc(train) 0.9193 | Acc(val) 0.9281 |
Epoch 00134 | Loss(train) 0.4073 | Acc(train) 0.9183 | Acc(val) 0.9284 |*
Epoch 00135 | Loss(train) 0.4069 | Acc(train) 0.9195 | Acc(val) 0.9283 |
Epoch 00136 | Loss(train) 0.4088 | Acc(train) 0.9194 | Acc(val) 0.9284 |
Epoch 00137 | Loss(train) 0.4065 | Acc(train) 0.9205 | Acc(val) 0.9285 |*
Epoch 00138 | Loss(train) 0.4074 | Acc(train) 0.9194 | Acc(val) 0.9284 |
Epoch 00139 | Loss(train) 0.4070 | Acc(train) 0.9195 | Acc(val) 0.9285 |
Epoch 00140 | Loss(train) 0.4059 | Acc(train) 0.9201 | Acc(val) 0.9285 |
Epoch 00141 | Loss(train) 0.4074 | Acc(train) 0.9190 | Acc(val) 0.9285 |*
Epoch 00142 | Loss(train) 0.4053 | Acc(train) 0.9190 | Acc(val) 0.9286 |*
Epoch 00143 | Loss(train) 0.4005 | Acc(train) 0.9208 | Acc(val) 0.9288 |*
Epoch 00144 | Loss(train) 0.4036 | Acc(train) 0.9200 | Acc(val) 0.9288 |*
Epoch 00145 | Loss(train) 0.4008 | Acc(train) 0.9200 | Acc(val) 0.9289 |*
Epoch 00146 | Loss(train) 0.3995 | Acc(train) 0.9209 | Acc(val) 0.9287 |
Epoch 00147 | Loss(train) 0.3982 | Acc(train) 0.9209 | Acc(val) 0.9289 |
Epoch 00148 | Loss(train) 0.3997 | Acc(train) 0.9208 | Acc(val) 0.9292 |*
Epoch 00149 | Loss(train) 0.3994 | Acc(train) 0.9198 | Acc(val) 0.9292 |
Epoch 00150 | Loss(train) 0.4015 | Acc(train) 0.9215 | Acc(val) 0.9293 |*
Epoch 00151 | Loss(train) 0.3968 | Acc(train) 0.9213 | Acc(val) 0.9291 |
Epoch 00152 | Loss(train) 0.3994 | Acc(train) 0.9197 | Acc(val) 0.9290 |
Epoch 00153 | Loss(train) 0.3968 | Acc(train) 0.9217 | Acc(val) 0.9289 |
Epoch 00154 | Loss(train) 0.3994 | Acc(train) 0.9212 | Acc(val) 0.9289 |
Epoch 00155 | Loss(train) 0.3972 | Acc(train) 0.9211 | Acc(val) 0.9290 |
Epoch 00156 | Loss(train) 0.3984 | Acc(train) 0.9202 | Acc(val) 0.9291 |
Epoch 00157 | Loss(train) 0.3958 | Acc(train) 0.9213 | Acc(val) 0.9291 |
Epoch 00158 | Loss(train) 0.3981 | Acc(train) 0.9203 | Acc(val) 0.9290 |
Epoch 00159 | Loss(train) 0.3927 | Acc(train) 0.9215 | Acc(val) 0.9291 |
Epoch 00160 | Loss(train) 0.3931 | Acc(train) 0.9205 | Acc(val) 0.9296 |*
Epoch 00161 | Loss(train) 0.3926 | Acc(train) 0.9201 | Acc(val) 0.9299 |*
Epoch 00162 | Loss(train) 0.3940 | Acc(train) 0.9219 | Acc(val) 0.9299 |
Epoch 00163 | Loss(train) 0.3916 | Acc(train) 0.9218 | Acc(val) 0.9300 |*
Epoch 00164 | Loss(train) 0.3936 | Acc(train) 0.9214 | Acc(val) 0.9299 |
Epoch 00165 | Loss(train) 0.3921 | Acc(train) 0.9209 | Acc(val) 0.9298 |
Epoch 00166 | Loss(train) 0.3913 | Acc(train) 0.9213 | Acc(val) 0.9298 |
Epoch 00167 | Loss(train) 0.3900 | Acc(train) 0.9217 | Acc(val) 0.9299 |
Epoch 00168 | Loss(train) 0.3935 | Acc(train) 0.9202 | Acc(val) 0.9297 |
Epoch 00169 | Loss(train) 0.3895 | Acc(train) 0.9223 | Acc(val) 0.9296 |
Epoch 00170 | Loss(train) 0.3935 | Acc(train) 0.9215 | Acc(val) 0.9299 |
Epoch 00171 | Loss(train) 0.3883 | Acc(train) 0.9211 | Acc(val) 0.9302 |*
Epoch 00172 | Loss(train) 0.3885 | Acc(train) 0.9215 | Acc(val) 0.9302 |
Epoch 00173 | Loss(train) 0.3858 | Acc(train) 0.9217 | Acc(val) 0.9305 |*
Epoch 00174 | Loss(train) 0.3907 | Acc(train) 0.9227 | Acc(val) 0.9304 |
Epoch 00175 | Loss(train) 0.3869 | Acc(train) 0.9230 | Acc(val) 0.9305 |*
Epoch 00176 | Loss(train) 0.3873 | Acc(train) 0.9229 | Acc(val) 0.9305 |
Epoch 00177 | Loss(train) 0.3868 | Acc(train) 0.9221 | Acc(val) 0.9303 |
Epoch 00178 | Loss(train) 0.3836 | Acc(train) 0.9227 | Acc(val) 0.9302 |
Epoch 00179 | Loss(train) 0.3821 | Acc(train) 0.9225 | Acc(val) 0.9304 |
Epoch 00180 | Loss(train) 0.3813 | Acc(train) 0.9230 | Acc(val) 0.9304 |
Epoch 00181 | Loss(train) 0.3812 | Acc(train) 0.9224 | Acc(val) 0.9301 |
Epoch 00182 | Loss(train) 0.3833 | Acc(train) 0.9225 | Acc(val) 0.9302 |
Epoch 00183 | Loss(train) 0.3830 | Acc(train) 0.9222 | Acc(val) 0.9303 |
Epoch 00184 | Loss(train) 0.3850 | Acc(train) 0.9230 | Acc(val) 0.9306 |*
Epoch 00185 | Loss(train) 0.3821 | Acc(train) 0.9232 | Acc(val) 0.9306 |
Epoch 00186 | Loss(train) 0.3824 | Acc(train) 0.9223 | Acc(val) 0.9308 |*
Epoch 00187 | Loss(train) 0.3772 | Acc(train) 0.9229 | Acc(val) 0.9310 |*
Epoch 00188 | Loss(train) 0.3838 | Acc(train) 0.9226 | Acc(val) 0.9310 |*
Epoch 00189 | Loss(train) 0.3805 | Acc(train) 0.9222 | Acc(val) 0.9311 |*
Epoch 00190 | Loss(train) 0.3818 | Acc(train) 0.9229 | Acc(val) 0.9311 |
Epoch 00191 | Loss(train) 0.3798 | Acc(train) 0.9230 | Acc(val) 0.9311 |
Epoch 00192 | Loss(train) 0.3819 | Acc(train) 0.9227 | Acc(val) 0.9309 |
Epoch 00193 | Loss(train) 0.3815 | Acc(train) 0.9227 | Acc(val) 0.9310 |
Epoch 00194 | Loss(train) 0.3794 | Acc(train) 0.9229 | Acc(val) 0.9308 |
Epoch 00195 | Loss(train) 0.3767 | Acc(train) 0.9228 | Acc(val) 0.9310 |
Epoch 00196 | Loss(train) 0.3785 | Acc(train) 0.9228 | Acc(val) 0.9309 |
Epoch 00197 | Loss(train) 0.3814 | Acc(train) 0.9227 | Acc(val) 0.9312 |*
Epoch 00198 | Loss(train) 0.3789 | Acc(train) 0.9223 | Acc(val) 0.9314 |*
Epoch 00199 | Loss(train) 0.3784 | Acc(train) 0.9232 | Acc(val) 0.9315 |*
Epoch 00200 | Loss(train) 0.3772 | Acc(train) 0.9231 | Acc(val) 0.9314 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.2, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 602, 'out_dim': 41}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 3235.96 MB
GPU Memory Reserved: 14232.00 MB
All runs:
Uncalibrated Test Accuracy: 93.10 ± 0.06
Uncalibrated Difference: 6.79 ± 0.10
Calibrated Test Accuracy: 93.10 ± 0.06
Calibrated Difference: 1.02 ± 0.06
