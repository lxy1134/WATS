  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
Dataset: pubmed | #Nodes: 19717 | #Edges: 108365 | #Classes: 3 |#Features: 500
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0986 | Acc(train) 0.3642 | Acc(val) 0.4133 |*
Epoch 00002 | Loss(train) 1.0903 | Acc(train) 0.4043 | Acc(val) 0.4133 |
Epoch 00003 | Loss(train) 1.0826 | Acc(train) 0.4045 | Acc(val) 0.4133 |
Epoch 00004 | Loss(train) 1.0739 | Acc(train) 0.4043 | Acc(val) 0.4133 |
Epoch 00005 | Loss(train) 1.0652 | Acc(train) 0.4043 | Acc(val) 0.4133 |
Epoch 00006 | Loss(train) 1.0581 | Acc(train) 0.4043 | Acc(val) 0.4133 |
Epoch 00007 | Loss(train) 1.0508 | Acc(train) 0.4043 | Acc(val) 0.4133 |
Epoch 00008 | Loss(train) 1.0432 | Acc(train) 0.4040 | Acc(val) 0.4133 |
Epoch 00009 | Loss(train) 1.0362 | Acc(train) 0.4045 | Acc(val) 0.4133 |
Epoch 00010 | Loss(train) 1.0283 | Acc(train) 0.4058 | Acc(val) 0.4133 |
Epoch 00011 | Loss(train) 1.0232 | Acc(train) 0.4078 | Acc(val) 0.4133 |
Epoch 00012 | Loss(train) 1.0160 | Acc(train) 0.4106 | Acc(val) 0.4133 |
Epoch 00013 | Loss(train) 1.0076 | Acc(train) 0.4152 | Acc(val) 0.4148 |*
Epoch 00014 | Loss(train) 1.0043 | Acc(train) 0.4169 | Acc(val) 0.4184 |*
Epoch 00015 | Loss(train) 0.9958 | Acc(train) 0.4192 | Acc(val) 0.4275 |*
Epoch 00016 | Loss(train) 0.9875 | Acc(train) 0.4410 | Acc(val) 0.4539 |*
Epoch 00017 | Loss(train) 0.9787 | Acc(train) 0.4684 | Acc(val) 0.4934 |*
Epoch 00018 | Loss(train) 0.9709 | Acc(train) 0.4864 | Acc(val) 0.5370 |*
Epoch 00019 | Loss(train) 0.9652 | Acc(train) 0.5181 | Acc(val) 0.5761 |*
Epoch 00020 | Loss(train) 0.9585 | Acc(train) 0.5222 | Acc(val) 0.6116 |*
Epoch 00021 | Loss(train) 0.9502 | Acc(train) 0.5734 | Acc(val) 0.6379 |*
Epoch 00022 | Loss(train) 0.9415 | Acc(train) 0.6039 | Acc(val) 0.6552 |*
Epoch 00023 | Loss(train) 0.9342 | Acc(train) 0.6262 | Acc(val) 0.6755 |*
Epoch 00024 | Loss(train) 0.9253 | Acc(train) 0.6320 | Acc(val) 0.6897 |*
Epoch 00025 | Loss(train) 0.9178 | Acc(train) 0.6569 | Acc(val) 0.6962 |*
Epoch 00026 | Loss(train) 0.9098 | Acc(train) 0.6589 | Acc(val) 0.7099 |*
Epoch 00027 | Loss(train) 0.9021 | Acc(train) 0.6614 | Acc(val) 0.7206 |*
Epoch 00028 | Loss(train) 0.8955 | Acc(train) 0.6564 | Acc(val) 0.7307 |*
Epoch 00029 | Loss(train) 0.8889 | Acc(train) 0.6673 | Acc(val) 0.7378 |*
Epoch 00030 | Loss(train) 0.8820 | Acc(train) 0.6741 | Acc(val) 0.7490 |*
Epoch 00031 | Loss(train) 0.8763 | Acc(train) 0.6728 | Acc(val) 0.7576 |*
Epoch 00032 | Loss(train) 0.8634 | Acc(train) 0.7035 | Acc(val) 0.7657 |*
Epoch 00033 | Loss(train) 0.8558 | Acc(train) 0.7000 | Acc(val) 0.7738 |*
Epoch 00034 | Loss(train) 0.8487 | Acc(train) 0.7025 | Acc(val) 0.7804 |*
Epoch 00035 | Loss(train) 0.8395 | Acc(train) 0.7215 | Acc(val) 0.7845 |*
Epoch 00036 | Loss(train) 0.8361 | Acc(train) 0.7243 | Acc(val) 0.7850 |*
Epoch 00037 | Loss(train) 0.8257 | Acc(train) 0.7231 | Acc(val) 0.7896 |*
Epoch 00038 | Loss(train) 0.8211 | Acc(train) 0.7231 | Acc(val) 0.7931 |*
Epoch 00039 | Loss(train) 0.8144 | Acc(train) 0.7302 | Acc(val) 0.7951 |*
Epoch 00040 | Loss(train) 0.8046 | Acc(train) 0.7400 | Acc(val) 0.7992 |*
Epoch 00041 | Loss(train) 0.7918 | Acc(train) 0.7403 | Acc(val) 0.8007 |*
Epoch 00042 | Loss(train) 0.7883 | Acc(train) 0.7449 | Acc(val) 0.8048 |*
Epoch 00043 | Loss(train) 0.7821 | Acc(train) 0.7373 | Acc(val) 0.8058 |*
Epoch 00044 | Loss(train) 0.7755 | Acc(train) 0.7474 | Acc(val) 0.8053 |
Epoch 00045 | Loss(train) 0.7656 | Acc(train) 0.7535 | Acc(val) 0.8063 |*
Epoch 00046 | Loss(train) 0.7606 | Acc(train) 0.7517 | Acc(val) 0.8073 |*
Epoch 00047 | Loss(train) 0.7578 | Acc(train) 0.7553 | Acc(val) 0.8038 |
Epoch 00048 | Loss(train) 0.7520 | Acc(train) 0.7499 | Acc(val) 0.8073 |
Epoch 00049 | Loss(train) 0.7452 | Acc(train) 0.7662 | Acc(val) 0.8109 |*
Epoch 00050 | Loss(train) 0.7310 | Acc(train) 0.7730 | Acc(val) 0.8119 |*
Epoch 00051 | Loss(train) 0.7292 | Acc(train) 0.7657 | Acc(val) 0.8164 |*
Epoch 00052 | Loss(train) 0.7215 | Acc(train) 0.7682 | Acc(val) 0.8185 |*
Epoch 00053 | Loss(train) 0.7201 | Acc(train) 0.7707 | Acc(val) 0.8180 |
Epoch 00054 | Loss(train) 0.7105 | Acc(train) 0.7707 | Acc(val) 0.8180 |
Epoch 00055 | Loss(train) 0.7040 | Acc(train) 0.7756 | Acc(val) 0.8215 |*
Epoch 00056 | Loss(train) 0.6978 | Acc(train) 0.7829 | Acc(val) 0.8225 |*
Epoch 00057 | Loss(train) 0.6891 | Acc(train) 0.7809 | Acc(val) 0.8245 |*
Epoch 00058 | Loss(train) 0.6869 | Acc(train) 0.7806 | Acc(val) 0.8266 |*
Epoch 00059 | Loss(train) 0.6848 | Acc(train) 0.7857 | Acc(val) 0.8286 |*
Epoch 00060 | Loss(train) 0.6854 | Acc(train) 0.7763 | Acc(val) 0.8301 |*
Epoch 00061 | Loss(train) 0.6810 | Acc(train) 0.7865 | Acc(val) 0.8332 |*
Epoch 00062 | Loss(train) 0.6642 | Acc(train) 0.7918 | Acc(val) 0.8347 |*
Epoch 00063 | Loss(train) 0.6698 | Acc(train) 0.7809 | Acc(val) 0.8322 |
Epoch 00064 | Loss(train) 0.6606 | Acc(train) 0.7804 | Acc(val) 0.8311 |
Epoch 00065 | Loss(train) 0.6536 | Acc(train) 0.7898 | Acc(val) 0.8301 |
Epoch 00066 | Loss(train) 0.6456 | Acc(train) 0.7984 | Acc(val) 0.8306 |
Epoch 00067 | Loss(train) 0.6459 | Acc(train) 0.7928 | Acc(val) 0.8332 |
Epoch 00068 | Loss(train) 0.6465 | Acc(train) 0.7961 | Acc(val) 0.8337 |
Epoch 00069 | Loss(train) 0.6379 | Acc(train) 0.7905 | Acc(val) 0.8342 |
Epoch 00070 | Loss(train) 0.6368 | Acc(train) 0.7966 | Acc(val) 0.8337 |
Epoch 00071 | Loss(train) 0.6283 | Acc(train) 0.8024 | Acc(val) 0.8347 |
Epoch 00072 | Loss(train) 0.6264 | Acc(train) 0.7961 | Acc(val) 0.8347 |
Epoch 00073 | Loss(train) 0.6251 | Acc(train) 0.8027 | Acc(val) 0.8362 |*
Epoch 00074 | Loss(train) 0.6205 | Acc(train) 0.8004 | Acc(val) 0.8372 |*
Epoch 00075 | Loss(train) 0.6184 | Acc(train) 0.8029 | Acc(val) 0.8377 |*
Epoch 00076 | Loss(train) 0.6194 | Acc(train) 0.7971 | Acc(val) 0.8377 |
Epoch 00077 | Loss(train) 0.6182 | Acc(train) 0.8032 | Acc(val) 0.8377 |
Epoch 00078 | Loss(train) 0.6083 | Acc(train) 0.8012 | Acc(val) 0.8387 |*
Epoch 00079 | Loss(train) 0.6096 | Acc(train) 0.8042 | Acc(val) 0.8403 |*
Epoch 00080 | Loss(train) 0.6025 | Acc(train) 0.8073 | Acc(val) 0.8428 |*
Epoch 00081 | Loss(train) 0.5957 | Acc(train) 0.8106 | Acc(val) 0.8428 |
Epoch 00082 | Loss(train) 0.5950 | Acc(train) 0.8128 | Acc(val) 0.8423 |
Epoch 00083 | Loss(train) 0.5934 | Acc(train) 0.8128 | Acc(val) 0.8428 |
Epoch 00084 | Loss(train) 0.5903 | Acc(train) 0.8078 | Acc(val) 0.8433 |*
Epoch 00085 | Loss(train) 0.5888 | Acc(train) 0.8093 | Acc(val) 0.8433 |
Epoch 00086 | Loss(train) 0.5886 | Acc(train) 0.8108 | Acc(val) 0.8443 |*
Epoch 00087 | Loss(train) 0.5835 | Acc(train) 0.8118 | Acc(val) 0.8433 |
Epoch 00088 | Loss(train) 0.5801 | Acc(train) 0.8131 | Acc(val) 0.8423 |
Epoch 00089 | Loss(train) 0.5795 | Acc(train) 0.8169 | Acc(val) 0.8438 |
Epoch 00090 | Loss(train) 0.5799 | Acc(train) 0.8187 | Acc(val) 0.8458 |*
Epoch 00091 | Loss(train) 0.5736 | Acc(train) 0.8230 | Acc(val) 0.8469 |*
Epoch 00092 | Loss(train) 0.5742 | Acc(train) 0.8126 | Acc(val) 0.8484 |*
Epoch 00093 | Loss(train) 0.5695 | Acc(train) 0.8199 | Acc(val) 0.8458 |
Epoch 00094 | Loss(train) 0.5708 | Acc(train) 0.8121 | Acc(val) 0.8469 |
Epoch 00095 | Loss(train) 0.5675 | Acc(train) 0.8202 | Acc(val) 0.8484 |
Epoch 00096 | Loss(train) 0.5656 | Acc(train) 0.8149 | Acc(val) 0.8484 |
Epoch 00097 | Loss(train) 0.5620 | Acc(train) 0.8217 | Acc(val) 0.8489 |*
Epoch 00098 | Loss(train) 0.5637 | Acc(train) 0.8242 | Acc(val) 0.8489 |
Epoch 00099 | Loss(train) 0.5535 | Acc(train) 0.8242 | Acc(val) 0.8489 |
Epoch 00100 | Loss(train) 0.5559 | Acc(train) 0.8227 | Acc(val) 0.8474 |
Epoch 00101 | Loss(train) 0.5582 | Acc(train) 0.8159 | Acc(val) 0.8489 |
Epoch 00102 | Loss(train) 0.5521 | Acc(train) 0.8227 | Acc(val) 0.8489 |
Epoch 00103 | Loss(train) 0.5555 | Acc(train) 0.8171 | Acc(val) 0.8494 |*
Epoch 00104 | Loss(train) 0.5507 | Acc(train) 0.8202 | Acc(val) 0.8499 |*
Epoch 00105 | Loss(train) 0.5467 | Acc(train) 0.8230 | Acc(val) 0.8479 |
Epoch 00106 | Loss(train) 0.5413 | Acc(train) 0.8291 | Acc(val) 0.8504 |*
Epoch 00107 | Loss(train) 0.5477 | Acc(train) 0.8194 | Acc(val) 0.8504 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00108 | Loss(train) 0.5380 | Acc(train) 0.8324 | Acc(val) 0.8489 |
Epoch 00109 | Loss(train) 0.5366 | Acc(train) 0.8177 | Acc(val) 0.8504 |
Epoch 00110 | Loss(train) 0.5429 | Acc(train) 0.8209 | Acc(val) 0.8499 |
Epoch 00111 | Loss(train) 0.5272 | Acc(train) 0.8354 | Acc(val) 0.8499 |
Epoch 00112 | Loss(train) 0.5376 | Acc(train) 0.8260 | Acc(val) 0.8514 |*
Epoch 00113 | Loss(train) 0.5377 | Acc(train) 0.8258 | Acc(val) 0.8514 |
Epoch 00114 | Loss(train) 0.5312 | Acc(train) 0.8359 | Acc(val) 0.8514 |
Epoch 00115 | Loss(train) 0.5334 | Acc(train) 0.8311 | Acc(val) 0.8509 |
Epoch 00116 | Loss(train) 0.5314 | Acc(train) 0.8280 | Acc(val) 0.8504 |
Epoch 00117 | Loss(train) 0.5285 | Acc(train) 0.8258 | Acc(val) 0.8509 |
Epoch 00118 | Loss(train) 0.5239 | Acc(train) 0.8311 | Acc(val) 0.8524 |*
Epoch 00119 | Loss(train) 0.5240 | Acc(train) 0.8291 | Acc(val) 0.8529 |*
Epoch 00120 | Loss(train) 0.5314 | Acc(train) 0.8306 | Acc(val) 0.8509 |
Epoch 00121 | Loss(train) 0.5315 | Acc(train) 0.8283 | Acc(val) 0.8509 |
Epoch 00122 | Loss(train) 0.5210 | Acc(train) 0.8357 | Acc(val) 0.8529 |
Epoch 00123 | Loss(train) 0.5198 | Acc(train) 0.8336 | Acc(val) 0.8540 |*
Epoch 00124 | Loss(train) 0.5248 | Acc(train) 0.8291 | Acc(val) 0.8529 |
Epoch 00125 | Loss(train) 0.5188 | Acc(train) 0.8303 | Acc(val) 0.8524 |
Epoch 00126 | Loss(train) 0.5185 | Acc(train) 0.8278 | Acc(val) 0.8519 |
Epoch 00127 | Loss(train) 0.5229 | Acc(train) 0.8303 | Acc(val) 0.8514 |
Epoch 00128 | Loss(train) 0.5160 | Acc(train) 0.8324 | Acc(val) 0.8524 |
Epoch 00129 | Loss(train) 0.5163 | Acc(train) 0.8352 | Acc(val) 0.8545 |*
Epoch 00130 | Loss(train) 0.5113 | Acc(train) 0.8336 | Acc(val) 0.8545 |
Epoch 00131 | Loss(train) 0.5092 | Acc(train) 0.8377 | Acc(val) 0.8550 |*
Epoch 00132 | Loss(train) 0.5052 | Acc(train) 0.8423 | Acc(val) 0.8540 |
Epoch 00133 | Loss(train) 0.5123 | Acc(train) 0.8369 | Acc(val) 0.8529 |
Epoch 00134 | Loss(train) 0.5108 | Acc(train) 0.8278 | Acc(val) 0.8545 |
Epoch 00135 | Loss(train) 0.5023 | Acc(train) 0.8359 | Acc(val) 0.8545 |
Epoch 00136 | Loss(train) 0.5066 | Acc(train) 0.8450 | Acc(val) 0.8524 |
Epoch 00137 | Loss(train) 0.5050 | Acc(train) 0.8390 | Acc(val) 0.8514 |
Epoch 00138 | Loss(train) 0.5076 | Acc(train) 0.8374 | Acc(val) 0.8560 |*
Epoch 00139 | Loss(train) 0.5051 | Acc(train) 0.8339 | Acc(val) 0.8545 |
Epoch 00140 | Loss(train) 0.5008 | Acc(train) 0.8407 | Acc(val) 0.8524 |
Epoch 00141 | Loss(train) 0.5039 | Acc(train) 0.8395 | Acc(val) 0.8534 |
Epoch 00142 | Loss(train) 0.4954 | Acc(train) 0.8417 | Acc(val) 0.8555 |
Epoch 00143 | Loss(train) 0.4960 | Acc(train) 0.8410 | Acc(val) 0.8534 |
Epoch 00144 | Loss(train) 0.4945 | Acc(train) 0.8453 | Acc(val) 0.8524 |
Epoch 00145 | Loss(train) 0.5029 | Acc(train) 0.8382 | Acc(val) 0.8519 |
Epoch 00146 | Loss(train) 0.4923 | Acc(train) 0.8392 | Acc(val) 0.8550 |
Epoch 00147 | Loss(train) 0.4948 | Acc(train) 0.8392 | Acc(val) 0.8540 |
Epoch 00148 | Loss(train) 0.4874 | Acc(train) 0.8435 | Acc(val) 0.8529 |
Epoch 00149 | Loss(train) 0.4912 | Acc(train) 0.8352 | Acc(val) 0.8545 |
Epoch 00150 | Loss(train) 0.5007 | Acc(train) 0.8324 | Acc(val) 0.8545 |
Epoch 00151 | Loss(train) 0.4912 | Acc(train) 0.8430 | Acc(val) 0.8540 |
Epoch 00152 | Loss(train) 0.4926 | Acc(train) 0.8405 | Acc(val) 0.8545 |
Epoch 00153 | Loss(train) 0.4894 | Acc(train) 0.8453 | Acc(val) 0.8550 |
Epoch 00154 | Loss(train) 0.4970 | Acc(train) 0.8430 | Acc(val) 0.8555 |
Epoch 00155 | Loss(train) 0.4969 | Acc(train) 0.8390 | Acc(val) 0.8550 |
Epoch 00156 | Loss(train) 0.4885 | Acc(train) 0.8374 | Acc(val) 0.8560 |
Epoch 00157 | Loss(train) 0.4867 | Acc(train) 0.8466 | Acc(val) 0.8555 |
Epoch 00158 | Loss(train) 0.4868 | Acc(train) 0.8417 | Acc(val) 0.8550 |
Epoch 00159 | Loss(train) 0.4868 | Acc(train) 0.8423 | Acc(val) 0.8540 |
Epoch 00160 | Loss(train) 0.4862 | Acc(train) 0.8468 | Acc(val) 0.8550 |
Epoch 00161 | Loss(train) 0.4859 | Acc(train) 0.8433 | Acc(val) 0.8540 |
Epoch 00162 | Loss(train) 0.4868 | Acc(train) 0.8417 | Acc(val) 0.8550 |
Epoch 00163 | Loss(train) 0.4868 | Acc(train) 0.8382 | Acc(val) 0.8550 |
Epoch 00164 | Loss(train) 0.4800 | Acc(train) 0.8445 | Acc(val) 0.8570 |*
Epoch 00165 | Loss(train) 0.4902 | Acc(train) 0.8382 | Acc(val) 0.8570 |
Epoch 00166 | Loss(train) 0.4828 | Acc(train) 0.8395 | Acc(val) 0.8550 |
Epoch 00167 | Loss(train) 0.4791 | Acc(train) 0.8473 | Acc(val) 0.8580 |*
Epoch 00168 | Loss(train) 0.4870 | Acc(train) 0.8428 | Acc(val) 0.8560 |
Epoch 00169 | Loss(train) 0.4726 | Acc(train) 0.8448 | Acc(val) 0.8565 |
Epoch 00170 | Loss(train) 0.4847 | Acc(train) 0.8410 | Acc(val) 0.8575 |
Epoch 00171 | Loss(train) 0.4833 | Acc(train) 0.8402 | Acc(val) 0.8560 |
Epoch 00172 | Loss(train) 0.4829 | Acc(train) 0.8354 | Acc(val) 0.8565 |
Epoch 00173 | Loss(train) 0.4770 | Acc(train) 0.8458 | Acc(val) 0.8555 |
Epoch 00174 | Loss(train) 0.4674 | Acc(train) 0.8519 | Acc(val) 0.8555 |
Epoch 00175 | Loss(train) 0.4755 | Acc(train) 0.8415 | Acc(val) 0.8565 |
Epoch 00176 | Loss(train) 0.4787 | Acc(train) 0.8407 | Acc(val) 0.8540 |
Epoch 00177 | Loss(train) 0.4780 | Acc(train) 0.8384 | Acc(val) 0.8575 |
Epoch 00178 | Loss(train) 0.4752 | Acc(train) 0.8428 | Acc(val) 0.8555 |
Epoch 00179 | Loss(train) 0.4754 | Acc(train) 0.8445 | Acc(val) 0.8545 |
Epoch 00180 | Loss(train) 0.4739 | Acc(train) 0.8471 | Acc(val) 0.8555 |
Epoch 00181 | Loss(train) 0.4778 | Acc(train) 0.8476 | Acc(val) 0.8570 |
Epoch 00182 | Loss(train) 0.4684 | Acc(train) 0.8506 | Acc(val) 0.8570 |
Epoch 00183 | Loss(train) 0.4708 | Acc(train) 0.8504 | Acc(val) 0.8580 |
Epoch 00184 | Loss(train) 0.4726 | Acc(train) 0.8430 | Acc(val) 0.8560 |
Epoch 00185 | Loss(train) 0.4709 | Acc(train) 0.8455 | Acc(val) 0.8560 |
Epoch 00186 | Loss(train) 0.4702 | Acc(train) 0.8481 | Acc(val) 0.8560 |
Epoch 00187 | Loss(train) 0.4653 | Acc(train) 0.8504 | Acc(val) 0.8560 |
Epoch 00188 | Loss(train) 0.4675 | Acc(train) 0.8450 | Acc(val) 0.8585 |*
Epoch 00189 | Loss(train) 0.4725 | Acc(train) 0.8476 | Acc(val) 0.8555 |
Epoch 00190 | Loss(train) 0.4653 | Acc(train) 0.8478 | Acc(val) 0.8570 |
Epoch 00191 | Loss(train) 0.4698 | Acc(train) 0.8443 | Acc(val) 0.8570 |
Epoch 00192 | Loss(train) 0.4680 | Acc(train) 0.8461 | Acc(val) 0.8560 |
Epoch 00193 | Loss(train) 0.4674 | Acc(train) 0.8466 | Acc(val) 0.8600 |*
Epoch 00194 | Loss(train) 0.4674 | Acc(train) 0.8524 | Acc(val) 0.8575 |
Epoch 00195 | Loss(train) 0.4652 | Acc(train) 0.8496 | Acc(val) 0.8565 |
Epoch 00196 | Loss(train) 0.4663 | Acc(train) 0.8509 | Acc(val) 0.8540 |
Epoch 00197 | Loss(train) 0.4660 | Acc(train) 0.8483 | Acc(val) 0.8585 |
Epoch 00198 | Loss(train) 0.4692 | Acc(train) 0.8468 | Acc(val) 0.8595 |
Epoch 00199 | Loss(train) 0.4659 | Acc(train) 0.8430 | Acc(val) 0.8611 |*
Epoch 00200 | Loss(train) 0.4574 | Acc(train) 0.8575 | Acc(val) 0.8600 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0992 | Acc(train) 0.3378 | Acc(val) 0.4249 |*
Epoch 00002 | Loss(train) 1.0904 | Acc(train) 0.4403 | Acc(val) 0.4042 |
Epoch 00003 | Loss(train) 1.0826 | Acc(train) 0.4296 | Acc(val) 0.4092 |
Epoch 00004 | Loss(train) 1.0741 | Acc(train) 0.4398 | Acc(val) 0.4214 |
Epoch 00005 | Loss(train) 1.0647 | Acc(train) 0.4517 | Acc(val) 0.4366 |*
Epoch 00006 | Loss(train) 1.0573 | Acc(train) 0.4471 | Acc(val) 0.4660 |*
Epoch 00007 | Loss(train) 1.0463 | Acc(train) 0.4874 | Acc(val) 0.4924 |*
Epoch 00008 | Loss(train) 1.0395 | Acc(train) 0.5082 | Acc(val) 0.5314 |*
Epoch 00009 | Loss(train) 1.0323 | Acc(train) 0.5278 | Acc(val) 0.5700 |*
Epoch 00010 | Loss(train) 1.0251 | Acc(train) 0.5481 | Acc(val) 0.6055 |*
Epoch 00011 | Loss(train) 1.0153 | Acc(train) 0.5689 | Acc(val) 0.6334 |*
Epoch 00012 | Loss(train) 1.0092 | Acc(train) 0.5765 | Acc(val) 0.6466 |*
Epoch 00013 | Loss(train) 1.0015 | Acc(train) 0.5823 | Acc(val) 0.6537 |*
Epoch 00014 | Loss(train) 0.9929 | Acc(train) 0.5973 | Acc(val) 0.6613 |*
Epoch 00015 | Loss(train) 0.9885 | Acc(train) 0.5985 | Acc(val) 0.6638 |*
Epoch 00016 | Loss(train) 0.9783 | Acc(train) 0.5988 | Acc(val) 0.6684 |*
Epoch 00017 | Loss(train) 0.9720 | Acc(train) 0.5988 | Acc(val) 0.6709 |*
Epoch 00018 | Loss(train) 0.9679 | Acc(train) 0.5904 | Acc(val) 0.6699 |
Epoch 00019 | Loss(train) 0.9559 | Acc(train) 0.6072 | Acc(val) 0.6689 |
Epoch 00020 | Loss(train) 0.9516 | Acc(train) 0.6061 | Acc(val) 0.6678 |
Epoch 00021 | Loss(train) 0.9426 | Acc(train) 0.6084 | Acc(val) 0.6643 |
Epoch 00022 | Loss(train) 0.9343 | Acc(train) 0.6092 | Acc(val) 0.6628 |
Epoch 00023 | Loss(train) 0.9252 | Acc(train) 0.6208 | Acc(val) 0.6663 |
Epoch 00024 | Loss(train) 0.9189 | Acc(train) 0.6132 | Acc(val) 0.6668 |
Epoch 00025 | Loss(train) 0.9100 | Acc(train) 0.6203 | Acc(val) 0.6668 |
Epoch 00026 | Loss(train) 0.9053 | Acc(train) 0.6198 | Acc(val) 0.6673 |
Epoch 00027 | Loss(train) 0.8969 | Acc(train) 0.6198 | Acc(val) 0.6694 |
Epoch 00028 | Loss(train) 0.8863 | Acc(train) 0.6252 | Acc(val) 0.6729 |*
Epoch 00029 | Loss(train) 0.8814 | Acc(train) 0.6254 | Acc(val) 0.6765 |*
Epoch 00030 | Loss(train) 0.8715 | Acc(train) 0.6297 | Acc(val) 0.6790 |*
Epoch 00031 | Loss(train) 0.8669 | Acc(train) 0.6290 | Acc(val) 0.6831 |*
Epoch 00032 | Loss(train) 0.8595 | Acc(train) 0.6439 | Acc(val) 0.6846 |*
Epoch 00033 | Loss(train) 0.8489 | Acc(train) 0.6442 | Acc(val) 0.6881 |*
Epoch 00034 | Loss(train) 0.8432 | Acc(train) 0.6396 | Acc(val) 0.6912 |*
Epoch 00035 | Loss(train) 0.8365 | Acc(train) 0.6472 | Acc(val) 0.6968 |*
Epoch 00036 | Loss(train) 0.8273 | Acc(train) 0.6637 | Acc(val) 0.7039 |*
Epoch 00037 | Loss(train) 0.8167 | Acc(train) 0.6670 | Acc(val) 0.7140 |*
Epoch 00038 | Loss(train) 0.8157 | Acc(train) 0.6665 | Acc(val) 0.7231 |*
Epoch 00039 | Loss(train) 0.8096 | Acc(train) 0.6675 | Acc(val) 0.7368 |*
Epoch 00040 | Loss(train) 0.8010 | Acc(train) 0.6820 | Acc(val) 0.7470 |*
Epoch 00041 | Loss(train) 0.7915 | Acc(train) 0.6906 | Acc(val) 0.7581 |*
Epoch 00042 | Loss(train) 0.7847 | Acc(train) 0.6977 | Acc(val) 0.7713 |*
Epoch 00043 | Loss(train) 0.7786 | Acc(train) 0.7177 | Acc(val) 0.7774 |*
Epoch 00044 | Loss(train) 0.7726 | Acc(train) 0.7165 | Acc(val) 0.7890 |*
Epoch 00045 | Loss(train) 0.7597 | Acc(train) 0.7218 | Acc(val) 0.7956 |*
Epoch 00046 | Loss(train) 0.7602 | Acc(train) 0.7256 | Acc(val) 0.7997 |*
Epoch 00047 | Loss(train) 0.7491 | Acc(train) 0.7317 | Acc(val) 0.8032 |*
Epoch 00048 | Loss(train) 0.7439 | Acc(train) 0.7431 | Acc(val) 0.8068 |*
Epoch 00049 | Loss(train) 0.7378 | Acc(train) 0.7474 | Acc(val) 0.8093 |*
Epoch 00050 | Loss(train) 0.7279 | Acc(train) 0.7479 | Acc(val) 0.8093 |
Epoch 00051 | Loss(train) 0.7352 | Acc(train) 0.7314 | Acc(val) 0.8129 |*
Epoch 00052 | Loss(train) 0.7221 | Acc(train) 0.7479 | Acc(val) 0.8139 |*
Epoch 00053 | Loss(train) 0.7119 | Acc(train) 0.7517 | Acc(val) 0.8164 |*
Epoch 00054 | Loss(train) 0.7075 | Acc(train) 0.7535 | Acc(val) 0.8180 |*
Epoch 00055 | Loss(train) 0.7084 | Acc(train) 0.7512 | Acc(val) 0.8180 |
Epoch 00056 | Loss(train) 0.6972 | Acc(train) 0.7639 | Acc(val) 0.8220 |*
Epoch 00057 | Loss(train) 0.6915 | Acc(train) 0.7624 | Acc(val) 0.8235 |*
Epoch 00058 | Loss(train) 0.6863 | Acc(train) 0.7659 | Acc(val) 0.8256 |*
Epoch 00059 | Loss(train) 0.6867 | Acc(train) 0.7649 | Acc(val) 0.8266 |*
Epoch 00060 | Loss(train) 0.6778 | Acc(train) 0.7758 | Acc(val) 0.8281 |*
Epoch 00061 | Loss(train) 0.6723 | Acc(train) 0.7794 | Acc(val) 0.8281 |
Epoch 00062 | Loss(train) 0.6652 | Acc(train) 0.7806 | Acc(val) 0.8291 |*
Epoch 00063 | Loss(train) 0.6647 | Acc(train) 0.7819 | Acc(val) 0.8301 |*
Epoch 00064 | Loss(train) 0.6642 | Acc(train) 0.7771 | Acc(val) 0.8306 |*
Epoch 00065 | Loss(train) 0.6584 | Acc(train) 0.7804 | Acc(val) 0.8301 |
Epoch 00066 | Loss(train) 0.6460 | Acc(train) 0.7885 | Acc(val) 0.8306 |
Epoch 00067 | Loss(train) 0.6523 | Acc(train) 0.7776 | Acc(val) 0.8311 |*
Epoch 00068 | Loss(train) 0.6417 | Acc(train) 0.7877 | Acc(val) 0.8327 |*
Epoch 00069 | Loss(train) 0.6428 | Acc(train) 0.7887 | Acc(val) 0.8352 |*
Epoch 00070 | Loss(train) 0.6434 | Acc(train) 0.7799 | Acc(val) 0.8352 |
Epoch 00071 | Loss(train) 0.6298 | Acc(train) 0.7953 | Acc(val) 0.8337 |
Epoch 00072 | Loss(train) 0.6284 | Acc(train) 0.7903 | Acc(val) 0.8322 |
Epoch 00073 | Loss(train) 0.6229 | Acc(train) 0.7882 | Acc(val) 0.8332 |
Epoch 00074 | Loss(train) 0.6219 | Acc(train) 0.8004 | Acc(val) 0.8372 |*
Epoch 00075 | Loss(train) 0.6209 | Acc(train) 0.8057 | Acc(val) 0.8367 |
Epoch 00076 | Loss(train) 0.6110 | Acc(train) 0.8029 | Acc(val) 0.8362 |
Epoch 00077 | Loss(train) 0.6152 | Acc(train) 0.7999 | Acc(val) 0.8362 |
Epoch 00078 | Loss(train) 0.6068 | Acc(train) 0.7984 | Acc(val) 0.8377 |*
Epoch 00079 | Loss(train) 0.6086 | Acc(train) 0.7943 | Acc(val) 0.8382 |*
Epoch 00080 | Loss(train) 0.6095 | Acc(train) 0.7971 | Acc(val) 0.8398 |*
Epoch 00081 | Loss(train) 0.6003 | Acc(train) 0.8055 | Acc(val) 0.8408 |*
Epoch 00082 | Loss(train) 0.6021 | Acc(train) 0.8055 | Acc(val) 0.8408 |
Epoch 00083 | Loss(train) 0.5939 | Acc(train) 0.8078 | Acc(val) 0.8392 |
Epoch 00084 | Loss(train) 0.5992 | Acc(train) 0.8093 | Acc(val) 0.8408 |
Epoch 00085 | Loss(train) 0.5933 | Acc(train) 0.8144 | Acc(val) 0.8418 |*
Epoch 00086 | Loss(train) 0.5936 | Acc(train) 0.8116 | Acc(val) 0.8408 |
Epoch 00087 | Loss(train) 0.5879 | Acc(train) 0.8093 | Acc(val) 0.8438 |*
Epoch 00088 | Loss(train) 0.5891 | Acc(train) 0.8128 | Acc(val) 0.8448 |*
Epoch 00089 | Loss(train) 0.5790 | Acc(train) 0.8098 | Acc(val) 0.8443 |
Epoch 00090 | Loss(train) 0.5819 | Acc(train) 0.8073 | Acc(val) 0.8413 |
Epoch 00091 | Loss(train) 0.5777 | Acc(train) 0.8019 | Acc(val) 0.8433 |
Epoch 00092 | Loss(train) 0.5784 | Acc(train) 0.8083 | Acc(val) 0.8423 |
Epoch 00093 | Loss(train) 0.5745 | Acc(train) 0.8204 | Acc(val) 0.8463 |*
Epoch 00094 | Loss(train) 0.5769 | Acc(train) 0.8164 | Acc(val) 0.8453 |
Epoch 00095 | Loss(train) 0.5665 | Acc(train) 0.8151 | Acc(val) 0.8479 |*
Epoch 00096 | Loss(train) 0.5700 | Acc(train) 0.8166 | Acc(val) 0.8443 |
Epoch 00097 | Loss(train) 0.5663 | Acc(train) 0.8128 | Acc(val) 0.8443 |
Epoch 00098 | Loss(train) 0.5658 | Acc(train) 0.8161 | Acc(val) 0.8443 |
Epoch 00099 | Loss(train) 0.5636 | Acc(train) 0.8217 | Acc(val) 0.8458 |
Epoch 00100 | Loss(train) 0.5632 | Acc(train) 0.8161 | Acc(val) 0.8463 |
Epoch 00101 | Loss(train) 0.5565 | Acc(train) 0.8225 | Acc(val) 0.8463 |
Epoch 00102 | Loss(train) 0.5547 | Acc(train) 0.8230 | Acc(val) 0.8474 |
Epoch 00103 | Loss(train) 0.5508 | Acc(train) 0.8217 | Acc(val) 0.8489 |*
Epoch 00104 | Loss(train) 0.5544 | Acc(train) 0.8161 | Acc(val) 0.8504 |*
Epoch 00105 | Loss(train) 0.5561 | Acc(train) 0.8138 | Acc(val) 0.8540 |*
Epoch 00106 | Loss(train) 0.5457 | Acc(train) 0.8240 | Acc(val) 0.8519 |
Epoch 00107 | Loss(train) 0.5464 | Acc(train) 0.8220 | Acc(val) 0.8484 |
Epoch 00108 | Loss(train) 0.5499 | Acc(train) 0.8192 | Acc(val) 0.8489 |
Epoch 00109 | Loss(train) 0.5441 | Acc(train) 0.8268 | Acc(val) 0.8524 |
Epoch 00110 | Loss(train) 0.5418 | Acc(train) 0.8268 | Acc(val) 0.8529 |
Epoch 00111 | Loss(train) 0.5390 | Acc(train) 0.8230 | Acc(val) 0.8529 |
Epoch 00112 | Loss(train) 0.5466 | Acc(train) 0.8202 | Acc(val) 0.8540 |
Epoch 00113 | Loss(train) 0.5445 | Acc(train) 0.8273 | Acc(val) 0.8534 |
Epoch 00114 | Loss(train) 0.5385 | Acc(train) 0.8319 | Acc(val) 0.8534 |
Epoch 00115 | Loss(train) 0.5389 | Acc(train) 0.8280 | Acc(val) 0.8534 |
Epoch 00116 | Loss(train) 0.5314 | Acc(train) 0.8326 | Acc(val) 0.8529 |
Epoch 00117 | Loss(train) 0.5327 | Acc(train) 0.8319 | Acc(val) 0.8529 |
Epoch 00118 | Loss(train) 0.5392 | Acc(train) 0.8207 | Acc(val) 0.8540 |
Epoch 00119 | Loss(train) 0.5274 | Acc(train) 0.8359 | Acc(val) 0.8540 |
Epoch 00120 | Loss(train) 0.5311 | Acc(train) 0.8265 | Acc(val) 0.8540 |
Epoch 00121 | Loss(train) 0.5327 | Acc(train) 0.8268 | Acc(val) 0.8550 |*
Epoch 00122 | Loss(train) 0.5295 | Acc(train) 0.8308 | Acc(val) 0.8560 |*
Epoch 00123 | Loss(train) 0.5215 | Acc(train) 0.8341 | Acc(val) 0.8545 |
Epoch 00124 | Loss(train) 0.5276 | Acc(train) 0.8275 | Acc(val) 0.8560 |
Epoch 00125 | Loss(train) 0.5260 | Acc(train) 0.8334 | Acc(val) 0.8545 |
Epoch 00126 | Loss(train) 0.5265 | Acc(train) 0.8283 | Acc(val) 0.8555 |
Epoch 00127 | Loss(train) 0.5201 | Acc(train) 0.8308 | Acc(val) 0.8555 |
Epoch 00128 | Loss(train) 0.5248 | Acc(train) 0.8286 | Acc(val) 0.8550 |
Epoch 00129 | Loss(train) 0.5241 | Acc(train) 0.8344 | Acc(val) 0.8555 |
Epoch 00130 | Loss(train) 0.5113 | Acc(train) 0.8407 | Acc(val) 0.8550 |
Epoch 00131 | Loss(train) 0.5230 | Acc(train) 0.8367 | Acc(val) 0.8570 |*
Epoch 00132 | Loss(train) 0.5154 | Acc(train) 0.8377 | Acc(val) 0.8570 |
Epoch 00133 | Loss(train) 0.5173 | Acc(train) 0.8329 | Acc(val) 0.8585 |*
Epoch 00134 | Loss(train) 0.5159 | Acc(train) 0.8354 | Acc(val) 0.8580 |
Epoch 00135 | Loss(train) 0.5141 | Acc(train) 0.8362 | Acc(val) 0.8560 |
Epoch 00136 | Loss(train) 0.5111 | Acc(train) 0.8372 | Acc(val) 0.8560 |
Epoch 00137 | Loss(train) 0.5103 | Acc(train) 0.8369 | Acc(val) 0.8540 |
Epoch 00138 | Loss(train) 0.5158 | Acc(train) 0.8324 | Acc(val) 0.8570 |
Epoch 00139 | Loss(train) 0.5118 | Acc(train) 0.8359 | Acc(val) 0.8575 |
Epoch 00140 | Loss(train) 0.5078 | Acc(train) 0.8417 | Acc(val) 0.8590 |*
Epoch 00141 | Loss(train) 0.5027 | Acc(train) 0.8395 | Acc(val) 0.8585 |
Epoch 00142 | Loss(train) 0.5142 | Acc(train) 0.8349 | Acc(val) 0.8565 |
Epoch 00143 | Loss(train) 0.5071 | Acc(train) 0.8369 | Acc(val) 0.8555 |
Epoch 00144 | Loss(train) 0.5098 | Acc(train) 0.8364 | Acc(val) 0.8550 |
Epoch 00145 | Loss(train) 0.5034 | Acc(train) 0.8357 | Acc(val) 0.8534 |
Epoch 00146 | Loss(train) 0.5032 | Acc(train) 0.8387 | Acc(val) 0.8580 |
Epoch 00147 | Loss(train) 0.5021 | Acc(train) 0.8339 | Acc(val) 0.8580 |
Epoch 00148 | Loss(train) 0.5012 | Acc(train) 0.8384 | Acc(val) 0.8585 |
Epoch 00149 | Loss(train) 0.5012 | Acc(train) 0.8364 | Acc(val) 0.8580 |
Epoch 00150 | Loss(train) 0.5013 | Acc(train) 0.8402 | Acc(val) 0.8545 |
Epoch 00151 | Loss(train) 0.5006 | Acc(train) 0.8405 | Acc(val) 0.8545 |
Epoch 00152 | Loss(train) 0.5018 | Acc(train) 0.8313 | Acc(val) 0.8585 |
Epoch 00153 | Loss(train) 0.4967 | Acc(train) 0.8390 | Acc(val) 0.8580 |
Epoch 00154 | Loss(train) 0.5032 | Acc(train) 0.8357 | Acc(val) 0.8565 |
Epoch 00155 | Loss(train) 0.5007 | Acc(train) 0.8321 | Acc(val) 0.8545 |
Epoch 00156 | Loss(train) 0.4980 | Acc(train) 0.8387 | Acc(val) 0.8545 |
Epoch 00157 | Loss(train) 0.4982 | Acc(train) 0.8392 | Acc(val) 0.8580 |
Epoch 00158 | Loss(train) 0.4939 | Acc(train) 0.8392 | Acc(val) 0.8605 |*
Epoch 00159 | Loss(train) 0.4939 | Acc(train) 0.8384 | Acc(val) 0.8605 |
Epoch 00160 | Loss(train) 0.4885 | Acc(train) 0.8428 | Acc(val) 0.8565 |
Epoch 00161 | Loss(train) 0.4950 | Acc(train) 0.8359 | Acc(val) 0.8560 |
Epoch 00162 | Loss(train) 0.4892 | Acc(train) 0.8463 | Acc(val) 0.8560 |
Epoch 00163 | Loss(train) 0.4906 | Acc(train) 0.8369 | Acc(val) 0.8560 |
Epoch 00164 | Loss(train) 0.4898 | Acc(train) 0.8428 | Acc(val) 0.8600 |
Epoch 00165 | Loss(train) 0.4899 | Acc(train) 0.8425 | Acc(val) 0.8611 |*
Epoch 00166 | Loss(train) 0.4926 | Acc(train) 0.8392 | Acc(val) 0.8595 |
Epoch 00167 | Loss(train) 0.4860 | Acc(train) 0.8410 | Acc(val) 0.8595 |
Epoch 00168 | Loss(train) 0.4846 | Acc(train) 0.8450 | Acc(val) 0.8590 |
Epoch 00169 | Loss(train) 0.4865 | Acc(train) 0.8430 | Acc(val) 0.8600 |
Epoch 00170 | Loss(train) 0.4910 | Acc(train) 0.8329 | Acc(val) 0.8605 |
Epoch 00171 | Loss(train) 0.4928 | Acc(train) 0.8400 | Acc(val) 0.8616 |*
Epoch 00172 | Loss(train) 0.4821 | Acc(train) 0.8478 | Acc(val) 0.8611 |
Epoch 00173 | Loss(train) 0.4881 | Acc(train) 0.8382 | Acc(val) 0.8590 |
Epoch 00174 | Loss(train) 0.4833 | Acc(train) 0.8478 | Acc(val) 0.8590 |
Epoch 00175 | Loss(train) 0.4844 | Acc(train) 0.8425 | Acc(val) 0.8600 |
Epoch 00176 | Loss(train) 0.4813 | Acc(train) 0.8420 | Acc(val) 0.8590 |
Epoch 00177 | Loss(train) 0.4804 | Acc(train) 0.8466 | Acc(val) 0.8595 |
Epoch 00178 | Loss(train) 0.4827 | Acc(train) 0.8412 | Acc(val) 0.8580 |
Epoch 00179 | Loss(train) 0.4748 | Acc(train) 0.8428 | Acc(val) 0.8595 |
Epoch 00180 | Loss(train) 0.4827 | Acc(train) 0.8494 | Acc(val) 0.8595 |
Epoch 00181 | Loss(train) 0.4788 | Acc(train) 0.8395 | Acc(val) 0.8590 |
Epoch 00182 | Loss(train) 0.4822 | Acc(train) 0.8453 | Acc(val) 0.8580 |
Epoch 00183 | Loss(train) 0.4801 | Acc(train) 0.8428 | Acc(val) 0.8580 |
Epoch 00184 | Loss(train) 0.4748 | Acc(train) 0.8438 | Acc(val) 0.8590 |
Epoch 00185 | Loss(train) 0.4806 | Acc(train) 0.8504 | Acc(val) 0.8600 |
Epoch 00186 | Loss(train) 0.4834 | Acc(train) 0.8435 | Acc(val) 0.8600 |
Epoch 00187 | Loss(train) 0.4857 | Acc(train) 0.8357 | Acc(val) 0.8605 |
Epoch 00188 | Loss(train) 0.4818 | Acc(train) 0.8476 | Acc(val) 0.8605 |
Epoch 00189 | Loss(train) 0.4849 | Acc(train) 0.8382 | Acc(val) 0.8600 |
Epoch 00190 | Loss(train) 0.4743 | Acc(train) 0.8461 | Acc(val) 0.8580 |
Epoch 00191 | Loss(train) 0.4724 | Acc(train) 0.8443 | Acc(val) 0.8590 |
Epoch 00192 | Loss(train) 0.4732 | Acc(train) 0.8448 | Acc(val) 0.8585 |
Epoch 00193 | Loss(train) 0.4775 | Acc(train) 0.8407 | Acc(val) 0.8585 |
Epoch 00194 | Loss(train) 0.4744 | Acc(train) 0.8438 | Acc(val) 0.8585 |
Epoch 00195 | Loss(train) 0.4741 | Acc(train) 0.8486 | Acc(val) 0.8616 |
Epoch 00196 | Loss(train) 0.4717 | Acc(train) 0.8463 | Acc(val) 0.8605 |
Epoch 00197 | Loss(train) 0.4845 | Acc(train) 0.8397 | Acc(val) 0.8631 |*
Epoch 00198 | Loss(train) 0.4709 | Acc(train) 0.8463 | Acc(val) 0.8621 |
Epoch 00199 | Loss(train) 0.4667 | Acc(train) 0.8481 | Acc(val) 0.8605 |
Epoch 00200 | Loss(train) 0.4756 | Acc(train) 0.8463 | Acc(val) 0.8590 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0983 | Acc(train) 0.3675 | Acc(val) 0.4158 |*
Epoch 00002 | Loss(train) 1.0883 | Acc(train) 0.4370 | Acc(val) 0.4133 |
Epoch 00003 | Loss(train) 1.0792 | Acc(train) 0.4278 | Acc(val) 0.4133 |
Epoch 00004 | Loss(train) 1.0689 | Acc(train) 0.4286 | Acc(val) 0.4133 |
Epoch 00005 | Loss(train) 1.0594 | Acc(train) 0.4195 | Acc(val) 0.4133 |
Epoch 00006 | Loss(train) 1.0505 | Acc(train) 0.4233 | Acc(val) 0.4133 |
Epoch 00007 | Loss(train) 1.0406 | Acc(train) 0.4256 | Acc(val) 0.4133 |
Epoch 00008 | Loss(train) 1.0348 | Acc(train) 0.4273 | Acc(val) 0.4133 |
Epoch 00009 | Loss(train) 1.0252 | Acc(train) 0.4410 | Acc(val) 0.4138 |
Epoch 00010 | Loss(train) 1.0180 | Acc(train) 0.4479 | Acc(val) 0.4270 |*
Epoch 00011 | Loss(train) 1.0091 | Acc(train) 0.4743 | Acc(val) 0.4716 |*
Epoch 00012 | Loss(train) 1.0028 | Acc(train) 0.4798 | Acc(val) 0.5218 |*
Epoch 00013 | Loss(train) 0.9945 | Acc(train) 0.5075 | Acc(val) 0.5664 |*
Epoch 00014 | Loss(train) 0.9880 | Acc(train) 0.5204 | Acc(val) 0.6131 |*
Epoch 00015 | Loss(train) 0.9780 | Acc(train) 0.5531 | Acc(val) 0.6430 |*
Epoch 00016 | Loss(train) 0.9715 | Acc(train) 0.5590 | Acc(val) 0.6572 |*
Epoch 00017 | Loss(train) 0.9623 | Acc(train) 0.5676 | Acc(val) 0.6663 |*
Epoch 00018 | Loss(train) 0.9541 | Acc(train) 0.5795 | Acc(val) 0.6709 |*
Epoch 00019 | Loss(train) 0.9471 | Acc(train) 0.5803 | Acc(val) 0.6714 |*
Epoch 00020 | Loss(train) 0.9398 | Acc(train) 0.5884 | Acc(val) 0.6744 |*
Epoch 00021 | Loss(train) 0.9286 | Acc(train) 0.6110 | Acc(val) 0.6815 |*
Epoch 00022 | Loss(train) 0.9214 | Acc(train) 0.6160 | Acc(val) 0.6891 |*
Epoch 00023 | Loss(train) 0.9111 | Acc(train) 0.6447 | Acc(val) 0.6998 |*
Epoch 00024 | Loss(train) 0.9000 | Acc(train) 0.6518 | Acc(val) 0.7074 |*
Epoch 00025 | Loss(train) 0.8952 | Acc(train) 0.6619 | Acc(val) 0.7226 |*
Epoch 00026 | Loss(train) 0.8901 | Acc(train) 0.6584 | Acc(val) 0.7297 |*
Epoch 00027 | Loss(train) 0.8826 | Acc(train) 0.6812 | Acc(val) 0.7444 |*
Epoch 00028 | Loss(train) 0.8745 | Acc(train) 0.6726 | Acc(val) 0.7535 |*
Epoch 00029 | Loss(train) 0.8624 | Acc(train) 0.7023 | Acc(val) 0.7647 |*
Epoch 00030 | Loss(train) 0.8527 | Acc(train) 0.7017 | Acc(val) 0.7718 |*
Epoch 00031 | Loss(train) 0.8463 | Acc(train) 0.7170 | Acc(val) 0.7789 |*
Epoch 00032 | Loss(train) 0.8425 | Acc(train) 0.7030 | Acc(val) 0.7825 |*
Epoch 00033 | Loss(train) 0.8325 | Acc(train) 0.7149 | Acc(val) 0.7885 |*
Epoch 00034 | Loss(train) 0.8260 | Acc(train) 0.7162 | Acc(val) 0.7941 |*
Epoch 00035 | Loss(train) 0.8138 | Acc(train) 0.7327 | Acc(val) 0.7956 |*
Epoch 00036 | Loss(train) 0.8124 | Acc(train) 0.7225 | Acc(val) 0.7977 |*
Epoch 00037 | Loss(train) 0.8017 | Acc(train) 0.7340 | Acc(val) 0.7997 |*
Epoch 00038 | Loss(train) 0.7941 | Acc(train) 0.7388 | Acc(val) 0.8022 |*
Epoch 00039 | Loss(train) 0.7901 | Acc(train) 0.7352 | Acc(val) 0.8068 |*
Epoch 00040 | Loss(train) 0.7787 | Acc(train) 0.7395 | Acc(val) 0.8109 |*
Epoch 00041 | Loss(train) 0.7777 | Acc(train) 0.7337 | Acc(val) 0.8124 |*
Epoch 00042 | Loss(train) 0.7669 | Acc(train) 0.7560 | Acc(val) 0.8119 |
Epoch 00043 | Loss(train) 0.7612 | Acc(train) 0.7575 | Acc(val) 0.8139 |*
Epoch 00044 | Loss(train) 0.7502 | Acc(train) 0.7657 | Acc(val) 0.8154 |*
Epoch 00045 | Loss(train) 0.7438 | Acc(train) 0.7626 | Acc(val) 0.8144 |
Epoch 00046 | Loss(train) 0.7365 | Acc(train) 0.7702 | Acc(val) 0.8159 |*
Epoch 00047 | Loss(train) 0.7339 | Acc(train) 0.7570 | Acc(val) 0.8174 |*
Epoch 00048 | Loss(train) 0.7253 | Acc(train) 0.7687 | Acc(val) 0.8200 |*
Epoch 00049 | Loss(train) 0.7237 | Acc(train) 0.7639 | Acc(val) 0.8200 |
Epoch 00050 | Loss(train) 0.7185 | Acc(train) 0.7677 | Acc(val) 0.8195 |
Epoch 00051 | Loss(train) 0.7129 | Acc(train) 0.7750 | Acc(val) 0.8215 |*
Epoch 00052 | Loss(train) 0.7036 | Acc(train) 0.7725 | Acc(val) 0.8210 |
Epoch 00053 | Loss(train) 0.7000 | Acc(train) 0.7768 | Acc(val) 0.8205 |
Epoch 00054 | Loss(train) 0.6914 | Acc(train) 0.7763 | Acc(val) 0.8240 |*
Epoch 00055 | Loss(train) 0.6912 | Acc(train) 0.7707 | Acc(val) 0.8245 |*
Epoch 00056 | Loss(train) 0.6862 | Acc(train) 0.7794 | Acc(val) 0.8245 |
Epoch 00057 | Loss(train) 0.6849 | Acc(train) 0.7804 | Acc(val) 0.8266 |*
Epoch 00058 | Loss(train) 0.6793 | Acc(train) 0.7783 | Acc(val) 0.8276 |*
Epoch 00059 | Loss(train) 0.6733 | Acc(train) 0.7743 | Acc(val) 0.8291 |*
Epoch 00060 | Loss(train) 0.6706 | Acc(train) 0.7842 | Acc(val) 0.8306 |*
Epoch 00061 | Loss(train) 0.6652 | Acc(train) 0.7936 | Acc(val) 0.8327 |*
Epoch 00062 | Loss(train) 0.6642 | Acc(train) 0.7872 | Acc(val) 0.8337 |*
Epoch 00063 | Loss(train) 0.6553 | Acc(train) 0.7890 | Acc(val) 0.8332 |
Epoch 00064 | Loss(train) 0.6526 | Acc(train) 0.7882 | Acc(val) 0.8322 |
Epoch 00065 | Loss(train) 0.6582 | Acc(train) 0.7811 | Acc(val) 0.8327 |
Epoch 00066 | Loss(train) 0.6466 | Acc(train) 0.7898 | Acc(val) 0.8352 |*
Epoch 00067 | Loss(train) 0.6482 | Acc(train) 0.7885 | Acc(val) 0.8367 |*
Epoch 00068 | Loss(train) 0.6368 | Acc(train) 0.7920 | Acc(val) 0.8357 |
Epoch 00069 | Loss(train) 0.6403 | Acc(train) 0.7933 | Acc(val) 0.8337 |
Epoch 00070 | Loss(train) 0.6287 | Acc(train) 0.8024 | Acc(val) 0.8347 |
Epoch 00071 | Loss(train) 0.6317 | Acc(train) 0.7969 | Acc(val) 0.8362 |
Epoch 00072 | Loss(train) 0.6266 | Acc(train) 0.7951 | Acc(val) 0.8357 |
Epoch 00073 | Loss(train) 0.6210 | Acc(train) 0.8098 | Acc(val) 0.8357 |
Epoch 00074 | Loss(train) 0.6236 | Acc(train) 0.7986 | Acc(val) 0.8352 |
Epoch 00075 | Loss(train) 0.6182 | Acc(train) 0.7994 | Acc(val) 0.8357 |
Epoch 00076 | Loss(train) 0.6128 | Acc(train) 0.8055 | Acc(val) 0.8372 |*
Epoch 00077 | Loss(train) 0.6114 | Acc(train) 0.8156 | Acc(val) 0.8382 |*
Epoch 00078 | Loss(train) 0.6115 | Acc(train) 0.8024 | Acc(val) 0.8382 |
Epoch 00079 | Loss(train) 0.6063 | Acc(train) 0.8100 | Acc(val) 0.8377 |
Epoch 00080 | Loss(train) 0.6030 | Acc(train) 0.8073 | Acc(val) 0.8362 |
Epoch 00081 | Loss(train) 0.6022 | Acc(train) 0.8047 | Acc(val) 0.8367 |
Epoch 00082 | Loss(train) 0.5981 | Acc(train) 0.8073 | Acc(val) 0.8367 |
Epoch 00083 | Loss(train) 0.5967 | Acc(train) 0.8123 | Acc(val) 0.8377 |
Epoch 00084 | Loss(train) 0.5928 | Acc(train) 0.8144 | Acc(val) 0.8382 |
Epoch 00085 | Loss(train) 0.5833 | Acc(train) 0.8123 | Acc(val) 0.8387 |*
Epoch 00086 | Loss(train) 0.5900 | Acc(train) 0.8123 | Acc(val) 0.8398 |*
Epoch 00087 | Loss(train) 0.5849 | Acc(train) 0.8187 | Acc(val) 0.8398 |
Epoch 00088 | Loss(train) 0.5827 | Acc(train) 0.8121 | Acc(val) 0.8392 |
Epoch 00089 | Loss(train) 0.5838 | Acc(train) 0.8202 | Acc(val) 0.8403 |*
Epoch 00090 | Loss(train) 0.5783 | Acc(train) 0.8204 | Acc(val) 0.8413 |*
Epoch 00091 | Loss(train) 0.5798 | Acc(train) 0.8123 | Acc(val) 0.8418 |*
Epoch 00092 | Loss(train) 0.5705 | Acc(train) 0.8174 | Acc(val) 0.8428 |*
Epoch 00093 | Loss(train) 0.5752 | Acc(train) 0.8212 | Acc(val) 0.8433 |*
Epoch 00094 | Loss(train) 0.5784 | Acc(train) 0.8067 | Acc(val) 0.8423 |
Epoch 00095 | Loss(train) 0.5788 | Acc(train) 0.8093 | Acc(val) 0.8423 |
Epoch 00096 | Loss(train) 0.5715 | Acc(train) 0.8184 | Acc(val) 0.8438 |*
Epoch 00097 | Loss(train) 0.5656 | Acc(train) 0.8121 | Acc(val) 0.8458 |*
Epoch 00098 | Loss(train) 0.5652 | Acc(train) 0.8235 | Acc(val) 0.8458 |
Epoch 00099 | Loss(train) 0.5637 | Acc(train) 0.8138 | Acc(val) 0.8463 |*
Epoch 00100 | Loss(train) 0.5606 | Acc(train) 0.8253 | Acc(val) 0.8474 |*
Epoch 00101 | Loss(train) 0.5639 | Acc(train) 0.8197 | Acc(val) 0.8469 |
Epoch 00102 | Loss(train) 0.5534 | Acc(train) 0.8215 | Acc(val) 0.8463 |
Epoch 00103 | Loss(train) 0.5589 | Acc(train) 0.8171 | Acc(val) 0.8474 |
Epoch 00104 | Loss(train) 0.5514 | Acc(train) 0.8263 | Acc(val) 0.8484 |*
Epoch 00105 | Loss(train) 0.5532 | Acc(train) 0.8192 | Acc(val) 0.8484 |
Epoch 00106 | Loss(train) 0.5497 | Acc(train) 0.8253 | Acc(val) 0.8484 |
Epoch 00107 | Loss(train) 0.5500 | Acc(train) 0.8273 | Acc(val) 0.8494 |*
Epoch 00108 | Loss(train) 0.5502 | Acc(train) 0.8245 | Acc(val) 0.8494 |
Epoch 00109 | Loss(train) 0.5419 | Acc(train) 0.8278 | Acc(val) 0.8484 |
Epoch 00110 | Loss(train) 0.5428 | Acc(train) 0.8235 | Acc(val) 0.8469 |
Epoch 00111 | Loss(train) 0.5394 | Acc(train) 0.8263 | Acc(val) 0.8484 |
Epoch 00112 | Loss(train) 0.5461 | Acc(train) 0.8280 | Acc(val) 0.8489 |
Epoch 00113 | Loss(train) 0.5507 | Acc(train) 0.8217 | Acc(val) 0.8479 |
Epoch 00114 | Loss(train) 0.5411 | Acc(train) 0.8275 | Acc(val) 0.8479 |
Epoch 00115 | Loss(train) 0.5403 | Acc(train) 0.8306 | Acc(val) 0.8479 |
Epoch 00116 | Loss(train) 0.5413 | Acc(train) 0.8250 | Acc(val) 0.8489 |
Epoch 00117 | Loss(train) 0.5327 | Acc(train) 0.8296 | Acc(val) 0.8499 |*
Epoch 00118 | Loss(train) 0.5314 | Acc(train) 0.8278 | Acc(val) 0.8499 |
Epoch 00119 | Loss(train) 0.5306 | Acc(train) 0.8296 | Acc(val) 0.8494 |
Epoch 00120 | Loss(train) 0.5324 | Acc(train) 0.8255 | Acc(val) 0.8494 |
Epoch 00121 | Loss(train) 0.5259 | Acc(train) 0.8326 | Acc(val) 0.8484 |
Epoch 00122 | Loss(train) 0.5322 | Acc(train) 0.8306 | Acc(val) 0.8489 |
Epoch 00123 | Loss(train) 0.5311 | Acc(train) 0.8248 | Acc(val) 0.8484 |
Epoch 00124 | Loss(train) 0.5237 | Acc(train) 0.8291 | Acc(val) 0.8499 |
Epoch 00125 | Loss(train) 0.5289 | Acc(train) 0.8293 | Acc(val) 0.8504 |*
Epoch 00126 | Loss(train) 0.5272 | Acc(train) 0.8298 | Acc(val) 0.8504 |
Epoch 00127 | Loss(train) 0.5204 | Acc(train) 0.8346 | Acc(val) 0.8494 |
Epoch 00128 | Loss(train) 0.5177 | Acc(train) 0.8291 | Acc(val) 0.8504 |
Epoch 00129 | Loss(train) 0.5199 | Acc(train) 0.8293 | Acc(val) 0.8489 |
Epoch 00130 | Loss(train) 0.5149 | Acc(train) 0.8341 | Acc(val) 0.8499 |
Epoch 00131 | Loss(train) 0.5194 | Acc(train) 0.8306 | Acc(val) 0.8519 |*
Epoch 00132 | Loss(train) 0.5244 | Acc(train) 0.8313 | Acc(val) 0.8519 |
Epoch 00133 | Loss(train) 0.5184 | Acc(train) 0.8364 | Acc(val) 0.8514 |
Epoch 00134 | Loss(train) 0.5097 | Acc(train) 0.8339 | Acc(val) 0.8519 |
Epoch 00135 | Loss(train) 0.5194 | Acc(train) 0.8324 | Acc(val) 0.8519 |
Epoch 00136 | Loss(train) 0.5178 | Acc(train) 0.8334 | Acc(val) 0.8550 |*
Epoch 00137 | Loss(train) 0.5169 | Acc(train) 0.8301 | Acc(val) 0.8529 |
Epoch 00138 | Loss(train) 0.5066 | Acc(train) 0.8392 | Acc(val) 0.8534 |
Epoch 00139 | Loss(train) 0.5132 | Acc(train) 0.8319 | Acc(val) 0.8529 |
Epoch 00140 | Loss(train) 0.5134 | Acc(train) 0.8301 | Acc(val) 0.8529 |
Epoch 00141 | Loss(train) 0.5078 | Acc(train) 0.8379 | Acc(val) 0.8519 |
Epoch 00142 | Loss(train) 0.5113 | Acc(train) 0.8288 | Acc(val) 0.8519 |
Epoch 00143 | Loss(train) 0.5074 | Acc(train) 0.8326 | Acc(val) 0.8540 |
Epoch 00144 | Loss(train) 0.5039 | Acc(train) 0.8392 | Acc(val) 0.8550 |
Epoch 00145 | Loss(train) 0.5128 | Acc(train) 0.8367 | Acc(val) 0.8545 |
Epoch 00146 | Loss(train) 0.5126 | Acc(train) 0.8316 | Acc(val) 0.8545 |
Epoch 00147 | Loss(train) 0.5076 | Acc(train) 0.8357 | Acc(val) 0.8545 |
Epoch 00148 | Loss(train) 0.5046 | Acc(train) 0.8397 | Acc(val) 0.8540 |
Epoch 00149 | Loss(train) 0.4992 | Acc(train) 0.8346 | Acc(val) 0.8570 |*
Epoch 00150 | Loss(train) 0.4986 | Acc(train) 0.8400 | Acc(val) 0.8565 |
Epoch 00151 | Loss(train) 0.4950 | Acc(train) 0.8417 | Acc(val) 0.8534 |
Epoch 00152 | Loss(train) 0.5000 | Acc(train) 0.8336 | Acc(val) 0.8534 |
Epoch 00153 | Loss(train) 0.5090 | Acc(train) 0.8303 | Acc(val) 0.8550 |
Epoch 00154 | Loss(train) 0.4937 | Acc(train) 0.8415 | Acc(val) 0.8509 |
Epoch 00155 | Loss(train) 0.5028 | Acc(train) 0.8336 | Acc(val) 0.8524 |
Epoch 00156 | Loss(train) 0.5046 | Acc(train) 0.8402 | Acc(val) 0.8540 |
Epoch 00157 | Loss(train) 0.4963 | Acc(train) 0.8405 | Acc(val) 0.8519 |
Epoch 00158 | Loss(train) 0.5026 | Acc(train) 0.8321 | Acc(val) 0.8524 |
Epoch 00159 | Loss(train) 0.5013 | Acc(train) 0.8321 | Acc(val) 0.8529 |
Epoch 00160 | Loss(train) 0.4964 | Acc(train) 0.8374 | Acc(val) 0.8514 |
Epoch 00161 | Loss(train) 0.4900 | Acc(train) 0.8430 | Acc(val) 0.8540 |
Epoch 00162 | Loss(train) 0.4935 | Acc(train) 0.8450 | Acc(val) 0.8545 |
Epoch 00163 | Loss(train) 0.4886 | Acc(train) 0.8466 | Acc(val) 0.8529 |
Epoch 00164 | Loss(train) 0.4857 | Acc(train) 0.8450 | Acc(val) 0.8540 |
Epoch 00165 | Loss(train) 0.4972 | Acc(train) 0.8364 | Acc(val) 0.8519 |
Epoch 00166 | Loss(train) 0.4940 | Acc(train) 0.8430 | Acc(val) 0.8519 |
Epoch 00167 | Loss(train) 0.4888 | Acc(train) 0.8352 | Acc(val) 0.8524 |
Epoch 00168 | Loss(train) 0.4924 | Acc(train) 0.8367 | Acc(val) 0.8529 |
Epoch 00169 | Loss(train) 0.4907 | Acc(train) 0.8379 | Acc(val) 0.8504 |
Epoch 00170 | Loss(train) 0.4904 | Acc(train) 0.8415 | Acc(val) 0.8524 |
Epoch 00171 | Loss(train) 0.4888 | Acc(train) 0.8397 | Acc(val) 0.8519 |
Epoch 00172 | Loss(train) 0.4837 | Acc(train) 0.8428 | Acc(val) 0.8514 |
Epoch 00173 | Loss(train) 0.4886 | Acc(train) 0.8415 | Acc(val) 0.8545 |
Epoch 00174 | Loss(train) 0.4857 | Acc(train) 0.8379 | Acc(val) 0.8545 |
Epoch 00175 | Loss(train) 0.4906 | Acc(train) 0.8379 | Acc(val) 0.8534 |
Epoch 00176 | Loss(train) 0.4846 | Acc(train) 0.8400 | Acc(val) 0.8504 |
Epoch 00177 | Loss(train) 0.4817 | Acc(train) 0.8379 | Acc(val) 0.8504 |
Epoch 00178 | Loss(train) 0.4858 | Acc(train) 0.8412 | Acc(val) 0.8514 |
Epoch 00179 | Loss(train) 0.4852 | Acc(train) 0.8397 | Acc(val) 0.8550 |
Epoch 00180 | Loss(train) 0.4812 | Acc(train) 0.8438 | Acc(val) 0.8565 |
Epoch 00181 | Loss(train) 0.4812 | Acc(train) 0.8410 | Acc(val) 0.8560 |
Epoch 00182 | Loss(train) 0.4810 | Acc(train) 0.8473 | Acc(val) 0.8534 |
Epoch 00183 | Loss(train) 0.4808 | Acc(train) 0.8461 | Acc(val) 0.8514 |
Epoch 00184 | Loss(train) 0.4837 | Acc(train) 0.8402 | Acc(val) 0.8534 |
Epoch 00185 | Loss(train) 0.4748 | Acc(train) 0.8478 | Acc(val) 0.8545 |
Epoch 00186 | Loss(train) 0.4814 | Acc(train) 0.8453 | Acc(val) 0.8565 |
Epoch 00187 | Loss(train) 0.4775 | Acc(train) 0.8476 | Acc(val) 0.8550 |
Epoch 00188 | Loss(train) 0.4771 | Acc(train) 0.8443 | Acc(val) 0.8524 |
Epoch 00189 | Loss(train) 0.4718 | Acc(train) 0.8397 | Acc(val) 0.8524 |
Epoch 00190 | Loss(train) 0.4749 | Acc(train) 0.8450 | Acc(val) 0.8555 |
Epoch 00191 | Loss(train) 0.4782 | Acc(train) 0.8430 | Acc(val) 0.8565 |
Epoch 00192 | Loss(train) 0.4794 | Acc(train) 0.8397 | Acc(val) 0.8555 |
Epoch 00193 | Loss(train) 0.4734 | Acc(train) 0.8468 | Acc(val) 0.8550 |
Epoch 00194 | Loss(train) 0.4746 | Acc(train) 0.8445 | Acc(val) 0.8534 |
Epoch 00195 | Loss(train) 0.4875 | Acc(train) 0.8461 | Acc(val) 0.8540 |
Epoch 00196 | Loss(train) 0.4712 | Acc(train) 0.8423 | Acc(val) 0.8555 |
Epoch 00197 | Loss(train) 0.4784 | Acc(train) 0.8438 | Acc(val) 0.8555 |
Epoch 00198 | Loss(train) 0.4782 | Acc(train) 0.8450 | Acc(val) 0.8555 |
Epoch 00199 | Loss(train) 0.4785 | Acc(train) 0.8390 | Acc(val) 0.8555 |
Epoch 00200 | Loss(train) 0.4781 | Acc(train) 0.8440 | Acc(val) 0.8524 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0984 | Acc(train) 0.3561 | Acc(val) 0.4752 |*
Epoch 00002 | Loss(train) 1.0902 | Acc(train) 0.4611 | Acc(val) 0.4234 |
Epoch 00003 | Loss(train) 1.0821 | Acc(train) 0.4514 | Acc(val) 0.4249 |
Epoch 00004 | Loss(train) 1.0737 | Acc(train) 0.4598 | Acc(val) 0.4326 |
Epoch 00005 | Loss(train) 1.0652 | Acc(train) 0.4674 | Acc(val) 0.4544 |
Epoch 00006 | Loss(train) 1.0571 | Acc(train) 0.4773 | Acc(val) 0.4757 |*
Epoch 00007 | Loss(train) 1.0503 | Acc(train) 0.4844 | Acc(val) 0.4985 |*
Epoch 00008 | Loss(train) 1.0411 | Acc(train) 0.5009 | Acc(val) 0.5162 |*
Epoch 00009 | Loss(train) 1.0343 | Acc(train) 0.5052 | Acc(val) 0.5365 |*
Epoch 00010 | Loss(train) 1.0292 | Acc(train) 0.5009 | Acc(val) 0.5624 |*
Epoch 00011 | Loss(train) 1.0207 | Acc(train) 0.5262 | Acc(val) 0.6004 |*
Epoch 00012 | Loss(train) 1.0139 | Acc(train) 0.5265 | Acc(val) 0.6298 |*
Epoch 00013 | Loss(train) 1.0052 | Acc(train) 0.5483 | Acc(val) 0.6608 |*
Epoch 00014 | Loss(train) 1.0015 | Acc(train) 0.5491 | Acc(val) 0.6689 |*
Epoch 00015 | Loss(train) 0.9945 | Acc(train) 0.5666 | Acc(val) 0.6724 |*
Epoch 00016 | Loss(train) 0.9868 | Acc(train) 0.5851 | Acc(val) 0.6760 |*
Epoch 00017 | Loss(train) 0.9792 | Acc(train) 0.5831 | Acc(val) 0.6755 |
Epoch 00018 | Loss(train) 0.9739 | Acc(train) 0.5820 | Acc(val) 0.6719 |
Epoch 00019 | Loss(train) 0.9642 | Acc(train) 0.6089 | Acc(val) 0.6704 |
Epoch 00020 | Loss(train) 0.9562 | Acc(train) 0.6013 | Acc(val) 0.6729 |
Epoch 00021 | Loss(train) 0.9478 | Acc(train) 0.6044 | Acc(val) 0.6749 |
Epoch 00022 | Loss(train) 0.9436 | Acc(train) 0.6018 | Acc(val) 0.6780 |*
Epoch 00023 | Loss(train) 0.9348 | Acc(train) 0.6056 | Acc(val) 0.6805 |*
Epoch 00024 | Loss(train) 0.9280 | Acc(train) 0.6099 | Acc(val) 0.6826 |*
Epoch 00025 | Loss(train) 0.9198 | Acc(train) 0.6186 | Acc(val) 0.6891 |*
Epoch 00026 | Loss(train) 0.9134 | Acc(train) 0.6272 | Acc(val) 0.6973 |*
Epoch 00027 | Loss(train) 0.9038 | Acc(train) 0.6401 | Acc(val) 0.7074 |*
Epoch 00028 | Loss(train) 0.8986 | Acc(train) 0.6368 | Acc(val) 0.7104 |*
Epoch 00029 | Loss(train) 0.8869 | Acc(train) 0.6586 | Acc(val) 0.7191 |*
Epoch 00030 | Loss(train) 0.8806 | Acc(train) 0.6515 | Acc(val) 0.7241 |*
Epoch 00031 | Loss(train) 0.8721 | Acc(train) 0.6599 | Acc(val) 0.7272 |*
Epoch 00032 | Loss(train) 0.8600 | Acc(train) 0.6749 | Acc(val) 0.7348 |*
Epoch 00033 | Loss(train) 0.8558 | Acc(train) 0.6797 | Acc(val) 0.7388 |*
Epoch 00034 | Loss(train) 0.8492 | Acc(train) 0.6825 | Acc(val) 0.7459 |*
Epoch 00035 | Loss(train) 0.8384 | Acc(train) 0.6853 | Acc(val) 0.7525 |*
Epoch 00036 | Loss(train) 0.8321 | Acc(train) 0.6916 | Acc(val) 0.7606 |*
Epoch 00037 | Loss(train) 0.8274 | Acc(train) 0.7020 | Acc(val) 0.7688 |*
Epoch 00038 | Loss(train) 0.8207 | Acc(train) 0.7007 | Acc(val) 0.7789 |*
Epoch 00039 | Loss(train) 0.8096 | Acc(train) 0.7083 | Acc(val) 0.7840 |*
Epoch 00040 | Loss(train) 0.8012 | Acc(train) 0.7137 | Acc(val) 0.7911 |*
Epoch 00041 | Loss(train) 0.7946 | Acc(train) 0.7170 | Acc(val) 0.7961 |*
Epoch 00042 | Loss(train) 0.7887 | Acc(train) 0.7233 | Acc(val) 0.7987 |*
Epoch 00043 | Loss(train) 0.7824 | Acc(train) 0.7223 | Acc(val) 0.8017 |*
Epoch 00044 | Loss(train) 0.7772 | Acc(train) 0.7314 | Acc(val) 0.8053 |*
Epoch 00045 | Loss(train) 0.7654 | Acc(train) 0.7342 | Acc(val) 0.8098 |*
Epoch 00046 | Loss(train) 0.7672 | Acc(train) 0.7370 | Acc(val) 0.8124 |*
Epoch 00047 | Loss(train) 0.7551 | Acc(train) 0.7510 | Acc(val) 0.8144 |*
Epoch 00048 | Loss(train) 0.7541 | Acc(train) 0.7367 | Acc(val) 0.8149 |*
Epoch 00049 | Loss(train) 0.7428 | Acc(train) 0.7406 | Acc(val) 0.8154 |*
Epoch 00050 | Loss(train) 0.7335 | Acc(train) 0.7449 | Acc(val) 0.8164 |*
Epoch 00051 | Loss(train) 0.7226 | Acc(train) 0.7545 | Acc(val) 0.8190 |*
Epoch 00052 | Loss(train) 0.7285 | Acc(train) 0.7517 | Acc(val) 0.8190 |
Epoch 00053 | Loss(train) 0.7164 | Acc(train) 0.7626 | Acc(val) 0.8210 |*
Epoch 00054 | Loss(train) 0.7184 | Acc(train) 0.7553 | Acc(val) 0.8235 |*
Epoch 00055 | Loss(train) 0.7096 | Acc(train) 0.7593 | Acc(val) 0.8256 |*
Epoch 00056 | Loss(train) 0.6938 | Acc(train) 0.7700 | Acc(val) 0.8261 |*
Epoch 00057 | Loss(train) 0.6897 | Acc(train) 0.7697 | Acc(val) 0.8276 |*
Epoch 00058 | Loss(train) 0.6927 | Acc(train) 0.7723 | Acc(val) 0.8286 |*
Epoch 00059 | Loss(train) 0.6848 | Acc(train) 0.7778 | Acc(val) 0.8296 |*
Epoch 00060 | Loss(train) 0.6846 | Acc(train) 0.7682 | Acc(val) 0.8306 |*
Epoch 00061 | Loss(train) 0.6790 | Acc(train) 0.7791 | Acc(val) 0.8281 |
Epoch 00062 | Loss(train) 0.6695 | Acc(train) 0.7827 | Acc(val) 0.8286 |
Epoch 00063 | Loss(train) 0.6759 | Acc(train) 0.7679 | Acc(val) 0.8291 |
Epoch 00064 | Loss(train) 0.6644 | Acc(train) 0.7811 | Acc(val) 0.8311 |*
Epoch 00065 | Loss(train) 0.6594 | Acc(train) 0.7852 | Acc(val) 0.8327 |*
Epoch 00066 | Loss(train) 0.6578 | Acc(train) 0.7748 | Acc(val) 0.8352 |*
Epoch 00067 | Loss(train) 0.6542 | Acc(train) 0.7844 | Acc(val) 0.8362 |*
Epoch 00068 | Loss(train) 0.6487 | Acc(train) 0.7936 | Acc(val) 0.8352 |
Epoch 00069 | Loss(train) 0.6450 | Acc(train) 0.7905 | Acc(val) 0.8372 |*
Epoch 00070 | Loss(train) 0.6449 | Acc(train) 0.7885 | Acc(val) 0.8362 |
Epoch 00071 | Loss(train) 0.6413 | Acc(train) 0.7915 | Acc(val) 0.8367 |
Epoch 00072 | Loss(train) 0.6378 | Acc(train) 0.8007 | Acc(val) 0.8377 |*
Epoch 00073 | Loss(train) 0.6374 | Acc(train) 0.7918 | Acc(val) 0.8382 |*
Epoch 00074 | Loss(train) 0.6251 | Acc(train) 0.7991 | Acc(val) 0.8377 |
Epoch 00075 | Loss(train) 0.6315 | Acc(train) 0.7974 | Acc(val) 0.8392 |*
Epoch 00076 | Loss(train) 0.6219 | Acc(train) 0.8007 | Acc(val) 0.8408 |*
Epoch 00077 | Loss(train) 0.6249 | Acc(train) 0.7963 | Acc(val) 0.8403 |
Epoch 00078 | Loss(train) 0.6160 | Acc(train) 0.8034 | Acc(val) 0.8403 |
Epoch 00079 | Loss(train) 0.6170 | Acc(train) 0.8027 | Acc(val) 0.8423 |*
Epoch 00080 | Loss(train) 0.6050 | Acc(train) 0.8060 | Acc(val) 0.8418 |
Epoch 00081 | Loss(train) 0.6085 | Acc(train) 0.8113 | Acc(val) 0.8418 |
Epoch 00082 | Loss(train) 0.6050 | Acc(train) 0.8075 | Acc(val) 0.8418 |
Epoch 00083 | Loss(train) 0.6022 | Acc(train) 0.8103 | Acc(val) 0.8423 |
Epoch 00084 | Loss(train) 0.6026 | Acc(train) 0.8083 | Acc(val) 0.8433 |*
Epoch 00085 | Loss(train) 0.5974 | Acc(train) 0.8106 | Acc(val) 0.8433 |
Epoch 00086 | Loss(train) 0.5958 | Acc(train) 0.8123 | Acc(val) 0.8448 |*
Epoch 00087 | Loss(train) 0.5919 | Acc(train) 0.8174 | Acc(val) 0.8443 |
Epoch 00088 | Loss(train) 0.5902 | Acc(train) 0.8138 | Acc(val) 0.8433 |
Epoch 00089 | Loss(train) 0.5838 | Acc(train) 0.8189 | Acc(val) 0.8443 |
Epoch 00090 | Loss(train) 0.5886 | Acc(train) 0.8052 | Acc(val) 0.8458 |*
Epoch 00091 | Loss(train) 0.5835 | Acc(train) 0.8161 | Acc(val) 0.8479 |*
Epoch 00092 | Loss(train) 0.5835 | Acc(train) 0.8100 | Acc(val) 0.8469 |
Epoch 00093 | Loss(train) 0.5780 | Acc(train) 0.8070 | Acc(val) 0.8474 |
Epoch 00094 | Loss(train) 0.5706 | Acc(train) 0.8187 | Acc(val) 0.8474 |
Epoch 00095 | Loss(train) 0.5706 | Acc(train) 0.8199 | Acc(val) 0.8479 |
Epoch 00096 | Loss(train) 0.5778 | Acc(train) 0.8146 | Acc(val) 0.8479 |
Epoch 00097 | Loss(train) 0.5762 | Acc(train) 0.8144 | Acc(val) 0.8484 |*
Epoch 00098 | Loss(train) 0.5697 | Acc(train) 0.8202 | Acc(val) 0.8494 |*
Epoch 00099 | Loss(train) 0.5693 | Acc(train) 0.8215 | Acc(val) 0.8504 |*
Epoch 00100 | Loss(train) 0.5644 | Acc(train) 0.8235 | Acc(val) 0.8489 |
Epoch 00101 | Loss(train) 0.5631 | Acc(train) 0.8212 | Acc(val) 0.8494 |
Epoch 00102 | Loss(train) 0.5637 | Acc(train) 0.8232 | Acc(val) 0.8479 |
Epoch 00103 | Loss(train) 0.5635 | Acc(train) 0.8215 | Acc(val) 0.8479 |
Epoch 00104 | Loss(train) 0.5569 | Acc(train) 0.8215 | Acc(val) 0.8509 |*
Epoch 00105 | Loss(train) 0.5537 | Acc(train) 0.8278 | Acc(val) 0.8524 |*
Epoch 00106 | Loss(train) 0.5592 | Acc(train) 0.8179 | Acc(val) 0.8540 |*
Epoch 00107 | Loss(train) 0.5565 | Acc(train) 0.8220 | Acc(val) 0.8524 |
Epoch 00108 | Loss(train) 0.5486 | Acc(train) 0.8253 | Acc(val) 0.8479 |
Epoch 00109 | Loss(train) 0.5540 | Acc(train) 0.8255 | Acc(val) 0.8499 |
Epoch 00110 | Loss(train) 0.5500 | Acc(train) 0.8253 | Acc(val) 0.8540 |
Epoch 00111 | Loss(train) 0.5492 | Acc(train) 0.8313 | Acc(val) 0.8534 |
Epoch 00112 | Loss(train) 0.5459 | Acc(train) 0.8255 | Acc(val) 0.8550 |*
Epoch 00113 | Loss(train) 0.5435 | Acc(train) 0.8308 | Acc(val) 0.8545 |
Epoch 00114 | Loss(train) 0.5414 | Acc(train) 0.8270 | Acc(val) 0.8545 |
Epoch 00115 | Loss(train) 0.5485 | Acc(train) 0.8222 | Acc(val) 0.8524 |
Epoch 00116 | Loss(train) 0.5435 | Acc(train) 0.8319 | Acc(val) 0.8550 |
Epoch 00117 | Loss(train) 0.5340 | Acc(train) 0.8354 | Acc(val) 0.8565 |*
Epoch 00118 | Loss(train) 0.5407 | Acc(train) 0.8248 | Acc(val) 0.8560 |
Epoch 00119 | Loss(train) 0.5344 | Acc(train) 0.8301 | Acc(val) 0.8555 |
Epoch 00120 | Loss(train) 0.5375 | Acc(train) 0.8303 | Acc(val) 0.8550 |
Epoch 00121 | Loss(train) 0.5351 | Acc(train) 0.8235 | Acc(val) 0.8504 |
Epoch 00122 | Loss(train) 0.5362 | Acc(train) 0.8265 | Acc(val) 0.8514 |
Epoch 00123 | Loss(train) 0.5328 | Acc(train) 0.8222 | Acc(val) 0.8524 |
Epoch 00124 | Loss(train) 0.5369 | Acc(train) 0.8280 | Acc(val) 0.8550 |
Epoch 00125 | Loss(train) 0.5311 | Acc(train) 0.8326 | Acc(val) 0.8580 |*
Epoch 00126 | Loss(train) 0.5300 | Acc(train) 0.8336 | Acc(val) 0.8580 |
Epoch 00127 | Loss(train) 0.5291 | Acc(train) 0.8319 | Acc(val) 0.8529 |
Epoch 00128 | Loss(train) 0.5340 | Acc(train) 0.8255 | Acc(val) 0.8534 |
Epoch 00129 | Loss(train) 0.5249 | Acc(train) 0.8352 | Acc(val) 0.8534 |
Epoch 00130 | Loss(train) 0.5282 | Acc(train) 0.8336 | Acc(val) 0.8560 |
Epoch 00131 | Loss(train) 0.5208 | Acc(train) 0.8319 | Acc(val) 0.8555 |
Epoch 00132 | Loss(train) 0.5280 | Acc(train) 0.8321 | Acc(val) 0.8560 |
Epoch 00133 | Loss(train) 0.5284 | Acc(train) 0.8291 | Acc(val) 0.8580 |
Epoch 00134 | Loss(train) 0.5207 | Acc(train) 0.8329 | Acc(val) 0.8575 |
Epoch 00135 | Loss(train) 0.5178 | Acc(train) 0.8321 | Acc(val) 0.8595 |*
Epoch 00136 | Loss(train) 0.5183 | Acc(train) 0.8263 | Acc(val) 0.8580 |
Epoch 00137 | Loss(train) 0.5148 | Acc(train) 0.8430 | Acc(val) 0.8575 |
Epoch 00138 | Loss(train) 0.5138 | Acc(train) 0.8308 | Acc(val) 0.8570 |
Epoch 00139 | Loss(train) 0.5162 | Acc(train) 0.8286 | Acc(val) 0.8555 |
Epoch 00140 | Loss(train) 0.5176 | Acc(train) 0.8329 | Acc(val) 0.8565 |
Epoch 00141 | Loss(train) 0.5148 | Acc(train) 0.8326 | Acc(val) 0.8585 |
Epoch 00142 | Loss(train) 0.5109 | Acc(train) 0.8291 | Acc(val) 0.8585 |
Epoch 00143 | Loss(train) 0.5116 | Acc(train) 0.8296 | Acc(val) 0.8575 |
Epoch 00144 | Loss(train) 0.5169 | Acc(train) 0.8379 | Acc(val) 0.8575 |
Epoch 00145 | Loss(train) 0.5151 | Acc(train) 0.8407 | Acc(val) 0.8575 |
Epoch 00146 | Loss(train) 0.5053 | Acc(train) 0.8405 | Acc(val) 0.8565 |
Epoch 00147 | Loss(train) 0.5013 | Acc(train) 0.8367 | Acc(val) 0.8575 |
Epoch 00148 | Loss(train) 0.5107 | Acc(train) 0.8349 | Acc(val) 0.8585 |
Epoch 00149 | Loss(train) 0.5085 | Acc(train) 0.8326 | Acc(val) 0.8595 |
Epoch 00150 | Loss(train) 0.5095 | Acc(train) 0.8354 | Acc(val) 0.8600 |*
Epoch 00151 | Loss(train) 0.5176 | Acc(train) 0.8311 | Acc(val) 0.8595 |
Epoch 00152 | Loss(train) 0.5090 | Acc(train) 0.8316 | Acc(val) 0.8590 |
Epoch 00153 | Loss(train) 0.5014 | Acc(train) 0.8425 | Acc(val) 0.8595 |
Epoch 00154 | Loss(train) 0.5041 | Acc(train) 0.8397 | Acc(val) 0.8585 |
Epoch 00155 | Loss(train) 0.5014 | Acc(train) 0.8357 | Acc(val) 0.8595 |
Epoch 00156 | Loss(train) 0.4995 | Acc(train) 0.8430 | Acc(val) 0.8590 |
Epoch 00157 | Loss(train) 0.5045 | Acc(train) 0.8379 | Acc(val) 0.8580 |
Epoch 00158 | Loss(train) 0.5028 | Acc(train) 0.8392 | Acc(val) 0.8590 |
Epoch 00159 | Loss(train) 0.5049 | Acc(train) 0.8352 | Acc(val) 0.8605 |*
Epoch 00160 | Loss(train) 0.4937 | Acc(train) 0.8387 | Acc(val) 0.8600 |
Epoch 00161 | Loss(train) 0.5037 | Acc(train) 0.8374 | Acc(val) 0.8595 |
Epoch 00162 | Loss(train) 0.4993 | Acc(train) 0.8415 | Acc(val) 0.8575 |
Epoch 00163 | Loss(train) 0.4961 | Acc(train) 0.8405 | Acc(val) 0.8595 |
Epoch 00164 | Loss(train) 0.5021 | Acc(train) 0.8280 | Acc(val) 0.8585 |
Epoch 00165 | Loss(train) 0.5003 | Acc(train) 0.8319 | Acc(val) 0.8595 |
Epoch 00166 | Loss(train) 0.4886 | Acc(train) 0.8486 | Acc(val) 0.8595 |
Epoch 00167 | Loss(train) 0.4916 | Acc(train) 0.8486 | Acc(val) 0.8595 |
Epoch 00168 | Loss(train) 0.4939 | Acc(train) 0.8443 | Acc(val) 0.8590 |
Epoch 00169 | Loss(train) 0.4909 | Acc(train) 0.8435 | Acc(val) 0.8585 |
Epoch 00170 | Loss(train) 0.4917 | Acc(train) 0.8415 | Acc(val) 0.8600 |
Epoch 00171 | Loss(train) 0.4983 | Acc(train) 0.8362 | Acc(val) 0.8590 |
Epoch 00172 | Loss(train) 0.4910 | Acc(train) 0.8448 | Acc(val) 0.8590 |
Epoch 00173 | Loss(train) 0.4927 | Acc(train) 0.8395 | Acc(val) 0.8575 |
Epoch 00174 | Loss(train) 0.4850 | Acc(train) 0.8463 | Acc(val) 0.8580 |
Epoch 00175 | Loss(train) 0.4906 | Acc(train) 0.8448 | Acc(val) 0.8590 |
Epoch 00176 | Loss(train) 0.4837 | Acc(train) 0.8433 | Acc(val) 0.8590 |
Epoch 00177 | Loss(train) 0.4890 | Acc(train) 0.8397 | Acc(val) 0.8595 |
Epoch 00178 | Loss(train) 0.4971 | Acc(train) 0.8417 | Acc(val) 0.8545 |
Epoch 00179 | Loss(train) 0.4852 | Acc(train) 0.8410 | Acc(val) 0.8590 |
Epoch 00180 | Loss(train) 0.4861 | Acc(train) 0.8410 | Acc(val) 0.8600 |
Epoch 00181 | Loss(train) 0.4879 | Acc(train) 0.8445 | Acc(val) 0.8580 |
Epoch 00182 | Loss(train) 0.4874 | Acc(train) 0.8450 | Acc(val) 0.8600 |
Epoch 00183 | Loss(train) 0.4905 | Acc(train) 0.8430 | Acc(val) 0.8611 |*
Epoch 00184 | Loss(train) 0.4909 | Acc(train) 0.8417 | Acc(val) 0.8580 |
Epoch 00185 | Loss(train) 0.4841 | Acc(train) 0.8382 | Acc(val) 0.8600 |
Epoch 00186 | Loss(train) 0.4853 | Acc(train) 0.8478 | Acc(val) 0.8595 |
Epoch 00187 | Loss(train) 0.4860 | Acc(train) 0.8450 | Acc(val) 0.8585 |
Epoch 00188 | Loss(train) 0.4755 | Acc(train) 0.8468 | Acc(val) 0.8600 |
Epoch 00189 | Loss(train) 0.4788 | Acc(train) 0.8491 | Acc(val) 0.8580 |
Epoch 00190 | Loss(train) 0.4894 | Acc(train) 0.8382 | Acc(val) 0.8600 |
Epoch 00191 | Loss(train) 0.4771 | Acc(train) 0.8496 | Acc(val) 0.8590 |
Epoch 00192 | Loss(train) 0.4807 | Acc(train) 0.8448 | Acc(val) 0.8595 |
Epoch 00193 | Loss(train) 0.4856 | Acc(train) 0.8390 | Acc(val) 0.8600 |
Epoch 00194 | Loss(train) 0.4848 | Acc(train) 0.8417 | Acc(val) 0.8570 |
Epoch 00195 | Loss(train) 0.4744 | Acc(train) 0.8428 | Acc(val) 0.8570 |
Epoch 00196 | Loss(train) 0.4802 | Acc(train) 0.8473 | Acc(val) 0.8585 |
Epoch 00197 | Loss(train) 0.4881 | Acc(train) 0.8423 | Acc(val) 0.8595 |
Epoch 00198 | Loss(train) 0.4771 | Acc(train) 0.8488 | Acc(val) 0.8600 |
Epoch 00199 | Loss(train) 0.4750 | Acc(train) 0.8476 | Acc(val) 0.8600 |
Epoch 00200 | Loss(train) 0.4756 | Acc(train) 0.8488 | Acc(val) 0.8616 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0986 | Acc(train) 0.3338 | Acc(val) 0.4868 |*
Epoch 00002 | Loss(train) 1.0904 | Acc(train) 0.4973 | Acc(val) 0.4655 |
Epoch 00003 | Loss(train) 1.0827 | Acc(train) 0.4763 | Acc(val) 0.4914 |*
Epoch 00004 | Loss(train) 1.0748 | Acc(train) 0.5019 | Acc(val) 0.5132 |*
Epoch 00005 | Loss(train) 1.0670 | Acc(train) 0.5133 | Acc(val) 0.5279 |*
Epoch 00006 | Loss(train) 1.0597 | Acc(train) 0.5209 | Acc(val) 0.5502 |*
Epoch 00007 | Loss(train) 1.0524 | Acc(train) 0.5247 | Acc(val) 0.5786 |*
Epoch 00008 | Loss(train) 1.0465 | Acc(train) 0.5290 | Acc(val) 0.5958 |*
Epoch 00009 | Loss(train) 1.0395 | Acc(train) 0.5369 | Acc(val) 0.6050 |*
Epoch 00010 | Loss(train) 1.0322 | Acc(train) 0.5562 | Acc(val) 0.6121 |*
Epoch 00011 | Loss(train) 1.0269 | Acc(train) 0.5399 | Acc(val) 0.6232 |*
Epoch 00012 | Loss(train) 1.0194 | Acc(train) 0.5595 | Acc(val) 0.6324 |*
Epoch 00013 | Loss(train) 1.0166 | Acc(train) 0.5399 | Acc(val) 0.6445 |*
Epoch 00014 | Loss(train) 1.0109 | Acc(train) 0.5503 | Acc(val) 0.6496 |*
Epoch 00015 | Loss(train) 1.0040 | Acc(train) 0.5701 | Acc(val) 0.6506 |*
Epoch 00016 | Loss(train) 0.9971 | Acc(train) 0.5640 | Acc(val) 0.6526 |*
Epoch 00017 | Loss(train) 0.9937 | Acc(train) 0.5645 | Acc(val) 0.6557 |*
Epoch 00018 | Loss(train) 0.9866 | Acc(train) 0.5635 | Acc(val) 0.6592 |*
Epoch 00019 | Loss(train) 0.9790 | Acc(train) 0.5803 | Acc(val) 0.6608 |*
Epoch 00020 | Loss(train) 0.9755 | Acc(train) 0.5798 | Acc(val) 0.6648 |*
Epoch 00021 | Loss(train) 0.9695 | Acc(train) 0.5770 | Acc(val) 0.6668 |*
Epoch 00022 | Loss(train) 0.9647 | Acc(train) 0.5722 | Acc(val) 0.6678 |*
Epoch 00023 | Loss(train) 0.9547 | Acc(train) 0.5940 | Acc(val) 0.6684 |*
Epoch 00024 | Loss(train) 0.9490 | Acc(train) 0.5881 | Acc(val) 0.6653 |
Epoch 00025 | Loss(train) 0.9452 | Acc(train) 0.5889 | Acc(val) 0.6668 |
Epoch 00026 | Loss(train) 0.9348 | Acc(train) 0.6069 | Acc(val) 0.6673 |
Epoch 00027 | Loss(train) 0.9307 | Acc(train) 0.6094 | Acc(val) 0.6729 |*
Epoch 00028 | Loss(train) 0.9272 | Acc(train) 0.6188 | Acc(val) 0.6785 |*
Epoch 00029 | Loss(train) 0.9224 | Acc(train) 0.6173 | Acc(val) 0.6831 |*
Epoch 00030 | Loss(train) 0.9130 | Acc(train) 0.6231 | Acc(val) 0.6876 |*
Epoch 00031 | Loss(train) 0.9020 | Acc(train) 0.6358 | Acc(val) 0.6942 |*
Epoch 00032 | Loss(train) 0.9002 | Acc(train) 0.6366 | Acc(val) 0.6962 |*
Epoch 00033 | Loss(train) 0.8928 | Acc(train) 0.6345 | Acc(val) 0.7039 |*
Epoch 00034 | Loss(train) 0.8872 | Acc(train) 0.6508 | Acc(val) 0.7089 |*
Epoch 00035 | Loss(train) 0.8795 | Acc(train) 0.6652 | Acc(val) 0.7145 |*
Epoch 00036 | Loss(train) 0.8796 | Acc(train) 0.6531 | Acc(val) 0.7201 |*
Epoch 00037 | Loss(train) 0.8716 | Acc(train) 0.6571 | Acc(val) 0.7231 |*
Epoch 00038 | Loss(train) 0.8642 | Acc(train) 0.6668 | Acc(val) 0.7328 |*
Epoch 00039 | Loss(train) 0.8603 | Acc(train) 0.6609 | Acc(val) 0.7388 |*
Epoch 00040 | Loss(train) 0.8530 | Acc(train) 0.6728 | Acc(val) 0.7444 |*
Epoch 00041 | Loss(train) 0.8416 | Acc(train) 0.6825 | Acc(val) 0.7561 |*
Epoch 00042 | Loss(train) 0.8389 | Acc(train) 0.6799 | Acc(val) 0.7617 |*
Epoch 00043 | Loss(train) 0.8300 | Acc(train) 0.6870 | Acc(val) 0.7713 |*
Epoch 00044 | Loss(train) 0.8288 | Acc(train) 0.6901 | Acc(val) 0.7769 |*
Epoch 00045 | Loss(train) 0.8160 | Acc(train) 0.6977 | Acc(val) 0.7809 |*
Epoch 00046 | Loss(train) 0.8167 | Acc(train) 0.7000 | Acc(val) 0.7855 |*
Epoch 00047 | Loss(train) 0.8112 | Acc(train) 0.6941 | Acc(val) 0.7885 |*
Epoch 00048 | Loss(train) 0.7992 | Acc(train) 0.7147 | Acc(val) 0.7921 |*
Epoch 00049 | Loss(train) 0.8045 | Acc(train) 0.7028 | Acc(val) 0.7967 |*
Epoch 00050 | Loss(train) 0.7959 | Acc(train) 0.7048 | Acc(val) 0.7982 |*
Epoch 00051 | Loss(train) 0.7831 | Acc(train) 0.7134 | Acc(val) 0.8032 |*
Epoch 00052 | Loss(train) 0.7786 | Acc(train) 0.7142 | Acc(val) 0.8058 |*
Epoch 00053 | Loss(train) 0.7816 | Acc(train) 0.7147 | Acc(val) 0.8078 |*
Epoch 00054 | Loss(train) 0.7736 | Acc(train) 0.7180 | Acc(val) 0.8088 |*
Epoch 00055 | Loss(train) 0.7644 | Acc(train) 0.7182 | Acc(val) 0.8109 |*
Epoch 00056 | Loss(train) 0.7601 | Acc(train) 0.7281 | Acc(val) 0.8119 |*
Epoch 00057 | Loss(train) 0.7644 | Acc(train) 0.7170 | Acc(val) 0.8129 |*
Epoch 00058 | Loss(train) 0.7485 | Acc(train) 0.7332 | Acc(val) 0.8139 |*
Epoch 00059 | Loss(train) 0.7464 | Acc(train) 0.7347 | Acc(val) 0.8149 |*
Epoch 00060 | Loss(train) 0.7390 | Acc(train) 0.7350 | Acc(val) 0.8164 |*
Epoch 00061 | Loss(train) 0.7399 | Acc(train) 0.7441 | Acc(val) 0.8169 |*
Epoch 00062 | Loss(train) 0.7351 | Acc(train) 0.7373 | Acc(val) 0.8169 |
Epoch 00063 | Loss(train) 0.7279 | Acc(train) 0.7418 | Acc(val) 0.8169 |
Epoch 00064 | Loss(train) 0.7327 | Acc(train) 0.7340 | Acc(val) 0.8205 |*
Epoch 00065 | Loss(train) 0.7158 | Acc(train) 0.7581 | Acc(val) 0.8205 |
Epoch 00066 | Loss(train) 0.7260 | Acc(train) 0.7352 | Acc(val) 0.8220 |*
Epoch 00067 | Loss(train) 0.7159 | Acc(train) 0.7494 | Acc(val) 0.8225 |*
Epoch 00068 | Loss(train) 0.7075 | Acc(train) 0.7545 | Acc(val) 0.8215 |
Epoch 00069 | Loss(train) 0.7050 | Acc(train) 0.7570 | Acc(val) 0.8210 |
Epoch 00070 | Loss(train) 0.7066 | Acc(train) 0.7550 | Acc(val) 0.8245 |*
Epoch 00071 | Loss(train) 0.6988 | Acc(train) 0.7621 | Acc(val) 0.8251 |*
Epoch 00072 | Loss(train) 0.6993 | Acc(train) 0.7545 | Acc(val) 0.8256 |*
Epoch 00073 | Loss(train) 0.6912 | Acc(train) 0.7629 | Acc(val) 0.8271 |*
Epoch 00074 | Loss(train) 0.6850 | Acc(train) 0.7591 | Acc(val) 0.8281 |*
Epoch 00075 | Loss(train) 0.6840 | Acc(train) 0.7583 | Acc(val) 0.8296 |*
Epoch 00076 | Loss(train) 0.6756 | Acc(train) 0.7745 | Acc(val) 0.8306 |*
Epoch 00077 | Loss(train) 0.6779 | Acc(train) 0.7631 | Acc(val) 0.8301 |
Epoch 00078 | Loss(train) 0.6823 | Acc(train) 0.7619 | Acc(val) 0.8301 |
Epoch 00079 | Loss(train) 0.6719 | Acc(train) 0.7626 | Acc(val) 0.8342 |*
Epoch 00080 | Loss(train) 0.6709 | Acc(train) 0.7766 | Acc(val) 0.8327 |
Epoch 00081 | Loss(train) 0.6741 | Acc(train) 0.7621 | Acc(val) 0.8327 |
Epoch 00082 | Loss(train) 0.6657 | Acc(train) 0.7677 | Acc(val) 0.8327 |
Epoch 00083 | Loss(train) 0.6665 | Acc(train) 0.7682 | Acc(val) 0.8327 |
Epoch 00084 | Loss(train) 0.6623 | Acc(train) 0.7725 | Acc(val) 0.8327 |
Epoch 00085 | Loss(train) 0.6545 | Acc(train) 0.7816 | Acc(val) 0.8342 |
Epoch 00086 | Loss(train) 0.6547 | Acc(train) 0.7796 | Acc(val) 0.8342 |
Epoch 00087 | Loss(train) 0.6507 | Acc(train) 0.7786 | Acc(val) 0.8352 |*
Epoch 00088 | Loss(train) 0.6448 | Acc(train) 0.7832 | Acc(val) 0.8347 |
Epoch 00089 | Loss(train) 0.6473 | Acc(train) 0.7781 | Acc(val) 0.8342 |
Epoch 00090 | Loss(train) 0.6523 | Acc(train) 0.7723 | Acc(val) 0.8342 |
Epoch 00091 | Loss(train) 0.6405 | Acc(train) 0.7804 | Acc(val) 0.8362 |*
Epoch 00092 | Loss(train) 0.6476 | Acc(train) 0.7740 | Acc(val) 0.8362 |
Epoch 00093 | Loss(train) 0.6297 | Acc(train) 0.7849 | Acc(val) 0.8377 |*
Epoch 00094 | Loss(train) 0.6296 | Acc(train) 0.7892 | Acc(val) 0.8382 |*
Epoch 00095 | Loss(train) 0.6372 | Acc(train) 0.7801 | Acc(val) 0.8392 |*
Epoch 00096 | Loss(train) 0.6312 | Acc(train) 0.7870 | Acc(val) 0.8382 |
Epoch 00097 | Loss(train) 0.6282 | Acc(train) 0.7849 | Acc(val) 0.8387 |
Epoch 00098 | Loss(train) 0.6230 | Acc(train) 0.7844 | Acc(val) 0.8398 |*
Epoch 00099 | Loss(train) 0.6258 | Acc(train) 0.7938 | Acc(val) 0.8408 |*
Epoch 00100 | Loss(train) 0.6194 | Acc(train) 0.7933 | Acc(val) 0.8418 |*
Epoch 00101 | Loss(train) 0.6264 | Acc(train) 0.7870 | Acc(val) 0.8413 |
Epoch 00102 | Loss(train) 0.6188 | Acc(train) 0.7867 | Acc(val) 0.8423 |*
Epoch 00103 | Loss(train) 0.6181 | Acc(train) 0.7870 | Acc(val) 0.8423 |
Epoch 00104 | Loss(train) 0.6196 | Acc(train) 0.7837 | Acc(val) 0.8433 |*
Epoch 00105 | Loss(train) 0.6140 | Acc(train) 0.7931 | Acc(val) 0.8448 |*
Epoch 00106 | Loss(train) 0.6158 | Acc(train) 0.7971 | Acc(val) 0.8433 |
Epoch 00107 | Loss(train) 0.6081 | Acc(train) 0.7920 | Acc(val) 0.8428 |
Epoch 00108 | Loss(train) 0.6068 | Acc(train) 0.7933 | Acc(val) 0.8433 |
Epoch 00109 | Loss(train) 0.6054 | Acc(train) 0.8007 | Acc(val) 0.8418 |
Epoch 00110 | Loss(train) 0.6028 | Acc(train) 0.7948 | Acc(val) 0.8418 |
Epoch 00111 | Loss(train) 0.6022 | Acc(train) 0.7979 | Acc(val) 0.8413 |
Epoch 00112 | Loss(train) 0.6024 | Acc(train) 0.7956 | Acc(val) 0.8423 |
Epoch 00113 | Loss(train) 0.6007 | Acc(train) 0.7961 | Acc(val) 0.8423 |
Epoch 00114 | Loss(train) 0.6034 | Acc(train) 0.7844 | Acc(val) 0.8423 |
Epoch 00115 | Loss(train) 0.6025 | Acc(train) 0.7961 | Acc(val) 0.8428 |
Epoch 00116 | Loss(train) 0.5932 | Acc(train) 0.7976 | Acc(val) 0.8448 |
Epoch 00117 | Loss(train) 0.5961 | Acc(train) 0.7963 | Acc(val) 0.8448 |
Epoch 00118 | Loss(train) 0.5989 | Acc(train) 0.7936 | Acc(val) 0.8463 |*
Epoch 00119 | Loss(train) 0.5798 | Acc(train) 0.8055 | Acc(val) 0.8469 |*
Epoch 00120 | Loss(train) 0.5898 | Acc(train) 0.7951 | Acc(val) 0.8474 |*
Epoch 00121 | Loss(train) 0.5834 | Acc(train) 0.8138 | Acc(val) 0.8474 |
Epoch 00122 | Loss(train) 0.5906 | Acc(train) 0.7946 | Acc(val) 0.8474 |
Epoch 00123 | Loss(train) 0.5774 | Acc(train) 0.8123 | Acc(val) 0.8469 |
Epoch 00124 | Loss(train) 0.5789 | Acc(train) 0.8040 | Acc(val) 0.8484 |*
Epoch 00125 | Loss(train) 0.5826 | Acc(train) 0.8022 | Acc(val) 0.8489 |*
Epoch 00126 | Loss(train) 0.5780 | Acc(train) 0.8090 | Acc(val) 0.8463 |
Epoch 00127 | Loss(train) 0.5893 | Acc(train) 0.7994 | Acc(val) 0.8469 |
Epoch 00128 | Loss(train) 0.5824 | Acc(train) 0.8004 | Acc(val) 0.8463 |
Epoch 00129 | Loss(train) 0.5700 | Acc(train) 0.8123 | Acc(val) 0.8463 |
Epoch 00130 | Loss(train) 0.5719 | Acc(train) 0.8098 | Acc(val) 0.8469 |
Epoch 00131 | Loss(train) 0.5705 | Acc(train) 0.8045 | Acc(val) 0.8469 |
Epoch 00132 | Loss(train) 0.5705 | Acc(train) 0.8121 | Acc(val) 0.8469 |
Epoch 00133 | Loss(train) 0.5772 | Acc(train) 0.8024 | Acc(val) 0.8469 |
Epoch 00134 | Loss(train) 0.5730 | Acc(train) 0.8103 | Acc(val) 0.8469 |
Epoch 00135 | Loss(train) 0.5764 | Acc(train) 0.8062 | Acc(val) 0.8463 |
Epoch 00136 | Loss(train) 0.5699 | Acc(train) 0.8126 | Acc(val) 0.8469 |
Epoch 00137 | Loss(train) 0.5727 | Acc(train) 0.8065 | Acc(val) 0.8458 |
Epoch 00138 | Loss(train) 0.5651 | Acc(train) 0.8151 | Acc(val) 0.8474 |
Epoch 00139 | Loss(train) 0.5638 | Acc(train) 0.8171 | Acc(val) 0.8494 |*
Epoch 00140 | Loss(train) 0.5594 | Acc(train) 0.8128 | Acc(val) 0.8499 |*
Epoch 00141 | Loss(train) 0.5640 | Acc(train) 0.8118 | Acc(val) 0.8494 |
Epoch 00142 | Loss(train) 0.5727 | Acc(train) 0.7986 | Acc(val) 0.8489 |
Epoch 00143 | Loss(train) 0.5594 | Acc(train) 0.8108 | Acc(val) 0.8494 |
Epoch 00144 | Loss(train) 0.5593 | Acc(train) 0.8078 | Acc(val) 0.8499 |
Epoch 00145 | Loss(train) 0.5651 | Acc(train) 0.8090 | Acc(val) 0.8509 |*
Epoch 00146 | Loss(train) 0.5619 | Acc(train) 0.8126 | Acc(val) 0.8519 |*
Epoch 00147 | Loss(train) 0.5677 | Acc(train) 0.8078 | Acc(val) 0.8509 |
Epoch 00148 | Loss(train) 0.5552 | Acc(train) 0.8189 | Acc(val) 0.8499 |
Epoch 00149 | Loss(train) 0.5551 | Acc(train) 0.8116 | Acc(val) 0.8499 |
Epoch 00150 | Loss(train) 0.5538 | Acc(train) 0.8222 | Acc(val) 0.8499 |
Epoch 00151 | Loss(train) 0.5511 | Acc(train) 0.8123 | Acc(val) 0.8499 |
Epoch 00152 | Loss(train) 0.5502 | Acc(train) 0.8128 | Acc(val) 0.8489 |
Epoch 00153 | Loss(train) 0.5657 | Acc(train) 0.8047 | Acc(val) 0.8499 |
Epoch 00154 | Loss(train) 0.5498 | Acc(train) 0.8108 | Acc(val) 0.8519 |
Epoch 00155 | Loss(train) 0.5500 | Acc(train) 0.8126 | Acc(val) 0.8529 |*
Epoch 00156 | Loss(train) 0.5511 | Acc(train) 0.8169 | Acc(val) 0.8529 |
Epoch 00157 | Loss(train) 0.5499 | Acc(train) 0.8106 | Acc(val) 0.8529 |
Epoch 00158 | Loss(train) 0.5523 | Acc(train) 0.8182 | Acc(val) 0.8499 |
Epoch 00159 | Loss(train) 0.5467 | Acc(train) 0.8164 | Acc(val) 0.8499 |
Epoch 00160 | Loss(train) 0.5397 | Acc(train) 0.8255 | Acc(val) 0.8529 |
Epoch 00161 | Loss(train) 0.5451 | Acc(train) 0.8204 | Acc(val) 0.8519 |
Epoch 00162 | Loss(train) 0.5442 | Acc(train) 0.8133 | Acc(val) 0.8519 |
Epoch 00163 | Loss(train) 0.5465 | Acc(train) 0.8100 | Acc(val) 0.8514 |
Epoch 00164 | Loss(train) 0.5411 | Acc(train) 0.8154 | Acc(val) 0.8524 |
Epoch 00165 | Loss(train) 0.5366 | Acc(train) 0.8225 | Acc(val) 0.8504 |
Epoch 00166 | Loss(train) 0.5397 | Acc(train) 0.8166 | Acc(val) 0.8534 |*
Epoch 00167 | Loss(train) 0.5362 | Acc(train) 0.8275 | Acc(val) 0.8534 |
Epoch 00168 | Loss(train) 0.5420 | Acc(train) 0.8184 | Acc(val) 0.8540 |*
Epoch 00169 | Loss(train) 0.5486 | Acc(train) 0.8116 | Acc(val) 0.8540 |
Epoch 00170 | Loss(train) 0.5319 | Acc(train) 0.8166 | Acc(val) 0.8524 |
Epoch 00171 | Loss(train) 0.5375 | Acc(train) 0.8202 | Acc(val) 0.8524 |
Epoch 00172 | Loss(train) 0.5293 | Acc(train) 0.8230 | Acc(val) 0.8494 |
Epoch 00173 | Loss(train) 0.5412 | Acc(train) 0.8133 | Acc(val) 0.8519 |
Epoch 00174 | Loss(train) 0.5321 | Acc(train) 0.8258 | Acc(val) 0.8519 |
Epoch 00175 | Loss(train) 0.5365 | Acc(train) 0.8212 | Acc(val) 0.8545 |*
Epoch 00176 | Loss(train) 0.5402 | Acc(train) 0.8166 | Acc(val) 0.8555 |*
Epoch 00177 | Loss(train) 0.5432 | Acc(train) 0.8199 | Acc(val) 0.8550 |
Epoch 00178 | Loss(train) 0.5284 | Acc(train) 0.8179 | Acc(val) 0.8545 |
Epoch 00179 | Loss(train) 0.5276 | Acc(train) 0.8265 | Acc(val) 0.8519 |
Epoch 00180 | Loss(train) 0.5266 | Acc(train) 0.8288 | Acc(val) 0.8524 |
Epoch 00181 | Loss(train) 0.5271 | Acc(train) 0.8296 | Acc(val) 0.8534 |
Epoch 00182 | Loss(train) 0.5310 | Acc(train) 0.8242 | Acc(val) 0.8540 |
Epoch 00183 | Loss(train) 0.5297 | Acc(train) 0.8171 | Acc(val) 0.8550 |
Epoch 00184 | Loss(train) 0.5235 | Acc(train) 0.8258 | Acc(val) 0.8565 |*
Epoch 00185 | Loss(train) 0.5313 | Acc(train) 0.8199 | Acc(val) 0.8560 |
Epoch 00186 | Loss(train) 0.5335 | Acc(train) 0.8169 | Acc(val) 0.8550 |
Epoch 00187 | Loss(train) 0.5319 | Acc(train) 0.8154 | Acc(val) 0.8529 |
Epoch 00188 | Loss(train) 0.5312 | Acc(train) 0.8215 | Acc(val) 0.8524 |
Epoch 00189 | Loss(train) 0.5240 | Acc(train) 0.8260 | Acc(val) 0.8529 |
Epoch 00190 | Loss(train) 0.5275 | Acc(train) 0.8255 | Acc(val) 0.8565 |
Epoch 00191 | Loss(train) 0.5331 | Acc(train) 0.8166 | Acc(val) 0.8565 |
Epoch 00192 | Loss(train) 0.5231 | Acc(train) 0.8288 | Acc(val) 0.8550 |
Epoch 00193 | Loss(train) 0.5212 | Acc(train) 0.8215 | Acc(val) 0.8560 |
Epoch 00194 | Loss(train) 0.5229 | Acc(train) 0.8177 | Acc(val) 0.8529 |
Epoch 00195 | Loss(train) 0.5285 | Acc(train) 0.8197 | Acc(val) 0.8540 |
Epoch 00196 | Loss(train) 0.5200 | Acc(train) 0.8189 | Acc(val) 0.8560 |
Epoch 00197 | Loss(train) 0.5229 | Acc(train) 0.8144 | Acc(val) 0.8565 |
Epoch 00198 | Loss(train) 0.5330 | Acc(train) 0.8179 | Acc(val) 0.8575 |*
Epoch 00199 | Loss(train) 0.5206 | Acc(train) 0.8232 | Acc(val) 0.8580 |*
Epoch 00200 | Loss(train) 0.5282 | Acc(train) 0.8225 | Acc(val) 0.8560 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.1003 | Acc(train) 0.1813 | Acc(val) 0.4823 |*
Epoch 00002 | Loss(train) 1.0941 | Acc(train) 0.4459 | Acc(val) 0.4326 |
Epoch 00003 | Loss(train) 1.0886 | Acc(train) 0.4405 | Acc(val) 0.4630 |
Epoch 00004 | Loss(train) 1.0826 | Acc(train) 0.4763 | Acc(val) 0.4970 |*
Epoch 00005 | Loss(train) 1.0762 | Acc(train) 0.4938 | Acc(val) 0.5228 |*
Epoch 00006 | Loss(train) 1.0700 | Acc(train) 0.5034 | Acc(val) 0.5512 |*
Epoch 00007 | Loss(train) 1.0635 | Acc(train) 0.5024 | Acc(val) 0.5751 |*
Epoch 00008 | Loss(train) 1.0572 | Acc(train) 0.5265 | Acc(val) 0.5908 |*
Epoch 00009 | Loss(train) 1.0522 | Acc(train) 0.5153 | Acc(val) 0.6014 |*
Epoch 00010 | Loss(train) 1.0462 | Acc(train) 0.5222 | Acc(val) 0.6131 |*
Epoch 00011 | Loss(train) 1.0412 | Acc(train) 0.5280 | Acc(val) 0.6212 |*
Epoch 00012 | Loss(train) 1.0347 | Acc(train) 0.5483 | Acc(val) 0.6258 |*
Epoch 00013 | Loss(train) 1.0301 | Acc(train) 0.5440 | Acc(val) 0.6313 |*
Epoch 00014 | Loss(train) 1.0247 | Acc(train) 0.5359 | Acc(val) 0.6324 |*
Epoch 00015 | Loss(train) 1.0203 | Acc(train) 0.5372 | Acc(val) 0.6339 |*
Epoch 00016 | Loss(train) 1.0146 | Acc(train) 0.5415 | Acc(val) 0.6308 |
Epoch 00017 | Loss(train) 1.0089 | Acc(train) 0.5392 | Acc(val) 0.6303 |
Epoch 00018 | Loss(train) 1.0050 | Acc(train) 0.5412 | Acc(val) 0.6253 |
Epoch 00019 | Loss(train) 1.0001 | Acc(train) 0.5476 | Acc(val) 0.6207 |
Epoch 00020 | Loss(train) 0.9947 | Acc(train) 0.5430 | Acc(val) 0.6187 |
Epoch 00021 | Loss(train) 0.9872 | Acc(train) 0.5481 | Acc(val) 0.6166 |
Epoch 00022 | Loss(train) 0.9842 | Acc(train) 0.5392 | Acc(val) 0.6182 |
Epoch 00023 | Loss(train) 0.9778 | Acc(train) 0.5384 | Acc(val) 0.6232 |
Epoch 00024 | Loss(train) 0.9721 | Acc(train) 0.5544 | Acc(val) 0.6329 |
Epoch 00025 | Loss(train) 0.9639 | Acc(train) 0.5676 | Acc(val) 0.6364 |*
Epoch 00026 | Loss(train) 0.9614 | Acc(train) 0.5585 | Acc(val) 0.6400 |*
Epoch 00027 | Loss(train) 0.9518 | Acc(train) 0.5798 | Acc(val) 0.6430 |*
Epoch 00028 | Loss(train) 0.9464 | Acc(train) 0.5833 | Acc(val) 0.6466 |*
Epoch 00029 | Loss(train) 0.9413 | Acc(train) 0.5851 | Acc(val) 0.6460 |
Epoch 00030 | Loss(train) 0.9375 | Acc(train) 0.5856 | Acc(val) 0.6471 |*
Epoch 00031 | Loss(train) 0.9291 | Acc(train) 0.6013 | Acc(val) 0.6511 |*
Epoch 00032 | Loss(train) 0.9252 | Acc(train) 0.5945 | Acc(val) 0.6486 |
Epoch 00033 | Loss(train) 0.9193 | Acc(train) 0.6061 | Acc(val) 0.6496 |
Epoch 00034 | Loss(train) 0.9109 | Acc(train) 0.6112 | Acc(val) 0.6496 |
Epoch 00035 | Loss(train) 0.9051 | Acc(train) 0.6211 | Acc(val) 0.6491 |
Epoch 00036 | Loss(train) 0.9012 | Acc(train) 0.6269 | Acc(val) 0.6491 |
Epoch 00037 | Loss(train) 0.8964 | Acc(train) 0.6318 | Acc(val) 0.6511 |
Epoch 00038 | Loss(train) 0.8869 | Acc(train) 0.6338 | Acc(val) 0.6537 |*
Epoch 00039 | Loss(train) 0.8814 | Acc(train) 0.6368 | Acc(val) 0.6572 |*
Epoch 00040 | Loss(train) 0.8764 | Acc(train) 0.6356 | Acc(val) 0.6653 |*
Epoch 00041 | Loss(train) 0.8686 | Acc(train) 0.6513 | Acc(val) 0.6724 |*
Epoch 00042 | Loss(train) 0.8625 | Acc(train) 0.6533 | Acc(val) 0.6820 |*
Epoch 00043 | Loss(train) 0.8567 | Acc(train) 0.6632 | Acc(val) 0.6932 |*
Epoch 00044 | Loss(train) 0.8538 | Acc(train) 0.6733 | Acc(val) 0.6998 |*
Epoch 00045 | Loss(train) 0.8429 | Acc(train) 0.6812 | Acc(val) 0.7089 |*
Epoch 00046 | Loss(train) 0.8393 | Acc(train) 0.6792 | Acc(val) 0.7155 |*
Epoch 00047 | Loss(train) 0.8326 | Acc(train) 0.6855 | Acc(val) 0.7236 |*
Epoch 00048 | Loss(train) 0.8273 | Acc(train) 0.6886 | Acc(val) 0.7282 |*
Epoch 00049 | Loss(train) 0.8239 | Acc(train) 0.6979 | Acc(val) 0.7338 |*
Epoch 00050 | Loss(train) 0.8159 | Acc(train) 0.6990 | Acc(val) 0.7394 |*
Epoch 00051 | Loss(train) 0.8118 | Acc(train) 0.6967 | Acc(val) 0.7459 |*
Epoch 00052 | Loss(train) 0.8054 | Acc(train) 0.7083 | Acc(val) 0.7515 |*
Epoch 00053 | Loss(train) 0.7972 | Acc(train) 0.7116 | Acc(val) 0.7551 |*
Epoch 00054 | Loss(train) 0.7973 | Acc(train) 0.7083 | Acc(val) 0.7642 |*
Epoch 00055 | Loss(train) 0.7888 | Acc(train) 0.7149 | Acc(val) 0.7703 |*
Epoch 00056 | Loss(train) 0.7840 | Acc(train) 0.7218 | Acc(val) 0.7748 |*
Epoch 00057 | Loss(train) 0.7804 | Acc(train) 0.7228 | Acc(val) 0.7809 |*
Epoch 00058 | Loss(train) 0.7746 | Acc(train) 0.7241 | Acc(val) 0.7860 |*
Epoch 00059 | Loss(train) 0.7757 | Acc(train) 0.7154 | Acc(val) 0.7885 |*
Epoch 00060 | Loss(train) 0.7652 | Acc(train) 0.7302 | Acc(val) 0.7921 |*
Epoch 00061 | Loss(train) 0.7633 | Acc(train) 0.7281 | Acc(val) 0.7936 |*
Epoch 00062 | Loss(train) 0.7572 | Acc(train) 0.7337 | Acc(val) 0.7982 |*
Epoch 00063 | Loss(train) 0.7539 | Acc(train) 0.7398 | Acc(val) 0.7997 |*
Epoch 00064 | Loss(train) 0.7490 | Acc(train) 0.7340 | Acc(val) 0.8027 |*
Epoch 00065 | Loss(train) 0.7428 | Acc(train) 0.7406 | Acc(val) 0.8073 |*
Epoch 00066 | Loss(train) 0.7388 | Acc(train) 0.7456 | Acc(val) 0.8068 |
Epoch 00067 | Loss(train) 0.7375 | Acc(train) 0.7390 | Acc(val) 0.8103 |*
Epoch 00068 | Loss(train) 0.7316 | Acc(train) 0.7474 | Acc(val) 0.8109 |*
Epoch 00069 | Loss(train) 0.7252 | Acc(train) 0.7517 | Acc(val) 0.8109 |
Epoch 00070 | Loss(train) 0.7285 | Acc(train) 0.7426 | Acc(val) 0.8139 |*
Epoch 00071 | Loss(train) 0.7227 | Acc(train) 0.7454 | Acc(val) 0.8154 |*
Epoch 00072 | Loss(train) 0.7187 | Acc(train) 0.7403 | Acc(val) 0.8149 |
Epoch 00073 | Loss(train) 0.7139 | Acc(train) 0.7438 | Acc(val) 0.8149 |
Epoch 00074 | Loss(train) 0.7117 | Acc(train) 0.7471 | Acc(val) 0.8139 |
Epoch 00075 | Loss(train) 0.7069 | Acc(train) 0.7565 | Acc(val) 0.8134 |
Epoch 00076 | Loss(train) 0.6964 | Acc(train) 0.7586 | Acc(val) 0.8149 |
Epoch 00077 | Loss(train) 0.6952 | Acc(train) 0.7560 | Acc(val) 0.8185 |*
Epoch 00078 | Loss(train) 0.6907 | Acc(train) 0.7710 | Acc(val) 0.8200 |*
Epoch 00079 | Loss(train) 0.6893 | Acc(train) 0.7692 | Acc(val) 0.8215 |*
Epoch 00080 | Loss(train) 0.6904 | Acc(train) 0.7723 | Acc(val) 0.8225 |*
Epoch 00081 | Loss(train) 0.6813 | Acc(train) 0.7692 | Acc(val) 0.8225 |
Epoch 00082 | Loss(train) 0.6871 | Acc(train) 0.7624 | Acc(val) 0.8210 |
Epoch 00083 | Loss(train) 0.6774 | Acc(train) 0.7717 | Acc(val) 0.8230 |*
Epoch 00084 | Loss(train) 0.6791 | Acc(train) 0.7639 | Acc(val) 0.8251 |*
Epoch 00085 | Loss(train) 0.6730 | Acc(train) 0.7644 | Acc(val) 0.8261 |*
Epoch 00086 | Loss(train) 0.6718 | Acc(train) 0.7687 | Acc(val) 0.8271 |*
Epoch 00087 | Loss(train) 0.6653 | Acc(train) 0.7733 | Acc(val) 0.8271 |
Epoch 00088 | Loss(train) 0.6646 | Acc(train) 0.7748 | Acc(val) 0.8281 |*
Epoch 00089 | Loss(train) 0.6640 | Acc(train) 0.7786 | Acc(val) 0.8281 |
Epoch 00090 | Loss(train) 0.6585 | Acc(train) 0.7761 | Acc(val) 0.8266 |
Epoch 00091 | Loss(train) 0.6541 | Acc(train) 0.7748 | Acc(val) 0.8281 |
Epoch 00092 | Loss(train) 0.6555 | Acc(train) 0.7778 | Acc(val) 0.8276 |
Epoch 00093 | Loss(train) 0.6527 | Acc(train) 0.7723 | Acc(val) 0.8306 |*
Epoch 00094 | Loss(train) 0.6441 | Acc(train) 0.7847 | Acc(val) 0.8311 |*
Epoch 00095 | Loss(train) 0.6426 | Acc(train) 0.7829 | Acc(val) 0.8337 |*
Epoch 00096 | Loss(train) 0.6419 | Acc(train) 0.7816 | Acc(val) 0.8337 |
Epoch 00097 | Loss(train) 0.6426 | Acc(train) 0.7761 | Acc(val) 0.8332 |
Epoch 00098 | Loss(train) 0.6381 | Acc(train) 0.7748 | Acc(val) 0.8311 |
Epoch 00099 | Loss(train) 0.6413 | Acc(train) 0.7842 | Acc(val) 0.8296 |
Epoch 00100 | Loss(train) 0.6369 | Acc(train) 0.7849 | Acc(val) 0.8337 |
Epoch 00101 | Loss(train) 0.6413 | Acc(train) 0.7768 | Acc(val) 0.8347 |*
Epoch 00102 | Loss(train) 0.6292 | Acc(train) 0.7865 | Acc(val) 0.8362 |*
Epoch 00103 | Loss(train) 0.6270 | Acc(train) 0.7892 | Acc(val) 0.8372 |*
Epoch 00104 | Loss(train) 0.6302 | Acc(train) 0.7877 | Acc(val) 0.8372 |
Epoch 00105 | Loss(train) 0.6249 | Acc(train) 0.7892 | Acc(val) 0.8352 |
Epoch 00106 | Loss(train) 0.6151 | Acc(train) 0.7951 | Acc(val) 0.8347 |
Epoch 00107 | Loss(train) 0.6263 | Acc(train) 0.7814 | Acc(val) 0.8352 |
Epoch 00108 | Loss(train) 0.6198 | Acc(train) 0.7781 | Acc(val) 0.8377 |*
Epoch 00109 | Loss(train) 0.6121 | Acc(train) 0.7908 | Acc(val) 0.8387 |*
Epoch 00110 | Loss(train) 0.6130 | Acc(train) 0.8017 | Acc(val) 0.8398 |*
Epoch 00111 | Loss(train) 0.6127 | Acc(train) 0.7979 | Acc(val) 0.8413 |*
Epoch 00112 | Loss(train) 0.6149 | Acc(train) 0.7882 | Acc(val) 0.8367 |
Epoch 00113 | Loss(train) 0.6166 | Acc(train) 0.7847 | Acc(val) 0.8382 |
Epoch 00114 | Loss(train) 0.6024 | Acc(train) 0.8045 | Acc(val) 0.8377 |
Epoch 00115 | Loss(train) 0.6117 | Acc(train) 0.7832 | Acc(val) 0.8377 |
Epoch 00116 | Loss(train) 0.6051 | Acc(train) 0.7961 | Acc(val) 0.8408 |
Epoch 00117 | Loss(train) 0.5954 | Acc(train) 0.8047 | Acc(val) 0.8408 |
Epoch 00118 | Loss(train) 0.6051 | Acc(train) 0.7854 | Acc(val) 0.8408 |
Epoch 00119 | Loss(train) 0.6030 | Acc(train) 0.7885 | Acc(val) 0.8387 |
Epoch 00120 | Loss(train) 0.5998 | Acc(train) 0.8037 | Acc(val) 0.8398 |
Epoch 00121 | Loss(train) 0.6012 | Acc(train) 0.7933 | Acc(val) 0.8398 |
Epoch 00122 | Loss(train) 0.5967 | Acc(train) 0.7941 | Acc(val) 0.8408 |
Epoch 00123 | Loss(train) 0.5934 | Acc(train) 0.7923 | Acc(val) 0.8392 |
Epoch 00124 | Loss(train) 0.5860 | Acc(train) 0.7979 | Acc(val) 0.8418 |*
Epoch 00125 | Loss(train) 0.5942 | Acc(train) 0.7963 | Acc(val) 0.8418 |
Epoch 00126 | Loss(train) 0.5935 | Acc(train) 0.8002 | Acc(val) 0.8408 |
Epoch 00127 | Loss(train) 0.5822 | Acc(train) 0.8060 | Acc(val) 0.8408 |
Epoch 00128 | Loss(train) 0.5866 | Acc(train) 0.8002 | Acc(val) 0.8403 |
Epoch 00129 | Loss(train) 0.5830 | Acc(train) 0.7979 | Acc(val) 0.8408 |
Epoch 00130 | Loss(train) 0.5890 | Acc(train) 0.7948 | Acc(val) 0.8423 |*
Epoch 00131 | Loss(train) 0.5823 | Acc(train) 0.8024 | Acc(val) 0.8433 |*
Epoch 00132 | Loss(train) 0.5885 | Acc(train) 0.7979 | Acc(val) 0.8433 |
Epoch 00133 | Loss(train) 0.5780 | Acc(train) 0.8029 | Acc(val) 0.8418 |
Epoch 00134 | Loss(train) 0.5758 | Acc(train) 0.7966 | Acc(val) 0.8418 |
Epoch 00135 | Loss(train) 0.5729 | Acc(train) 0.7999 | Acc(val) 0.8423 |
Epoch 00136 | Loss(train) 0.5782 | Acc(train) 0.7946 | Acc(val) 0.8423 |
Epoch 00137 | Loss(train) 0.5672 | Acc(train) 0.8062 | Acc(val) 0.8443 |*
Epoch 00138 | Loss(train) 0.5801 | Acc(train) 0.7956 | Acc(val) 0.8438 |
Epoch 00139 | Loss(train) 0.5710 | Acc(train) 0.8080 | Acc(val) 0.8418 |
Epoch 00140 | Loss(train) 0.5759 | Acc(train) 0.7996 | Acc(val) 0.8433 |
Epoch 00141 | Loss(train) 0.5752 | Acc(train) 0.8012 | Acc(val) 0.8428 |
Epoch 00142 | Loss(train) 0.5708 | Acc(train) 0.7976 | Acc(val) 0.8433 |
Epoch 00143 | Loss(train) 0.5721 | Acc(train) 0.8009 | Acc(val) 0.8463 |*
Epoch 00144 | Loss(train) 0.5680 | Acc(train) 0.8062 | Acc(val) 0.8458 |
Epoch 00145 | Loss(train) 0.5567 | Acc(train) 0.8199 | Acc(val) 0.8438 |
Epoch 00146 | Loss(train) 0.5673 | Acc(train) 0.8014 | Acc(val) 0.8463 |
Epoch 00147 | Loss(train) 0.5714 | Acc(train) 0.8012 | Acc(val) 0.8458 |
Epoch 00148 | Loss(train) 0.5608 | Acc(train) 0.8067 | Acc(val) 0.8453 |
Epoch 00149 | Loss(train) 0.5612 | Acc(train) 0.8052 | Acc(val) 0.8474 |*
Epoch 00150 | Loss(train) 0.5611 | Acc(train) 0.8029 | Acc(val) 0.8499 |*
Epoch 00151 | Loss(train) 0.5616 | Acc(train) 0.8128 | Acc(val) 0.8494 |
Epoch 00152 | Loss(train) 0.5546 | Acc(train) 0.8083 | Acc(val) 0.8474 |
Epoch 00153 | Loss(train) 0.5596 | Acc(train) 0.7996 | Acc(val) 0.8463 |
Epoch 00154 | Loss(train) 0.5630 | Acc(train) 0.7971 | Acc(val) 0.8469 |
Epoch 00155 | Loss(train) 0.5502 | Acc(train) 0.8083 | Acc(val) 0.8458 |
Epoch 00156 | Loss(train) 0.5553 | Acc(train) 0.7999 | Acc(val) 0.8484 |
Epoch 00157 | Loss(train) 0.5490 | Acc(train) 0.8103 | Acc(val) 0.8514 |*
Epoch 00158 | Loss(train) 0.5468 | Acc(train) 0.8149 | Acc(val) 0.8504 |
Epoch 00159 | Loss(train) 0.5552 | Acc(train) 0.8014 | Acc(val) 0.8479 |
Epoch 00160 | Loss(train) 0.5526 | Acc(train) 0.8085 | Acc(val) 0.8479 |
Epoch 00161 | Loss(train) 0.5521 | Acc(train) 0.8095 | Acc(val) 0.8474 |
Epoch 00162 | Loss(train) 0.5475 | Acc(train) 0.8093 | Acc(val) 0.8489 |
Epoch 00163 | Loss(train) 0.5515 | Acc(train) 0.8085 | Acc(val) 0.8494 |
Epoch 00164 | Loss(train) 0.5530 | Acc(train) 0.8095 | Acc(val) 0.8499 |
Epoch 00165 | Loss(train) 0.5339 | Acc(train) 0.8215 | Acc(val) 0.8504 |
Epoch 00166 | Loss(train) 0.5461 | Acc(train) 0.8098 | Acc(val) 0.8469 |
Epoch 00167 | Loss(train) 0.5417 | Acc(train) 0.8078 | Acc(val) 0.8474 |
Epoch 00168 | Loss(train) 0.5454 | Acc(train) 0.8090 | Acc(val) 0.8489 |
Epoch 00169 | Loss(train) 0.5423 | Acc(train) 0.8070 | Acc(val) 0.8519 |*
Epoch 00170 | Loss(train) 0.5477 | Acc(train) 0.8093 | Acc(val) 0.8534 |*
Epoch 00171 | Loss(train) 0.5383 | Acc(train) 0.8057 | Acc(val) 0.8524 |
Epoch 00172 | Loss(train) 0.5463 | Acc(train) 0.8055 | Acc(val) 0.8504 |
Epoch 00173 | Loss(train) 0.5397 | Acc(train) 0.8116 | Acc(val) 0.8504 |
Epoch 00174 | Loss(train) 0.5330 | Acc(train) 0.8161 | Acc(val) 0.8494 |
Epoch 00175 | Loss(train) 0.5477 | Acc(train) 0.8055 | Acc(val) 0.8494 |
Epoch 00176 | Loss(train) 0.5350 | Acc(train) 0.8164 | Acc(val) 0.8524 |
Epoch 00177 | Loss(train) 0.5340 | Acc(train) 0.8085 | Acc(val) 0.8519 |
Epoch 00178 | Loss(train) 0.5455 | Acc(train) 0.8106 | Acc(val) 0.8529 |
Epoch 00179 | Loss(train) 0.5493 | Acc(train) 0.8004 | Acc(val) 0.8509 |
Epoch 00180 | Loss(train) 0.5318 | Acc(train) 0.8177 | Acc(val) 0.8504 |
Epoch 00181 | Loss(train) 0.5317 | Acc(train) 0.8121 | Acc(val) 0.8499 |
Epoch 00182 | Loss(train) 0.5409 | Acc(train) 0.8095 | Acc(val) 0.8514 |
Epoch 00183 | Loss(train) 0.5350 | Acc(train) 0.8161 | Acc(val) 0.8529 |
Epoch 00184 | Loss(train) 0.5318 | Acc(train) 0.8171 | Acc(val) 0.8529 |
Epoch 00185 | Loss(train) 0.5322 | Acc(train) 0.8166 | Acc(val) 0.8519 |
Epoch 00186 | Loss(train) 0.5357 | Acc(train) 0.8123 | Acc(val) 0.8499 |
Epoch 00187 | Loss(train) 0.5325 | Acc(train) 0.8149 | Acc(val) 0.8489 |
Epoch 00188 | Loss(train) 0.5284 | Acc(train) 0.8095 | Acc(val) 0.8529 |
Epoch 00189 | Loss(train) 0.5281 | Acc(train) 0.8088 | Acc(val) 0.8545 |*
Epoch 00190 | Loss(train) 0.5298 | Acc(train) 0.8156 | Acc(val) 0.8545 |
Epoch 00191 | Loss(train) 0.5308 | Acc(train) 0.8093 | Acc(val) 0.8540 |
Epoch 00192 | Loss(train) 0.5280 | Acc(train) 0.8123 | Acc(val) 0.8494 |
Epoch 00193 | Loss(train) 0.5235 | Acc(train) 0.8187 | Acc(val) 0.8489 |
Epoch 00194 | Loss(train) 0.5205 | Acc(train) 0.8220 | Acc(val) 0.8489 |
Epoch 00195 | Loss(train) 0.5253 | Acc(train) 0.8159 | Acc(val) 0.8540 |
Epoch 00196 | Loss(train) 0.5230 | Acc(train) 0.8174 | Acc(val) 0.8560 |*
Epoch 00197 | Loss(train) 0.5231 | Acc(train) 0.8207 | Acc(val) 0.8565 |*
Epoch 00198 | Loss(train) 0.5218 | Acc(train) 0.8159 | Acc(val) 0.8524 |
Epoch 00199 | Loss(train) 0.5183 | Acc(train) 0.8179 | Acc(val) 0.8504 |
Epoch 00200 | Loss(train) 0.5205 | Acc(train) 0.8189 | Acc(val) 0.8499 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0982 | Acc(train) 0.3591 | Acc(val) 0.5527 |*
Epoch 00002 | Loss(train) 1.0883 | Acc(train) 0.4897 | Acc(val) 0.6263 |*
Epoch 00003 | Loss(train) 1.0788 | Acc(train) 0.5308 | Acc(val) 0.5573 |
Epoch 00004 | Loss(train) 1.0698 | Acc(train) 0.5080 | Acc(val) 0.4863 |
Epoch 00005 | Loss(train) 1.0603 | Acc(train) 0.4885 | Acc(val) 0.4883 |
Epoch 00006 | Loss(train) 1.0520 | Acc(train) 0.4978 | Acc(val) 0.5477 |
Epoch 00007 | Loss(train) 1.0423 | Acc(train) 0.5159 | Acc(val) 0.6029 |
Epoch 00008 | Loss(train) 1.0351 | Acc(train) 0.5369 | Acc(val) 0.6384 |*
Epoch 00009 | Loss(train) 1.0289 | Acc(train) 0.5321 | Acc(val) 0.6562 |*
Epoch 00010 | Loss(train) 1.0209 | Acc(train) 0.5493 | Acc(val) 0.6684 |*
Epoch 00011 | Loss(train) 1.0130 | Acc(train) 0.5663 | Acc(val) 0.6678 |
Epoch 00012 | Loss(train) 1.0071 | Acc(train) 0.5742 | Acc(val) 0.6704 |*
Epoch 00013 | Loss(train) 1.0014 | Acc(train) 0.5810 | Acc(val) 0.6684 |
Epoch 00014 | Loss(train) 0.9969 | Acc(train) 0.5683 | Acc(val) 0.6699 |
Epoch 00015 | Loss(train) 0.9867 | Acc(train) 0.5871 | Acc(val) 0.6719 |*
Epoch 00016 | Loss(train) 0.9799 | Acc(train) 0.6036 | Acc(val) 0.6724 |*
Epoch 00017 | Loss(train) 0.9724 | Acc(train) 0.5973 | Acc(val) 0.6719 |
Epoch 00018 | Loss(train) 0.9637 | Acc(train) 0.6097 | Acc(val) 0.6744 |*
Epoch 00019 | Loss(train) 0.9594 | Acc(train) 0.6094 | Acc(val) 0.6749 |*
Epoch 00020 | Loss(train) 0.9521 | Acc(train) 0.6049 | Acc(val) 0.6744 |
Epoch 00021 | Loss(train) 0.9430 | Acc(train) 0.6160 | Acc(val) 0.6770 |*
Epoch 00022 | Loss(train) 0.9352 | Acc(train) 0.6244 | Acc(val) 0.6770 |
Epoch 00023 | Loss(train) 0.9280 | Acc(train) 0.6188 | Acc(val) 0.6790 |*
Epoch 00024 | Loss(train) 0.9221 | Acc(train) 0.6191 | Acc(val) 0.6765 |
Epoch 00025 | Loss(train) 0.9152 | Acc(train) 0.6285 | Acc(val) 0.6780 |
Epoch 00026 | Loss(train) 0.9073 | Acc(train) 0.6282 | Acc(val) 0.6755 |
Epoch 00027 | Loss(train) 0.9010 | Acc(train) 0.6226 | Acc(val) 0.6755 |
Epoch 00028 | Loss(train) 0.8935 | Acc(train) 0.6219 | Acc(val) 0.6770 |
Epoch 00029 | Loss(train) 0.8856 | Acc(train) 0.6292 | Acc(val) 0.6800 |*
Epoch 00030 | Loss(train) 0.8792 | Acc(train) 0.6358 | Acc(val) 0.6795 |
Epoch 00031 | Loss(train) 0.8700 | Acc(train) 0.6343 | Acc(val) 0.6826 |*
Epoch 00032 | Loss(train) 0.8630 | Acc(train) 0.6376 | Acc(val) 0.6831 |*
Epoch 00033 | Loss(train) 0.8549 | Acc(train) 0.6409 | Acc(val) 0.6866 |*
Epoch 00034 | Loss(train) 0.8516 | Acc(train) 0.6366 | Acc(val) 0.6881 |*
Epoch 00035 | Loss(train) 0.8431 | Acc(train) 0.6457 | Acc(val) 0.6897 |*
Epoch 00036 | Loss(train) 0.8336 | Acc(train) 0.6439 | Acc(val) 0.6917 |*
Epoch 00037 | Loss(train) 0.8264 | Acc(train) 0.6551 | Acc(val) 0.6937 |*
Epoch 00038 | Loss(train) 0.8268 | Acc(train) 0.6424 | Acc(val) 0.6947 |*
Epoch 00039 | Loss(train) 0.8131 | Acc(train) 0.6493 | Acc(val) 0.6973 |*
Epoch 00040 | Loss(train) 0.8060 | Acc(train) 0.6569 | Acc(val) 0.6983 |*
Epoch 00041 | Loss(train) 0.7999 | Acc(train) 0.6584 | Acc(val) 0.7003 |*
Epoch 00042 | Loss(train) 0.7981 | Acc(train) 0.6571 | Acc(val) 0.7044 |*
Epoch 00043 | Loss(train) 0.7918 | Acc(train) 0.6617 | Acc(val) 0.7064 |*
Epoch 00044 | Loss(train) 0.7808 | Acc(train) 0.6810 | Acc(val) 0.7181 |*
Epoch 00045 | Loss(train) 0.7728 | Acc(train) 0.6802 | Acc(val) 0.7343 |*
Epoch 00046 | Loss(train) 0.7752 | Acc(train) 0.7007 | Acc(val) 0.7480 |*
Epoch 00047 | Loss(train) 0.7626 | Acc(train) 0.7175 | Acc(val) 0.7576 |*
Epoch 00048 | Loss(train) 0.7535 | Acc(train) 0.7243 | Acc(val) 0.7632 |*
Epoch 00049 | Loss(train) 0.7489 | Acc(train) 0.7314 | Acc(val) 0.7713 |*
Epoch 00050 | Loss(train) 0.7470 | Acc(train) 0.7279 | Acc(val) 0.7809 |*
Epoch 00051 | Loss(train) 0.7360 | Acc(train) 0.7438 | Acc(val) 0.7921 |*
Epoch 00052 | Loss(train) 0.7311 | Acc(train) 0.7393 | Acc(val) 0.7992 |*
Epoch 00053 | Loss(train) 0.7271 | Acc(train) 0.7535 | Acc(val) 0.8063 |*
Epoch 00054 | Loss(train) 0.7196 | Acc(train) 0.7522 | Acc(val) 0.8093 |*
Epoch 00055 | Loss(train) 0.7126 | Acc(train) 0.7624 | Acc(val) 0.8124 |*
Epoch 00056 | Loss(train) 0.7088 | Acc(train) 0.7652 | Acc(val) 0.8149 |*
Epoch 00057 | Loss(train) 0.7036 | Acc(train) 0.7667 | Acc(val) 0.8195 |*
Epoch 00058 | Loss(train) 0.6933 | Acc(train) 0.7748 | Acc(val) 0.8225 |*
Epoch 00059 | Loss(train) 0.6912 | Acc(train) 0.7728 | Acc(val) 0.8235 |*
Epoch 00060 | Loss(train) 0.6916 | Acc(train) 0.7659 | Acc(val) 0.8256 |*
Epoch 00061 | Loss(train) 0.6904 | Acc(train) 0.7674 | Acc(val) 0.8266 |*
Epoch 00062 | Loss(train) 0.6755 | Acc(train) 0.7819 | Acc(val) 0.8286 |*
Epoch 00063 | Loss(train) 0.6731 | Acc(train) 0.7811 | Acc(val) 0.8311 |*
Epoch 00064 | Loss(train) 0.6761 | Acc(train) 0.7788 | Acc(val) 0.8327 |*
Epoch 00065 | Loss(train) 0.6662 | Acc(train) 0.7859 | Acc(val) 0.8347 |*
Epoch 00066 | Loss(train) 0.6588 | Acc(train) 0.7905 | Acc(val) 0.8352 |*
Epoch 00067 | Loss(train) 0.6588 | Acc(train) 0.7943 | Acc(val) 0.8352 |
Epoch 00068 | Loss(train) 0.6520 | Acc(train) 0.7933 | Acc(val) 0.8372 |*
Epoch 00069 | Loss(train) 0.6443 | Acc(train) 0.7925 | Acc(val) 0.8382 |*
Epoch 00070 | Loss(train) 0.6407 | Acc(train) 0.8019 | Acc(val) 0.8387 |*
Epoch 00071 | Loss(train) 0.6413 | Acc(train) 0.7966 | Acc(val) 0.8387 |
Epoch 00072 | Loss(train) 0.6380 | Acc(train) 0.7981 | Acc(val) 0.8392 |*
Epoch 00073 | Loss(train) 0.6413 | Acc(train) 0.7918 | Acc(val) 0.8398 |*
Epoch 00074 | Loss(train) 0.6304 | Acc(train) 0.8057 | Acc(val) 0.8387 |
Epoch 00075 | Loss(train) 0.6186 | Acc(train) 0.8098 | Acc(val) 0.8392 |
Epoch 00076 | Loss(train) 0.6208 | Acc(train) 0.8090 | Acc(val) 0.8398 |
Epoch 00077 | Loss(train) 0.6153 | Acc(train) 0.8075 | Acc(val) 0.8413 |*
Epoch 00078 | Loss(train) 0.6154 | Acc(train) 0.8095 | Acc(val) 0.8423 |*
Epoch 00079 | Loss(train) 0.6103 | Acc(train) 0.8057 | Acc(val) 0.8428 |*
Epoch 00080 | Loss(train) 0.6131 | Acc(train) 0.8073 | Acc(val) 0.8423 |
Epoch 00081 | Loss(train) 0.6107 | Acc(train) 0.8118 | Acc(val) 0.8403 |
Epoch 00082 | Loss(train) 0.6105 | Acc(train) 0.8024 | Acc(val) 0.8377 |
Epoch 00083 | Loss(train) 0.6117 | Acc(train) 0.8057 | Acc(val) 0.8377 |
Epoch 00084 | Loss(train) 0.5983 | Acc(train) 0.8156 | Acc(val) 0.8448 |*
Epoch 00085 | Loss(train) 0.5914 | Acc(train) 0.8197 | Acc(val) 0.8453 |*
Epoch 00086 | Loss(train) 0.5929 | Acc(train) 0.8161 | Acc(val) 0.8453 |
Epoch 00087 | Loss(train) 0.5943 | Acc(train) 0.8169 | Acc(val) 0.8474 |*
Epoch 00088 | Loss(train) 0.5880 | Acc(train) 0.8151 | Acc(val) 0.8469 |
Epoch 00089 | Loss(train) 0.5877 | Acc(train) 0.8131 | Acc(val) 0.8453 |
Epoch 00090 | Loss(train) 0.5919 | Acc(train) 0.8154 | Acc(val) 0.8474 |
Epoch 00091 | Loss(train) 0.5766 | Acc(train) 0.8131 | Acc(val) 0.8489 |*
Epoch 00092 | Loss(train) 0.5775 | Acc(train) 0.8146 | Acc(val) 0.8494 |*
Epoch 00093 | Loss(train) 0.5761 | Acc(train) 0.8174 | Acc(val) 0.8489 |
Epoch 00094 | Loss(train) 0.5763 | Acc(train) 0.8245 | Acc(val) 0.8494 |
Epoch 00095 | Loss(train) 0.5754 | Acc(train) 0.8166 | Acc(val) 0.8494 |
Epoch 00096 | Loss(train) 0.5710 | Acc(train) 0.8220 | Acc(val) 0.8494 |
Epoch 00097 | Loss(train) 0.5713 | Acc(train) 0.8280 | Acc(val) 0.8494 |
Epoch 00098 | Loss(train) 0.5595 | Acc(train) 0.8329 | Acc(val) 0.8504 |*
Epoch 00099 | Loss(train) 0.5659 | Acc(train) 0.8265 | Acc(val) 0.8494 |
Epoch 00100 | Loss(train) 0.5605 | Acc(train) 0.8275 | Acc(val) 0.8504 |
Epoch 00101 | Loss(train) 0.5624 | Acc(train) 0.8258 | Acc(val) 0.8504 |
Epoch 00102 | Loss(train) 0.5546 | Acc(train) 0.8283 | Acc(val) 0.8494 |
Epoch 00103 | Loss(train) 0.5561 | Acc(train) 0.8319 | Acc(val) 0.8499 |
Epoch 00104 | Loss(train) 0.5585 | Acc(train) 0.8321 | Acc(val) 0.8499 |
Epoch 00105 | Loss(train) 0.5558 | Acc(train) 0.8293 | Acc(val) 0.8489 |
Epoch 00106 | Loss(train) 0.5524 | Acc(train) 0.8311 | Acc(val) 0.8519 |*
Epoch 00107 | Loss(train) 0.5441 | Acc(train) 0.8352 | Acc(val) 0.8524 |*
Epoch 00108 | Loss(train) 0.5571 | Acc(train) 0.8230 | Acc(val) 0.8504 |
Epoch 00109 | Loss(train) 0.5524 | Acc(train) 0.8367 | Acc(val) 0.8479 |
Epoch 00110 | Loss(train) 0.5497 | Acc(train) 0.8311 | Acc(val) 0.8489 |
Epoch 00111 | Loss(train) 0.5493 | Acc(train) 0.8311 | Acc(val) 0.8504 |
Epoch 00112 | Loss(train) 0.5366 | Acc(train) 0.8372 | Acc(val) 0.8514 |
Epoch 00113 | Loss(train) 0.5336 | Acc(train) 0.8349 | Acc(val) 0.8504 |
Epoch 00114 | Loss(train) 0.5433 | Acc(train) 0.8306 | Acc(val) 0.8514 |
Epoch 00115 | Loss(train) 0.5402 | Acc(train) 0.8311 | Acc(val) 0.8514 |
Epoch 00116 | Loss(train) 0.5307 | Acc(train) 0.8346 | Acc(val) 0.8504 |
Epoch 00117 | Loss(train) 0.5281 | Acc(train) 0.8362 | Acc(val) 0.8484 |
Epoch 00118 | Loss(train) 0.5338 | Acc(train) 0.8369 | Acc(val) 0.8494 |
Epoch 00119 | Loss(train) 0.5348 | Acc(train) 0.8303 | Acc(val) 0.8519 |
Epoch 00120 | Loss(train) 0.5303 | Acc(train) 0.8412 | Acc(val) 0.8519 |
Epoch 00121 | Loss(train) 0.5318 | Acc(train) 0.8339 | Acc(val) 0.8519 |
Epoch 00122 | Loss(train) 0.5325 | Acc(train) 0.8319 | Acc(val) 0.8509 |
Epoch 00123 | Loss(train) 0.5313 | Acc(train) 0.8326 | Acc(val) 0.8514 |
Epoch 00124 | Loss(train) 0.5256 | Acc(train) 0.8344 | Acc(val) 0.8524 |
Epoch 00125 | Loss(train) 0.5277 | Acc(train) 0.8354 | Acc(val) 0.8534 |*
Epoch 00126 | Loss(train) 0.5229 | Acc(train) 0.8395 | Acc(val) 0.8534 |
Epoch 00127 | Loss(train) 0.5231 | Acc(train) 0.8374 | Acc(val) 0.8529 |
Epoch 00128 | Loss(train) 0.5155 | Acc(train) 0.8428 | Acc(val) 0.8519 |
Epoch 00129 | Loss(train) 0.5126 | Acc(train) 0.8400 | Acc(val) 0.8509 |
Epoch 00130 | Loss(train) 0.5170 | Acc(train) 0.8384 | Acc(val) 0.8524 |
Epoch 00131 | Loss(train) 0.5093 | Acc(train) 0.8405 | Acc(val) 0.8524 |
Epoch 00132 | Loss(train) 0.5146 | Acc(train) 0.8357 | Acc(val) 0.8560 |*
Epoch 00133 | Loss(train) 0.5183 | Acc(train) 0.8392 | Acc(val) 0.8565 |*
Epoch 00134 | Loss(train) 0.5176 | Acc(train) 0.8402 | Acc(val) 0.8560 |
Epoch 00135 | Loss(train) 0.5131 | Acc(train) 0.8423 | Acc(val) 0.8540 |
Epoch 00136 | Loss(train) 0.5106 | Acc(train) 0.8369 | Acc(val) 0.8560 |
Epoch 00137 | Loss(train) 0.5134 | Acc(train) 0.8455 | Acc(val) 0.8550 |
Epoch 00138 | Loss(train) 0.5070 | Acc(train) 0.8379 | Acc(val) 0.8570 |*
Epoch 00139 | Loss(train) 0.5004 | Acc(train) 0.8423 | Acc(val) 0.8590 |*
Epoch 00140 | Loss(train) 0.5126 | Acc(train) 0.8344 | Acc(val) 0.8575 |
Epoch 00141 | Loss(train) 0.5094 | Acc(train) 0.8463 | Acc(val) 0.8565 |
Epoch 00142 | Loss(train) 0.5024 | Acc(train) 0.8501 | Acc(val) 0.8555 |
Epoch 00143 | Loss(train) 0.5098 | Acc(train) 0.8392 | Acc(val) 0.8570 |
Epoch 00144 | Loss(train) 0.5139 | Acc(train) 0.8316 | Acc(val) 0.8585 |
Epoch 00145 | Loss(train) 0.5086 | Acc(train) 0.8478 | Acc(val) 0.8590 |
Epoch 00146 | Loss(train) 0.5068 | Acc(train) 0.8450 | Acc(val) 0.8585 |
Epoch 00147 | Loss(train) 0.5029 | Acc(train) 0.8486 | Acc(val) 0.8560 |
Epoch 00148 | Loss(train) 0.5042 | Acc(train) 0.8392 | Acc(val) 0.8560 |
Epoch 00149 | Loss(train) 0.5085 | Acc(train) 0.8382 | Acc(val) 0.8585 |
Epoch 00150 | Loss(train) 0.5031 | Acc(train) 0.8395 | Acc(val) 0.8611 |*
Epoch 00151 | Loss(train) 0.5032 | Acc(train) 0.8435 | Acc(val) 0.8590 |
Epoch 00152 | Loss(train) 0.4977 | Acc(train) 0.8395 | Acc(val) 0.8575 |
Epoch 00153 | Loss(train) 0.5007 | Acc(train) 0.8425 | Acc(val) 0.8575 |
Epoch 00154 | Loss(train) 0.4973 | Acc(train) 0.8448 | Acc(val) 0.8585 |
Epoch 00155 | Loss(train) 0.4980 | Acc(train) 0.8415 | Acc(val) 0.8580 |
Epoch 00156 | Loss(train) 0.5021 | Acc(train) 0.8390 | Acc(val) 0.8585 |
Epoch 00157 | Loss(train) 0.4954 | Acc(train) 0.8392 | Acc(val) 0.8570 |
Epoch 00158 | Loss(train) 0.4932 | Acc(train) 0.8402 | Acc(val) 0.8575 |
Epoch 00159 | Loss(train) 0.5000 | Acc(train) 0.8463 | Acc(val) 0.8595 |
Epoch 00160 | Loss(train) 0.4929 | Acc(train) 0.8466 | Acc(val) 0.8605 |
Epoch 00161 | Loss(train) 0.4914 | Acc(train) 0.8478 | Acc(val) 0.8605 |
Epoch 00162 | Loss(train) 0.4944 | Acc(train) 0.8463 | Acc(val) 0.8631 |*
Epoch 00163 | Loss(train) 0.4912 | Acc(train) 0.8407 | Acc(val) 0.8616 |
Epoch 00164 | Loss(train) 0.4946 | Acc(train) 0.8488 | Acc(val) 0.8600 |
Epoch 00165 | Loss(train) 0.4886 | Acc(train) 0.8478 | Acc(val) 0.8580 |
Epoch 00166 | Loss(train) 0.4842 | Acc(train) 0.8483 | Acc(val) 0.8590 |
Epoch 00167 | Loss(train) 0.4896 | Acc(train) 0.8412 | Acc(val) 0.8626 |
Epoch 00168 | Loss(train) 0.4813 | Acc(train) 0.8392 | Acc(val) 0.8626 |
Epoch 00169 | Loss(train) 0.4782 | Acc(train) 0.8547 | Acc(val) 0.8631 |
Epoch 00170 | Loss(train) 0.4896 | Acc(train) 0.8547 | Acc(val) 0.8646 |*
Epoch 00171 | Loss(train) 0.4865 | Acc(train) 0.8481 | Acc(val) 0.8595 |
Epoch 00172 | Loss(train) 0.4802 | Acc(train) 0.8473 | Acc(val) 0.8595 |
Epoch 00173 | Loss(train) 0.4785 | Acc(train) 0.8461 | Acc(val) 0.8626 |
Epoch 00174 | Loss(train) 0.4905 | Acc(train) 0.8496 | Acc(val) 0.8646 |
Epoch 00175 | Loss(train) 0.4779 | Acc(train) 0.8466 | Acc(val) 0.8661 |*
Epoch 00176 | Loss(train) 0.4843 | Acc(train) 0.8478 | Acc(val) 0.8636 |
Epoch 00177 | Loss(train) 0.4766 | Acc(train) 0.8478 | Acc(val) 0.8631 |
Epoch 00178 | Loss(train) 0.4842 | Acc(train) 0.8455 | Acc(val) 0.8651 |
Epoch 00179 | Loss(train) 0.4820 | Acc(train) 0.8486 | Acc(val) 0.8641 |
Epoch 00180 | Loss(train) 0.4818 | Acc(train) 0.8481 | Acc(val) 0.8641 |
Epoch 00181 | Loss(train) 0.4751 | Acc(train) 0.8486 | Acc(val) 0.8656 |
Epoch 00182 | Loss(train) 0.4829 | Acc(train) 0.8435 | Acc(val) 0.8661 |
Epoch 00183 | Loss(train) 0.4808 | Acc(train) 0.8468 | Acc(val) 0.8641 |
Epoch 00184 | Loss(train) 0.4775 | Acc(train) 0.8453 | Acc(val) 0.8646 |
Epoch 00185 | Loss(train) 0.4787 | Acc(train) 0.8494 | Acc(val) 0.8656 |
Epoch 00186 | Loss(train) 0.4754 | Acc(train) 0.8504 | Acc(val) 0.8641 |
Epoch 00187 | Loss(train) 0.4819 | Acc(train) 0.8537 | Acc(val) 0.8641 |
Epoch 00188 | Loss(train) 0.4806 | Acc(train) 0.8488 | Acc(val) 0.8646 |
Epoch 00189 | Loss(train) 0.4806 | Acc(train) 0.8473 | Acc(val) 0.8646 |
Epoch 00190 | Loss(train) 0.4684 | Acc(train) 0.8486 | Acc(val) 0.8656 |
Epoch 00191 | Loss(train) 0.4742 | Acc(train) 0.8519 | Acc(val) 0.8636 |
Epoch 00192 | Loss(train) 0.4712 | Acc(train) 0.8463 | Acc(val) 0.8646 |
Epoch 00193 | Loss(train) 0.4707 | Acc(train) 0.8473 | Acc(val) 0.8651 |
Epoch 00194 | Loss(train) 0.4666 | Acc(train) 0.8554 | Acc(val) 0.8661 |
Epoch 00195 | Loss(train) 0.4680 | Acc(train) 0.8537 | Acc(val) 0.8651 |
Epoch 00196 | Loss(train) 0.4699 | Acc(train) 0.8488 | Acc(val) 0.8641 |
Epoch 00197 | Loss(train) 0.4710 | Acc(train) 0.8524 | Acc(val) 0.8646 |
Epoch 00198 | Loss(train) 0.4745 | Acc(train) 0.8516 | Acc(val) 0.8646 |
Epoch 00199 | Loss(train) 0.4659 | Acc(train) 0.8549 | Acc(val) 0.8671 |*
Epoch 00200 | Loss(train) 0.4771 | Acc(train) 0.8466 | Acc(val) 0.8676 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0979 | Acc(train) 0.4240 | Acc(val) 0.5406 |*
Epoch 00002 | Loss(train) 1.0884 | Acc(train) 0.4989 | Acc(val) 0.5710 |*
Epoch 00003 | Loss(train) 1.0790 | Acc(train) 0.5176 | Acc(val) 0.5974 |*
Epoch 00004 | Loss(train) 1.0687 | Acc(train) 0.5323 | Acc(val) 0.6009 |*
Epoch 00005 | Loss(train) 1.0596 | Acc(train) 0.5252 | Acc(val) 0.6126 |*
Epoch 00006 | Loss(train) 1.0501 | Acc(train) 0.5379 | Acc(val) 0.6313 |*
Epoch 00007 | Loss(train) 1.0409 | Acc(train) 0.5496 | Acc(val) 0.6521 |*
Epoch 00008 | Loss(train) 1.0330 | Acc(train) 0.5590 | Acc(val) 0.6562 |*
Epoch 00009 | Loss(train) 1.0244 | Acc(train) 0.5526 | Acc(val) 0.6668 |*
Epoch 00010 | Loss(train) 1.0177 | Acc(train) 0.5554 | Acc(val) 0.6699 |*
Epoch 00011 | Loss(train) 1.0110 | Acc(train) 0.5572 | Acc(val) 0.6694 |
Epoch 00012 | Loss(train) 1.0044 | Acc(train) 0.5628 | Acc(val) 0.6699 |
Epoch 00013 | Loss(train) 0.9986 | Acc(train) 0.5635 | Acc(val) 0.6704 |*
Epoch 00014 | Loss(train) 0.9891 | Acc(train) 0.5689 | Acc(val) 0.6714 |*
Epoch 00015 | Loss(train) 0.9825 | Acc(train) 0.5704 | Acc(val) 0.6749 |*
Epoch 00016 | Loss(train) 0.9714 | Acc(train) 0.5874 | Acc(val) 0.6749 |
Epoch 00017 | Loss(train) 0.9639 | Acc(train) 0.5891 | Acc(val) 0.6729 |
Epoch 00018 | Loss(train) 0.9555 | Acc(train) 0.5947 | Acc(val) 0.6714 |
Epoch 00019 | Loss(train) 0.9473 | Acc(train) 0.6006 | Acc(val) 0.6805 |*
Epoch 00020 | Loss(train) 0.9370 | Acc(train) 0.6153 | Acc(val) 0.6993 |*
Epoch 00021 | Loss(train) 0.9295 | Acc(train) 0.6292 | Acc(val) 0.7181 |*
Epoch 00022 | Loss(train) 0.9190 | Acc(train) 0.6495 | Acc(val) 0.7338 |*
Epoch 00023 | Loss(train) 0.9121 | Acc(train) 0.6685 | Acc(val) 0.7485 |*
Epoch 00024 | Loss(train) 0.8998 | Acc(train) 0.6802 | Acc(val) 0.7581 |*
Epoch 00025 | Loss(train) 0.8948 | Acc(train) 0.6820 | Acc(val) 0.7642 |*
Epoch 00026 | Loss(train) 0.8830 | Acc(train) 0.6924 | Acc(val) 0.7708 |*
Epoch 00027 | Loss(train) 0.8777 | Acc(train) 0.6896 | Acc(val) 0.7774 |*
Epoch 00028 | Loss(train) 0.8704 | Acc(train) 0.7020 | Acc(val) 0.7825 |*
Epoch 00029 | Loss(train) 0.8576 | Acc(train) 0.6949 | Acc(val) 0.7885 |*
Epoch 00030 | Loss(train) 0.8484 | Acc(train) 0.7094 | Acc(val) 0.7921 |*
Epoch 00031 | Loss(train) 0.8372 | Acc(train) 0.7091 | Acc(val) 0.7967 |*
Epoch 00032 | Loss(train) 0.8308 | Acc(train) 0.7147 | Acc(val) 0.7982 |*
Epoch 00033 | Loss(train) 0.8166 | Acc(train) 0.7213 | Acc(val) 0.8012 |*
Epoch 00034 | Loss(train) 0.8096 | Acc(train) 0.7269 | Acc(val) 0.8002 |
Epoch 00035 | Loss(train) 0.8008 | Acc(train) 0.7395 | Acc(val) 0.8017 |*
Epoch 00036 | Loss(train) 0.7909 | Acc(train) 0.7466 | Acc(val) 0.8048 |*
Epoch 00037 | Loss(train) 0.7852 | Acc(train) 0.7403 | Acc(val) 0.8083 |*
Epoch 00038 | Loss(train) 0.7730 | Acc(train) 0.7504 | Acc(val) 0.8103 |*
Epoch 00039 | Loss(train) 0.7719 | Acc(train) 0.7423 | Acc(val) 0.8124 |*
Epoch 00040 | Loss(train) 0.7609 | Acc(train) 0.7454 | Acc(val) 0.8124 |
Epoch 00041 | Loss(train) 0.7551 | Acc(train) 0.7423 | Acc(val) 0.8144 |*
Epoch 00042 | Loss(train) 0.7482 | Acc(train) 0.7512 | Acc(val) 0.8149 |*
Epoch 00043 | Loss(train) 0.7385 | Acc(train) 0.7644 | Acc(val) 0.8159 |*
Epoch 00044 | Loss(train) 0.7265 | Acc(train) 0.7679 | Acc(val) 0.8154 |
Epoch 00045 | Loss(train) 0.7185 | Acc(train) 0.7705 | Acc(val) 0.8149 |
Epoch 00046 | Loss(train) 0.7202 | Acc(train) 0.7646 | Acc(val) 0.8149 |
Epoch 00047 | Loss(train) 0.7078 | Acc(train) 0.7692 | Acc(val) 0.8144 |
Epoch 00048 | Loss(train) 0.7015 | Acc(train) 0.7667 | Acc(val) 0.8169 |*
Epoch 00049 | Loss(train) 0.6998 | Acc(train) 0.7646 | Acc(val) 0.8195 |*
Epoch 00050 | Loss(train) 0.6910 | Acc(train) 0.7753 | Acc(val) 0.8245 |*
Epoch 00051 | Loss(train) 0.6840 | Acc(train) 0.7738 | Acc(val) 0.8271 |*
Epoch 00052 | Loss(train) 0.6780 | Acc(train) 0.7839 | Acc(val) 0.8276 |*
Epoch 00053 | Loss(train) 0.6701 | Acc(train) 0.7865 | Acc(val) 0.8266 |
Epoch 00054 | Loss(train) 0.6696 | Acc(train) 0.7900 | Acc(val) 0.8281 |*
Epoch 00055 | Loss(train) 0.6648 | Acc(train) 0.7847 | Acc(val) 0.8291 |*
Epoch 00056 | Loss(train) 0.6617 | Acc(train) 0.7811 | Acc(val) 0.8306 |*
Epoch 00057 | Loss(train) 0.6578 | Acc(train) 0.7827 | Acc(val) 0.8311 |*
Epoch 00058 | Loss(train) 0.6513 | Acc(train) 0.7827 | Acc(val) 0.8327 |*
Epoch 00059 | Loss(train) 0.6465 | Acc(train) 0.7887 | Acc(val) 0.8327 |
Epoch 00060 | Loss(train) 0.6438 | Acc(train) 0.7905 | Acc(val) 0.8352 |*
Epoch 00061 | Loss(train) 0.6347 | Acc(train) 0.7989 | Acc(val) 0.8352 |
Epoch 00062 | Loss(train) 0.6394 | Acc(train) 0.7928 | Acc(val) 0.8382 |*
Epoch 00063 | Loss(train) 0.6327 | Acc(train) 0.7974 | Acc(val) 0.8382 |
Epoch 00064 | Loss(train) 0.6269 | Acc(train) 0.8032 | Acc(val) 0.8382 |
Epoch 00065 | Loss(train) 0.6273 | Acc(train) 0.7953 | Acc(val) 0.8367 |
Epoch 00066 | Loss(train) 0.6165 | Acc(train) 0.8019 | Acc(val) 0.8387 |*
Epoch 00067 | Loss(train) 0.6155 | Acc(train) 0.7984 | Acc(val) 0.8413 |*
Epoch 00068 | Loss(train) 0.6128 | Acc(train) 0.8045 | Acc(val) 0.8382 |
Epoch 00069 | Loss(train) 0.6088 | Acc(train) 0.8050 | Acc(val) 0.8413 |
Epoch 00070 | Loss(train) 0.6031 | Acc(train) 0.8090 | Acc(val) 0.8413 |
Epoch 00071 | Loss(train) 0.6022 | Acc(train) 0.8032 | Acc(val) 0.8413 |
Epoch 00072 | Loss(train) 0.6000 | Acc(train) 0.8088 | Acc(val) 0.8403 |
Epoch 00073 | Loss(train) 0.5913 | Acc(train) 0.8121 | Acc(val) 0.8408 |
Epoch 00074 | Loss(train) 0.5905 | Acc(train) 0.8080 | Acc(val) 0.8418 |*
Epoch 00075 | Loss(train) 0.5832 | Acc(train) 0.8126 | Acc(val) 0.8423 |*
Epoch 00076 | Loss(train) 0.5869 | Acc(train) 0.8136 | Acc(val) 0.8418 |
Epoch 00077 | Loss(train) 0.5905 | Acc(train) 0.8128 | Acc(val) 0.8428 |*
Epoch 00078 | Loss(train) 0.5811 | Acc(train) 0.8161 | Acc(val) 0.8438 |*
Epoch 00079 | Loss(train) 0.5775 | Acc(train) 0.8197 | Acc(val) 0.8433 |
Epoch 00080 | Loss(train) 0.5738 | Acc(train) 0.8151 | Acc(val) 0.8428 |
Epoch 00081 | Loss(train) 0.5717 | Acc(train) 0.8156 | Acc(val) 0.8438 |
Epoch 00082 | Loss(train) 0.5762 | Acc(train) 0.8192 | Acc(val) 0.8443 |*
Epoch 00083 | Loss(train) 0.5674 | Acc(train) 0.8169 | Acc(val) 0.8453 |*
Epoch 00084 | Loss(train) 0.5692 | Acc(train) 0.8187 | Acc(val) 0.8428 |
Epoch 00085 | Loss(train) 0.5618 | Acc(train) 0.8265 | Acc(val) 0.8443 |
Epoch 00086 | Loss(train) 0.5567 | Acc(train) 0.8273 | Acc(val) 0.8474 |*
Epoch 00087 | Loss(train) 0.5604 | Acc(train) 0.8192 | Acc(val) 0.8448 |
Epoch 00088 | Loss(train) 0.5560 | Acc(train) 0.8293 | Acc(val) 0.8443 |
Epoch 00089 | Loss(train) 0.5568 | Acc(train) 0.8293 | Acc(val) 0.8448 |
Epoch 00090 | Loss(train) 0.5539 | Acc(train) 0.8316 | Acc(val) 0.8453 |
Epoch 00091 | Loss(train) 0.5522 | Acc(train) 0.8250 | Acc(val) 0.8453 |
Epoch 00092 | Loss(train) 0.5514 | Acc(train) 0.8258 | Acc(val) 0.8463 |
Epoch 00093 | Loss(train) 0.5469 | Acc(train) 0.8245 | Acc(val) 0.8484 |*
Epoch 00094 | Loss(train) 0.5450 | Acc(train) 0.8283 | Acc(val) 0.8534 |*
Epoch 00095 | Loss(train) 0.5501 | Acc(train) 0.8255 | Acc(val) 0.8519 |
Epoch 00096 | Loss(train) 0.5481 | Acc(train) 0.8288 | Acc(val) 0.8479 |
Epoch 00097 | Loss(train) 0.5380 | Acc(train) 0.8336 | Acc(val) 0.8474 |
Epoch 00098 | Loss(train) 0.5388 | Acc(train) 0.8263 | Acc(val) 0.8479 |
Epoch 00099 | Loss(train) 0.5341 | Acc(train) 0.8291 | Acc(val) 0.8504 |
Epoch 00100 | Loss(train) 0.5405 | Acc(train) 0.8359 | Acc(val) 0.8529 |
Epoch 00101 | Loss(train) 0.5351 | Acc(train) 0.8253 | Acc(val) 0.8534 |
Epoch 00102 | Loss(train) 0.5319 | Acc(train) 0.8288 | Acc(val) 0.8545 |*
Epoch 00103 | Loss(train) 0.5331 | Acc(train) 0.8270 | Acc(val) 0.8529 |
Epoch 00104 | Loss(train) 0.5317 | Acc(train) 0.8283 | Acc(val) 0.8524 |
Epoch 00105 | Loss(train) 0.5214 | Acc(train) 0.8420 | Acc(val) 0.8524 |
Epoch 00106 | Loss(train) 0.5263 | Acc(train) 0.8367 | Acc(val) 0.8534 |
Epoch 00107 | Loss(train) 0.5202 | Acc(train) 0.8410 | Acc(val) 0.8540 |
Epoch 00108 | Loss(train) 0.5226 | Acc(train) 0.8412 | Acc(val) 0.8545 |
Epoch 00109 | Loss(train) 0.5269 | Acc(train) 0.8298 | Acc(val) 0.8540 |
Epoch 00110 | Loss(train) 0.5152 | Acc(train) 0.8364 | Acc(val) 0.8534 |
Epoch 00111 | Loss(train) 0.5204 | Acc(train) 0.8410 | Acc(val) 0.8529 |
Epoch 00112 | Loss(train) 0.5229 | Acc(train) 0.8321 | Acc(val) 0.8529 |
Epoch 00113 | Loss(train) 0.5205 | Acc(train) 0.8331 | Acc(val) 0.8545 |
Epoch 00114 | Loss(train) 0.5125 | Acc(train) 0.8402 | Acc(val) 0.8534 |
Epoch 00115 | Loss(train) 0.5148 | Acc(train) 0.8364 | Acc(val) 0.8545 |
Epoch 00116 | Loss(train) 0.5137 | Acc(train) 0.8387 | Acc(val) 0.8545 |
Epoch 00117 | Loss(train) 0.5135 | Acc(train) 0.8331 | Acc(val) 0.8534 |
Epoch 00118 | Loss(train) 0.5105 | Acc(train) 0.8346 | Acc(val) 0.8534 |
Epoch 00119 | Loss(train) 0.5175 | Acc(train) 0.8362 | Acc(val) 0.8529 |
Epoch 00120 | Loss(train) 0.5125 | Acc(train) 0.8377 | Acc(val) 0.8534 |
Epoch 00121 | Loss(train) 0.5092 | Acc(train) 0.8410 | Acc(val) 0.8545 |
Epoch 00122 | Loss(train) 0.5039 | Acc(train) 0.8435 | Acc(val) 0.8555 |*
Epoch 00123 | Loss(train) 0.5075 | Acc(train) 0.8483 | Acc(val) 0.8570 |*
Epoch 00124 | Loss(train) 0.5064 | Acc(train) 0.8344 | Acc(val) 0.8540 |
Epoch 00125 | Loss(train) 0.5035 | Acc(train) 0.8433 | Acc(val) 0.8529 |
Epoch 00126 | Loss(train) 0.4957 | Acc(train) 0.8400 | Acc(val) 0.8545 |
Epoch 00127 | Loss(train) 0.5008 | Acc(train) 0.8392 | Acc(val) 0.8570 |
Epoch 00128 | Loss(train) 0.5005 | Acc(train) 0.8415 | Acc(val) 0.8575 |*
Epoch 00129 | Loss(train) 0.5001 | Acc(train) 0.8433 | Acc(val) 0.8565 |
Epoch 00130 | Loss(train) 0.5011 | Acc(train) 0.8395 | Acc(val) 0.8550 |
Epoch 00131 | Loss(train) 0.4928 | Acc(train) 0.8420 | Acc(val) 0.8540 |
Epoch 00132 | Loss(train) 0.4991 | Acc(train) 0.8359 | Acc(val) 0.8534 |
Epoch 00133 | Loss(train) 0.4897 | Acc(train) 0.8455 | Acc(val) 0.8565 |
Epoch 00134 | Loss(train) 0.4969 | Acc(train) 0.8420 | Acc(val) 0.8585 |*
Epoch 00135 | Loss(train) 0.4926 | Acc(train) 0.8445 | Acc(val) 0.8570 |
Epoch 00136 | Loss(train) 0.4943 | Acc(train) 0.8468 | Acc(val) 0.8560 |
Epoch 00137 | Loss(train) 0.4922 | Acc(train) 0.8455 | Acc(val) 0.8540 |
Epoch 00138 | Loss(train) 0.4850 | Acc(train) 0.8438 | Acc(val) 0.8550 |
Epoch 00139 | Loss(train) 0.4915 | Acc(train) 0.8412 | Acc(val) 0.8565 |
Epoch 00140 | Loss(train) 0.4930 | Acc(train) 0.8428 | Acc(val) 0.8570 |
Epoch 00141 | Loss(train) 0.4938 | Acc(train) 0.8420 | Acc(val) 0.8560 |
Epoch 00142 | Loss(train) 0.4884 | Acc(train) 0.8392 | Acc(val) 0.8560 |
Epoch 00143 | Loss(train) 0.4879 | Acc(train) 0.8448 | Acc(val) 0.8565 |
Epoch 00144 | Loss(train) 0.4918 | Acc(train) 0.8488 | Acc(val) 0.8570 |
Epoch 00145 | Loss(train) 0.4805 | Acc(train) 0.8445 | Acc(val) 0.8570 |
Epoch 00146 | Loss(train) 0.4886 | Acc(train) 0.8430 | Acc(val) 0.8565 |
Epoch 00147 | Loss(train) 0.4836 | Acc(train) 0.8461 | Acc(val) 0.8585 |
Epoch 00148 | Loss(train) 0.4828 | Acc(train) 0.8433 | Acc(val) 0.8570 |
Epoch 00149 | Loss(train) 0.4806 | Acc(train) 0.8471 | Acc(val) 0.8570 |
Epoch 00150 | Loss(train) 0.4846 | Acc(train) 0.8499 | Acc(val) 0.8555 |
Epoch 00151 | Loss(train) 0.4828 | Acc(train) 0.8415 | Acc(val) 0.8550 |
Epoch 00152 | Loss(train) 0.4785 | Acc(train) 0.8521 | Acc(val) 0.8605 |*
Epoch 00153 | Loss(train) 0.4801 | Acc(train) 0.8494 | Acc(val) 0.8605 |
Epoch 00154 | Loss(train) 0.4779 | Acc(train) 0.8481 | Acc(val) 0.8580 |
Epoch 00155 | Loss(train) 0.4768 | Acc(train) 0.8562 | Acc(val) 0.8550 |
Epoch 00156 | Loss(train) 0.4807 | Acc(train) 0.8390 | Acc(val) 0.8565 |
Epoch 00157 | Loss(train) 0.4774 | Acc(train) 0.8423 | Acc(val) 0.8590 |
Epoch 00158 | Loss(train) 0.4773 | Acc(train) 0.8478 | Acc(val) 0.8585 |
Epoch 00159 | Loss(train) 0.4742 | Acc(train) 0.8499 | Acc(val) 0.8590 |
Epoch 00160 | Loss(train) 0.4803 | Acc(train) 0.8468 | Acc(val) 0.8600 |
Epoch 00161 | Loss(train) 0.4750 | Acc(train) 0.8524 | Acc(val) 0.8565 |
Epoch 00162 | Loss(train) 0.4730 | Acc(train) 0.8514 | Acc(val) 0.8534 |
Epoch 00163 | Loss(train) 0.4759 | Acc(train) 0.8415 | Acc(val) 0.8560 |
Epoch 00164 | Loss(train) 0.4830 | Acc(train) 0.8425 | Acc(val) 0.8585 |
Epoch 00165 | Loss(train) 0.4697 | Acc(train) 0.8552 | Acc(val) 0.8590 |
Epoch 00166 | Loss(train) 0.4680 | Acc(train) 0.8542 | Acc(val) 0.8590 |
Epoch 00167 | Loss(train) 0.4757 | Acc(train) 0.8440 | Acc(val) 0.8590 |
Epoch 00168 | Loss(train) 0.4777 | Acc(train) 0.8483 | Acc(val) 0.8560 |
Epoch 00169 | Loss(train) 0.4664 | Acc(train) 0.8532 | Acc(val) 0.8555 |
Epoch 00170 | Loss(train) 0.4688 | Acc(train) 0.8483 | Acc(val) 0.8580 |
Epoch 00171 | Loss(train) 0.4707 | Acc(train) 0.8494 | Acc(val) 0.8590 |
Epoch 00172 | Loss(train) 0.4704 | Acc(train) 0.8461 | Acc(val) 0.8585 |
Epoch 00173 | Loss(train) 0.4660 | Acc(train) 0.8549 | Acc(val) 0.8600 |
Epoch 00174 | Loss(train) 0.4725 | Acc(train) 0.8496 | Acc(val) 0.8595 |
Epoch 00175 | Loss(train) 0.4642 | Acc(train) 0.8539 | Acc(val) 0.8585 |
Epoch 00176 | Loss(train) 0.4667 | Acc(train) 0.8514 | Acc(val) 0.8590 |
Epoch 00177 | Loss(train) 0.4660 | Acc(train) 0.8514 | Acc(val) 0.8605 |
Epoch 00178 | Loss(train) 0.4722 | Acc(train) 0.8529 | Acc(val) 0.8600 |
Epoch 00179 | Loss(train) 0.4704 | Acc(train) 0.8524 | Acc(val) 0.8590 |
Epoch 00180 | Loss(train) 0.4645 | Acc(train) 0.8544 | Acc(val) 0.8580 |
Epoch 00181 | Loss(train) 0.4603 | Acc(train) 0.8552 | Acc(val) 0.8595 |
Epoch 00182 | Loss(train) 0.4589 | Acc(train) 0.8529 | Acc(val) 0.8605 |
Epoch 00183 | Loss(train) 0.4633 | Acc(train) 0.8585 | Acc(val) 0.8585 |
Epoch 00184 | Loss(train) 0.4658 | Acc(train) 0.8453 | Acc(val) 0.8585 |
Epoch 00185 | Loss(train) 0.4670 | Acc(train) 0.8511 | Acc(val) 0.8595 |
Epoch 00186 | Loss(train) 0.4626 | Acc(train) 0.8534 | Acc(val) 0.8585 |
Epoch 00187 | Loss(train) 0.4665 | Acc(train) 0.8481 | Acc(val) 0.8595 |
Epoch 00188 | Loss(train) 0.4622 | Acc(train) 0.8511 | Acc(val) 0.8621 |*
Epoch 00189 | Loss(train) 0.4615 | Acc(train) 0.8473 | Acc(val) 0.8626 |*
Epoch 00190 | Loss(train) 0.4629 | Acc(train) 0.8491 | Acc(val) 0.8600 |
Epoch 00191 | Loss(train) 0.4591 | Acc(train) 0.8532 | Acc(val) 0.8590 |
Epoch 00192 | Loss(train) 0.4603 | Acc(train) 0.8516 | Acc(val) 0.8590 |
Epoch 00193 | Loss(train) 0.4525 | Acc(train) 0.8600 | Acc(val) 0.8600 |
Epoch 00194 | Loss(train) 0.4541 | Acc(train) 0.8519 | Acc(val) 0.8616 |
Epoch 00195 | Loss(train) 0.4580 | Acc(train) 0.8567 | Acc(val) 0.8621 |
Epoch 00196 | Loss(train) 0.4574 | Acc(train) 0.8496 | Acc(val) 0.8621 |
Epoch 00197 | Loss(train) 0.4549 | Acc(train) 0.8554 | Acc(val) 0.8611 |
Epoch 00198 | Loss(train) 0.4572 | Acc(train) 0.8514 | Acc(val) 0.8626 |
Epoch 00199 | Loss(train) 0.4515 | Acc(train) 0.8552 | Acc(val) 0.8621 |
Epoch 00200 | Loss(train) 0.4545 | Acc(train) 0.8504 | Acc(val) 0.8626 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.0986 | Acc(train) 0.3799 | Acc(val) 0.5401 |*
Epoch 00002 | Loss(train) 1.0888 | Acc(train) 0.5004 | Acc(val) 0.5355 |
Epoch 00003 | Loss(train) 1.0790 | Acc(train) 0.5077 | Acc(val) 0.5451 |*
Epoch 00004 | Loss(train) 1.0688 | Acc(train) 0.5252 | Acc(val) 0.5735 |*
Epoch 00005 | Loss(train) 1.0592 | Acc(train) 0.5318 | Acc(val) 0.5984 |*
Epoch 00006 | Loss(train) 1.0506 | Acc(train) 0.5339 | Acc(val) 0.6166 |*
Epoch 00007 | Loss(train) 1.0410 | Acc(train) 0.5554 | Acc(val) 0.6318 |*
Epoch 00008 | Loss(train) 1.0335 | Acc(train) 0.5554 | Acc(val) 0.6405 |*
Epoch 00009 | Loss(train) 1.0267 | Acc(train) 0.5557 | Acc(val) 0.6516 |*
Epoch 00010 | Loss(train) 1.0179 | Acc(train) 0.5605 | Acc(val) 0.6567 |*
Epoch 00011 | Loss(train) 1.0107 | Acc(train) 0.5734 | Acc(val) 0.6577 |*
Epoch 00012 | Loss(train) 1.0051 | Acc(train) 0.5676 | Acc(val) 0.6572 |
Epoch 00013 | Loss(train) 0.9995 | Acc(train) 0.5607 | Acc(val) 0.6587 |*
Epoch 00014 | Loss(train) 0.9904 | Acc(train) 0.5716 | Acc(val) 0.6592 |*
Epoch 00015 | Loss(train) 0.9819 | Acc(train) 0.5881 | Acc(val) 0.6597 |*
Epoch 00016 | Loss(train) 0.9767 | Acc(train) 0.5767 | Acc(val) 0.6597 |
Epoch 00017 | Loss(train) 0.9692 | Acc(train) 0.5876 | Acc(val) 0.6592 |
Epoch 00018 | Loss(train) 0.9618 | Acc(train) 0.5914 | Acc(val) 0.6587 |
Epoch 00019 | Loss(train) 0.9519 | Acc(train) 0.6036 | Acc(val) 0.6628 |*
Epoch 00020 | Loss(train) 0.9464 | Acc(train) 0.6016 | Acc(val) 0.6643 |*
Epoch 00021 | Loss(train) 0.9380 | Acc(train) 0.6018 | Acc(val) 0.6638 |
Epoch 00022 | Loss(train) 0.9313 | Acc(train) 0.6125 | Acc(val) 0.6628 |
Epoch 00023 | Loss(train) 0.9223 | Acc(train) 0.6193 | Acc(val) 0.6648 |*
Epoch 00024 | Loss(train) 0.9174 | Acc(train) 0.6061 | Acc(val) 0.6663 |*
Epoch 00025 | Loss(train) 0.9090 | Acc(train) 0.6104 | Acc(val) 0.6684 |*
Epoch 00026 | Loss(train) 0.8987 | Acc(train) 0.6148 | Acc(val) 0.6689 |*
Epoch 00027 | Loss(train) 0.8939 | Acc(train) 0.6206 | Acc(val) 0.6699 |*
Epoch 00028 | Loss(train) 0.8869 | Acc(train) 0.6193 | Acc(val) 0.6739 |*
Epoch 00029 | Loss(train) 0.8760 | Acc(train) 0.6236 | Acc(val) 0.6749 |*
Epoch 00030 | Loss(train) 0.8723 | Acc(train) 0.6231 | Acc(val) 0.6765 |*
Epoch 00031 | Loss(train) 0.8642 | Acc(train) 0.6325 | Acc(val) 0.6775 |*
Epoch 00032 | Loss(train) 0.8599 | Acc(train) 0.6231 | Acc(val) 0.6790 |*
Epoch 00033 | Loss(train) 0.8512 | Acc(train) 0.6366 | Acc(val) 0.6820 |*
Epoch 00034 | Loss(train) 0.8416 | Acc(train) 0.6452 | Acc(val) 0.6856 |*
Epoch 00035 | Loss(train) 0.8352 | Acc(train) 0.6505 | Acc(val) 0.6912 |*
Epoch 00036 | Loss(train) 0.8263 | Acc(train) 0.6662 | Acc(val) 0.6983 |*
Epoch 00037 | Loss(train) 0.8158 | Acc(train) 0.6787 | Acc(val) 0.7094 |*
Epoch 00038 | Loss(train) 0.8114 | Acc(train) 0.6832 | Acc(val) 0.7282 |*
Epoch 00039 | Loss(train) 0.8069 | Acc(train) 0.6837 | Acc(val) 0.7429 |*
Epoch 00040 | Loss(train) 0.7954 | Acc(train) 0.7053 | Acc(val) 0.7525 |*
Epoch 00041 | Loss(train) 0.7937 | Acc(train) 0.7040 | Acc(val) 0.7647 |*
Epoch 00042 | Loss(train) 0.7806 | Acc(train) 0.7225 | Acc(val) 0.7733 |*
Epoch 00043 | Loss(train) 0.7757 | Acc(train) 0.7233 | Acc(val) 0.7779 |*
Epoch 00044 | Loss(train) 0.7697 | Acc(train) 0.7154 | Acc(val) 0.7825 |*
Epoch 00045 | Loss(train) 0.7619 | Acc(train) 0.7309 | Acc(val) 0.7901 |*
Epoch 00046 | Loss(train) 0.7577 | Acc(train) 0.7390 | Acc(val) 0.7946 |*
Epoch 00047 | Loss(train) 0.7487 | Acc(train) 0.7390 | Acc(val) 0.8002 |*
Epoch 00048 | Loss(train) 0.7401 | Acc(train) 0.7446 | Acc(val) 0.8038 |*
Epoch 00049 | Loss(train) 0.7410 | Acc(train) 0.7433 | Acc(val) 0.8114 |*
Epoch 00050 | Loss(train) 0.7334 | Acc(train) 0.7451 | Acc(val) 0.8154 |*
Epoch 00051 | Loss(train) 0.7240 | Acc(train) 0.7555 | Acc(val) 0.8185 |*
Epoch 00052 | Loss(train) 0.7238 | Acc(train) 0.7560 | Acc(val) 0.8230 |*
Epoch 00053 | Loss(train) 0.7137 | Acc(train) 0.7616 | Acc(val) 0.8235 |*
Epoch 00054 | Loss(train) 0.7098 | Acc(train) 0.7619 | Acc(val) 0.8240 |*
Epoch 00055 | Loss(train) 0.7048 | Acc(train) 0.7672 | Acc(val) 0.8240 |
Epoch 00056 | Loss(train) 0.7061 | Acc(train) 0.7621 | Acc(val) 0.8245 |*
Epoch 00057 | Loss(train) 0.6954 | Acc(train) 0.7639 | Acc(val) 0.8251 |*
Epoch 00058 | Loss(train) 0.6901 | Acc(train) 0.7697 | Acc(val) 0.8261 |*
Epoch 00059 | Loss(train) 0.6796 | Acc(train) 0.7771 | Acc(val) 0.8271 |*
Epoch 00060 | Loss(train) 0.6804 | Acc(train) 0.7768 | Acc(val) 0.8301 |*
Epoch 00061 | Loss(train) 0.6754 | Acc(train) 0.7738 | Acc(val) 0.8311 |*
Epoch 00062 | Loss(train) 0.6741 | Acc(train) 0.7740 | Acc(val) 0.8327 |*
Epoch 00063 | Loss(train) 0.6660 | Acc(train) 0.7783 | Acc(val) 0.8342 |*
Epoch 00064 | Loss(train) 0.6648 | Acc(train) 0.7834 | Acc(val) 0.8347 |*
Epoch 00065 | Loss(train) 0.6563 | Acc(train) 0.7877 | Acc(val) 0.8327 |
Epoch 00066 | Loss(train) 0.6506 | Acc(train) 0.7839 | Acc(val) 0.8332 |
Epoch 00067 | Loss(train) 0.6440 | Acc(train) 0.7885 | Acc(val) 0.8347 |
Epoch 00068 | Loss(train) 0.6438 | Acc(train) 0.7806 | Acc(val) 0.8382 |*
Epoch 00069 | Loss(train) 0.6430 | Acc(train) 0.7859 | Acc(val) 0.8398 |*
Epoch 00070 | Loss(train) 0.6340 | Acc(train) 0.7931 | Acc(val) 0.8398 |
Epoch 00071 | Loss(train) 0.6422 | Acc(train) 0.7865 | Acc(val) 0.8428 |*
Epoch 00072 | Loss(train) 0.6313 | Acc(train) 0.7862 | Acc(val) 0.8413 |
Epoch 00073 | Loss(train) 0.6259 | Acc(train) 0.7938 | Acc(val) 0.8408 |
Epoch 00074 | Loss(train) 0.6208 | Acc(train) 0.7971 | Acc(val) 0.8403 |
Epoch 00075 | Loss(train) 0.6180 | Acc(train) 0.8037 | Acc(val) 0.8408 |
Epoch 00076 | Loss(train) 0.6235 | Acc(train) 0.7948 | Acc(val) 0.8438 |*
Epoch 00077 | Loss(train) 0.6156 | Acc(train) 0.7948 | Acc(val) 0.8438 |
Epoch 00078 | Loss(train) 0.6100 | Acc(train) 0.8014 | Acc(val) 0.8433 |
Epoch 00079 | Loss(train) 0.6058 | Acc(train) 0.8019 | Acc(val) 0.8423 |
Epoch 00080 | Loss(train) 0.6041 | Acc(train) 0.8012 | Acc(val) 0.8398 |
Epoch 00081 | Loss(train) 0.5974 | Acc(train) 0.8141 | Acc(val) 0.8387 |
Epoch 00082 | Loss(train) 0.5965 | Acc(train) 0.8080 | Acc(val) 0.8392 |
Epoch 00083 | Loss(train) 0.5998 | Acc(train) 0.8047 | Acc(val) 0.8418 |
Epoch 00084 | Loss(train) 0.5929 | Acc(train) 0.8184 | Acc(val) 0.8458 |*
Epoch 00085 | Loss(train) 0.6019 | Acc(train) 0.8065 | Acc(val) 0.8458 |
Epoch 00086 | Loss(train) 0.5865 | Acc(train) 0.8141 | Acc(val) 0.8428 |
Epoch 00087 | Loss(train) 0.5816 | Acc(train) 0.8141 | Acc(val) 0.8398 |
Epoch 00088 | Loss(train) 0.5798 | Acc(train) 0.8108 | Acc(val) 0.8398 |
Epoch 00089 | Loss(train) 0.5867 | Acc(train) 0.8088 | Acc(val) 0.8433 |
Epoch 00090 | Loss(train) 0.5742 | Acc(train) 0.8235 | Acc(val) 0.8479 |*
Epoch 00091 | Loss(train) 0.5755 | Acc(train) 0.8199 | Acc(val) 0.8484 |*
Epoch 00092 | Loss(train) 0.5756 | Acc(train) 0.8237 | Acc(val) 0.8494 |*
Epoch 00093 | Loss(train) 0.5710 | Acc(train) 0.8301 | Acc(val) 0.8474 |
Epoch 00094 | Loss(train) 0.5748 | Acc(train) 0.8131 | Acc(val) 0.8453 |
Epoch 00095 | Loss(train) 0.5651 | Acc(train) 0.8268 | Acc(val) 0.8479 |
Epoch 00096 | Loss(train) 0.5657 | Acc(train) 0.8169 | Acc(val) 0.8499 |*
Epoch 00097 | Loss(train) 0.5682 | Acc(train) 0.8179 | Acc(val) 0.8504 |*
Epoch 00098 | Loss(train) 0.5613 | Acc(train) 0.8212 | Acc(val) 0.8499 |
Epoch 00099 | Loss(train) 0.5656 | Acc(train) 0.8225 | Acc(val) 0.8489 |
Epoch 00100 | Loss(train) 0.5586 | Acc(train) 0.8194 | Acc(val) 0.8494 |
Epoch 00101 | Loss(train) 0.5589 | Acc(train) 0.8253 | Acc(val) 0.8489 |
Epoch 00102 | Loss(train) 0.5532 | Acc(train) 0.8278 | Acc(val) 0.8489 |
Epoch 00103 | Loss(train) 0.5563 | Acc(train) 0.8207 | Acc(val) 0.8494 |
Epoch 00104 | Loss(train) 0.5518 | Acc(train) 0.8321 | Acc(val) 0.8489 |
Epoch 00105 | Loss(train) 0.5576 | Acc(train) 0.8207 | Acc(val) 0.8489 |
Epoch 00106 | Loss(train) 0.5470 | Acc(train) 0.8311 | Acc(val) 0.8504 |
Epoch 00107 | Loss(train) 0.5528 | Acc(train) 0.8253 | Acc(val) 0.8494 |
Epoch 00108 | Loss(train) 0.5489 | Acc(train) 0.8268 | Acc(val) 0.8463 |
Epoch 00109 | Loss(train) 0.5493 | Acc(train) 0.8215 | Acc(val) 0.8469 |
Epoch 00110 | Loss(train) 0.5395 | Acc(train) 0.8313 | Acc(val) 0.8469 |
Epoch 00111 | Loss(train) 0.5422 | Acc(train) 0.8293 | Acc(val) 0.8499 |
Epoch 00112 | Loss(train) 0.5405 | Acc(train) 0.8331 | Acc(val) 0.8519 |*
Epoch 00113 | Loss(train) 0.5337 | Acc(train) 0.8275 | Acc(val) 0.8509 |
Epoch 00114 | Loss(train) 0.5412 | Acc(train) 0.8293 | Acc(val) 0.8484 |
Epoch 00115 | Loss(train) 0.5358 | Acc(train) 0.8311 | Acc(val) 0.8453 |
Epoch 00116 | Loss(train) 0.5305 | Acc(train) 0.8402 | Acc(val) 0.8479 |
Epoch 00117 | Loss(train) 0.5300 | Acc(train) 0.8362 | Acc(val) 0.8509 |
Epoch 00118 | Loss(train) 0.5356 | Acc(train) 0.8293 | Acc(val) 0.8550 |*
Epoch 00119 | Loss(train) 0.5306 | Acc(train) 0.8341 | Acc(val) 0.8534 |
Epoch 00120 | Loss(train) 0.5296 | Acc(train) 0.8392 | Acc(val) 0.8514 |
Epoch 00121 | Loss(train) 0.5256 | Acc(train) 0.8346 | Acc(val) 0.8499 |
Epoch 00122 | Loss(train) 0.5272 | Acc(train) 0.8354 | Acc(val) 0.8489 |
Epoch 00123 | Loss(train) 0.5292 | Acc(train) 0.8336 | Acc(val) 0.8494 |
Epoch 00124 | Loss(train) 0.5207 | Acc(train) 0.8392 | Acc(val) 0.8509 |
Epoch 00125 | Loss(train) 0.5259 | Acc(train) 0.8357 | Acc(val) 0.8519 |
Epoch 00126 | Loss(train) 0.5276 | Acc(train) 0.8341 | Acc(val) 0.8524 |
Epoch 00127 | Loss(train) 0.5186 | Acc(train) 0.8405 | Acc(val) 0.8519 |
Epoch 00128 | Loss(train) 0.5245 | Acc(train) 0.8374 | Acc(val) 0.8540 |
Epoch 00129 | Loss(train) 0.5248 | Acc(train) 0.8369 | Acc(val) 0.8540 |
Epoch 00130 | Loss(train) 0.5194 | Acc(train) 0.8392 | Acc(val) 0.8545 |
Epoch 00131 | Loss(train) 0.5154 | Acc(train) 0.8445 | Acc(val) 0.8540 |
Epoch 00132 | Loss(train) 0.5225 | Acc(train) 0.8352 | Acc(val) 0.8534 |
Epoch 00133 | Loss(train) 0.5089 | Acc(train) 0.8390 | Acc(val) 0.8534 |
Epoch 00134 | Loss(train) 0.5160 | Acc(train) 0.8400 | Acc(val) 0.8560 |*
Epoch 00135 | Loss(train) 0.5128 | Acc(train) 0.8458 | Acc(val) 0.8560 |
Epoch 00136 | Loss(train) 0.5156 | Acc(train) 0.8367 | Acc(val) 0.8560 |
Epoch 00137 | Loss(train) 0.5074 | Acc(train) 0.8372 | Acc(val) 0.8550 |
Epoch 00138 | Loss(train) 0.5063 | Acc(train) 0.8471 | Acc(val) 0.8550 |
Epoch 00139 | Loss(train) 0.5037 | Acc(train) 0.8433 | Acc(val) 0.8575 |*
Epoch 00140 | Loss(train) 0.5051 | Acc(train) 0.8458 | Acc(val) 0.8595 |*
Epoch 00141 | Loss(train) 0.5078 | Acc(train) 0.8387 | Acc(val) 0.8585 |
Epoch 00142 | Loss(train) 0.5058 | Acc(train) 0.8377 | Acc(val) 0.8575 |
Epoch 00143 | Loss(train) 0.5062 | Acc(train) 0.8443 | Acc(val) 0.8590 |
Epoch 00144 | Loss(train) 0.5022 | Acc(train) 0.8466 | Acc(val) 0.8565 |
Epoch 00145 | Loss(train) 0.5041 | Acc(train) 0.8384 | Acc(val) 0.8575 |
Epoch 00146 | Loss(train) 0.5044 | Acc(train) 0.8417 | Acc(val) 0.8580 |
Epoch 00147 | Loss(train) 0.5065 | Acc(train) 0.8377 | Acc(val) 0.8560 |
Epoch 00148 | Loss(train) 0.4999 | Acc(train) 0.8468 | Acc(val) 0.8575 |
Epoch 00149 | Loss(train) 0.5002 | Acc(train) 0.8428 | Acc(val) 0.8600 |*
Epoch 00150 | Loss(train) 0.4983 | Acc(train) 0.8478 | Acc(val) 0.8585 |
Epoch 00151 | Loss(train) 0.4995 | Acc(train) 0.8420 | Acc(val) 0.8570 |
Epoch 00152 | Loss(train) 0.4874 | Acc(train) 0.8488 | Acc(val) 0.8565 |
Epoch 00153 | Loss(train) 0.4979 | Acc(train) 0.8390 | Acc(val) 0.8565 |
Epoch 00154 | Loss(train) 0.4972 | Acc(train) 0.8417 | Acc(val) 0.8590 |
Epoch 00155 | Loss(train) 0.4868 | Acc(train) 0.8476 | Acc(val) 0.8600 |
Epoch 00156 | Loss(train) 0.4921 | Acc(train) 0.8453 | Acc(val) 0.8590 |
Epoch 00157 | Loss(train) 0.4928 | Acc(train) 0.8443 | Acc(val) 0.8595 |
Epoch 00158 | Loss(train) 0.4933 | Acc(train) 0.8476 | Acc(val) 0.8585 |
Epoch 00159 | Loss(train) 0.4894 | Acc(train) 0.8511 | Acc(val) 0.8565 |
Epoch 00160 | Loss(train) 0.4944 | Acc(train) 0.8402 | Acc(val) 0.8605 |*
Epoch 00161 | Loss(train) 0.4948 | Acc(train) 0.8450 | Acc(val) 0.8636 |*
Epoch 00162 | Loss(train) 0.4795 | Acc(train) 0.8511 | Acc(val) 0.8631 |
Epoch 00163 | Loss(train) 0.4868 | Acc(train) 0.8463 | Acc(val) 0.8616 |
Epoch 00164 | Loss(train) 0.4950 | Acc(train) 0.8461 | Acc(val) 0.8590 |
Epoch 00165 | Loss(train) 0.4933 | Acc(train) 0.8438 | Acc(val) 0.8590 |
Epoch 00166 | Loss(train) 0.4846 | Acc(train) 0.8483 | Acc(val) 0.8585 |
Epoch 00167 | Loss(train) 0.4952 | Acc(train) 0.8438 | Acc(val) 0.8616 |
Epoch 00168 | Loss(train) 0.4863 | Acc(train) 0.8450 | Acc(val) 0.8646 |*
Epoch 00169 | Loss(train) 0.4879 | Acc(train) 0.8466 | Acc(val) 0.8605 |
Epoch 00170 | Loss(train) 0.4892 | Acc(train) 0.8435 | Acc(val) 0.8600 |
Epoch 00171 | Loss(train) 0.4864 | Acc(train) 0.8428 | Acc(val) 0.8626 |
Epoch 00172 | Loss(train) 0.4907 | Acc(train) 0.8397 | Acc(val) 0.8616 |
Epoch 00173 | Loss(train) 0.4822 | Acc(train) 0.8468 | Acc(val) 0.8611 |
Epoch 00174 | Loss(train) 0.4808 | Acc(train) 0.8450 | Acc(val) 0.8585 |
Epoch 00175 | Loss(train) 0.4819 | Acc(train) 0.8458 | Acc(val) 0.8590 |
Epoch 00176 | Loss(train) 0.4797 | Acc(train) 0.8509 | Acc(val) 0.8631 |
Epoch 00177 | Loss(train) 0.4752 | Acc(train) 0.8461 | Acc(val) 0.8631 |
Epoch 00178 | Loss(train) 0.4789 | Acc(train) 0.8504 | Acc(val) 0.8621 |
Epoch 00179 | Loss(train) 0.4804 | Acc(train) 0.8476 | Acc(val) 0.8621 |
Epoch 00180 | Loss(train) 0.4851 | Acc(train) 0.8433 | Acc(val) 0.8616 |
Epoch 00181 | Loss(train) 0.4827 | Acc(train) 0.8481 | Acc(val) 0.8641 |
Epoch 00182 | Loss(train) 0.4714 | Acc(train) 0.8506 | Acc(val) 0.8646 |
Epoch 00183 | Loss(train) 0.4780 | Acc(train) 0.8468 | Acc(val) 0.8626 |
Epoch 00184 | Loss(train) 0.4785 | Acc(train) 0.8458 | Acc(val) 0.8621 |
Epoch 00185 | Loss(train) 0.4730 | Acc(train) 0.8468 | Acc(val) 0.8621 |
Epoch 00186 | Loss(train) 0.4729 | Acc(train) 0.8532 | Acc(val) 0.8616 |
Epoch 00187 | Loss(train) 0.4753 | Acc(train) 0.8417 | Acc(val) 0.8631 |
Epoch 00188 | Loss(train) 0.4781 | Acc(train) 0.8450 | Acc(val) 0.8631 |
Epoch 00189 | Loss(train) 0.4820 | Acc(train) 0.8501 | Acc(val) 0.8621 |
Epoch 00190 | Loss(train) 0.4748 | Acc(train) 0.8529 | Acc(val) 0.8631 |
Epoch 00191 | Loss(train) 0.4738 | Acc(train) 0.8423 | Acc(val) 0.8631 |
Epoch 00192 | Loss(train) 0.4806 | Acc(train) 0.8443 | Acc(val) 0.8641 |
Epoch 00193 | Loss(train) 0.4718 | Acc(train) 0.8496 | Acc(val) 0.8621 |
Epoch 00194 | Loss(train) 0.4720 | Acc(train) 0.8504 | Acc(val) 0.8631 |
Epoch 00195 | Loss(train) 0.4703 | Acc(train) 0.8549 | Acc(val) 0.8636 |
Epoch 00196 | Loss(train) 0.4707 | Acc(train) 0.8486 | Acc(val) 0.8626 |
Epoch 00197 | Loss(train) 0.4740 | Acc(train) 0.8466 | Acc(val) 0.8636 |
Epoch 00198 | Loss(train) 0.4751 | Acc(train) 0.8494 | Acc(val) 0.8651 |*
Epoch 00199 | Loss(train) 0.4751 | Acc(train) 0.8450 | Acc(val) 0.8651 |
Epoch 00200 | Loss(train) 0.4647 | Acc(train) 0.8509 | Acc(val) 0.8651 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 1.1003 | Acc(train) 0.2835 | Acc(val) 0.5446 |*
Epoch 00002 | Loss(train) 1.0909 | Acc(train) 0.4968 | Acc(val) 0.5441 |
Epoch 00003 | Loss(train) 1.0837 | Acc(train) 0.5019 | Acc(val) 0.5284 |
Epoch 00004 | Loss(train) 1.0761 | Acc(train) 0.5151 | Acc(val) 0.5076 |
Epoch 00005 | Loss(train) 1.0689 | Acc(train) 0.5037 | Acc(val) 0.5071 |
Epoch 00006 | Loss(train) 1.0635 | Acc(train) 0.4986 | Acc(val) 0.5193 |
Epoch 00007 | Loss(train) 1.0541 | Acc(train) 0.5204 | Acc(val) 0.5365 |
Epoch 00008 | Loss(train) 1.0493 | Acc(train) 0.5153 | Acc(val) 0.5532 |*
Epoch 00009 | Loss(train) 1.0394 | Acc(train) 0.5341 | Acc(val) 0.5710 |*
Epoch 00010 | Loss(train) 1.0341 | Acc(train) 0.5399 | Acc(val) 0.5791 |*
Epoch 00011 | Loss(train) 1.0286 | Acc(train) 0.5369 | Acc(val) 0.5877 |*
Epoch 00012 | Loss(train) 1.0233 | Acc(train) 0.5288 | Acc(val) 0.5963 |*
Epoch 00013 | Loss(train) 1.0154 | Acc(train) 0.5552 | Acc(val) 0.6060 |*
Epoch 00014 | Loss(train) 1.0056 | Acc(train) 0.5605 | Acc(val) 0.6217 |*
Epoch 00015 | Loss(train) 1.0027 | Acc(train) 0.5557 | Acc(val) 0.6329 |*
Epoch 00016 | Loss(train) 0.9947 | Acc(train) 0.5765 | Acc(val) 0.6430 |*
Epoch 00017 | Loss(train) 0.9902 | Acc(train) 0.5676 | Acc(val) 0.6526 |*
Epoch 00018 | Loss(train) 0.9842 | Acc(train) 0.5742 | Acc(val) 0.6567 |*
Epoch 00019 | Loss(train) 0.9786 | Acc(train) 0.5691 | Acc(val) 0.6587 |*
Epoch 00020 | Loss(train) 0.9715 | Acc(train) 0.5823 | Acc(val) 0.6613 |*
Epoch 00021 | Loss(train) 0.9632 | Acc(train) 0.5651 | Acc(val) 0.6633 |*
Epoch 00022 | Loss(train) 0.9582 | Acc(train) 0.5828 | Acc(val) 0.6643 |*
Epoch 00023 | Loss(train) 0.9516 | Acc(train) 0.5798 | Acc(val) 0.6628 |
Epoch 00024 | Loss(train) 0.9450 | Acc(train) 0.5777 | Acc(val) 0.6643 |
Epoch 00025 | Loss(train) 0.9380 | Acc(train) 0.5947 | Acc(val) 0.6638 |
Epoch 00026 | Loss(train) 0.9324 | Acc(train) 0.5826 | Acc(val) 0.6663 |*
Epoch 00027 | Loss(train) 0.9240 | Acc(train) 0.6031 | Acc(val) 0.6755 |*
Epoch 00028 | Loss(train) 0.9181 | Acc(train) 0.6173 | Acc(val) 0.6846 |*
Epoch 00029 | Loss(train) 0.9076 | Acc(train) 0.6158 | Acc(val) 0.6922 |*
Epoch 00030 | Loss(train) 0.9022 | Acc(train) 0.6274 | Acc(val) 0.6978 |*
Epoch 00031 | Loss(train) 0.8984 | Acc(train) 0.6290 | Acc(val) 0.7033 |*
Epoch 00032 | Loss(train) 0.8890 | Acc(train) 0.6343 | Acc(val) 0.7094 |*
Epoch 00033 | Loss(train) 0.8822 | Acc(train) 0.6409 | Acc(val) 0.7155 |*
Epoch 00034 | Loss(train) 0.8735 | Acc(train) 0.6482 | Acc(val) 0.7241 |*
Epoch 00035 | Loss(train) 0.8744 | Acc(train) 0.6449 | Acc(val) 0.7312 |*
Epoch 00036 | Loss(train) 0.8598 | Acc(train) 0.6602 | Acc(val) 0.7394 |*
Epoch 00037 | Loss(train) 0.8483 | Acc(train) 0.6741 | Acc(val) 0.7485 |*
Epoch 00038 | Loss(train) 0.8456 | Acc(train) 0.6675 | Acc(val) 0.7586 |*
Epoch 00039 | Loss(train) 0.8372 | Acc(train) 0.6853 | Acc(val) 0.7698 |*
Epoch 00040 | Loss(train) 0.8366 | Acc(train) 0.6840 | Acc(val) 0.7804 |*
Epoch 00041 | Loss(train) 0.8274 | Acc(train) 0.6901 | Acc(val) 0.7901 |*
Epoch 00042 | Loss(train) 0.8237 | Acc(train) 0.7000 | Acc(val) 0.7946 |*
Epoch 00043 | Loss(train) 0.8087 | Acc(train) 0.7111 | Acc(val) 0.7977 |*
Epoch 00044 | Loss(train) 0.8126 | Acc(train) 0.7040 | Acc(val) 0.8027 |*
Epoch 00045 | Loss(train) 0.8027 | Acc(train) 0.7038 | Acc(val) 0.8058 |*
Epoch 00046 | Loss(train) 0.7947 | Acc(train) 0.7177 | Acc(val) 0.8078 |*
Epoch 00047 | Loss(train) 0.7891 | Acc(train) 0.7149 | Acc(val) 0.8078 |
Epoch 00048 | Loss(train) 0.7783 | Acc(train) 0.7248 | Acc(val) 0.8078 |
Epoch 00049 | Loss(train) 0.7758 | Acc(train) 0.7271 | Acc(val) 0.8098 |*
Epoch 00050 | Loss(train) 0.7746 | Acc(train) 0.7291 | Acc(val) 0.8103 |*
Epoch 00051 | Loss(train) 0.7673 | Acc(train) 0.7274 | Acc(val) 0.8114 |*
Epoch 00052 | Loss(train) 0.7534 | Acc(train) 0.7464 | Acc(val) 0.8139 |*
Epoch 00053 | Loss(train) 0.7497 | Acc(train) 0.7367 | Acc(val) 0.8159 |*
Epoch 00054 | Loss(train) 0.7511 | Acc(train) 0.7421 | Acc(val) 0.8159 |
Epoch 00055 | Loss(train) 0.7413 | Acc(train) 0.7367 | Acc(val) 0.8159 |
Epoch 00056 | Loss(train) 0.7452 | Acc(train) 0.7421 | Acc(val) 0.8195 |*
Epoch 00057 | Loss(train) 0.7352 | Acc(train) 0.7421 | Acc(val) 0.8215 |*
Epoch 00058 | Loss(train) 0.7318 | Acc(train) 0.7482 | Acc(val) 0.8210 |
Epoch 00059 | Loss(train) 0.7261 | Acc(train) 0.7449 | Acc(val) 0.8230 |*
Epoch 00060 | Loss(train) 0.7197 | Acc(train) 0.7537 | Acc(val) 0.8230 |
Epoch 00061 | Loss(train) 0.7206 | Acc(train) 0.7454 | Acc(val) 0.8240 |*
Epoch 00062 | Loss(train) 0.7118 | Acc(train) 0.7558 | Acc(val) 0.8251 |*
Epoch 00063 | Loss(train) 0.7018 | Acc(train) 0.7586 | Acc(val) 0.8261 |*
Epoch 00064 | Loss(train) 0.7049 | Acc(train) 0.7588 | Acc(val) 0.8256 |
Epoch 00065 | Loss(train) 0.6974 | Acc(train) 0.7697 | Acc(val) 0.8276 |*
Epoch 00066 | Loss(train) 0.6930 | Acc(train) 0.7674 | Acc(val) 0.8271 |
Epoch 00067 | Loss(train) 0.6849 | Acc(train) 0.7687 | Acc(val) 0.8296 |*
Epoch 00068 | Loss(train) 0.6842 | Acc(train) 0.7634 | Acc(val) 0.8276 |
Epoch 00069 | Loss(train) 0.6832 | Acc(train) 0.7745 | Acc(val) 0.8281 |
Epoch 00070 | Loss(train) 0.6785 | Acc(train) 0.7794 | Acc(val) 0.8271 |
Epoch 00071 | Loss(train) 0.6771 | Acc(train) 0.7667 | Acc(val) 0.8266 |
Epoch 00072 | Loss(train) 0.6745 | Acc(train) 0.7606 | Acc(val) 0.8286 |
Epoch 00073 | Loss(train) 0.6656 | Acc(train) 0.7834 | Acc(val) 0.8286 |
Epoch 00074 | Loss(train) 0.6681 | Acc(train) 0.7738 | Acc(val) 0.8291 |
Epoch 00075 | Loss(train) 0.6649 | Acc(train) 0.7733 | Acc(val) 0.8281 |
Epoch 00076 | Loss(train) 0.6624 | Acc(train) 0.7723 | Acc(val) 0.8291 |
Epoch 00077 | Loss(train) 0.6550 | Acc(train) 0.7781 | Acc(val) 0.8311 |*
Epoch 00078 | Loss(train) 0.6464 | Acc(train) 0.7877 | Acc(val) 0.8332 |*
Epoch 00079 | Loss(train) 0.6468 | Acc(train) 0.7834 | Acc(val) 0.8337 |*
Epoch 00080 | Loss(train) 0.6488 | Acc(train) 0.7898 | Acc(val) 0.8337 |
Epoch 00081 | Loss(train) 0.6396 | Acc(train) 0.7862 | Acc(val) 0.8337 |
Epoch 00082 | Loss(train) 0.6373 | Acc(train) 0.7895 | Acc(val) 0.8337 |
Epoch 00083 | Loss(train) 0.6343 | Acc(train) 0.7936 | Acc(val) 0.8342 |*
Epoch 00084 | Loss(train) 0.6399 | Acc(train) 0.7857 | Acc(val) 0.8347 |*
Epoch 00085 | Loss(train) 0.6258 | Acc(train) 0.7963 | Acc(val) 0.8352 |*
Epoch 00086 | Loss(train) 0.6341 | Acc(train) 0.7783 | Acc(val) 0.8347 |
Epoch 00087 | Loss(train) 0.6294 | Acc(train) 0.7885 | Acc(val) 0.8352 |
Epoch 00088 | Loss(train) 0.6227 | Acc(train) 0.7936 | Acc(val) 0.8382 |*
Epoch 00089 | Loss(train) 0.6262 | Acc(train) 0.7979 | Acc(val) 0.8398 |*
Epoch 00090 | Loss(train) 0.6144 | Acc(train) 0.7979 | Acc(val) 0.8372 |
Epoch 00091 | Loss(train) 0.6229 | Acc(train) 0.7925 | Acc(val) 0.8357 |
Epoch 00092 | Loss(train) 0.6199 | Acc(train) 0.7925 | Acc(val) 0.8362 |
Epoch 00093 | Loss(train) 0.6086 | Acc(train) 0.8032 | Acc(val) 0.8367 |
Epoch 00094 | Loss(train) 0.6057 | Acc(train) 0.8014 | Acc(val) 0.8408 |*
Epoch 00095 | Loss(train) 0.6124 | Acc(train) 0.7961 | Acc(val) 0.8433 |*
Epoch 00096 | Loss(train) 0.6050 | Acc(train) 0.7996 | Acc(val) 0.8448 |*
Epoch 00097 | Loss(train) 0.6013 | Acc(train) 0.8024 | Acc(val) 0.8438 |
Epoch 00098 | Loss(train) 0.5997 | Acc(train) 0.7981 | Acc(val) 0.8428 |
Epoch 00099 | Loss(train) 0.6044 | Acc(train) 0.7984 | Acc(val) 0.8413 |
Epoch 00100 | Loss(train) 0.5983 | Acc(train) 0.7974 | Acc(val) 0.8408 |
Epoch 00101 | Loss(train) 0.5977 | Acc(train) 0.7984 | Acc(val) 0.8433 |
Epoch 00102 | Loss(train) 0.5934 | Acc(train) 0.8040 | Acc(val) 0.8453 |*
Epoch 00103 | Loss(train) 0.5912 | Acc(train) 0.8050 | Acc(val) 0.8463 |*
Epoch 00104 | Loss(train) 0.5875 | Acc(train) 0.8034 | Acc(val) 0.8458 |
Epoch 00105 | Loss(train) 0.5849 | Acc(train) 0.8083 | Acc(val) 0.8448 |
Epoch 00106 | Loss(train) 0.5867 | Acc(train) 0.8088 | Acc(val) 0.8443 |
Epoch 00107 | Loss(train) 0.5861 | Acc(train) 0.8100 | Acc(val) 0.8443 |
Epoch 00108 | Loss(train) 0.5833 | Acc(train) 0.8088 | Acc(val) 0.8438 |
Epoch 00109 | Loss(train) 0.5811 | Acc(train) 0.8070 | Acc(val) 0.8469 |*
Epoch 00110 | Loss(train) 0.5740 | Acc(train) 0.8090 | Acc(val) 0.8463 |
Epoch 00111 | Loss(train) 0.5702 | Acc(train) 0.8136 | Acc(val) 0.8469 |
Epoch 00112 | Loss(train) 0.5793 | Acc(train) 0.8113 | Acc(val) 0.8479 |*
Epoch 00113 | Loss(train) 0.5829 | Acc(train) 0.8022 | Acc(val) 0.8494 |*
Epoch 00114 | Loss(train) 0.5763 | Acc(train) 0.8085 | Acc(val) 0.8494 |
Epoch 00115 | Loss(train) 0.5731 | Acc(train) 0.8118 | Acc(val) 0.8484 |
Epoch 00116 | Loss(train) 0.5672 | Acc(train) 0.8192 | Acc(val) 0.8504 |*
Epoch 00117 | Loss(train) 0.5689 | Acc(train) 0.8075 | Acc(val) 0.8489 |
Epoch 00118 | Loss(train) 0.5643 | Acc(train) 0.8182 | Acc(val) 0.8494 |
Epoch 00119 | Loss(train) 0.5696 | Acc(train) 0.8133 | Acc(val) 0.8499 |
Epoch 00120 | Loss(train) 0.5580 | Acc(train) 0.8177 | Acc(val) 0.8504 |
Epoch 00121 | Loss(train) 0.5610 | Acc(train) 0.8111 | Acc(val) 0.8524 |*
Epoch 00122 | Loss(train) 0.5580 | Acc(train) 0.8177 | Acc(val) 0.8519 |
Epoch 00123 | Loss(train) 0.5655 | Acc(train) 0.8103 | Acc(val) 0.8529 |*
Epoch 00124 | Loss(train) 0.5552 | Acc(train) 0.8232 | Acc(val) 0.8529 |
Epoch 00125 | Loss(train) 0.5508 | Acc(train) 0.8245 | Acc(val) 0.8504 |
Epoch 00126 | Loss(train) 0.5641 | Acc(train) 0.8075 | Acc(val) 0.8499 |
Epoch 00127 | Loss(train) 0.5528 | Acc(train) 0.8207 | Acc(val) 0.8494 |
Epoch 00128 | Loss(train) 0.5557 | Acc(train) 0.8136 | Acc(val) 0.8499 |
Epoch 00129 | Loss(train) 0.5530 | Acc(train) 0.8197 | Acc(val) 0.8509 |
Epoch 00130 | Loss(train) 0.5446 | Acc(train) 0.8232 | Acc(val) 0.8524 |
Epoch 00131 | Loss(train) 0.5566 | Acc(train) 0.8204 | Acc(val) 0.8514 |
Epoch 00132 | Loss(train) 0.5489 | Acc(train) 0.8146 | Acc(val) 0.8494 |
Epoch 00133 | Loss(train) 0.5514 | Acc(train) 0.8189 | Acc(val) 0.8499 |
Epoch 00134 | Loss(train) 0.5499 | Acc(train) 0.8273 | Acc(val) 0.8499 |
Epoch 00135 | Loss(train) 0.5481 | Acc(train) 0.8194 | Acc(val) 0.8545 |*
Epoch 00136 | Loss(train) 0.5609 | Acc(train) 0.8174 | Acc(val) 0.8545 |
Epoch 00137 | Loss(train) 0.5516 | Acc(train) 0.8177 | Acc(val) 0.8545 |
Epoch 00138 | Loss(train) 0.5358 | Acc(train) 0.8275 | Acc(val) 0.8529 |
Epoch 00139 | Loss(train) 0.5375 | Acc(train) 0.8204 | Acc(val) 0.8529 |
Epoch 00140 | Loss(train) 0.5357 | Acc(train) 0.8184 | Acc(val) 0.8534 |
Epoch 00141 | Loss(train) 0.5457 | Acc(train) 0.8222 | Acc(val) 0.8529 |
Epoch 00142 | Loss(train) 0.5430 | Acc(train) 0.8146 | Acc(val) 0.8540 |
Epoch 00143 | Loss(train) 0.5385 | Acc(train) 0.8283 | Acc(val) 0.8524 |
Epoch 00144 | Loss(train) 0.5415 | Acc(train) 0.8179 | Acc(val) 0.8509 |
Epoch 00145 | Loss(train) 0.5390 | Acc(train) 0.8177 | Acc(val) 0.8519 |
Epoch 00146 | Loss(train) 0.5292 | Acc(train) 0.8250 | Acc(val) 0.8545 |
Epoch 00147 | Loss(train) 0.5395 | Acc(train) 0.8149 | Acc(val) 0.8555 |*
Epoch 00148 | Loss(train) 0.5369 | Acc(train) 0.8237 | Acc(val) 0.8545 |
Epoch 00149 | Loss(train) 0.5408 | Acc(train) 0.8263 | Acc(val) 0.8519 |
Epoch 00150 | Loss(train) 0.5308 | Acc(train) 0.8237 | Acc(val) 0.8509 |
Epoch 00151 | Loss(train) 0.5340 | Acc(train) 0.8237 | Acc(val) 0.8499 |
Epoch 00152 | Loss(train) 0.5342 | Acc(train) 0.8197 | Acc(val) 0.8499 |
Epoch 00153 | Loss(train) 0.5282 | Acc(train) 0.8258 | Acc(val) 0.8534 |
Epoch 00154 | Loss(train) 0.5421 | Acc(train) 0.8174 | Acc(val) 0.8550 |
Epoch 00155 | Loss(train) 0.5327 | Acc(train) 0.8286 | Acc(val) 0.8545 |
Epoch 00156 | Loss(train) 0.5223 | Acc(train) 0.8275 | Acc(val) 0.8524 |
Epoch 00157 | Loss(train) 0.5322 | Acc(train) 0.8202 | Acc(val) 0.8514 |
Epoch 00158 | Loss(train) 0.5291 | Acc(train) 0.8260 | Acc(val) 0.8494 |
Epoch 00159 | Loss(train) 0.5220 | Acc(train) 0.8321 | Acc(val) 0.8524 |
Epoch 00160 | Loss(train) 0.5294 | Acc(train) 0.8179 | Acc(val) 0.8565 |*
Epoch 00161 | Loss(train) 0.5222 | Acc(train) 0.8286 | Acc(val) 0.8575 |*
Epoch 00162 | Loss(train) 0.5204 | Acc(train) 0.8212 | Acc(val) 0.8540 |
Epoch 00163 | Loss(train) 0.5172 | Acc(train) 0.8321 | Acc(val) 0.8534 |
Epoch 00164 | Loss(train) 0.5197 | Acc(train) 0.8293 | Acc(val) 0.8545 |
Epoch 00165 | Loss(train) 0.5188 | Acc(train) 0.8217 | Acc(val) 0.8555 |
Epoch 00166 | Loss(train) 0.5203 | Acc(train) 0.8263 | Acc(val) 0.8585 |*
Epoch 00167 | Loss(train) 0.5208 | Acc(train) 0.8275 | Acc(val) 0.8580 |
Epoch 00168 | Loss(train) 0.5175 | Acc(train) 0.8248 | Acc(val) 0.8565 |
Epoch 00169 | Loss(train) 0.5229 | Acc(train) 0.8235 | Acc(val) 0.8565 |
Epoch 00170 | Loss(train) 0.5184 | Acc(train) 0.8245 | Acc(val) 0.8575 |
Epoch 00171 | Loss(train) 0.5224 | Acc(train) 0.8288 | Acc(val) 0.8580 |
Epoch 00172 | Loss(train) 0.5151 | Acc(train) 0.8316 | Acc(val) 0.8595 |*
Epoch 00173 | Loss(train) 0.5114 | Acc(train) 0.8344 | Acc(val) 0.8605 |*
Epoch 00174 | Loss(train) 0.5098 | Acc(train) 0.8364 | Acc(val) 0.8600 |
Epoch 00175 | Loss(train) 0.5107 | Acc(train) 0.8346 | Acc(val) 0.8570 |
Epoch 00176 | Loss(train) 0.5092 | Acc(train) 0.8321 | Acc(val) 0.8550 |
Epoch 00177 | Loss(train) 0.5190 | Acc(train) 0.8222 | Acc(val) 0.8545 |
Epoch 00178 | Loss(train) 0.5126 | Acc(train) 0.8260 | Acc(val) 0.8545 |
Epoch 00179 | Loss(train) 0.5053 | Acc(train) 0.8308 | Acc(val) 0.8550 |
Epoch 00180 | Loss(train) 0.5146 | Acc(train) 0.8250 | Acc(val) 0.8585 |
Epoch 00181 | Loss(train) 0.5061 | Acc(train) 0.8369 | Acc(val) 0.8575 |
Epoch 00182 | Loss(train) 0.5112 | Acc(train) 0.8255 | Acc(val) 0.8570 |
Epoch 00183 | Loss(train) 0.5089 | Acc(train) 0.8273 | Acc(val) 0.8570 |
Epoch 00184 | Loss(train) 0.5002 | Acc(train) 0.8367 | Acc(val) 0.8580 |
Epoch 00185 | Loss(train) 0.5111 | Acc(train) 0.8296 | Acc(val) 0.8555 |
Epoch 00186 | Loss(train) 0.5091 | Acc(train) 0.8293 | Acc(val) 0.8580 |
Epoch 00187 | Loss(train) 0.5057 | Acc(train) 0.8321 | Acc(val) 0.8595 |
Epoch 00188 | Loss(train) 0.5106 | Acc(train) 0.8362 | Acc(val) 0.8565 |
Epoch 00189 | Loss(train) 0.5089 | Acc(train) 0.8321 | Acc(val) 0.8560 |
Epoch 00190 | Loss(train) 0.5068 | Acc(train) 0.8321 | Acc(val) 0.8570 |
Epoch 00191 | Loss(train) 0.5043 | Acc(train) 0.8275 | Acc(val) 0.8580 |
Epoch 00192 | Loss(train) 0.5026 | Acc(train) 0.8443 | Acc(val) 0.8560 |
Epoch 00193 | Loss(train) 0.4967 | Acc(train) 0.8395 | Acc(val) 0.8580 |
Epoch 00194 | Loss(train) 0.4986 | Acc(train) 0.8341 | Acc(val) 0.8590 |
Epoch 00195 | Loss(train) 0.4969 | Acc(train) 0.8374 | Acc(val) 0.8565 |
Epoch 00196 | Loss(train) 0.5027 | Acc(train) 0.8288 | Acc(val) 0.8575 |
Epoch 00197 | Loss(train) 0.5058 | Acc(train) 0.8319 | Acc(val) 0.8570 |
Epoch 00198 | Loss(train) 0.4995 | Acc(train) 0.8283 | Acc(val) 0.8575 |
Epoch 00199 | Loss(train) 0.5007 | Acc(train) 0.8331 | Acc(val) 0.8585 |
Epoch 00200 | Loss(train) 0.5024 | Acc(train) 0.8291 | Acc(val) 0.8585 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 16, 'dropout': 0.5, 'norm': None, 'in_dim': 500, 'out_dim': 3}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.0005, 'patience': None})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 105.30 MB
GPU Memory Reserved: 170.00 MB
All runs:
Uncalibrated Test Accuracy: 86.17 ± 0.31
Uncalibrated Difference: 14.38 ± 1.19
Calibrated Test Accuracy: 86.17 ± 0.31
Calibrated Difference: 1.04 ± 0.07
