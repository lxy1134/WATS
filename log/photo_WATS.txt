/usr/local/lib/python3.11/dist-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning(
Dataset: photo | #Nodes: 7487 | #Edges: 238087 | #Classes: 8 |#Features: 745
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.2535 | Acc(train) 0.0381 | Acc(val) 0.1989 |*
Epoch 00002 | Loss(train) 4.1512 | Acc(train) 0.2037 | Acc(val) 0.2550 |*
Epoch 00003 | Loss(train) 4.5611 | Acc(train) 0.2712 | Acc(val) 0.3551 |*
Epoch 00004 | Loss(train) 3.1442 | Acc(train) 0.3079 | Acc(val) 0.1335 |
Epoch 00005 | Loss(train) 2.9618 | Acc(train) 0.1269 | Acc(val) 0.1615 |
Epoch 00006 | Loss(train) 2.2708 | Acc(train) 0.1951 | Acc(val) 0.2336 |
Epoch 00007 | Loss(train) 2.1135 | Acc(train) 0.2178 | Acc(val) 0.2430 |
Epoch 00008 | Loss(train) 1.8722 | Acc(train) 0.3146 | Acc(val) 0.5234 |*
Epoch 00009 | Loss(train) 1.7206 | Acc(train) 0.4202 | Acc(val) 0.3111 |
Epoch 00010 | Loss(train) 1.7476 | Acc(train) 0.4202 | Acc(val) 0.4419 |
Epoch 00011 | Loss(train) 1.6979 | Acc(train) 0.4228 | Acc(val) 0.6475 |*
Epoch 00012 | Loss(train) 1.5865 | Acc(train) 0.5023 | Acc(val) 0.6422 |
Epoch 00013 | Loss(train) 1.5502 | Acc(train) 0.5003 | Acc(val) 0.6302 |
Epoch 00014 | Loss(train) 1.5310 | Acc(train) 0.4696 | Acc(val) 0.6008 |
Epoch 00015 | Loss(train) 1.3739 | Acc(train) 0.5691 | Acc(val) 0.6422 |
Epoch 00016 | Loss(train) 1.3015 | Acc(train) 0.5845 | Acc(val) 0.6742 |*
Epoch 00017 | Loss(train) 1.2353 | Acc(train) 0.6132 | Acc(val) 0.7116 |*
Epoch 00018 | Loss(train) 1.2183 | Acc(train) 0.6219 | Acc(val) 0.6796 |
Epoch 00019 | Loss(train) 1.2176 | Acc(train) 0.6199 | Acc(val) 0.6876 |
Epoch 00020 | Loss(train) 1.1848 | Acc(train) 0.6446 | Acc(val) 0.7116 |
Epoch 00021 | Loss(train) 1.1221 | Acc(train) 0.6546 | Acc(val) 0.7290 |*
Epoch 00022 | Loss(train) 1.0794 | Acc(train) 0.6820 | Acc(val) 0.7063 |
Epoch 00023 | Loss(train) 1.0136 | Acc(train) 0.6787 | Acc(val) 0.6956 |
Epoch 00024 | Loss(train) 1.0233 | Acc(train) 0.6900 | Acc(val) 0.7116 |
Epoch 00025 | Loss(train) 0.9920 | Acc(train) 0.6894 | Acc(val) 0.7650 |*
Epoch 00026 | Loss(train) 0.9785 | Acc(train) 0.6727 | Acc(val) 0.7904 |*
Epoch 00027 | Loss(train) 0.9328 | Acc(train) 0.7088 | Acc(val) 0.8051 |*
Epoch 00028 | Loss(train) 0.9088 | Acc(train) 0.7341 | Acc(val) 0.8037 |
Epoch 00029 | Loss(train) 0.8367 | Acc(train) 0.7602 | Acc(val) 0.7984 |
Epoch 00030 | Loss(train) 0.8326 | Acc(train) 0.7675 | Acc(val) 0.7957 |
Epoch 00031 | Loss(train) 0.8360 | Acc(train) 0.7548 | Acc(val) 0.7931 |
Epoch 00032 | Loss(train) 0.7900 | Acc(train) 0.7522 | Acc(val) 0.8171 |*
Epoch 00033 | Loss(train) 0.8093 | Acc(train) 0.7361 | Acc(val) 0.8478 |*
Epoch 00034 | Loss(train) 0.8015 | Acc(train) 0.7575 | Acc(val) 0.8558 |*
Epoch 00035 | Loss(train) 0.7548 | Acc(train) 0.7742 | Acc(val) 0.8638 |*
Epoch 00036 | Loss(train) 0.7410 | Acc(train) 0.7735 | Acc(val) 0.8718 |*
Epoch 00037 | Loss(train) 0.7216 | Acc(train) 0.7969 | Acc(val) 0.8838 |*
Epoch 00038 | Loss(train) 0.6933 | Acc(train) 0.8029 | Acc(val) 0.8718 |
Epoch 00039 | Loss(train) 0.6811 | Acc(train) 0.8003 | Acc(val) 0.8772 |
Epoch 00040 | Loss(train) 0.7003 | Acc(train) 0.7816 | Acc(val) 0.8905 |*
Epoch 00041 | Loss(train) 0.6647 | Acc(train) 0.8036 | Acc(val) 0.8919 |*
Epoch 00042 | Loss(train) 0.6721 | Acc(train) 0.7983 | Acc(val) 0.8959 |*
Epoch 00043 | Loss(train) 0.6393 | Acc(train) 0.8110 | Acc(val) 0.9012 |*
Epoch 00044 | Loss(train) 0.6325 | Acc(train) 0.8183 | Acc(val) 0.9025 |*
Epoch 00045 | Loss(train) 0.6048 | Acc(train) 0.8343 | Acc(val) 0.9039 |*
Epoch 00046 | Loss(train) 0.5940 | Acc(train) 0.8363 | Acc(val) 0.9025 |
Epoch 00047 | Loss(train) 0.6005 | Acc(train) 0.8383 | Acc(val) 0.9025 |
Epoch 00048 | Loss(train) 0.5716 | Acc(train) 0.8277 | Acc(val) 0.8985 |
Epoch 00049 | Loss(train) 0.5625 | Acc(train) 0.8457 | Acc(val) 0.9012 |
Epoch 00050 | Loss(train) 0.5650 | Acc(train) 0.8350 | Acc(val) 0.9039 |
Epoch 00051 | Loss(train) 0.5595 | Acc(train) 0.8444 | Acc(val) 0.9039 |
Epoch 00052 | Loss(train) 0.5447 | Acc(train) 0.8464 | Acc(val) 0.9052 |*
Epoch 00053 | Loss(train) 0.5275 | Acc(train) 0.8484 | Acc(val) 0.9052 |
Epoch 00054 | Loss(train) 0.5336 | Acc(train) 0.8457 | Acc(val) 0.9039 |
Epoch 00055 | Loss(train) 0.5055 | Acc(train) 0.8464 | Acc(val) 0.9052 |
Epoch 00056 | Loss(train) 0.5235 | Acc(train) 0.8350 | Acc(val) 0.9105 |*
Epoch 00057 | Loss(train) 0.5110 | Acc(train) 0.8464 | Acc(val) 0.9092 |
Epoch 00058 | Loss(train) 0.5458 | Acc(train) 0.8277 | Acc(val) 0.9079 |
Epoch 00059 | Loss(train) 0.4945 | Acc(train) 0.8497 | Acc(val) 0.9119 |*
Epoch 00060 | Loss(train) 0.5095 | Acc(train) 0.8417 | Acc(val) 0.9146 |*
Epoch 00061 | Loss(train) 0.4770 | Acc(train) 0.8557 | Acc(val) 0.9119 |
Epoch 00062 | Loss(train) 0.4922 | Acc(train) 0.8363 | Acc(val) 0.9132 |
Epoch 00063 | Loss(train) 0.4703 | Acc(train) 0.8664 | Acc(val) 0.9132 |
Epoch 00064 | Loss(train) 0.4736 | Acc(train) 0.8631 | Acc(val) 0.9132 |
Epoch 00065 | Loss(train) 0.4789 | Acc(train) 0.8637 | Acc(val) 0.9119 |
Epoch 00066 | Loss(train) 0.4635 | Acc(train) 0.8671 | Acc(val) 0.9132 |
Epoch 00067 | Loss(train) 0.4595 | Acc(train) 0.8637 | Acc(val) 0.9172 |*
Epoch 00068 | Loss(train) 0.4318 | Acc(train) 0.8731 | Acc(val) 0.9199 |*
Epoch 00069 | Loss(train) 0.4457 | Acc(train) 0.8724 | Acc(val) 0.9146 |
Epoch 00070 | Loss(train) 0.4495 | Acc(train) 0.8704 | Acc(val) 0.9119 |
Epoch 00071 | Loss(train) 0.4729 | Acc(train) 0.8510 | Acc(val) 0.9119 |
Epoch 00072 | Loss(train) 0.4436 | Acc(train) 0.8697 | Acc(val) 0.9226 |*
Epoch 00073 | Loss(train) 0.4441 | Acc(train) 0.8711 | Acc(val) 0.9172 |
Epoch 00074 | Loss(train) 0.4410 | Acc(train) 0.8651 | Acc(val) 0.9159 |
Epoch 00075 | Loss(train) 0.4361 | Acc(train) 0.8677 | Acc(val) 0.9159 |
Epoch 00076 | Loss(train) 0.4319 | Acc(train) 0.8711 | Acc(val) 0.9239 |*
Epoch 00077 | Loss(train) 0.4175 | Acc(train) 0.8751 | Acc(val) 0.9266 |*
Epoch 00078 | Loss(train) 0.4144 | Acc(train) 0.8724 | Acc(val) 0.9252 |
Epoch 00079 | Loss(train) 0.4145 | Acc(train) 0.8751 | Acc(val) 0.9212 |
Epoch 00080 | Loss(train) 0.4042 | Acc(train) 0.8737 | Acc(val) 0.9212 |
Epoch 00081 | Loss(train) 0.4180 | Acc(train) 0.8631 | Acc(val) 0.9212 |
Epoch 00082 | Loss(train) 0.4130 | Acc(train) 0.8664 | Acc(val) 0.9239 |
Epoch 00083 | Loss(train) 0.4156 | Acc(train) 0.8677 | Acc(val) 0.9226 |
Epoch 00084 | Loss(train) 0.4152 | Acc(train) 0.8697 | Acc(val) 0.9212 |
Epoch 00085 | Loss(train) 0.4017 | Acc(train) 0.8751 | Acc(val) 0.9239 |
Epoch 00086 | Loss(train) 0.3901 | Acc(train) 0.8838 | Acc(val) 0.9226 |
Epoch 00087 | Loss(train) 0.3855 | Acc(train) 0.8804 | Acc(val) 0.9252 |
Epoch 00088 | Loss(train) 0.3849 | Acc(train) 0.8858 | Acc(val) 0.9266 |
Epoch 00089 | Loss(train) 0.3903 | Acc(train) 0.8891 | Acc(val) 0.9279 |*
Epoch 00090 | Loss(train) 0.4031 | Acc(train) 0.8657 | Acc(val) 0.9266 |
Epoch 00091 | Loss(train) 0.3581 | Acc(train) 0.8918 | Acc(val) 0.9266 |
Epoch 00092 | Loss(train) 0.4023 | Acc(train) 0.8764 | Acc(val) 0.9266 |
Epoch 00093 | Loss(train) 0.3902 | Acc(train) 0.8778 | Acc(val) 0.9252 |
Epoch 00094 | Loss(train) 0.3722 | Acc(train) 0.8818 | Acc(val) 0.9266 |
Epoch 00095 | Loss(train) 0.3647 | Acc(train) 0.8931 | Acc(val) 0.9252 |
Epoch 00096 | Loss(train) 0.3736 | Acc(train) 0.8864 | Acc(val) 0.9279 |
Epoch 00097 | Loss(train) 0.3723 | Acc(train) 0.8864 | Acc(val) 0.9292 |*
Epoch 00098 | Loss(train) 0.3852 | Acc(train) 0.8891 | Acc(val) 0.9292 |
Epoch 00099 | Loss(train) 0.3673 | Acc(train) 0.8891 | Acc(val) 0.9239 |
Epoch 00100 | Loss(train) 0.3628 | Acc(train) 0.8951 | Acc(val) 0.9252 |
Epoch 00101 | Loss(train) 0.3510 | Acc(train) 0.8991 | Acc(val) 0.9279 |
Epoch 00102 | Loss(train) 0.3801 | Acc(train) 0.8731 | Acc(val) 0.9279 |
Epoch 00103 | Loss(train) 0.3592 | Acc(train) 0.8851 | Acc(val) 0.9266 |
Epoch 00104 | Loss(train) 0.3688 | Acc(train) 0.8958 | Acc(val) 0.9266 |
Epoch 00105 | Loss(train) 0.3742 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00106 | Loss(train) 0.3664 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00107 | Loss(train) 0.3571 | Acc(train) 0.8791 | Acc(val) 0.9292 |
Epoch 00108 | Loss(train) 0.3425 | Acc(train) 0.9011 | Acc(val) 0.9306 |*
Epoch 00109 | Loss(train) 0.3598 | Acc(train) 0.8858 | Acc(val) 0.9266 |
Epoch 00110 | Loss(train) 0.3457 | Acc(train) 0.8871 | Acc(val) 0.9306 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00111 | Loss(train) 0.3569 | Acc(train) 0.8811 | Acc(val) 0.9279 |
Epoch 00112 | Loss(train) 0.3589 | Acc(train) 0.8884 | Acc(val) 0.9346 |*
Epoch 00113 | Loss(train) 0.3572 | Acc(train) 0.8958 | Acc(val) 0.9292 |
Epoch 00114 | Loss(train) 0.3395 | Acc(train) 0.8958 | Acc(val) 0.9279 |
Epoch 00115 | Loss(train) 0.3459 | Acc(train) 0.8998 | Acc(val) 0.9266 |
Epoch 00116 | Loss(train) 0.3448 | Acc(train) 0.8871 | Acc(val) 0.9292 |
Epoch 00117 | Loss(train) 0.3277 | Acc(train) 0.8951 | Acc(val) 0.9292 |
Epoch 00118 | Loss(train) 0.3314 | Acc(train) 0.8965 | Acc(val) 0.9306 |
Epoch 00119 | Loss(train) 0.3403 | Acc(train) 0.8938 | Acc(val) 0.9306 |
Epoch 00120 | Loss(train) 0.3483 | Acc(train) 0.8951 | Acc(val) 0.9292 |
Epoch 00121 | Loss(train) 0.3385 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00122 | Loss(train) 0.3393 | Acc(train) 0.8971 | Acc(val) 0.9306 |
Epoch 00123 | Loss(train) 0.3340 | Acc(train) 0.9031 | Acc(val) 0.9279 |
Epoch 00124 | Loss(train) 0.3261 | Acc(train) 0.8971 | Acc(val) 0.9292 |
Epoch 00125 | Loss(train) 0.3515 | Acc(train) 0.8878 | Acc(val) 0.9292 |
Epoch 00126 | Loss(train) 0.3175 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00127 | Loss(train) 0.3601 | Acc(train) 0.8864 | Acc(val) 0.9319 |
Epoch 00128 | Loss(train) 0.3364 | Acc(train) 0.8938 | Acc(val) 0.9372 |*
Epoch 00129 | Loss(train) 0.3441 | Acc(train) 0.8898 | Acc(val) 0.9306 |
Epoch 00130 | Loss(train) 0.3558 | Acc(train) 0.8951 | Acc(val) 0.9319 |
Epoch 00131 | Loss(train) 0.3300 | Acc(train) 0.8998 | Acc(val) 0.9306 |
Epoch 00132 | Loss(train) 0.3295 | Acc(train) 0.9038 | Acc(val) 0.9239 |
Epoch 00133 | Loss(train) 0.3376 | Acc(train) 0.8965 | Acc(val) 0.9252 |
Epoch 00134 | Loss(train) 0.3481 | Acc(train) 0.8925 | Acc(val) 0.9279 |
Epoch 00135 | Loss(train) 0.3302 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00136 | Loss(train) 0.3125 | Acc(train) 0.9031 | Acc(val) 0.9319 |
Epoch 00137 | Loss(train) 0.3526 | Acc(train) 0.8938 | Acc(val) 0.9292 |
Epoch 00138 | Loss(train) 0.3463 | Acc(train) 0.9018 | Acc(val) 0.9306 |
Epoch 00139 | Loss(train) 0.3266 | Acc(train) 0.8985 | Acc(val) 0.9292 |
Epoch 00140 | Loss(train) 0.3442 | Acc(train) 0.8951 | Acc(val) 0.9306 |
Epoch 00141 | Loss(train) 0.3355 | Acc(train) 0.8971 | Acc(val) 0.9252 |
Epoch 00142 | Loss(train) 0.3466 | Acc(train) 0.8985 | Acc(val) 0.9292 |
Epoch 00143 | Loss(train) 0.3459 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00144 | Loss(train) 0.3299 | Acc(train) 0.9071 | Acc(val) 0.9346 |
Epoch 00145 | Loss(train) 0.3193 | Acc(train) 0.9065 | Acc(val) 0.9319 |
Epoch 00146 | Loss(train) 0.3360 | Acc(train) 0.9031 | Acc(val) 0.9319 |
Epoch 00147 | Loss(train) 0.3121 | Acc(train) 0.9145 | Acc(val) 0.9319 |
Epoch 00148 | Loss(train) 0.3425 | Acc(train) 0.8891 | Acc(val) 0.9306 |
Epoch 00149 | Loss(train) 0.3331 | Acc(train) 0.8965 | Acc(val) 0.9332 |
Epoch 00150 | Loss(train) 0.3188 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00151 | Loss(train) 0.3018 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00152 | Loss(train) 0.3383 | Acc(train) 0.8958 | Acc(val) 0.9372 |
Epoch 00153 | Loss(train) 0.3211 | Acc(train) 0.9025 | Acc(val) 0.9359 |
Epoch 00154 | Loss(train) 0.3169 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00155 | Loss(train) 0.3282 | Acc(train) 0.8945 | Acc(val) 0.9319 |
Epoch 00156 | Loss(train) 0.3220 | Acc(train) 0.8971 | Acc(val) 0.9306 |
Epoch 00157 | Loss(train) 0.3185 | Acc(train) 0.9018 | Acc(val) 0.9292 |
Epoch 00158 | Loss(train) 0.3262 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00159 | Loss(train) 0.3068 | Acc(train) 0.9092 | Acc(val) 0.9306 |
Epoch 00160 | Loss(train) 0.3154 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.3181 | Acc(train) 0.9051 | Acc(val) 0.9319 |
Epoch 00162 | Loss(train) 0.3178 | Acc(train) 0.9005 | Acc(val) 0.9306 |
Epoch 00163 | Loss(train) 0.3003 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00164 | Loss(train) 0.3148 | Acc(train) 0.9025 | Acc(val) 0.9292 |
Epoch 00165 | Loss(train) 0.3059 | Acc(train) 0.9058 | Acc(val) 0.9359 |
Epoch 00166 | Loss(train) 0.3258 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00167 | Loss(train) 0.3276 | Acc(train) 0.8978 | Acc(val) 0.9319 |
Epoch 00168 | Loss(train) 0.3048 | Acc(train) 0.9031 | Acc(val) 0.9319 |
Epoch 00169 | Loss(train) 0.3116 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00170 | Loss(train) 0.3094 | Acc(train) 0.9112 | Acc(val) 0.9306 |
Epoch 00171 | Loss(train) 0.3040 | Acc(train) 0.9071 | Acc(val) 0.9359 |
Epoch 00172 | Loss(train) 0.3226 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Epoch 00173 | Loss(train) 0.2934 | Acc(train) 0.9172 | Acc(val) 0.9319 |
Epoch 00174 | Loss(train) 0.3125 | Acc(train) 0.9112 | Acc(val) 0.9306 |
Epoch 00175 | Loss(train) 0.3080 | Acc(train) 0.9018 | Acc(val) 0.9332 |
Epoch 00176 | Loss(train) 0.3138 | Acc(train) 0.9125 | Acc(val) 0.9319 |
Epoch 00177 | Loss(train) 0.3171 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Early stopping at epoch 177
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3004 | Acc(train) 0.0922 | Acc(val) 0.1989 |*
Epoch 00002 | Loss(train) 4.0025 | Acc(train) 0.2144 | Acc(val) 0.2550 |*
Epoch 00003 | Loss(train) 4.3692 | Acc(train) 0.2752 | Acc(val) 0.1148 |
Epoch 00004 | Loss(train) 3.1587 | Acc(train) 0.1323 | Acc(val) 0.1148 |
Epoch 00005 | Loss(train) 2.6131 | Acc(train) 0.1089 | Acc(val) 0.2069 |
Epoch 00006 | Loss(train) 2.1525 | Acc(train) 0.2191 | Acc(val) 0.2243 |
Epoch 00007 | Loss(train) 2.3864 | Acc(train) 0.2318 | Acc(val) 0.3244 |*
Epoch 00008 | Loss(train) 2.1227 | Acc(train) 0.2512 | Acc(val) 0.5247 |*
Epoch 00009 | Loss(train) 1.7548 | Acc(train) 0.4362 | Acc(val) 0.2563 |
Epoch 00010 | Loss(train) 1.8954 | Acc(train) 0.3113 | Acc(val) 0.2563 |
Epoch 00011 | Loss(train) 1.7645 | Acc(train) 0.3180 | Acc(val) 0.5381 |*
Epoch 00012 | Loss(train) 1.5612 | Acc(train) 0.4703 | Acc(val) 0.5834 |*
Epoch 00013 | Loss(train) 1.4986 | Acc(train) 0.5304 | Acc(val) 0.4446 |
Epoch 00014 | Loss(train) 1.5532 | Acc(train) 0.4369 | Acc(val) 0.4513 |
Epoch 00015 | Loss(train) 1.5588 | Acc(train) 0.4182 | Acc(val) 0.6128 |*
Epoch 00016 | Loss(train) 1.5196 | Acc(train) 0.5478 | Acc(val) 0.7343 |*
Epoch 00017 | Loss(train) 1.4529 | Acc(train) 0.6593 | Acc(val) 0.8051 |*
Epoch 00018 | Loss(train) 1.3600 | Acc(train) 0.7047 | Acc(val) 0.7503 |
Epoch 00019 | Loss(train) 1.3184 | Acc(train) 0.6887 | Acc(val) 0.7023 |
Epoch 00020 | Loss(train) 1.2831 | Acc(train) 0.6513 | Acc(val) 0.6262 |
Epoch 00021 | Loss(train) 1.2417 | Acc(train) 0.6279 | Acc(val) 0.6595 |
Epoch 00022 | Loss(train) 1.1227 | Acc(train) 0.6333 | Acc(val) 0.7036 |
Epoch 00023 | Loss(train) 1.1203 | Acc(train) 0.6473 | Acc(val) 0.7236 |
Epoch 00024 | Loss(train) 1.0409 | Acc(train) 0.6647 | Acc(val) 0.7503 |
Epoch 00025 | Loss(train) 1.0656 | Acc(train) 0.6967 | Acc(val) 0.7730 |
Epoch 00026 | Loss(train) 0.9876 | Acc(train) 0.7061 | Acc(val) 0.7877 |
Epoch 00027 | Loss(train) 0.9657 | Acc(train) 0.6987 | Acc(val) 0.8091 |*
Epoch 00028 | Loss(train) 0.9320 | Acc(train) 0.6921 | Acc(val) 0.8358 |*
Epoch 00029 | Loss(train) 0.8914 | Acc(train) 0.7448 | Acc(val) 0.8465 |*
Epoch 00030 | Loss(train) 0.8579 | Acc(train) 0.7568 | Acc(val) 0.8518 |*
Epoch 00031 | Loss(train) 0.8522 | Acc(train) 0.7482 | Acc(val) 0.8772 |*
Epoch 00032 | Loss(train) 0.8732 | Acc(train) 0.7288 | Acc(val) 0.8838 |*
Epoch 00033 | Loss(train) 0.7703 | Acc(train) 0.8069 | Acc(val) 0.8798 |
Epoch 00034 | Loss(train) 0.8222 | Acc(train) 0.7542 | Acc(val) 0.8812 |
Epoch 00035 | Loss(train) 0.7978 | Acc(train) 0.7769 | Acc(val) 0.8785 |
Epoch 00036 | Loss(train) 0.7322 | Acc(train) 0.8029 | Acc(val) 0.8825 |
Epoch 00037 | Loss(train) 0.7401 | Acc(train) 0.7842 | Acc(val) 0.8879 |*
Epoch 00038 | Loss(train) 0.7427 | Acc(train) 0.7882 | Acc(val) 0.8879 |
Epoch 00039 | Loss(train) 0.7314 | Acc(train) 0.7882 | Acc(val) 0.8945 |*
Epoch 00040 | Loss(train) 0.6844 | Acc(train) 0.8110 | Acc(val) 0.8972 |*
Epoch 00041 | Loss(train) 0.6575 | Acc(train) 0.8110 | Acc(val) 0.8999 |*
Epoch 00042 | Loss(train) 0.6667 | Acc(train) 0.8136 | Acc(val) 0.8972 |
Epoch 00043 | Loss(train) 0.6468 | Acc(train) 0.8123 | Acc(val) 0.9025 |*
Epoch 00044 | Loss(train) 0.6279 | Acc(train) 0.8257 | Acc(val) 0.9052 |*
Epoch 00045 | Loss(train) 0.6514 | Acc(train) 0.8216 | Acc(val) 0.8999 |
Epoch 00046 | Loss(train) 0.6131 | Acc(train) 0.8270 | Acc(val) 0.8999 |
Epoch 00047 | Loss(train) 0.5956 | Acc(train) 0.8310 | Acc(val) 0.8985 |
Epoch 00048 | Loss(train) 0.6215 | Acc(train) 0.8363 | Acc(val) 0.9052 |
Epoch 00049 | Loss(train) 0.5881 | Acc(train) 0.8424 | Acc(val) 0.9065 |*
Epoch 00050 | Loss(train) 0.6005 | Acc(train) 0.8203 | Acc(val) 0.9052 |
Epoch 00051 | Loss(train) 0.5766 | Acc(train) 0.8383 | Acc(val) 0.9092 |*
Epoch 00052 | Loss(train) 0.5734 | Acc(train) 0.8297 | Acc(val) 0.9065 |
Epoch 00053 | Loss(train) 0.5501 | Acc(train) 0.8450 | Acc(val) 0.9052 |
Epoch 00054 | Loss(train) 0.5297 | Acc(train) 0.8470 | Acc(val) 0.9065 |
Epoch 00055 | Loss(train) 0.5327 | Acc(train) 0.8383 | Acc(val) 0.9039 |
Epoch 00056 | Loss(train) 0.5400 | Acc(train) 0.8424 | Acc(val) 0.9025 |
Epoch 00057 | Loss(train) 0.5118 | Acc(train) 0.8484 | Acc(val) 0.9012 |
Epoch 00058 | Loss(train) 0.5026 | Acc(train) 0.8470 | Acc(val) 0.9092 |
Epoch 00059 | Loss(train) 0.5006 | Acc(train) 0.8444 | Acc(val) 0.9105 |*
Epoch 00060 | Loss(train) 0.5219 | Acc(train) 0.8397 | Acc(val) 0.9079 |
Epoch 00061 | Loss(train) 0.5097 | Acc(train) 0.8377 | Acc(val) 0.9092 |
Epoch 00062 | Loss(train) 0.4890 | Acc(train) 0.8591 | Acc(val) 0.9105 |
Epoch 00063 | Loss(train) 0.4993 | Acc(train) 0.8343 | Acc(val) 0.9065 |
Epoch 00064 | Loss(train) 0.4577 | Acc(train) 0.8691 | Acc(val) 0.9092 |
Epoch 00065 | Loss(train) 0.4759 | Acc(train) 0.8597 | Acc(val) 0.9092 |
Epoch 00066 | Loss(train) 0.4619 | Acc(train) 0.8664 | Acc(val) 0.9119 |*
Epoch 00067 | Loss(train) 0.4809 | Acc(train) 0.8570 | Acc(val) 0.9119 |
Epoch 00068 | Loss(train) 0.4705 | Acc(train) 0.8550 | Acc(val) 0.9146 |*
Epoch 00069 | Loss(train) 0.4455 | Acc(train) 0.8570 | Acc(val) 0.9146 |
Epoch 00070 | Loss(train) 0.4615 | Acc(train) 0.8517 | Acc(val) 0.9146 |
Epoch 00071 | Loss(train) 0.4430 | Acc(train) 0.8624 | Acc(val) 0.9132 |
Epoch 00072 | Loss(train) 0.4297 | Acc(train) 0.8677 | Acc(val) 0.9146 |
Epoch 00073 | Loss(train) 0.4408 | Acc(train) 0.8644 | Acc(val) 0.9199 |*
Epoch 00074 | Loss(train) 0.4258 | Acc(train) 0.8624 | Acc(val) 0.9172 |
Epoch 00075 | Loss(train) 0.4484 | Acc(train) 0.8604 | Acc(val) 0.9172 |
Epoch 00076 | Loss(train) 0.4273 | Acc(train) 0.8637 | Acc(val) 0.9172 |
Epoch 00077 | Loss(train) 0.4333 | Acc(train) 0.8631 | Acc(val) 0.9199 |
Epoch 00078 | Loss(train) 0.3979 | Acc(train) 0.8737 | Acc(val) 0.9239 |*
Epoch 00079 | Loss(train) 0.4337 | Acc(train) 0.8671 | Acc(val) 0.9226 |
Epoch 00080 | Loss(train) 0.4079 | Acc(train) 0.8737 | Acc(val) 0.9239 |
Epoch 00081 | Loss(train) 0.4012 | Acc(train) 0.8751 | Acc(val) 0.9199 |
Epoch 00082 | Loss(train) 0.4150 | Acc(train) 0.8704 | Acc(val) 0.9172 |
Epoch 00083 | Loss(train) 0.3989 | Acc(train) 0.8644 | Acc(val) 0.9212 |
Epoch 00084 | Loss(train) 0.4174 | Acc(train) 0.8717 | Acc(val) 0.9226 |
Epoch 00085 | Loss(train) 0.4088 | Acc(train) 0.8764 | Acc(val) 0.9252 |*
Epoch 00086 | Loss(train) 0.4147 | Acc(train) 0.8544 | Acc(val) 0.9239 |
Epoch 00087 | Loss(train) 0.4070 | Acc(train) 0.8744 | Acc(val) 0.9239 |
Epoch 00088 | Loss(train) 0.4157 | Acc(train) 0.8684 | Acc(val) 0.9199 |
Epoch 00089 | Loss(train) 0.4095 | Acc(train) 0.8657 | Acc(val) 0.9266 |*
Epoch 00090 | Loss(train) 0.3832 | Acc(train) 0.8864 | Acc(val) 0.9252 |
Epoch 00091 | Loss(train) 0.3932 | Acc(train) 0.8798 | Acc(val) 0.9266 |
Epoch 00092 | Loss(train) 0.3930 | Acc(train) 0.8838 | Acc(val) 0.9239 |
Epoch 00093 | Loss(train) 0.4120 | Acc(train) 0.8684 | Acc(val) 0.9306 |*
Epoch 00094 | Loss(train) 0.3933 | Acc(train) 0.8804 | Acc(val) 0.9239 |
Epoch 00095 | Loss(train) 0.3933 | Acc(train) 0.8824 | Acc(val) 0.9239 |
Epoch 00096 | Loss(train) 0.3835 | Acc(train) 0.8758 | Acc(val) 0.9292 |
Epoch 00097 | Loss(train) 0.3908 | Acc(train) 0.8818 | Acc(val) 0.9306 |
Epoch 00098 | Loss(train) 0.3729 | Acc(train) 0.8851 | Acc(val) 0.9266 |
Epoch 00099 | Loss(train) 0.3865 | Acc(train) 0.8758 | Acc(val) 0.9252 |
Epoch 00100 | Loss(train) 0.3873 | Acc(train) 0.8784 | Acc(val) 0.9319 |*
Epoch 00101 | Loss(train) 0.3797 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00102 | Loss(train) 0.3674 | Acc(train) 0.8878 | Acc(val) 0.9279 |
Epoch 00103 | Loss(train) 0.3898 | Acc(train) 0.8717 | Acc(val) 0.9319 |
Epoch 00104 | Loss(train) 0.3637 | Acc(train) 0.8871 | Acc(val) 0.9292 |
Epoch 00105 | Loss(train) 0.3635 | Acc(train) 0.8898 | Acc(val) 0.9266 |
Epoch 00106 | Loss(train) 0.3807 | Acc(train) 0.8778 | Acc(val) 0.9306 |
Epoch 00107 | Loss(train) 0.3604 | Acc(train) 0.8784 | Acc(val) 0.9346 |*
Epoch 00108 | Loss(train) 0.3601 | Acc(train) 0.8838 | Acc(val) 0.9306 |
Epoch 00109 | Loss(train) 0.3687 | Acc(train) 0.8804 | Acc(val) 0.9306 |
Epoch 00110 | Loss(train) 0.3662 | Acc(train) 0.8871 | Acc(val) 0.9319 |
Epoch 00111 | Loss(train) 0.3760 | Acc(train) 0.8858 | Acc(val) 0.9319 |
Epoch 00112 | Loss(train) 0.3641 | Acc(train) 0.8898 | Acc(val) 0.9346 |
Epoch 00113 | Loss(train) 0.3362 | Acc(train) 0.8965 | Acc(val) 0.9319 |
Epoch 00114 | Loss(train) 0.3569 | Acc(train) 0.8898 | Acc(val) 0.9332 |
Epoch 00115 | Loss(train) 0.3531 | Acc(train) 0.9005 | Acc(val) 0.9306 |
Epoch 00116 | Loss(train) 0.3421 | Acc(train) 0.8945 | Acc(val) 0.9292 |
Epoch 00117 | Loss(train) 0.3775 | Acc(train) 0.8751 | Acc(val) 0.9332 |
Epoch 00118 | Loss(train) 0.3696 | Acc(train) 0.8891 | Acc(val) 0.9319 |
Epoch 00119 | Loss(train) 0.3576 | Acc(train) 0.8864 | Acc(val) 0.9292 |
Epoch 00120 | Loss(train) 0.3494 | Acc(train) 0.8985 | Acc(val) 0.9359 |*
Epoch 00121 | Loss(train) 0.3539 | Acc(train) 0.8891 | Acc(val) 0.9332 |
Epoch 00122 | Loss(train) 0.3481 | Acc(train) 0.8891 | Acc(val) 0.9332 |
Epoch 00123 | Loss(train) 0.3513 | Acc(train) 0.8938 | Acc(val) 0.9332 |
Epoch 00124 | Loss(train) 0.3543 | Acc(train) 0.8891 | Acc(val) 0.9346 |
Epoch 00125 | Loss(train) 0.3448 | Acc(train) 0.8938 | Acc(val) 0.9332 |
Epoch 00126 | Loss(train) 0.3463 | Acc(train) 0.8918 | Acc(val) 0.9332 |
Epoch 00127 | Loss(train) 0.3364 | Acc(train) 0.8978 | Acc(val) 0.9332 |
Epoch 00128 | Loss(train) 0.3492 | Acc(train) 0.8958 | Acc(val) 0.9319 |
Epoch 00129 | Loss(train) 0.3596 | Acc(train) 0.8998 | Acc(val) 0.9319 |
Epoch 00130 | Loss(train) 0.3358 | Acc(train) 0.8958 | Acc(val) 0.9319 |
Epoch 00131 | Loss(train) 0.3412 | Acc(train) 0.8958 | Acc(val) 0.9372 |*
Epoch 00132 | Loss(train) 0.3310 | Acc(train) 0.9038 | Acc(val) 0.9346 |
Epoch 00133 | Loss(train) 0.3100 | Acc(train) 0.9098 | Acc(val) 0.9346 |
Epoch 00134 | Loss(train) 0.3365 | Acc(train) 0.8918 | Acc(val) 0.9306 |
Epoch 00135 | Loss(train) 0.3384 | Acc(train) 0.8945 | Acc(val) 0.9332 |
Epoch 00136 | Loss(train) 0.3486 | Acc(train) 0.8931 | Acc(val) 0.9306 |
Epoch 00137 | Loss(train) 0.3393 | Acc(train) 0.8965 | Acc(val) 0.9319 |
Epoch 00138 | Loss(train) 0.3396 | Acc(train) 0.8971 | Acc(val) 0.9346 |
Epoch 00139 | Loss(train) 0.3423 | Acc(train) 0.8844 | Acc(val) 0.9306 |
Epoch 00140 | Loss(train) 0.3343 | Acc(train) 0.8978 | Acc(val) 0.9319 |
Epoch 00141 | Loss(train) 0.3527 | Acc(train) 0.8838 | Acc(val) 0.9359 |
Epoch 00142 | Loss(train) 0.3236 | Acc(train) 0.9011 | Acc(val) 0.9359 |
Epoch 00143 | Loss(train) 0.3412 | Acc(train) 0.9018 | Acc(val) 0.9359 |
Epoch 00144 | Loss(train) 0.3396 | Acc(train) 0.8918 | Acc(val) 0.9372 |
Epoch 00145 | Loss(train) 0.3424 | Acc(train) 0.8918 | Acc(val) 0.9332 |
Epoch 00146 | Loss(train) 0.3325 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00147 | Loss(train) 0.3327 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00148 | Loss(train) 0.3430 | Acc(train) 0.8931 | Acc(val) 0.9359 |
Epoch 00149 | Loss(train) 0.3199 | Acc(train) 0.9071 | Acc(val) 0.9359 |
Epoch 00150 | Loss(train) 0.3449 | Acc(train) 0.8911 | Acc(val) 0.9332 |
Epoch 00151 | Loss(train) 0.3304 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00152 | Loss(train) 0.3310 | Acc(train) 0.8931 | Acc(val) 0.9332 |
Epoch 00153 | Loss(train) 0.3193 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00154 | Loss(train) 0.3283 | Acc(train) 0.9018 | Acc(val) 0.9372 |
Epoch 00155 | Loss(train) 0.3248 | Acc(train) 0.9031 | Acc(val) 0.9372 |
Epoch 00156 | Loss(train) 0.3235 | Acc(train) 0.9031 | Acc(val) 0.9332 |
Epoch 00157 | Loss(train) 0.3166 | Acc(train) 0.9018 | Acc(val) 0.9319 |
Epoch 00158 | Loss(train) 0.3397 | Acc(train) 0.8931 | Acc(val) 0.9319 |
Epoch 00159 | Loss(train) 0.3328 | Acc(train) 0.8991 | Acc(val) 0.9359 |
Epoch 00160 | Loss(train) 0.3269 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.3196 | Acc(train) 0.8985 | Acc(val) 0.9346 |
Epoch 00162 | Loss(train) 0.3245 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00163 | Loss(train) 0.3298 | Acc(train) 0.9005 | Acc(val) 0.9359 |
Epoch 00164 | Loss(train) 0.3127 | Acc(train) 0.8978 | Acc(val) 0.9359 |
Epoch 00165 | Loss(train) 0.3113 | Acc(train) 0.9031 | Acc(val) 0.9332 |
Epoch 00166 | Loss(train) 0.3064 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00167 | Loss(train) 0.3049 | Acc(train) 0.9112 | Acc(val) 0.9386 |*
Epoch 00168 | Loss(train) 0.3186 | Acc(train) 0.9058 | Acc(val) 0.9386 |
Epoch 00169 | Loss(train) 0.3169 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00170 | Loss(train) 0.3018 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00171 | Loss(train) 0.3143 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00172 | Loss(train) 0.3097 | Acc(train) 0.9038 | Acc(val) 0.9346 |
Epoch 00173 | Loss(train) 0.3248 | Acc(train) 0.8985 | Acc(val) 0.9359 |
Epoch 00174 | Loss(train) 0.3100 | Acc(train) 0.8998 | Acc(val) 0.9359 |
Epoch 00175 | Loss(train) 0.3276 | Acc(train) 0.9031 | Acc(val) 0.9386 |
Epoch 00176 | Loss(train) 0.3258 | Acc(train) 0.9031 | Acc(val) 0.9332 |
Epoch 00177 | Loss(train) 0.3221 | Acc(train) 0.8918 | Acc(val) 0.9346 |
Epoch 00178 | Loss(train) 0.3120 | Acc(train) 0.9078 | Acc(val) 0.9372 |
Epoch 00179 | Loss(train) 0.3041 | Acc(train) 0.9058 | Acc(val) 0.9386 |
Epoch 00180 | Loss(train) 0.3013 | Acc(train) 0.9132 | Acc(val) 0.9359 |
Epoch 00181 | Loss(train) 0.3077 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.3053 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00183 | Loss(train) 0.3032 | Acc(train) 0.9078 | Acc(val) 0.9399 |*
Epoch 00184 | Loss(train) 0.2907 | Acc(train) 0.9085 | Acc(val) 0.9372 |
Epoch 00185 | Loss(train) 0.3214 | Acc(train) 0.8985 | Acc(val) 0.9359 |
Epoch 00186 | Loss(train) 0.3112 | Acc(train) 0.9045 | Acc(val) 0.9332 |
Epoch 00187 | Loss(train) 0.3143 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00188 | Loss(train) 0.2993 | Acc(train) 0.9051 | Acc(val) 0.9386 |
Epoch 00189 | Loss(train) 0.2960 | Acc(train) 0.9098 | Acc(val) 0.9386 |
Epoch 00190 | Loss(train) 0.3064 | Acc(train) 0.9098 | Acc(val) 0.9359 |
Epoch 00191 | Loss(train) 0.3144 | Acc(train) 0.9018 | Acc(val) 0.9359 |
Epoch 00192 | Loss(train) 0.2940 | Acc(train) 0.9078 | Acc(val) 0.9332 |
Epoch 00193 | Loss(train) 0.2905 | Acc(train) 0.9071 | Acc(val) 0.9346 |
Epoch 00194 | Loss(train) 0.2999 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00195 | Loss(train) 0.3071 | Acc(train) 0.9112 | Acc(val) 0.9359 |
Epoch 00196 | Loss(train) 0.3017 | Acc(train) 0.9058 | Acc(val) 0.9359 |
Epoch 00197 | Loss(train) 0.3059 | Acc(train) 0.9025 | Acc(val) 0.9359 |
Epoch 00198 | Loss(train) 0.2864 | Acc(train) 0.9185 | Acc(val) 0.9372 |
Epoch 00199 | Loss(train) 0.3009 | Acc(train) 0.9092 | Acc(val) 0.9386 |
Epoch 00200 | Loss(train) 0.2874 | Acc(train) 0.9145 | Acc(val) 0.9386 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3133 | Acc(train) 0.0407 | Acc(val) 0.3351 |*
Epoch 00002 | Loss(train) 2.6350 | Acc(train) 0.2705 | Acc(val) 0.2003 |
Epoch 00003 | Loss(train) 3.2271 | Acc(train) 0.2398 | Acc(val) 0.2977 |
Epoch 00004 | Loss(train) 2.7895 | Acc(train) 0.2037 | Acc(val) 0.2550 |
Epoch 00005 | Loss(train) 2.3979 | Acc(train) 0.3280 | Acc(val) 0.6048 |*
Epoch 00006 | Loss(train) 1.6988 | Acc(train) 0.4329 | Acc(val) 0.2190 |
Epoch 00007 | Loss(train) 1.9021 | Acc(train) 0.2545 | Acc(val) 0.2697 |
Epoch 00008 | Loss(train) 1.9116 | Acc(train) 0.2371 | Acc(val) 0.4232 |
Epoch 00009 | Loss(train) 1.6525 | Acc(train) 0.3814 | Acc(val) 0.4860 |
Epoch 00010 | Loss(train) 1.4986 | Acc(train) 0.4790 | Acc(val) 0.4980 |
Epoch 00011 | Loss(train) 1.4423 | Acc(train) 0.5130 | Acc(val) 0.4766 |
Epoch 00012 | Loss(train) 1.4803 | Acc(train) 0.4723 | Acc(val) 0.6075 |*
Epoch 00013 | Loss(train) 1.4416 | Acc(train) 0.5424 | Acc(val) 0.6529 |*
Epoch 00014 | Loss(train) 1.3541 | Acc(train) 0.6099 | Acc(val) 0.7103 |*
Epoch 00015 | Loss(train) 1.2942 | Acc(train) 0.6420 | Acc(val) 0.6983 |
Epoch 00016 | Loss(train) 1.2229 | Acc(train) 0.6560 | Acc(val) 0.6796 |
Epoch 00017 | Loss(train) 1.1760 | Acc(train) 0.6633 | Acc(val) 0.7156 |*
Epoch 00018 | Loss(train) 1.1557 | Acc(train) 0.6440 | Acc(val) 0.7637 |*
Epoch 00019 | Loss(train) 1.0769 | Acc(train) 0.6981 | Acc(val) 0.8331 |*
Epoch 00020 | Loss(train) 1.1074 | Acc(train) 0.6774 | Acc(val) 0.8385 |*
Epoch 00021 | Loss(train) 1.0329 | Acc(train) 0.6954 | Acc(val) 0.8318 |
Epoch 00022 | Loss(train) 0.9939 | Acc(train) 0.7128 | Acc(val) 0.8251 |
Epoch 00023 | Loss(train) 0.9533 | Acc(train) 0.7074 | Acc(val) 0.8184 |
Epoch 00024 | Loss(train) 0.9387 | Acc(train) 0.7067 | Acc(val) 0.8064 |
Epoch 00025 | Loss(train) 0.9174 | Acc(train) 0.7094 | Acc(val) 0.8304 |
Epoch 00026 | Loss(train) 0.8815 | Acc(train) 0.7355 | Acc(val) 0.8411 |*
Epoch 00027 | Loss(train) 0.8839 | Acc(train) 0.7288 | Acc(val) 0.8598 |*
Epoch 00028 | Loss(train) 0.8477 | Acc(train) 0.7595 | Acc(val) 0.8638 |*
Epoch 00029 | Loss(train) 0.7994 | Acc(train) 0.7622 | Acc(val) 0.8585 |
Epoch 00030 | Loss(train) 0.7798 | Acc(train) 0.7896 | Acc(val) 0.8545 |
Epoch 00031 | Loss(train) 0.7586 | Acc(train) 0.7782 | Acc(val) 0.8505 |
Epoch 00032 | Loss(train) 0.7405 | Acc(train) 0.7782 | Acc(val) 0.8531 |
Epoch 00033 | Loss(train) 0.7173 | Acc(train) 0.7943 | Acc(val) 0.8692 |*
Epoch 00034 | Loss(train) 0.6863 | Acc(train) 0.7963 | Acc(val) 0.8892 |*
Epoch 00035 | Loss(train) 0.6829 | Acc(train) 0.8183 | Acc(val) 0.8892 |
Epoch 00036 | Loss(train) 0.6897 | Acc(train) 0.7976 | Acc(val) 0.8945 |*
Epoch 00037 | Loss(train) 0.6533 | Acc(train) 0.8150 | Acc(val) 0.9012 |*
Epoch 00038 | Loss(train) 0.6267 | Acc(train) 0.8383 | Acc(val) 0.8999 |
Epoch 00039 | Loss(train) 0.6193 | Acc(train) 0.8383 | Acc(val) 0.8972 |
Epoch 00040 | Loss(train) 0.6131 | Acc(train) 0.8277 | Acc(val) 0.8919 |
Epoch 00041 | Loss(train) 0.6062 | Acc(train) 0.8196 | Acc(val) 0.8825 |
Epoch 00042 | Loss(train) 0.6076 | Acc(train) 0.8196 | Acc(val) 0.8905 |
Epoch 00043 | Loss(train) 0.5789 | Acc(train) 0.8283 | Acc(val) 0.9012 |
Epoch 00044 | Loss(train) 0.5719 | Acc(train) 0.8343 | Acc(val) 0.9065 |*
Epoch 00045 | Loss(train) 0.5685 | Acc(train) 0.8310 | Acc(val) 0.9079 |*
Epoch 00046 | Loss(train) 0.5584 | Acc(train) 0.8283 | Acc(val) 0.9092 |*
Epoch 00047 | Loss(train) 0.5361 | Acc(train) 0.8450 | Acc(val) 0.9039 |
Epoch 00048 | Loss(train) 0.5288 | Acc(train) 0.8424 | Acc(val) 0.8972 |
Epoch 00049 | Loss(train) 0.5505 | Acc(train) 0.8337 | Acc(val) 0.8959 |
Epoch 00050 | Loss(train) 0.5171 | Acc(train) 0.8357 | Acc(val) 0.8959 |
Epoch 00051 | Loss(train) 0.4955 | Acc(train) 0.8517 | Acc(val) 0.9025 |
Epoch 00052 | Loss(train) 0.5054 | Acc(train) 0.8510 | Acc(val) 0.9052 |
Epoch 00053 | Loss(train) 0.4801 | Acc(train) 0.8591 | Acc(val) 0.9092 |
Epoch 00054 | Loss(train) 0.5141 | Acc(train) 0.8343 | Acc(val) 0.9092 |
Epoch 00055 | Loss(train) 0.5028 | Acc(train) 0.8497 | Acc(val) 0.9025 |
Epoch 00056 | Loss(train) 0.4799 | Acc(train) 0.8517 | Acc(val) 0.9065 |
Epoch 00057 | Loss(train) 0.4823 | Acc(train) 0.8477 | Acc(val) 0.9039 |
Epoch 00058 | Loss(train) 0.4521 | Acc(train) 0.8657 | Acc(val) 0.8999 |
Epoch 00059 | Loss(train) 0.4555 | Acc(train) 0.8657 | Acc(val) 0.9039 |
Epoch 00060 | Loss(train) 0.4746 | Acc(train) 0.8644 | Acc(val) 0.9052 |
Epoch 00061 | Loss(train) 0.4643 | Acc(train) 0.8537 | Acc(val) 0.9079 |
Epoch 00062 | Loss(train) 0.4654 | Acc(train) 0.8497 | Acc(val) 0.9105 |*
Epoch 00063 | Loss(train) 0.4318 | Acc(train) 0.8677 | Acc(val) 0.9159 |*
Epoch 00064 | Loss(train) 0.4383 | Acc(train) 0.8677 | Acc(val) 0.9172 |*
Epoch 00065 | Loss(train) 0.4473 | Acc(train) 0.8764 | Acc(val) 0.9159 |
Epoch 00066 | Loss(train) 0.4363 | Acc(train) 0.8644 | Acc(val) 0.9132 |
Epoch 00067 | Loss(train) 0.4253 | Acc(train) 0.8697 | Acc(val) 0.9105 |
Epoch 00068 | Loss(train) 0.4294 | Acc(train) 0.8637 | Acc(val) 0.9079 |
Epoch 00069 | Loss(train) 0.4430 | Acc(train) 0.8617 | Acc(val) 0.9065 |
Epoch 00070 | Loss(train) 0.4140 | Acc(train) 0.8677 | Acc(val) 0.9092 |
Epoch 00071 | Loss(train) 0.4292 | Acc(train) 0.8604 | Acc(val) 0.9159 |
Epoch 00072 | Loss(train) 0.4072 | Acc(train) 0.8791 | Acc(val) 0.9186 |*
Epoch 00073 | Loss(train) 0.4042 | Acc(train) 0.8737 | Acc(val) 0.9226 |*
Epoch 00074 | Loss(train) 0.3942 | Acc(train) 0.8864 | Acc(val) 0.9199 |
Epoch 00075 | Loss(train) 0.4051 | Acc(train) 0.8751 | Acc(val) 0.9212 |
Epoch 00076 | Loss(train) 0.4004 | Acc(train) 0.8737 | Acc(val) 0.9212 |
Epoch 00077 | Loss(train) 0.3761 | Acc(train) 0.8838 | Acc(val) 0.9172 |
Epoch 00078 | Loss(train) 0.3949 | Acc(train) 0.8864 | Acc(val) 0.9212 |
Epoch 00079 | Loss(train) 0.3894 | Acc(train) 0.8878 | Acc(val) 0.9186 |
Epoch 00080 | Loss(train) 0.3771 | Acc(train) 0.8851 | Acc(val) 0.9239 |*
Epoch 00081 | Loss(train) 0.3975 | Acc(train) 0.8744 | Acc(val) 0.9226 |
Epoch 00082 | Loss(train) 0.3944 | Acc(train) 0.8771 | Acc(val) 0.9199 |
Epoch 00083 | Loss(train) 0.3750 | Acc(train) 0.8911 | Acc(val) 0.9212 |
Epoch 00084 | Loss(train) 0.3756 | Acc(train) 0.8938 | Acc(val) 0.9279 |*
Epoch 00085 | Loss(train) 0.3653 | Acc(train) 0.8838 | Acc(val) 0.9199 |
Epoch 00086 | Loss(train) 0.3654 | Acc(train) 0.8831 | Acc(val) 0.9199 |
Epoch 00087 | Loss(train) 0.3655 | Acc(train) 0.8951 | Acc(val) 0.9279 |
Epoch 00088 | Loss(train) 0.3607 | Acc(train) 0.8871 | Acc(val) 0.9239 |
Epoch 00089 | Loss(train) 0.3665 | Acc(train) 0.8918 | Acc(val) 0.9239 |
Epoch 00090 | Loss(train) 0.3762 | Acc(train) 0.8891 | Acc(val) 0.9266 |
Epoch 00091 | Loss(train) 0.3471 | Acc(train) 0.8978 | Acc(val) 0.9292 |*
Epoch 00092 | Loss(train) 0.3587 | Acc(train) 0.8951 | Acc(val) 0.9279 |
Epoch 00093 | Loss(train) 0.3609 | Acc(train) 0.8911 | Acc(val) 0.9266 |
Epoch 00094 | Loss(train) 0.3503 | Acc(train) 0.8985 | Acc(val) 0.9266 |
Epoch 00095 | Loss(train) 0.3647 | Acc(train) 0.8864 | Acc(val) 0.9266 |
Epoch 00096 | Loss(train) 0.3523 | Acc(train) 0.8985 | Acc(val) 0.9359 |*
Epoch 00097 | Loss(train) 0.3589 | Acc(train) 0.8831 | Acc(val) 0.9359 |
Epoch 00098 | Loss(train) 0.3502 | Acc(train) 0.8958 | Acc(val) 0.9332 |
Epoch 00099 | Loss(train) 0.3388 | Acc(train) 0.9058 | Acc(val) 0.9279 |
Epoch 00100 | Loss(train) 0.3521 | Acc(train) 0.9005 | Acc(val) 0.9319 |
Epoch 00101 | Loss(train) 0.3463 | Acc(train) 0.8965 | Acc(val) 0.9292 |
Epoch 00102 | Loss(train) 0.3437 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00103 | Loss(train) 0.3287 | Acc(train) 0.9005 | Acc(val) 0.9279 |
Epoch 00104 | Loss(train) 0.3566 | Acc(train) 0.8878 | Acc(val) 0.9279 |
Epoch 00105 | Loss(train) 0.3411 | Acc(train) 0.9011 | Acc(val) 0.9292 |
Epoch 00106 | Loss(train) 0.3227 | Acc(train) 0.9011 | Acc(val) 0.9279 |
Epoch 00107 | Loss(train) 0.3283 | Acc(train) 0.8971 | Acc(val) 0.9292 |
Epoch 00108 | Loss(train) 0.3381 | Acc(train) 0.8951 | Acc(val) 0.9306 |
Epoch 00109 | Loss(train) 0.3167 | Acc(train) 0.9011 | Acc(val) 0.9319 |
Epoch 00110 | Loss(train) 0.3154 | Acc(train) 0.9025 | Acc(val) 0.9319 |
Epoch 00111 | Loss(train) 0.3174 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00112 | Loss(train) 0.3344 | Acc(train) 0.9065 | Acc(val) 0.9292 |
Epoch 00113 | Loss(train) 0.3182 | Acc(train) 0.8985 | Acc(val) 0.9306 |
Epoch 00114 | Loss(train) 0.3381 | Acc(train) 0.8898 | Acc(val) 0.9306 |
Epoch 00115 | Loss(train) 0.2968 | Acc(train) 0.9125 | Acc(val) 0.9292 |
Epoch 00116 | Loss(train) 0.3056 | Acc(train) 0.9132 | Acc(val) 0.9319 |
Epoch 00117 | Loss(train) 0.3136 | Acc(train) 0.9078 | Acc(val) 0.9279 |
Epoch 00118 | Loss(train) 0.2966 | Acc(train) 0.9071 | Acc(val) 0.9292 |
Epoch 00119 | Loss(train) 0.2964 | Acc(train) 0.9058 | Acc(val) 0.9332 |
Epoch 00120 | Loss(train) 0.3060 | Acc(train) 0.9051 | Acc(val) 0.9332 |
Epoch 00121 | Loss(train) 0.3073 | Acc(train) 0.9112 | Acc(val) 0.9319 |
Epoch 00122 | Loss(train) 0.3025 | Acc(train) 0.9018 | Acc(val) 0.9306 |
Epoch 00123 | Loss(train) 0.3092 | Acc(train) 0.9038 | Acc(val) 0.9292 |
Epoch 00124 | Loss(train) 0.2899 | Acc(train) 0.9152 | Acc(val) 0.9319 |
Epoch 00125 | Loss(train) 0.3139 | Acc(train) 0.9045 | Acc(val) 0.9306 |
Epoch 00126 | Loss(train) 0.2936 | Acc(train) 0.9112 | Acc(val) 0.9332 |
Epoch 00127 | Loss(train) 0.3151 | Acc(train) 0.8985 | Acc(val) 0.9319 |
Epoch 00128 | Loss(train) 0.3015 | Acc(train) 0.9098 | Acc(val) 0.9319 |
Epoch 00129 | Loss(train) 0.3011 | Acc(train) 0.9138 | Acc(val) 0.9359 |
Epoch 00130 | Loss(train) 0.2993 | Acc(train) 0.9112 | Acc(val) 0.9319 |
Epoch 00131 | Loss(train) 0.3248 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00132 | Loss(train) 0.3038 | Acc(train) 0.9105 | Acc(val) 0.9332 |
Epoch 00133 | Loss(train) 0.3065 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00134 | Loss(train) 0.2951 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00135 | Loss(train) 0.3031 | Acc(train) 0.9058 | Acc(val) 0.9306 |
Epoch 00136 | Loss(train) 0.3189 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00137 | Loss(train) 0.3024 | Acc(train) 0.9051 | Acc(val) 0.9306 |
Epoch 00138 | Loss(train) 0.2905 | Acc(train) 0.9112 | Acc(val) 0.9332 |
Epoch 00139 | Loss(train) 0.3035 | Acc(train) 0.9038 | Acc(val) 0.9372 |*
Epoch 00140 | Loss(train) 0.2943 | Acc(train) 0.9058 | Acc(val) 0.9386 |*
Epoch 00141 | Loss(train) 0.3055 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00142 | Loss(train) 0.3116 | Acc(train) 0.9051 | Acc(val) 0.9332 |
Epoch 00143 | Loss(train) 0.3223 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00144 | Loss(train) 0.2944 | Acc(train) 0.9071 | Acc(val) 0.9386 |
Epoch 00145 | Loss(train) 0.2923 | Acc(train) 0.9158 | Acc(val) 0.9413 |*
Epoch 00146 | Loss(train) 0.2945 | Acc(train) 0.9178 | Acc(val) 0.9372 |
Epoch 00147 | Loss(train) 0.3003 | Acc(train) 0.9071 | Acc(val) 0.9319 |
Epoch 00148 | Loss(train) 0.2924 | Acc(train) 0.9165 | Acc(val) 0.9372 |
Epoch 00149 | Loss(train) 0.3018 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00150 | Loss(train) 0.2839 | Acc(train) 0.9172 | Acc(val) 0.9346 |
Epoch 00151 | Loss(train) 0.3148 | Acc(train) 0.8978 | Acc(val) 0.9372 |
Epoch 00152 | Loss(train) 0.2970 | Acc(train) 0.9178 | Acc(val) 0.9399 |
Epoch 00153 | Loss(train) 0.2900 | Acc(train) 0.9185 | Acc(val) 0.9386 |
Epoch 00154 | Loss(train) 0.2864 | Acc(train) 0.9098 | Acc(val) 0.9346 |
Epoch 00155 | Loss(train) 0.2897 | Acc(train) 0.9071 | Acc(val) 0.9359 |
Epoch 00156 | Loss(train) 0.2744 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00157 | Loss(train) 0.3144 | Acc(train) 0.8985 | Acc(val) 0.9399 |
Epoch 00158 | Loss(train) 0.3231 | Acc(train) 0.9071 | Acc(val) 0.9306 |
Epoch 00159 | Loss(train) 0.2831 | Acc(train) 0.9138 | Acc(val) 0.9306 |
Epoch 00160 | Loss(train) 0.2877 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.2754 | Acc(train) 0.9185 | Acc(val) 0.9359 |
Epoch 00162 | Loss(train) 0.2798 | Acc(train) 0.9225 | Acc(val) 0.9346 |
Epoch 00163 | Loss(train) 0.2980 | Acc(train) 0.9078 | Acc(val) 0.9386 |
Epoch 00164 | Loss(train) 0.2913 | Acc(train) 0.9138 | Acc(val) 0.9386 |
Epoch 00165 | Loss(train) 0.3124 | Acc(train) 0.9058 | Acc(val) 0.9332 |
Epoch 00166 | Loss(train) 0.3034 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00167 | Loss(train) 0.2971 | Acc(train) 0.9018 | Acc(val) 0.9372 |
Epoch 00168 | Loss(train) 0.3009 | Acc(train) 0.9031 | Acc(val) 0.9319 |
Epoch 00169 | Loss(train) 0.2887 | Acc(train) 0.9132 | Acc(val) 0.9359 |
Epoch 00170 | Loss(train) 0.2859 | Acc(train) 0.9172 | Acc(val) 0.9332 |
Epoch 00171 | Loss(train) 0.3023 | Acc(train) 0.9018 | Acc(val) 0.9359 |
Epoch 00172 | Loss(train) 0.3125 | Acc(train) 0.9051 | Acc(val) 0.9386 |
Epoch 00173 | Loss(train) 0.2821 | Acc(train) 0.9098 | Acc(val) 0.9359 |
Epoch 00174 | Loss(train) 0.2918 | Acc(train) 0.9138 | Acc(val) 0.9346 |
Epoch 00175 | Loss(train) 0.2853 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00176 | Loss(train) 0.2744 | Acc(train) 0.9125 | Acc(val) 0.9372 |
Epoch 00177 | Loss(train) 0.2868 | Acc(train) 0.9078 | Acc(val) 0.9372 |
Epoch 00178 | Loss(train) 0.2834 | Acc(train) 0.9185 | Acc(val) 0.9399 |
Epoch 00179 | Loss(train) 0.3069 | Acc(train) 0.9092 | Acc(val) 0.9399 |
Epoch 00180 | Loss(train) 0.2772 | Acc(train) 0.9178 | Acc(val) 0.9399 |
Epoch 00181 | Loss(train) 0.2924 | Acc(train) 0.9112 | Acc(val) 0.9332 |
Epoch 00182 | Loss(train) 0.2798 | Acc(train) 0.9245 | Acc(val) 0.9332 |
Epoch 00183 | Loss(train) 0.2993 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00184 | Loss(train) 0.2929 | Acc(train) 0.9132 | Acc(val) 0.9332 |
Epoch 00185 | Loss(train) 0.2743 | Acc(train) 0.9212 | Acc(val) 0.9386 |
Epoch 00186 | Loss(train) 0.3105 | Acc(train) 0.9078 | Acc(val) 0.9372 |
Epoch 00187 | Loss(train) 0.2963 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00188 | Loss(train) 0.2850 | Acc(train) 0.8985 | Acc(val) 0.9372 |
Epoch 00189 | Loss(train) 0.2919 | Acc(train) 0.9112 | Acc(val) 0.9359 |
Epoch 00190 | Loss(train) 0.2677 | Acc(train) 0.9212 | Acc(val) 0.9399 |
Epoch 00191 | Loss(train) 0.2721 | Acc(train) 0.9192 | Acc(val) 0.9359 |
Epoch 00192 | Loss(train) 0.2742 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00193 | Loss(train) 0.2875 | Acc(train) 0.9018 | Acc(val) 0.9332 |
Epoch 00194 | Loss(train) 0.2766 | Acc(train) 0.9118 | Acc(val) 0.9359 |
Early stopping at epoch 194
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.4412 | Acc(train) 0.1096 | Acc(val) 0.3792 |*
Epoch 00002 | Loss(train) 3.7351 | Acc(train) 0.2846 | Acc(val) 0.3445 |
Epoch 00003 | Loss(train) 4.5559 | Acc(train) 0.2465 | Acc(val) 0.2283 |
Epoch 00004 | Loss(train) 3.1316 | Acc(train) 0.1984 | Acc(val) 0.2617 |
Epoch 00005 | Loss(train) 3.2177 | Acc(train) 0.2071 | Acc(val) 0.2270 |
Epoch 00006 | Loss(train) 2.6350 | Acc(train) 0.2258 | Acc(val) 0.5541 |*
Epoch 00007 | Loss(train) 1.7182 | Acc(train) 0.4803 | Acc(val) 0.2911 |
Epoch 00008 | Loss(train) 1.8258 | Acc(train) 0.3387 | Acc(val) 0.3858 |
Epoch 00009 | Loss(train) 1.6755 | Acc(train) 0.4175 | Acc(val) 0.4900 |
Epoch 00010 | Loss(train) 1.5701 | Acc(train) 0.4696 | Acc(val) 0.4179 |
Epoch 00011 | Loss(train) 1.5796 | Acc(train) 0.4582 | Acc(val) 0.4179 |
Epoch 00012 | Loss(train) 1.5850 | Acc(train) 0.4529 | Acc(val) 0.5007 |
Epoch 00013 | Loss(train) 1.5583 | Acc(train) 0.4970 | Acc(val) 0.6048 |*
Epoch 00014 | Loss(train) 1.3830 | Acc(train) 0.5778 | Acc(val) 0.6168 |*
Epoch 00015 | Loss(train) 1.3988 | Acc(train) 0.5731 | Acc(val) 0.5941 |
Epoch 00016 | Loss(train) 1.3943 | Acc(train) 0.5498 | Acc(val) 0.6355 |*
Epoch 00017 | Loss(train) 1.3271 | Acc(train) 0.5585 | Acc(val) 0.6542 |*
Epoch 00018 | Loss(train) 1.2756 | Acc(train) 0.6072 | Acc(val) 0.6782 |*
Epoch 00019 | Loss(train) 1.2726 | Acc(train) 0.6172 | Acc(val) 0.7170 |*
Epoch 00020 | Loss(train) 1.1969 | Acc(train) 0.6506 | Acc(val) 0.7637 |*
Epoch 00021 | Loss(train) 1.1600 | Acc(train) 0.6500 | Acc(val) 0.7623 |
Epoch 00022 | Loss(train) 1.1234 | Acc(train) 0.6667 | Acc(val) 0.7557 |
Epoch 00023 | Loss(train) 1.0752 | Acc(train) 0.6914 | Acc(val) 0.7049 |
Epoch 00024 | Loss(train) 1.1189 | Acc(train) 0.6546 | Acc(val) 0.6983 |
Epoch 00025 | Loss(train) 1.0346 | Acc(train) 0.6680 | Acc(val) 0.7116 |
Epoch 00026 | Loss(train) 0.9921 | Acc(train) 0.6794 | Acc(val) 0.7557 |
Epoch 00027 | Loss(train) 0.9666 | Acc(train) 0.6961 | Acc(val) 0.7944 |*
Epoch 00028 | Loss(train) 0.9392 | Acc(train) 0.7054 | Acc(val) 0.8291 |*
Epoch 00029 | Loss(train) 0.8799 | Acc(train) 0.7622 | Acc(val) 0.8385 |*
Epoch 00030 | Loss(train) 0.8754 | Acc(train) 0.7555 | Acc(val) 0.8425 |*
Epoch 00031 | Loss(train) 0.8839 | Acc(train) 0.7555 | Acc(val) 0.8331 |
Epoch 00032 | Loss(train) 0.8163 | Acc(train) 0.7749 | Acc(val) 0.8358 |
Epoch 00033 | Loss(train) 0.8010 | Acc(train) 0.7522 | Acc(val) 0.8385 |
Epoch 00034 | Loss(train) 0.7889 | Acc(train) 0.7609 | Acc(val) 0.8491 |*
Epoch 00035 | Loss(train) 0.7544 | Acc(train) 0.7735 | Acc(val) 0.8451 |
Epoch 00036 | Loss(train) 0.7255 | Acc(train) 0.7842 | Acc(val) 0.8705 |*
Epoch 00037 | Loss(train) 0.7179 | Acc(train) 0.7749 | Acc(val) 0.8665 |
Epoch 00038 | Loss(train) 0.7287 | Acc(train) 0.7769 | Acc(val) 0.8705 |
Epoch 00039 | Loss(train) 0.7057 | Acc(train) 0.7989 | Acc(val) 0.8892 |*
Epoch 00040 | Loss(train) 0.6831 | Acc(train) 0.8096 | Acc(val) 0.8985 |*
Epoch 00041 | Loss(train) 0.6661 | Acc(train) 0.8156 | Acc(val) 0.9039 |*
Epoch 00042 | Loss(train) 0.6598 | Acc(train) 0.8063 | Acc(val) 0.8972 |
Epoch 00043 | Loss(train) 0.6083 | Acc(train) 0.8190 | Acc(val) 0.9025 |
Epoch 00044 | Loss(train) 0.5870 | Acc(train) 0.8263 | Acc(val) 0.9132 |*
Epoch 00045 | Loss(train) 0.5759 | Acc(train) 0.8343 | Acc(val) 0.9159 |*
Epoch 00046 | Loss(train) 0.6112 | Acc(train) 0.8263 | Acc(val) 0.9119 |
Epoch 00047 | Loss(train) 0.5720 | Acc(train) 0.8403 | Acc(val) 0.9025 |
Epoch 00048 | Loss(train) 0.5872 | Acc(train) 0.8350 | Acc(val) 0.8999 |
Epoch 00049 | Loss(train) 0.5725 | Acc(train) 0.8196 | Acc(val) 0.9025 |
Epoch 00050 | Loss(train) 0.5563 | Acc(train) 0.8444 | Acc(val) 0.9079 |
Epoch 00051 | Loss(train) 0.5374 | Acc(train) 0.8390 | Acc(val) 0.9092 |
Epoch 00052 | Loss(train) 0.5390 | Acc(train) 0.8323 | Acc(val) 0.9039 |
Epoch 00053 | Loss(train) 0.5387 | Acc(train) 0.8370 | Acc(val) 0.9012 |
Epoch 00054 | Loss(train) 0.5210 | Acc(train) 0.8464 | Acc(val) 0.9039 |
Epoch 00055 | Loss(train) 0.5251 | Acc(train) 0.8377 | Acc(val) 0.9025 |
Epoch 00056 | Loss(train) 0.4986 | Acc(train) 0.8510 | Acc(val) 0.9132 |
Epoch 00057 | Loss(train) 0.4799 | Acc(train) 0.8537 | Acc(val) 0.9132 |
Epoch 00058 | Loss(train) 0.4574 | Acc(train) 0.8657 | Acc(val) 0.9119 |
Epoch 00059 | Loss(train) 0.4994 | Acc(train) 0.8544 | Acc(val) 0.9159 |
Epoch 00060 | Loss(train) 0.4874 | Acc(train) 0.8530 | Acc(val) 0.9212 |*
Epoch 00061 | Loss(train) 0.4850 | Acc(train) 0.8577 | Acc(val) 0.9212 |
Epoch 00062 | Loss(train) 0.4784 | Acc(train) 0.8497 | Acc(val) 0.9226 |*
Epoch 00063 | Loss(train) 0.4713 | Acc(train) 0.8624 | Acc(val) 0.9132 |
Epoch 00064 | Loss(train) 0.4615 | Acc(train) 0.8684 | Acc(val) 0.9092 |
Epoch 00065 | Loss(train) 0.4531 | Acc(train) 0.8611 | Acc(val) 0.9172 |
Epoch 00066 | Loss(train) 0.4376 | Acc(train) 0.8671 | Acc(val) 0.9212 |
Epoch 00067 | Loss(train) 0.4338 | Acc(train) 0.8664 | Acc(val) 0.9186 |
Epoch 00068 | Loss(train) 0.4447 | Acc(train) 0.8577 | Acc(val) 0.9132 |
Epoch 00069 | Loss(train) 0.4579 | Acc(train) 0.8617 | Acc(val) 0.9105 |
Epoch 00070 | Loss(train) 0.4281 | Acc(train) 0.8651 | Acc(val) 0.9239 |*
Epoch 00071 | Loss(train) 0.4230 | Acc(train) 0.8684 | Acc(val) 0.9252 |*
Epoch 00072 | Loss(train) 0.4134 | Acc(train) 0.8751 | Acc(val) 0.9239 |
Epoch 00073 | Loss(train) 0.4426 | Acc(train) 0.8577 | Acc(val) 0.9239 |
Epoch 00074 | Loss(train) 0.4186 | Acc(train) 0.8684 | Acc(val) 0.9226 |
Epoch 00075 | Loss(train) 0.4240 | Acc(train) 0.8778 | Acc(val) 0.9212 |
Epoch 00076 | Loss(train) 0.3923 | Acc(train) 0.8851 | Acc(val) 0.9226 |
Epoch 00077 | Loss(train) 0.4269 | Acc(train) 0.8697 | Acc(val) 0.9199 |
Epoch 00078 | Loss(train) 0.4104 | Acc(train) 0.8771 | Acc(val) 0.9226 |
Epoch 00079 | Loss(train) 0.4121 | Acc(train) 0.8784 | Acc(val) 0.9239 |
Epoch 00080 | Loss(train) 0.4096 | Acc(train) 0.8671 | Acc(val) 0.9239 |
Epoch 00081 | Loss(train) 0.3898 | Acc(train) 0.8778 | Acc(val) 0.9239 |
Epoch 00082 | Loss(train) 0.3761 | Acc(train) 0.8824 | Acc(val) 0.9239 |
Epoch 00083 | Loss(train) 0.3947 | Acc(train) 0.8858 | Acc(val) 0.9226 |
Epoch 00084 | Loss(train) 0.3996 | Acc(train) 0.8744 | Acc(val) 0.9252 |
Epoch 00085 | Loss(train) 0.4025 | Acc(train) 0.8824 | Acc(val) 0.9226 |
Epoch 00086 | Loss(train) 0.3721 | Acc(train) 0.8851 | Acc(val) 0.9239 |
Epoch 00087 | Loss(train) 0.3589 | Acc(train) 0.8871 | Acc(val) 0.9252 |
Epoch 00088 | Loss(train) 0.3801 | Acc(train) 0.8858 | Acc(val) 0.9252 |
Epoch 00089 | Loss(train) 0.4021 | Acc(train) 0.8824 | Acc(val) 0.9266 |*
Epoch 00090 | Loss(train) 0.3702 | Acc(train) 0.8858 | Acc(val) 0.9212 |
Epoch 00091 | Loss(train) 0.3888 | Acc(train) 0.8791 | Acc(val) 0.9252 |
Epoch 00092 | Loss(train) 0.3867 | Acc(train) 0.8858 | Acc(val) 0.9239 |
Epoch 00093 | Loss(train) 0.3524 | Acc(train) 0.8971 | Acc(val) 0.9279 |*
Epoch 00094 | Loss(train) 0.3642 | Acc(train) 0.8811 | Acc(val) 0.9292 |*
Epoch 00095 | Loss(train) 0.3834 | Acc(train) 0.8918 | Acc(val) 0.9292 |
Epoch 00096 | Loss(train) 0.3817 | Acc(train) 0.8764 | Acc(val) 0.9306 |*
Epoch 00097 | Loss(train) 0.3699 | Acc(train) 0.8858 | Acc(val) 0.9252 |
Epoch 00098 | Loss(train) 0.3645 | Acc(train) 0.8911 | Acc(val) 0.9266 |
Epoch 00099 | Loss(train) 0.3679 | Acc(train) 0.8904 | Acc(val) 0.9239 |
Epoch 00100 | Loss(train) 0.3847 | Acc(train) 0.8818 | Acc(val) 0.9226 |
Epoch 00101 | Loss(train) 0.3593 | Acc(train) 0.8891 | Acc(val) 0.9266 |
Epoch 00102 | Loss(train) 0.3567 | Acc(train) 0.8951 | Acc(val) 0.9279 |
Epoch 00103 | Loss(train) 0.3662 | Acc(train) 0.8951 | Acc(val) 0.9252 |
Epoch 00104 | Loss(train) 0.3645 | Acc(train) 0.8798 | Acc(val) 0.9279 |
Epoch 00105 | Loss(train) 0.3687 | Acc(train) 0.8851 | Acc(val) 0.9279 |
Epoch 00106 | Loss(train) 0.3581 | Acc(train) 0.8838 | Acc(val) 0.9266 |
Epoch 00107 | Loss(train) 0.3623 | Acc(train) 0.8898 | Acc(val) 0.9279 |
Epoch 00108 | Loss(train) 0.3632 | Acc(train) 0.8904 | Acc(val) 0.9279 |
Epoch 00109 | Loss(train) 0.3691 | Acc(train) 0.8904 | Acc(val) 0.9279 |
Epoch 00110 | Loss(train) 0.3623 | Acc(train) 0.8898 | Acc(val) 0.9279 |
Epoch 00111 | Loss(train) 0.3598 | Acc(train) 0.8844 | Acc(val) 0.9266 |
Epoch 00112 | Loss(train) 0.3385 | Acc(train) 0.8911 | Acc(val) 0.9292 |
Epoch 00113 | Loss(train) 0.3582 | Acc(train) 0.8884 | Acc(val) 0.9279 |
Epoch 00114 | Loss(train) 0.3384 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00115 | Loss(train) 0.3459 | Acc(train) 0.8951 | Acc(val) 0.9279 |
Epoch 00116 | Loss(train) 0.3473 | Acc(train) 0.8898 | Acc(val) 0.9252 |
Epoch 00117 | Loss(train) 0.3478 | Acc(train) 0.8945 | Acc(val) 0.9292 |
Epoch 00118 | Loss(train) 0.3404 | Acc(train) 0.9031 | Acc(val) 0.9292 |
Epoch 00119 | Loss(train) 0.3397 | Acc(train) 0.9092 | Acc(val) 0.9279 |
Epoch 00120 | Loss(train) 0.3448 | Acc(train) 0.9038 | Acc(val) 0.9319 |*
Epoch 00121 | Loss(train) 0.3432 | Acc(train) 0.8898 | Acc(val) 0.9319 |
Epoch 00122 | Loss(train) 0.3479 | Acc(train) 0.8978 | Acc(val) 0.9279 |
Epoch 00123 | Loss(train) 0.3596 | Acc(train) 0.8911 | Acc(val) 0.9292 |
Epoch 00124 | Loss(train) 0.3539 | Acc(train) 0.8918 | Acc(val) 0.9332 |*
Epoch 00125 | Loss(train) 0.3703 | Acc(train) 0.8844 | Acc(val) 0.9292 |
Epoch 00126 | Loss(train) 0.3348 | Acc(train) 0.9011 | Acc(val) 0.9306 |
Epoch 00127 | Loss(train) 0.3640 | Acc(train) 0.8904 | Acc(val) 0.9306 |
Epoch 00128 | Loss(train) 0.3305 | Acc(train) 0.8978 | Acc(val) 0.9332 |
Epoch 00129 | Loss(train) 0.3465 | Acc(train) 0.8938 | Acc(val) 0.9346 |*
Epoch 00130 | Loss(train) 0.3397 | Acc(train) 0.8985 | Acc(val) 0.9319 |
Epoch 00131 | Loss(train) 0.3625 | Acc(train) 0.8925 | Acc(val) 0.9319 |
Epoch 00132 | Loss(train) 0.3342 | Acc(train) 0.8998 | Acc(val) 0.9332 |
Epoch 00133 | Loss(train) 0.3205 | Acc(train) 0.8985 | Acc(val) 0.9292 |
Epoch 00134 | Loss(train) 0.3353 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00135 | Loss(train) 0.3362 | Acc(train) 0.8878 | Acc(val) 0.9279 |
Epoch 00136 | Loss(train) 0.3250 | Acc(train) 0.9005 | Acc(val) 0.9319 |
Epoch 00137 | Loss(train) 0.3394 | Acc(train) 0.8965 | Acc(val) 0.9332 |
Epoch 00138 | Loss(train) 0.3204 | Acc(train) 0.8965 | Acc(val) 0.9346 |
Epoch 00139 | Loss(train) 0.3363 | Acc(train) 0.9078 | Acc(val) 0.9319 |
Epoch 00140 | Loss(train) 0.3227 | Acc(train) 0.8965 | Acc(val) 0.9306 |
Epoch 00141 | Loss(train) 0.3242 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00142 | Loss(train) 0.3341 | Acc(train) 0.9005 | Acc(val) 0.9319 |
Epoch 00143 | Loss(train) 0.3502 | Acc(train) 0.8918 | Acc(val) 0.9346 |
Epoch 00144 | Loss(train) 0.3255 | Acc(train) 0.8891 | Acc(val) 0.9359 |*
Epoch 00145 | Loss(train) 0.3299 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00146 | Loss(train) 0.3060 | Acc(train) 0.9071 | Acc(val) 0.9319 |
Epoch 00147 | Loss(train) 0.3091 | Acc(train) 0.9138 | Acc(val) 0.9332 |
Epoch 00148 | Loss(train) 0.3261 | Acc(train) 0.8971 | Acc(val) 0.9319 |
Epoch 00149 | Loss(train) 0.3161 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00150 | Loss(train) 0.3223 | Acc(train) 0.9051 | Acc(val) 0.9319 |
Epoch 00151 | Loss(train) 0.3183 | Acc(train) 0.9078 | Acc(val) 0.9306 |
Epoch 00152 | Loss(train) 0.3350 | Acc(train) 0.9051 | Acc(val) 0.9279 |
Epoch 00153 | Loss(train) 0.3074 | Acc(train) 0.9051 | Acc(val) 0.9306 |
Epoch 00154 | Loss(train) 0.3192 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Epoch 00155 | Loss(train) 0.3172 | Acc(train) 0.9058 | Acc(val) 0.9346 |
Epoch 00156 | Loss(train) 0.3245 | Acc(train) 0.9005 | Acc(val) 0.9372 |*
Epoch 00157 | Loss(train) 0.3100 | Acc(train) 0.9132 | Acc(val) 0.9359 |
Epoch 00158 | Loss(train) 0.3088 | Acc(train) 0.9078 | Acc(val) 0.9332 |
Epoch 00159 | Loss(train) 0.3187 | Acc(train) 0.8911 | Acc(val) 0.9332 |
Epoch 00160 | Loss(train) 0.3068 | Acc(train) 0.8991 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.3173 | Acc(train) 0.9018 | Acc(val) 0.9332 |
Epoch 00162 | Loss(train) 0.2981 | Acc(train) 0.9092 | Acc(val) 0.9346 |
Epoch 00163 | Loss(train) 0.3026 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00164 | Loss(train) 0.3049 | Acc(train) 0.9112 | Acc(val) 0.9359 |
Epoch 00165 | Loss(train) 0.3027 | Acc(train) 0.9098 | Acc(val) 0.9359 |
Epoch 00166 | Loss(train) 0.3014 | Acc(train) 0.9045 | Acc(val) 0.9292 |
Epoch 00167 | Loss(train) 0.3384 | Acc(train) 0.8904 | Acc(val) 0.9359 |
Epoch 00168 | Loss(train) 0.3217 | Acc(train) 0.8998 | Acc(val) 0.9359 |
Epoch 00169 | Loss(train) 0.2946 | Acc(train) 0.9025 | Acc(val) 0.9346 |
Epoch 00170 | Loss(train) 0.3235 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00171 | Loss(train) 0.2981 | Acc(train) 0.9198 | Acc(val) 0.9346 |
Epoch 00172 | Loss(train) 0.3155 | Acc(train) 0.9058 | Acc(val) 0.9346 |
Epoch 00173 | Loss(train) 0.2990 | Acc(train) 0.9025 | Acc(val) 0.9346 |
Epoch 00174 | Loss(train) 0.3058 | Acc(train) 0.9071 | Acc(val) 0.9359 |
Epoch 00175 | Loss(train) 0.3040 | Acc(train) 0.9065 | Acc(val) 0.9359 |
Epoch 00176 | Loss(train) 0.3177 | Acc(train) 0.9085 | Acc(val) 0.9346 |
Epoch 00177 | Loss(train) 0.3030 | Acc(train) 0.9105 | Acc(val) 0.9386 |*
Epoch 00178 | Loss(train) 0.3005 | Acc(train) 0.9085 | Acc(val) 0.9413 |*
Epoch 00179 | Loss(train) 0.2713 | Acc(train) 0.9145 | Acc(val) 0.9426 |*
Epoch 00180 | Loss(train) 0.3035 | Acc(train) 0.9045 | Acc(val) 0.9372 |
Epoch 00181 | Loss(train) 0.2900 | Acc(train) 0.9145 | Acc(val) 0.9426 |
Epoch 00182 | Loss(train) 0.3052 | Acc(train) 0.9005 | Acc(val) 0.9372 |
Epoch 00183 | Loss(train) 0.3092 | Acc(train) 0.9031 | Acc(val) 0.9372 |
Epoch 00184 | Loss(train) 0.3054 | Acc(train) 0.9005 | Acc(val) 0.9372 |
Epoch 00185 | Loss(train) 0.2971 | Acc(train) 0.9058 | Acc(val) 0.9359 |
Epoch 00186 | Loss(train) 0.2902 | Acc(train) 0.9105 | Acc(val) 0.9413 |
Epoch 00187 | Loss(train) 0.3061 | Acc(train) 0.9138 | Acc(val) 0.9413 |
Epoch 00188 | Loss(train) 0.3049 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00189 | Loss(train) 0.3045 | Acc(train) 0.9045 | Acc(val) 0.9413 |
Epoch 00190 | Loss(train) 0.2997 | Acc(train) 0.9098 | Acc(val) 0.9399 |
Epoch 00191 | Loss(train) 0.2949 | Acc(train) 0.9045 | Acc(val) 0.9413 |
Epoch 00192 | Loss(train) 0.3046 | Acc(train) 0.9045 | Acc(val) 0.9386 |
Epoch 00193 | Loss(train) 0.2891 | Acc(train) 0.9078 | Acc(val) 0.9359 |
Epoch 00194 | Loss(train) 0.2814 | Acc(train) 0.9238 | Acc(val) 0.9372 |
Epoch 00195 | Loss(train) 0.2802 | Acc(train) 0.9085 | Acc(val) 0.9399 |
Epoch 00196 | Loss(train) 0.2878 | Acc(train) 0.9105 | Acc(val) 0.9386 |
Epoch 00197 | Loss(train) 0.2876 | Acc(train) 0.9011 | Acc(val) 0.9372 |
Epoch 00198 | Loss(train) 0.2770 | Acc(train) 0.9051 | Acc(val) 0.9372 |
Epoch 00199 | Loss(train) 0.2851 | Acc(train) 0.9078 | Acc(val) 0.9413 |
Epoch 00200 | Loss(train) 0.2880 | Acc(train) 0.9132 | Acc(val) 0.9426 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.1620 | Acc(train) 0.2358 | Acc(val) 0.1989 |*
Epoch 00002 | Loss(train) 4.9148 | Acc(train) 0.2091 | Acc(val) 0.2550 |*
Epoch 00003 | Loss(train) 3.7954 | Acc(train) 0.2852 | Acc(val) 0.3271 |*
Epoch 00004 | Loss(train) 2.5275 | Acc(train) 0.3046 | Acc(val) 0.1282 |
Epoch 00005 | Loss(train) 2.6715 | Acc(train) 0.1663 | Acc(val) 0.3284 |*
Epoch 00006 | Loss(train) 2.4764 | Acc(train) 0.1837 | Acc(val) 0.4366 |*
Epoch 00007 | Loss(train) 2.1145 | Acc(train) 0.2558 | Acc(val) 0.2750 |
Epoch 00008 | Loss(train) 2.0109 | Acc(train) 0.2452 | Acc(val) 0.4513 |*
Epoch 00009 | Loss(train) 1.7290 | Acc(train) 0.4068 | Acc(val) 0.4766 |*
Epoch 00010 | Loss(train) 1.7272 | Acc(train) 0.4148 | Acc(val) 0.2817 |
Epoch 00011 | Loss(train) 1.8248 | Acc(train) 0.3627 | Acc(val) 0.4486 |
Epoch 00012 | Loss(train) 1.6980 | Acc(train) 0.4102 | Acc(val) 0.5634 |*
Epoch 00013 | Loss(train) 1.5275 | Acc(train) 0.4790 | Acc(val) 0.4913 |
Epoch 00014 | Loss(train) 1.5155 | Acc(train) 0.4749 | Acc(val) 0.4940 |
Epoch 00015 | Loss(train) 1.4370 | Acc(train) 0.5331 | Acc(val) 0.5527 |
Epoch 00016 | Loss(train) 1.4385 | Acc(train) 0.5384 | Acc(val) 0.6035 |*
Epoch 00017 | Loss(train) 1.3146 | Acc(train) 0.5945 | Acc(val) 0.6435 |*
Epoch 00018 | Loss(train) 1.2887 | Acc(train) 0.6319 | Acc(val) 0.7130 |*
Epoch 00019 | Loss(train) 1.3318 | Acc(train) 0.6126 | Acc(val) 0.6916 |
Epoch 00020 | Loss(train) 1.2830 | Acc(train) 0.6460 | Acc(val) 0.6742 |
Epoch 00021 | Loss(train) 1.2515 | Acc(train) 0.6306 | Acc(val) 0.6515 |
Epoch 00022 | Loss(train) 1.2364 | Acc(train) 0.6039 | Acc(val) 0.6368 |
Epoch 00023 | Loss(train) 1.1804 | Acc(train) 0.6112 | Acc(val) 0.6075 |
Epoch 00024 | Loss(train) 1.1555 | Acc(train) 0.6019 | Acc(val) 0.6449 |
Epoch 00025 | Loss(train) 1.1362 | Acc(train) 0.5919 | Acc(val) 0.7196 |*
Epoch 00026 | Loss(train) 1.0635 | Acc(train) 0.6460 | Acc(val) 0.7650 |*
Epoch 00027 | Loss(train) 1.0539 | Acc(train) 0.6867 | Acc(val) 0.7850 |*
Epoch 00028 | Loss(train) 1.0203 | Acc(train) 0.6847 | Acc(val) 0.7810 |
Epoch 00029 | Loss(train) 0.9736 | Acc(train) 0.7067 | Acc(val) 0.7997 |*
Epoch 00030 | Loss(train) 0.9645 | Acc(train) 0.7034 | Acc(val) 0.8171 |*
Epoch 00031 | Loss(train) 0.9436 | Acc(train) 0.7275 | Acc(val) 0.8318 |*
Epoch 00032 | Loss(train) 0.8949 | Acc(train) 0.7488 | Acc(val) 0.8331 |*
Epoch 00033 | Loss(train) 0.8801 | Acc(train) 0.7295 | Acc(val) 0.8238 |
Epoch 00034 | Loss(train) 0.8610 | Acc(train) 0.7388 | Acc(val) 0.8358 |*
Epoch 00035 | Loss(train) 0.8347 | Acc(train) 0.7502 | Acc(val) 0.8385 |*
Epoch 00036 | Loss(train) 0.8275 | Acc(train) 0.7609 | Acc(val) 0.8478 |*
Epoch 00037 | Loss(train) 0.7848 | Acc(train) 0.7715 | Acc(val) 0.8438 |
Epoch 00038 | Loss(train) 0.7858 | Acc(train) 0.7622 | Acc(val) 0.8451 |
Epoch 00039 | Loss(train) 0.7403 | Acc(train) 0.7816 | Acc(val) 0.8545 |*
Epoch 00040 | Loss(train) 0.7259 | Acc(train) 0.7842 | Acc(val) 0.8571 |*
Epoch 00041 | Loss(train) 0.7151 | Acc(train) 0.7989 | Acc(val) 0.8678 |*
Epoch 00042 | Loss(train) 0.7327 | Acc(train) 0.7756 | Acc(val) 0.8852 |*
Epoch 00043 | Loss(train) 0.6762 | Acc(train) 0.8043 | Acc(val) 0.8985 |*
Epoch 00044 | Loss(train) 0.6550 | Acc(train) 0.8290 | Acc(val) 0.8959 |
Epoch 00045 | Loss(train) 0.6534 | Acc(train) 0.8123 | Acc(val) 0.8879 |
Epoch 00046 | Loss(train) 0.6393 | Acc(train) 0.8283 | Acc(val) 0.8812 |
Epoch 00047 | Loss(train) 0.6247 | Acc(train) 0.8230 | Acc(val) 0.8919 |
Epoch 00048 | Loss(train) 0.5964 | Acc(train) 0.8183 | Acc(val) 0.9025 |*
Epoch 00049 | Loss(train) 0.6226 | Acc(train) 0.8176 | Acc(val) 0.9052 |*
Epoch 00050 | Loss(train) 0.5386 | Acc(train) 0.8310 | Acc(val) 0.9052 |
Epoch 00051 | Loss(train) 0.6101 | Acc(train) 0.8190 | Acc(val) 0.9012 |
Epoch 00052 | Loss(train) 0.5656 | Acc(train) 0.8363 | Acc(val) 0.8985 |
Epoch 00053 | Loss(train) 0.5655 | Acc(train) 0.8290 | Acc(val) 0.9012 |
Epoch 00054 | Loss(train) 0.5371 | Acc(train) 0.8397 | Acc(val) 0.9079 |*
Epoch 00055 | Loss(train) 0.5252 | Acc(train) 0.8450 | Acc(val) 0.9092 |*
Epoch 00056 | Loss(train) 0.5360 | Acc(train) 0.8424 | Acc(val) 0.9065 |
Epoch 00057 | Loss(train) 0.4989 | Acc(train) 0.8631 | Acc(val) 0.9079 |
Epoch 00058 | Loss(train) 0.5136 | Acc(train) 0.8397 | Acc(val) 0.9039 |
Epoch 00059 | Loss(train) 0.4979 | Acc(train) 0.8544 | Acc(val) 0.9052 |
Epoch 00060 | Loss(train) 0.4982 | Acc(train) 0.8510 | Acc(val) 0.9039 |
Epoch 00061 | Loss(train) 0.4698 | Acc(train) 0.8577 | Acc(val) 0.9052 |
Epoch 00062 | Loss(train) 0.5010 | Acc(train) 0.8410 | Acc(val) 0.9079 |
Epoch 00063 | Loss(train) 0.4755 | Acc(train) 0.8651 | Acc(val) 0.9146 |*
Epoch 00064 | Loss(train) 0.4569 | Acc(train) 0.8604 | Acc(val) 0.9146 |
Epoch 00065 | Loss(train) 0.4588 | Acc(train) 0.8617 | Acc(val) 0.9172 |*
Epoch 00066 | Loss(train) 0.4443 | Acc(train) 0.8651 | Acc(val) 0.9159 |
Epoch 00067 | Loss(train) 0.4439 | Acc(train) 0.8604 | Acc(val) 0.9186 |*
Epoch 00068 | Loss(train) 0.4592 | Acc(train) 0.8624 | Acc(val) 0.9172 |
Epoch 00069 | Loss(train) 0.4527 | Acc(train) 0.8691 | Acc(val) 0.9226 |*
Epoch 00070 | Loss(train) 0.4463 | Acc(train) 0.8671 | Acc(val) 0.9252 |*
Epoch 00071 | Loss(train) 0.4199 | Acc(train) 0.8824 | Acc(val) 0.9292 |*
Epoch 00072 | Loss(train) 0.4239 | Acc(train) 0.8737 | Acc(val) 0.9292 |
Epoch 00073 | Loss(train) 0.4057 | Acc(train) 0.8771 | Acc(val) 0.9212 |
Epoch 00074 | Loss(train) 0.4207 | Acc(train) 0.8671 | Acc(val) 0.9172 |
Epoch 00075 | Loss(train) 0.4333 | Acc(train) 0.8677 | Acc(val) 0.9212 |
Epoch 00076 | Loss(train) 0.4150 | Acc(train) 0.8671 | Acc(val) 0.9212 |
Epoch 00077 | Loss(train) 0.4074 | Acc(train) 0.8824 | Acc(val) 0.9239 |
Epoch 00078 | Loss(train) 0.4322 | Acc(train) 0.8711 | Acc(val) 0.9239 |
Epoch 00079 | Loss(train) 0.4061 | Acc(train) 0.8657 | Acc(val) 0.9212 |
Epoch 00080 | Loss(train) 0.4344 | Acc(train) 0.8717 | Acc(val) 0.9226 |
Epoch 00081 | Loss(train) 0.3987 | Acc(train) 0.8744 | Acc(val) 0.9252 |
Epoch 00082 | Loss(train) 0.4160 | Acc(train) 0.8811 | Acc(val) 0.9266 |
Epoch 00083 | Loss(train) 0.3982 | Acc(train) 0.8871 | Acc(val) 0.9266 |
Epoch 00084 | Loss(train) 0.3860 | Acc(train) 0.8824 | Acc(val) 0.9306 |*
Epoch 00085 | Loss(train) 0.3992 | Acc(train) 0.8831 | Acc(val) 0.9292 |
Epoch 00086 | Loss(train) 0.3843 | Acc(train) 0.8764 | Acc(val) 0.9292 |
Epoch 00087 | Loss(train) 0.3881 | Acc(train) 0.8791 | Acc(val) 0.9306 |
Epoch 00088 | Loss(train) 0.3659 | Acc(train) 0.8931 | Acc(val) 0.9292 |
Epoch 00089 | Loss(train) 0.3871 | Acc(train) 0.8811 | Acc(val) 0.9319 |*
Epoch 00090 | Loss(train) 0.3791 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00091 | Loss(train) 0.3674 | Acc(train) 0.8958 | Acc(val) 0.9306 |
Epoch 00092 | Loss(train) 0.3765 | Acc(train) 0.8798 | Acc(val) 0.9279 |
Epoch 00093 | Loss(train) 0.3734 | Acc(train) 0.8878 | Acc(val) 0.9292 |
Epoch 00094 | Loss(train) 0.3834 | Acc(train) 0.8878 | Acc(val) 0.9306 |
Epoch 00095 | Loss(train) 0.3720 | Acc(train) 0.8844 | Acc(val) 0.9319 |
Epoch 00096 | Loss(train) 0.3621 | Acc(train) 0.8971 | Acc(val) 0.9292 |
Epoch 00097 | Loss(train) 0.3835 | Acc(train) 0.8818 | Acc(val) 0.9306 |
Epoch 00098 | Loss(train) 0.3864 | Acc(train) 0.8844 | Acc(val) 0.9319 |
Epoch 00099 | Loss(train) 0.3710 | Acc(train) 0.8925 | Acc(val) 0.9306 |
Epoch 00100 | Loss(train) 0.3500 | Acc(train) 0.8938 | Acc(val) 0.9346 |*
Epoch 00101 | Loss(train) 0.3667 | Acc(train) 0.8911 | Acc(val) 0.9292 |
Epoch 00102 | Loss(train) 0.3786 | Acc(train) 0.8938 | Acc(val) 0.9292 |
Epoch 00103 | Loss(train) 0.3672 | Acc(train) 0.8858 | Acc(val) 0.9319 |
Epoch 00104 | Loss(train) 0.3683 | Acc(train) 0.8864 | Acc(val) 0.9306 |
Epoch 00105 | Loss(train) 0.3566 | Acc(train) 0.8918 | Acc(val) 0.9346 |
Epoch 00106 | Loss(train) 0.3640 | Acc(train) 0.8871 | Acc(val) 0.9346 |
Epoch 00107 | Loss(train) 0.3499 | Acc(train) 0.8871 | Acc(val) 0.9346 |
Epoch 00108 | Loss(train) 0.3652 | Acc(train) 0.8884 | Acc(val) 0.9346 |
Epoch 00109 | Loss(train) 0.3403 | Acc(train) 0.8898 | Acc(val) 0.9346 |
Epoch 00110 | Loss(train) 0.3442 | Acc(train) 0.8918 | Acc(val) 0.9319 |
Epoch 00111 | Loss(train) 0.3469 | Acc(train) 0.8951 | Acc(val) 0.9279 |
Epoch 00112 | Loss(train) 0.3529 | Acc(train) 0.8904 | Acc(val) 0.9279 |
Epoch 00113 | Loss(train) 0.3469 | Acc(train) 0.8878 | Acc(val) 0.9332 |
Epoch 00114 | Loss(train) 0.3497 | Acc(train) 0.8871 | Acc(val) 0.9346 |
Epoch 00115 | Loss(train) 0.3720 | Acc(train) 0.8804 | Acc(val) 0.9346 |
Epoch 00116 | Loss(train) 0.3409 | Acc(train) 0.8945 | Acc(val) 0.9359 |*
Epoch 00117 | Loss(train) 0.3468 | Acc(train) 0.8891 | Acc(val) 0.9359 |
Epoch 00118 | Loss(train) 0.3596 | Acc(train) 0.8904 | Acc(val) 0.9332 |
Epoch 00119 | Loss(train) 0.3344 | Acc(train) 0.8945 | Acc(val) 0.9332 |
Epoch 00120 | Loss(train) 0.3338 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00121 | Loss(train) 0.3416 | Acc(train) 0.8938 | Acc(val) 0.9332 |
Epoch 00122 | Loss(train) 0.3577 | Acc(train) 0.8898 | Acc(val) 0.9359 |
Epoch 00123 | Loss(train) 0.3492 | Acc(train) 0.8891 | Acc(val) 0.9359 |
Epoch 00124 | Loss(train) 0.3393 | Acc(train) 0.8965 | Acc(val) 0.9359 |
Epoch 00125 | Loss(train) 0.3464 | Acc(train) 0.8911 | Acc(val) 0.9346 |
Epoch 00126 | Loss(train) 0.3519 | Acc(train) 0.8904 | Acc(val) 0.9359 |
Epoch 00127 | Loss(train) 0.3235 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00128 | Loss(train) 0.3151 | Acc(train) 0.9005 | Acc(val) 0.9332 |
Epoch 00129 | Loss(train) 0.3218 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00130 | Loss(train) 0.3328 | Acc(train) 0.8951 | Acc(val) 0.9346 |
Epoch 00131 | Loss(train) 0.3243 | Acc(train) 0.8945 | Acc(val) 0.9372 |*
Epoch 00132 | Loss(train) 0.3267 | Acc(train) 0.8971 | Acc(val) 0.9359 |
Epoch 00133 | Loss(train) 0.3207 | Acc(train) 0.8998 | Acc(val) 0.9359 |
Epoch 00134 | Loss(train) 0.3334 | Acc(train) 0.8945 | Acc(val) 0.9346 |
Epoch 00135 | Loss(train) 0.3155 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00136 | Loss(train) 0.3222 | Acc(train) 0.9038 | Acc(val) 0.9306 |
Epoch 00137 | Loss(train) 0.3168 | Acc(train) 0.9038 | Acc(val) 0.9319 |
Epoch 00138 | Loss(train) 0.3203 | Acc(train) 0.9038 | Acc(val) 0.9346 |
Epoch 00139 | Loss(train) 0.3172 | Acc(train) 0.9025 | Acc(val) 0.9372 |
Epoch 00140 | Loss(train) 0.3164 | Acc(train) 0.8998 | Acc(val) 0.9319 |
Epoch 00141 | Loss(train) 0.3252 | Acc(train) 0.9038 | Acc(val) 0.9319 |
Epoch 00142 | Loss(train) 0.3374 | Acc(train) 0.8904 | Acc(val) 0.9332 |
Epoch 00143 | Loss(train) 0.3200 | Acc(train) 0.9045 | Acc(val) 0.9372 |
Epoch 00144 | Loss(train) 0.3330 | Acc(train) 0.8945 | Acc(val) 0.9346 |
Epoch 00145 | Loss(train) 0.3367 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00146 | Loss(train) 0.3405 | Acc(train) 0.8938 | Acc(val) 0.9319 |
Epoch 00147 | Loss(train) 0.3383 | Acc(train) 0.8851 | Acc(val) 0.9346 |
Epoch 00148 | Loss(train) 0.3288 | Acc(train) 0.8971 | Acc(val) 0.9359 |
Epoch 00149 | Loss(train) 0.3255 | Acc(train) 0.9038 | Acc(val) 0.9346 |
Epoch 00150 | Loss(train) 0.3115 | Acc(train) 0.9112 | Acc(val) 0.9359 |
Epoch 00151 | Loss(train) 0.3388 | Acc(train) 0.8945 | Acc(val) 0.9372 |
Epoch 00152 | Loss(train) 0.3260 | Acc(train) 0.9051 | Acc(val) 0.9359 |
Epoch 00153 | Loss(train) 0.3223 | Acc(train) 0.9051 | Acc(val) 0.9332 |
Epoch 00154 | Loss(train) 0.3092 | Acc(train) 0.9071 | Acc(val) 0.9319 |
Epoch 00155 | Loss(train) 0.3115 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00156 | Loss(train) 0.3173 | Acc(train) 0.8991 | Acc(val) 0.9372 |
Epoch 00157 | Loss(train) 0.2922 | Acc(train) 0.9125 | Acc(val) 0.9346 |
Epoch 00158 | Loss(train) 0.3293 | Acc(train) 0.8965 | Acc(val) 0.9386 |*
Epoch 00159 | Loss(train) 0.3221 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00160 | Loss(train) 0.3239 | Acc(train) 0.8978 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.3359 | Acc(train) 0.9051 | Acc(val) 0.9359 |
Epoch 00162 | Loss(train) 0.3189 | Acc(train) 0.9011 | Acc(val) 0.9372 |
Epoch 00163 | Loss(train) 0.3106 | Acc(train) 0.9112 | Acc(val) 0.9346 |
Epoch 00164 | Loss(train) 0.3088 | Acc(train) 0.9112 | Acc(val) 0.9359 |
Epoch 00165 | Loss(train) 0.3156 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00166 | Loss(train) 0.3190 | Acc(train) 0.9045 | Acc(val) 0.9359 |
Epoch 00167 | Loss(train) 0.3189 | Acc(train) 0.9038 | Acc(val) 0.9399 |*
Epoch 00168 | Loss(train) 0.3168 | Acc(train) 0.9071 | Acc(val) 0.9386 |
Epoch 00169 | Loss(train) 0.3154 | Acc(train) 0.8991 | Acc(val) 0.9386 |
Epoch 00170 | Loss(train) 0.3089 | Acc(train) 0.9078 | Acc(val) 0.9413 |*
Epoch 00171 | Loss(train) 0.3037 | Acc(train) 0.9098 | Acc(val) 0.9346 |
Epoch 00172 | Loss(train) 0.2987 | Acc(train) 0.9025 | Acc(val) 0.9346 |
Epoch 00173 | Loss(train) 0.3169 | Acc(train) 0.8978 | Acc(val) 0.9386 |
Epoch 00174 | Loss(train) 0.2940 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00175 | Loss(train) 0.3400 | Acc(train) 0.8844 | Acc(val) 0.9399 |
Epoch 00176 | Loss(train) 0.3233 | Acc(train) 0.8925 | Acc(val) 0.9346 |
Epoch 00177 | Loss(train) 0.3042 | Acc(train) 0.9065 | Acc(val) 0.9319 |
Epoch 00178 | Loss(train) 0.3261 | Acc(train) 0.8851 | Acc(val) 0.9346 |
Epoch 00179 | Loss(train) 0.3030 | Acc(train) 0.9078 | Acc(val) 0.9346 |
Epoch 00180 | Loss(train) 0.3163 | Acc(train) 0.9038 | Acc(val) 0.9386 |
Epoch 00181 | Loss(train) 0.2906 | Acc(train) 0.9198 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.3161 | Acc(train) 0.9045 | Acc(val) 0.9413 |
Epoch 00183 | Loss(train) 0.3117 | Acc(train) 0.9011 | Acc(val) 0.9386 |
Epoch 00184 | Loss(train) 0.3202 | Acc(train) 0.8991 | Acc(val) 0.9359 |
Epoch 00185 | Loss(train) 0.3135 | Acc(train) 0.8985 | Acc(val) 0.9359 |
Epoch 00186 | Loss(train) 0.3081 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00187 | Loss(train) 0.2902 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00188 | Loss(train) 0.3022 | Acc(train) 0.9078 | Acc(val) 0.9359 |
Epoch 00189 | Loss(train) 0.2950 | Acc(train) 0.9145 | Acc(val) 0.9386 |
Epoch 00190 | Loss(train) 0.3168 | Acc(train) 0.9045 | Acc(val) 0.9386 |
Epoch 00191 | Loss(train) 0.3044 | Acc(train) 0.9138 | Acc(val) 0.9372 |
Epoch 00192 | Loss(train) 0.3118 | Acc(train) 0.9011 | Acc(val) 0.9386 |
Epoch 00193 | Loss(train) 0.3086 | Acc(train) 0.9071 | Acc(val) 0.9386 |
Epoch 00194 | Loss(train) 0.2943 | Acc(train) 0.9112 | Acc(val) 0.9413 |
Epoch 00195 | Loss(train) 0.3207 | Acc(train) 0.9038 | Acc(val) 0.9386 |
Epoch 00196 | Loss(train) 0.2823 | Acc(train) 0.9092 | Acc(val) 0.9386 |
Epoch 00197 | Loss(train) 0.3015 | Acc(train) 0.9038 | Acc(val) 0.9372 |
Epoch 00198 | Loss(train) 0.2986 | Acc(train) 0.8998 | Acc(val) 0.9399 |
Epoch 00199 | Loss(train) 0.3047 | Acc(train) 0.9098 | Acc(val) 0.9413 |
Epoch 00200 | Loss(train) 0.3086 | Acc(train) 0.9038 | Acc(val) 0.9399 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3732 | Acc(train) 0.0735 | Acc(val) 0.3271 |*
Epoch 00002 | Loss(train) 2.2938 | Acc(train) 0.3033 | Acc(val) 0.2003 |
Epoch 00003 | Loss(train) 3.3904 | Acc(train) 0.2004 | Acc(val) 0.4099 |*
Epoch 00004 | Loss(train) 2.2879 | Acc(train) 0.2432 | Acc(val) 0.3672 |
Epoch 00005 | Loss(train) 2.1371 | Acc(train) 0.2538 | Acc(val) 0.5621 |*
Epoch 00006 | Loss(train) 1.5311 | Acc(train) 0.4496 | Acc(val) 0.6021 |*
Epoch 00007 | Loss(train) 1.5608 | Acc(train) 0.4629 | Acc(val) 0.5834 |
Epoch 00008 | Loss(train) 1.5517 | Acc(train) 0.5050 | Acc(val) 0.6222 |*
Epoch 00009 | Loss(train) 1.4151 | Acc(train) 0.5458 | Acc(val) 0.6168 |
Epoch 00010 | Loss(train) 1.3296 | Acc(train) 0.5478 | Acc(val) 0.6248 |*
Epoch 00011 | Loss(train) 1.2375 | Acc(train) 0.5691 | Acc(val) 0.7423 |*
Epoch 00012 | Loss(train) 1.1280 | Acc(train) 0.6560 | Acc(val) 0.7597 |*
Epoch 00013 | Loss(train) 1.0798 | Acc(train) 0.6760 | Acc(val) 0.7877 |*
Epoch 00014 | Loss(train) 1.0383 | Acc(train) 0.7034 | Acc(val) 0.7597 |
Epoch 00015 | Loss(train) 1.0261 | Acc(train) 0.7047 | Acc(val) 0.7557 |
Epoch 00016 | Loss(train) 1.0165 | Acc(train) 0.7047 | Acc(val) 0.7437 |
Epoch 00017 | Loss(train) 0.9638 | Acc(train) 0.6894 | Acc(val) 0.7730 |
Epoch 00018 | Loss(train) 0.8910 | Acc(train) 0.7308 | Acc(val) 0.8131 |*
Epoch 00019 | Loss(train) 0.8909 | Acc(train) 0.7535 | Acc(val) 0.8398 |*
Epoch 00020 | Loss(train) 0.8443 | Acc(train) 0.7448 | Acc(val) 0.8505 |*
Epoch 00021 | Loss(train) 0.8356 | Acc(train) 0.7562 | Acc(val) 0.8518 |*
Epoch 00022 | Loss(train) 0.7862 | Acc(train) 0.7642 | Acc(val) 0.8425 |
Epoch 00023 | Loss(train) 0.7439 | Acc(train) 0.7488 | Acc(val) 0.8304 |
Epoch 00024 | Loss(train) 0.7188 | Acc(train) 0.7622 | Acc(val) 0.8344 |
Epoch 00025 | Loss(train) 0.7283 | Acc(train) 0.7602 | Acc(val) 0.8358 |
Epoch 00026 | Loss(train) 0.6802 | Acc(train) 0.7796 | Acc(val) 0.8465 |
Epoch 00027 | Loss(train) 0.6712 | Acc(train) 0.7842 | Acc(val) 0.8625 |*
Epoch 00028 | Loss(train) 0.6467 | Acc(train) 0.8130 | Acc(val) 0.8785 |*
Epoch 00029 | Loss(train) 0.6638 | Acc(train) 0.8009 | Acc(val) 0.8932 |*
Epoch 00030 | Loss(train) 0.6173 | Acc(train) 0.8196 | Acc(val) 0.8972 |*
Epoch 00031 | Loss(train) 0.5995 | Acc(train) 0.8337 | Acc(val) 0.9012 |*
Epoch 00032 | Loss(train) 0.5593 | Acc(train) 0.8457 | Acc(val) 0.8959 |
Epoch 00033 | Loss(train) 0.5879 | Acc(train) 0.8290 | Acc(val) 0.8972 |
Epoch 00034 | Loss(train) 0.5528 | Acc(train) 0.8330 | Acc(val) 0.9012 |
Epoch 00035 | Loss(train) 0.5504 | Acc(train) 0.8464 | Acc(val) 0.9039 |*
Epoch 00036 | Loss(train) 0.5569 | Acc(train) 0.8390 | Acc(val) 0.9092 |*
Epoch 00037 | Loss(train) 0.5414 | Acc(train) 0.8444 | Acc(val) 0.9119 |*
Epoch 00038 | Loss(train) 0.5294 | Acc(train) 0.8484 | Acc(val) 0.9159 |*
Epoch 00039 | Loss(train) 0.5152 | Acc(train) 0.8437 | Acc(val) 0.9159 |
Epoch 00040 | Loss(train) 0.5124 | Acc(train) 0.8557 | Acc(val) 0.9172 |*
Epoch 00041 | Loss(train) 0.4933 | Acc(train) 0.8570 | Acc(val) 0.9132 |
Epoch 00042 | Loss(train) 0.4805 | Acc(train) 0.8611 | Acc(val) 0.9105 |
Epoch 00043 | Loss(train) 0.4898 | Acc(train) 0.8490 | Acc(val) 0.9119 |
Epoch 00044 | Loss(train) 0.4827 | Acc(train) 0.8437 | Acc(val) 0.9119 |
Epoch 00045 | Loss(train) 0.4500 | Acc(train) 0.8711 | Acc(val) 0.9132 |
Epoch 00046 | Loss(train) 0.4700 | Acc(train) 0.8691 | Acc(val) 0.9159 |
Epoch 00047 | Loss(train) 0.4738 | Acc(train) 0.8584 | Acc(val) 0.9199 |*
Epoch 00048 | Loss(train) 0.4735 | Acc(train) 0.8664 | Acc(val) 0.9239 |*
Epoch 00049 | Loss(train) 0.4479 | Acc(train) 0.8644 | Acc(val) 0.9212 |
Epoch 00050 | Loss(train) 0.4647 | Acc(train) 0.8550 | Acc(val) 0.9199 |
Epoch 00051 | Loss(train) 0.4250 | Acc(train) 0.8871 | Acc(val) 0.9212 |
Epoch 00052 | Loss(train) 0.4263 | Acc(train) 0.8717 | Acc(val) 0.9226 |
Epoch 00053 | Loss(train) 0.4328 | Acc(train) 0.8724 | Acc(val) 0.9239 |
Epoch 00054 | Loss(train) 0.4309 | Acc(train) 0.8751 | Acc(val) 0.9239 |
Epoch 00055 | Loss(train) 0.4111 | Acc(train) 0.8758 | Acc(val) 0.9212 |
Epoch 00056 | Loss(train) 0.4113 | Acc(train) 0.8804 | Acc(val) 0.9199 |
Epoch 00057 | Loss(train) 0.4026 | Acc(train) 0.8784 | Acc(val) 0.9172 |
Epoch 00058 | Loss(train) 0.3954 | Acc(train) 0.8925 | Acc(val) 0.9172 |
Epoch 00059 | Loss(train) 0.4346 | Acc(train) 0.8664 | Acc(val) 0.9172 |
Epoch 00060 | Loss(train) 0.4005 | Acc(train) 0.8838 | Acc(val) 0.9199 |
Epoch 00061 | Loss(train) 0.4005 | Acc(train) 0.8851 | Acc(val) 0.9226 |
Epoch 00062 | Loss(train) 0.3819 | Acc(train) 0.8904 | Acc(val) 0.9266 |*
Epoch 00063 | Loss(train) 0.3762 | Acc(train) 0.8891 | Acc(val) 0.9279 |*
Epoch 00064 | Loss(train) 0.3596 | Acc(train) 0.9031 | Acc(val) 0.9266 |
Epoch 00065 | Loss(train) 0.3698 | Acc(train) 0.8931 | Acc(val) 0.9266 |
Epoch 00066 | Loss(train) 0.3672 | Acc(train) 0.8911 | Acc(val) 0.9252 |
Epoch 00067 | Loss(train) 0.3727 | Acc(train) 0.8918 | Acc(val) 0.9212 |
Epoch 00068 | Loss(train) 0.3728 | Acc(train) 0.8918 | Acc(val) 0.9226 |
Epoch 00069 | Loss(train) 0.3553 | Acc(train) 0.8931 | Acc(val) 0.9252 |
Epoch 00070 | Loss(train) 0.3587 | Acc(train) 0.8991 | Acc(val) 0.9292 |*
Epoch 00071 | Loss(train) 0.3506 | Acc(train) 0.8891 | Acc(val) 0.9292 |
Epoch 00072 | Loss(train) 0.3616 | Acc(train) 0.8938 | Acc(val) 0.9306 |*
Epoch 00073 | Loss(train) 0.3481 | Acc(train) 0.8998 | Acc(val) 0.9292 |
Epoch 00074 | Loss(train) 0.3531 | Acc(train) 0.8938 | Acc(val) 0.9306 |
Epoch 00075 | Loss(train) 0.3409 | Acc(train) 0.8951 | Acc(val) 0.9292 |
Epoch 00076 | Loss(train) 0.3533 | Acc(train) 0.8985 | Acc(val) 0.9279 |
Epoch 00077 | Loss(train) 0.3535 | Acc(train) 0.8925 | Acc(val) 0.9266 |
Epoch 00078 | Loss(train) 0.3766 | Acc(train) 0.8818 | Acc(val) 0.9319 |*
Epoch 00079 | Loss(train) 0.3488 | Acc(train) 0.8951 | Acc(val) 0.9306 |
Epoch 00080 | Loss(train) 0.3399 | Acc(train) 0.8951 | Acc(val) 0.9306 |
Epoch 00081 | Loss(train) 0.3361 | Acc(train) 0.8991 | Acc(val) 0.9306 |
Epoch 00082 | Loss(train) 0.3298 | Acc(train) 0.9011 | Acc(val) 0.9319 |
Epoch 00083 | Loss(train) 0.3322 | Acc(train) 0.9011 | Acc(val) 0.9306 |
Epoch 00084 | Loss(train) 0.3393 | Acc(train) 0.9132 | Acc(val) 0.9332 |*
Epoch 00085 | Loss(train) 0.3344 | Acc(train) 0.8985 | Acc(val) 0.9306 |
Epoch 00086 | Loss(train) 0.3395 | Acc(train) 0.8971 | Acc(val) 0.9306 |
Epoch 00087 | Loss(train) 0.3152 | Acc(train) 0.9058 | Acc(val) 0.9332 |
Epoch 00088 | Loss(train) 0.3306 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00089 | Loss(train) 0.3271 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00090 | Loss(train) 0.3259 | Acc(train) 0.8965 | Acc(val) 0.9306 |
Epoch 00091 | Loss(train) 0.3362 | Acc(train) 0.8945 | Acc(val) 0.9292 |
Epoch 00092 | Loss(train) 0.3182 | Acc(train) 0.9125 | Acc(val) 0.9319 |
Epoch 00093 | Loss(train) 0.3258 | Acc(train) 0.9098 | Acc(val) 0.9332 |
Epoch 00094 | Loss(train) 0.3184 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00095 | Loss(train) 0.3129 | Acc(train) 0.9038 | Acc(val) 0.9346 |*
Epoch 00096 | Loss(train) 0.3086 | Acc(train) 0.9098 | Acc(val) 0.9346 |
Epoch 00097 | Loss(train) 0.3197 | Acc(train) 0.8998 | Acc(val) 0.9332 |
Epoch 00098 | Loss(train) 0.3178 | Acc(train) 0.9018 | Acc(val) 0.9332 |
Epoch 00099 | Loss(train) 0.3109 | Acc(train) 0.9045 | Acc(val) 0.9346 |
Epoch 00100 | Loss(train) 0.3124 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00101 | Loss(train) 0.3341 | Acc(train) 0.8971 | Acc(val) 0.9346 |
Epoch 00102 | Loss(train) 0.2848 | Acc(train) 0.9178 | Acc(val) 0.9319 |
Epoch 00103 | Loss(train) 0.3099 | Acc(train) 0.9105 | Acc(val) 0.9319 |
Epoch 00104 | Loss(train) 0.3019 | Acc(train) 0.9172 | Acc(val) 0.9332 |
Epoch 00105 | Loss(train) 0.2967 | Acc(train) 0.9152 | Acc(val) 0.9319 |
Epoch 00106 | Loss(train) 0.3024 | Acc(train) 0.9112 | Acc(val) 0.9346 |
Epoch 00107 | Loss(train) 0.2843 | Acc(train) 0.9152 | Acc(val) 0.9359 |*
Epoch 00108 | Loss(train) 0.2895 | Acc(train) 0.9118 | Acc(val) 0.9319 |
Epoch 00109 | Loss(train) 0.2989 | Acc(train) 0.9011 | Acc(val) 0.9319 |
Epoch 00110 | Loss(train) 0.3030 | Acc(train) 0.9158 | Acc(val) 0.9346 |
Epoch 00111 | Loss(train) 0.2880 | Acc(train) 0.9172 | Acc(val) 0.9306 |
Epoch 00112 | Loss(train) 0.2959 | Acc(train) 0.9178 | Acc(val) 0.9319 |
Epoch 00113 | Loss(train) 0.2986 | Acc(train) 0.9092 | Acc(val) 0.9306 |
Epoch 00114 | Loss(train) 0.3017 | Acc(train) 0.9105 | Acc(val) 0.9319 |
Epoch 00115 | Loss(train) 0.3125 | Acc(train) 0.9125 | Acc(val) 0.9346 |
Epoch 00116 | Loss(train) 0.2976 | Acc(train) 0.9078 | Acc(val) 0.9372 |*
Epoch 00117 | Loss(train) 0.2948 | Acc(train) 0.9158 | Acc(val) 0.9346 |
Epoch 00118 | Loss(train) 0.3084 | Acc(train) 0.9078 | Acc(val) 0.9332 |
Epoch 00119 | Loss(train) 0.3031 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00120 | Loss(train) 0.2928 | Acc(train) 0.9145 | Acc(val) 0.9346 |
Epoch 00121 | Loss(train) 0.2773 | Acc(train) 0.9225 | Acc(val) 0.9359 |
Epoch 00122 | Loss(train) 0.2952 | Acc(train) 0.9092 | Acc(val) 0.9332 |
Epoch 00123 | Loss(train) 0.2883 | Acc(train) 0.9212 | Acc(val) 0.9346 |
Epoch 00124 | Loss(train) 0.2895 | Acc(train) 0.9198 | Acc(val) 0.9306 |
Epoch 00125 | Loss(train) 0.2950 | Acc(train) 0.9078 | Acc(val) 0.9346 |
Epoch 00126 | Loss(train) 0.2928 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00127 | Loss(train) 0.2958 | Acc(train) 0.9132 | Acc(val) 0.9359 |
Epoch 00128 | Loss(train) 0.3071 | Acc(train) 0.9031 | Acc(val) 0.9306 |
Epoch 00129 | Loss(train) 0.2905 | Acc(train) 0.9125 | Acc(val) 0.9306 |
Epoch 00130 | Loss(train) 0.3100 | Acc(train) 0.9011 | Acc(val) 0.9306 |
Epoch 00131 | Loss(train) 0.2808 | Acc(train) 0.9172 | Acc(val) 0.9332 |
Epoch 00132 | Loss(train) 0.2910 | Acc(train) 0.9165 | Acc(val) 0.9332 |
Epoch 00133 | Loss(train) 0.2853 | Acc(train) 0.9152 | Acc(val) 0.9332 |
Epoch 00134 | Loss(train) 0.2760 | Acc(train) 0.9185 | Acc(val) 0.9319 |
Epoch 00135 | Loss(train) 0.2898 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00136 | Loss(train) 0.2756 | Acc(train) 0.9118 | Acc(val) 0.9386 |*
Epoch 00137 | Loss(train) 0.2994 | Acc(train) 0.9138 | Acc(val) 0.9346 |
Epoch 00138 | Loss(train) 0.2819 | Acc(train) 0.9112 | Acc(val) 0.9346 |
Epoch 00139 | Loss(train) 0.2901 | Acc(train) 0.9125 | Acc(val) 0.9386 |
Epoch 00140 | Loss(train) 0.2667 | Acc(train) 0.9165 | Acc(val) 0.9346 |
Epoch 00141 | Loss(train) 0.2802 | Acc(train) 0.9105 | Acc(val) 0.9319 |
Epoch 00142 | Loss(train) 0.2897 | Acc(train) 0.9092 | Acc(val) 0.9359 |
Epoch 00143 | Loss(train) 0.2915 | Acc(train) 0.9145 | Acc(val) 0.9332 |
Epoch 00144 | Loss(train) 0.2948 | Acc(train) 0.9051 | Acc(val) 0.9359 |
Epoch 00145 | Loss(train) 0.2811 | Acc(train) 0.9218 | Acc(val) 0.9372 |
Epoch 00146 | Loss(train) 0.2814 | Acc(train) 0.9192 | Acc(val) 0.9346 |
Epoch 00147 | Loss(train) 0.2814 | Acc(train) 0.9125 | Acc(val) 0.9359 |
Epoch 00148 | Loss(train) 0.2751 | Acc(train) 0.9165 | Acc(val) 0.9306 |
Epoch 00149 | Loss(train) 0.2891 | Acc(train) 0.9132 | Acc(val) 0.9346 |
Epoch 00150 | Loss(train) 0.2776 | Acc(train) 0.9212 | Acc(val) 0.9319 |
Epoch 00151 | Loss(train) 0.2646 | Acc(train) 0.9172 | Acc(val) 0.9359 |
Epoch 00152 | Loss(train) 0.2826 | Acc(train) 0.9105 | Acc(val) 0.9359 |
Epoch 00153 | Loss(train) 0.2742 | Acc(train) 0.9185 | Acc(val) 0.9319 |
Epoch 00154 | Loss(train) 0.2624 | Acc(train) 0.9185 | Acc(val) 0.9346 |
Epoch 00155 | Loss(train) 0.2851 | Acc(train) 0.9118 | Acc(val) 0.9386 |
Epoch 00156 | Loss(train) 0.2882 | Acc(train) 0.9152 | Acc(val) 0.9399 |*
Epoch 00157 | Loss(train) 0.2724 | Acc(train) 0.9178 | Acc(val) 0.9346 |
Epoch 00158 | Loss(train) 0.2719 | Acc(train) 0.9192 | Acc(val) 0.9359 |
Epoch 00159 | Loss(train) 0.2719 | Acc(train) 0.9218 | Acc(val) 0.9372 |
Epoch 00160 | Loss(train) 0.2728 | Acc(train) 0.9132 | Acc(val) 0.9372 |
Epoch 00161 | Loss(train) 0.2816 | Acc(train) 0.9118 | Acc(val) 0.9372 |
Epoch 00162 | Loss(train) 0.2849 | Acc(train) 0.9152 | Acc(val) 0.9439 |*
Epoch 00163 | Loss(train) 0.2818 | Acc(train) 0.9125 | Acc(val) 0.9319 |
Epoch 00164 | Loss(train) 0.2598 | Acc(train) 0.9218 | Acc(val) 0.9306 |
Epoch 00165 | Loss(train) 0.2769 | Acc(train) 0.9058 | Acc(val) 0.9346 |
Epoch 00166 | Loss(train) 0.2638 | Acc(train) 0.9185 | Acc(val) 0.9372 |
Epoch 00167 | Loss(train) 0.2855 | Acc(train) 0.9185 | Acc(val) 0.9332 |
Epoch 00168 | Loss(train) 0.2684 | Acc(train) 0.9198 | Acc(val) 0.9332 |
Epoch 00169 | Loss(train) 0.2842 | Acc(train) 0.9092 | Acc(val) 0.9306 |
Epoch 00170 | Loss(train) 0.2597 | Acc(train) 0.9292 | Acc(val) 0.9386 |
Epoch 00171 | Loss(train) 0.2693 | Acc(train) 0.9145 | Acc(val) 0.9346 |
Epoch 00172 | Loss(train) 0.2707 | Acc(train) 0.9118 | Acc(val) 0.9399 |
Epoch 00173 | Loss(train) 0.2791 | Acc(train) 0.9132 | Acc(val) 0.9372 |
Epoch 00174 | Loss(train) 0.2754 | Acc(train) 0.9138 | Acc(val) 0.9332 |
Epoch 00175 | Loss(train) 0.3028 | Acc(train) 0.9038 | Acc(val) 0.9413 |
Epoch 00176 | Loss(train) 0.2687 | Acc(train) 0.9238 | Acc(val) 0.9386 |
Epoch 00177 | Loss(train) 0.2803 | Acc(train) 0.9172 | Acc(val) 0.9346 |
Epoch 00178 | Loss(train) 0.2637 | Acc(train) 0.9205 | Acc(val) 0.9346 |
Epoch 00179 | Loss(train) 0.2980 | Acc(train) 0.9031 | Acc(val) 0.9332 |
Epoch 00180 | Loss(train) 0.2721 | Acc(train) 0.9065 | Acc(val) 0.9319 |
Epoch 00181 | Loss(train) 0.2685 | Acc(train) 0.9178 | Acc(val) 0.9399 |
Epoch 00182 | Loss(train) 0.2704 | Acc(train) 0.9205 | Acc(val) 0.9292 |
Epoch 00183 | Loss(train) 0.2905 | Acc(train) 0.9212 | Acc(val) 0.9372 |
Epoch 00184 | Loss(train) 0.2719 | Acc(train) 0.9165 | Acc(val) 0.9332 |
Epoch 00185 | Loss(train) 0.2749 | Acc(train) 0.9138 | Acc(val) 0.9332 |
Epoch 00186 | Loss(train) 0.2573 | Acc(train) 0.9225 | Acc(val) 0.9399 |
Epoch 00187 | Loss(train) 0.2820 | Acc(train) 0.9218 | Acc(val) 0.9426 |
Epoch 00188 | Loss(train) 0.2759 | Acc(train) 0.9132 | Acc(val) 0.9413 |
Epoch 00189 | Loss(train) 0.2698 | Acc(train) 0.9205 | Acc(val) 0.9332 |
Epoch 00190 | Loss(train) 0.2572 | Acc(train) 0.9205 | Acc(val) 0.9332 |
Epoch 00191 | Loss(train) 0.2771 | Acc(train) 0.9138 | Acc(val) 0.9386 |
Epoch 00192 | Loss(train) 0.2670 | Acc(train) 0.9192 | Acc(val) 0.9372 |
Epoch 00193 | Loss(train) 0.2648 | Acc(train) 0.9165 | Acc(val) 0.9399 |
Epoch 00194 | Loss(train) 0.2537 | Acc(train) 0.9259 | Acc(val) 0.9359 |
Epoch 00195 | Loss(train) 0.2581 | Acc(train) 0.9245 | Acc(val) 0.9359 |
Epoch 00196 | Loss(train) 0.2633 | Acc(train) 0.9192 | Acc(val) 0.9399 |
Epoch 00197 | Loss(train) 0.2536 | Acc(train) 0.9218 | Acc(val) 0.9359 |
Epoch 00198 | Loss(train) 0.2537 | Acc(train) 0.9218 | Acc(val) 0.9413 |
Epoch 00199 | Loss(train) 0.2542 | Acc(train) 0.9232 | Acc(val) 0.9386 |
Epoch 00200 | Loss(train) 0.2598 | Acc(train) 0.9198 | Acc(val) 0.9386 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.2492 | Acc(train) 0.0327 | Acc(val) 0.1989 |*
Epoch 00002 | Loss(train) 4.5363 | Acc(train) 0.2091 | Acc(val) 0.2550 |*
Epoch 00003 | Loss(train) 2.7731 | Acc(train) 0.2886 | Acc(val) 0.2724 |*
Epoch 00004 | Loss(train) 2.4393 | Acc(train) 0.2131 | Acc(val) 0.3858 |*
Epoch 00005 | Loss(train) 1.9807 | Acc(train) 0.3267 | Acc(val) 0.1242 |
Epoch 00006 | Loss(train) 1.9645 | Acc(train) 0.2077 | Acc(val) 0.3284 |
Epoch 00007 | Loss(train) 1.7776 | Acc(train) 0.3340 | Acc(val) 0.2363 |
Epoch 00008 | Loss(train) 1.8150 | Acc(train) 0.2452 | Acc(val) 0.2056 |
Epoch 00009 | Loss(train) 1.7668 | Acc(train) 0.2211 | Acc(val) 0.3685 |
Epoch 00010 | Loss(train) 1.6743 | Acc(train) 0.3721 | Acc(val) 0.4700 |*
Epoch 00011 | Loss(train) 1.5851 | Acc(train) 0.4643 | Acc(val) 0.4246 |
Epoch 00012 | Loss(train) 1.5527 | Acc(train) 0.4175 | Acc(val) 0.4539 |
Epoch 00013 | Loss(train) 1.5093 | Acc(train) 0.4369 | Acc(val) 0.6061 |*
Epoch 00014 | Loss(train) 1.4230 | Acc(train) 0.5498 | Acc(val) 0.6142 |*
Epoch 00015 | Loss(train) 1.4173 | Acc(train) 0.5251 | Acc(val) 0.5848 |
Epoch 00016 | Loss(train) 1.3157 | Acc(train) 0.5698 | Acc(val) 0.5728 |
Epoch 00017 | Loss(train) 1.3019 | Acc(train) 0.5878 | Acc(val) 0.5754 |
Epoch 00018 | Loss(train) 1.2478 | Acc(train) 0.5665 | Acc(val) 0.6182 |*
Epoch 00019 | Loss(train) 1.2245 | Acc(train) 0.5772 | Acc(val) 0.6729 |*
Epoch 00020 | Loss(train) 1.1696 | Acc(train) 0.6045 | Acc(val) 0.7423 |*
Epoch 00021 | Loss(train) 1.1918 | Acc(train) 0.6293 | Acc(val) 0.7503 |*
Epoch 00022 | Loss(train) 1.1150 | Acc(train) 0.6887 | Acc(val) 0.7343 |
Epoch 00023 | Loss(train) 1.0768 | Acc(train) 0.6653 | Acc(val) 0.6849 |
Epoch 00024 | Loss(train) 1.0596 | Acc(train) 0.6480 | Acc(val) 0.6742 |
Epoch 00025 | Loss(train) 1.0539 | Acc(train) 0.6319 | Acc(val) 0.7063 |
Epoch 00026 | Loss(train) 1.0277 | Acc(train) 0.6647 | Acc(val) 0.7583 |*
Epoch 00027 | Loss(train) 0.9871 | Acc(train) 0.6860 | Acc(val) 0.7864 |*
Epoch 00028 | Loss(train) 0.9928 | Acc(train) 0.6954 | Acc(val) 0.8037 |*
Epoch 00029 | Loss(train) 0.9368 | Acc(train) 0.7241 | Acc(val) 0.8238 |*
Epoch 00030 | Loss(train) 0.9538 | Acc(train) 0.7141 | Acc(val) 0.8184 |
Epoch 00031 | Loss(train) 0.8868 | Acc(train) 0.7415 | Acc(val) 0.8238 |
Epoch 00032 | Loss(train) 0.8844 | Acc(train) 0.7435 | Acc(val) 0.8117 |
Epoch 00033 | Loss(train) 0.8412 | Acc(train) 0.7442 | Acc(val) 0.7891 |
Epoch 00034 | Loss(train) 0.8225 | Acc(train) 0.7442 | Acc(val) 0.7824 |
Epoch 00035 | Loss(train) 0.8103 | Acc(train) 0.7428 | Acc(val) 0.8531 |*
Epoch 00036 | Loss(train) 0.7796 | Acc(train) 0.7729 | Acc(val) 0.8798 |*
Epoch 00037 | Loss(train) 0.7762 | Acc(train) 0.7856 | Acc(val) 0.8825 |*
Epoch 00038 | Loss(train) 0.7461 | Acc(train) 0.7909 | Acc(val) 0.8825 |
Epoch 00039 | Loss(train) 0.7867 | Acc(train) 0.7789 | Acc(val) 0.8852 |*
Epoch 00040 | Loss(train) 0.7006 | Acc(train) 0.8090 | Acc(val) 0.8718 |
Epoch 00041 | Loss(train) 0.7048 | Acc(train) 0.8009 | Acc(val) 0.8585 |
Epoch 00042 | Loss(train) 0.6993 | Acc(train) 0.7943 | Acc(val) 0.8652 |
Epoch 00043 | Loss(train) 0.6885 | Acc(train) 0.7983 | Acc(val) 0.8879 |*
Epoch 00044 | Loss(train) 0.6521 | Acc(train) 0.8043 | Acc(val) 0.9012 |*
Epoch 00045 | Loss(train) 0.6390 | Acc(train) 0.8150 | Acc(val) 0.9052 |*
Epoch 00046 | Loss(train) 0.6343 | Acc(train) 0.8069 | Acc(val) 0.9079 |*
Epoch 00047 | Loss(train) 0.6006 | Acc(train) 0.8156 | Acc(val) 0.9105 |*
Epoch 00048 | Loss(train) 0.6185 | Acc(train) 0.8270 | Acc(val) 0.9079 |
Epoch 00049 | Loss(train) 0.5753 | Acc(train) 0.8250 | Acc(val) 0.9119 |*
Epoch 00050 | Loss(train) 0.5759 | Acc(train) 0.8363 | Acc(val) 0.9172 |*
Epoch 00051 | Loss(train) 0.5498 | Acc(train) 0.8343 | Acc(val) 0.9146 |
Epoch 00052 | Loss(train) 0.5252 | Acc(train) 0.8444 | Acc(val) 0.9159 |
Epoch 00053 | Loss(train) 0.5515 | Acc(train) 0.8363 | Acc(val) 0.9119 |
Epoch 00054 | Loss(train) 0.4958 | Acc(train) 0.8484 | Acc(val) 0.9105 |
Epoch 00055 | Loss(train) 0.5066 | Acc(train) 0.8510 | Acc(val) 0.9105 |
Epoch 00056 | Loss(train) 0.5279 | Acc(train) 0.8517 | Acc(val) 0.9105 |
Epoch 00057 | Loss(train) 0.5051 | Acc(train) 0.8564 | Acc(val) 0.9159 |
Epoch 00058 | Loss(train) 0.4862 | Acc(train) 0.8484 | Acc(val) 0.9159 |
Epoch 00059 | Loss(train) 0.4747 | Acc(train) 0.8644 | Acc(val) 0.9186 |*
Epoch 00060 | Loss(train) 0.4609 | Acc(train) 0.8597 | Acc(val) 0.9172 |
Epoch 00061 | Loss(train) 0.4786 | Acc(train) 0.8570 | Acc(val) 0.9172 |
Epoch 00062 | Loss(train) 0.4498 | Acc(train) 0.8537 | Acc(val) 0.9212 |*
Epoch 00063 | Loss(train) 0.4426 | Acc(train) 0.8684 | Acc(val) 0.9199 |
Epoch 00064 | Loss(train) 0.4930 | Acc(train) 0.8524 | Acc(val) 0.9239 |*
Epoch 00065 | Loss(train) 0.4435 | Acc(train) 0.8711 | Acc(val) 0.9226 |
Epoch 00066 | Loss(train) 0.4334 | Acc(train) 0.8717 | Acc(val) 0.9212 |
Epoch 00067 | Loss(train) 0.4194 | Acc(train) 0.8704 | Acc(val) 0.9186 |
Epoch 00068 | Loss(train) 0.4284 | Acc(train) 0.8577 | Acc(val) 0.9226 |
Epoch 00069 | Loss(train) 0.4196 | Acc(train) 0.8691 | Acc(val) 0.9239 |
Epoch 00070 | Loss(train) 0.4290 | Acc(train) 0.8671 | Acc(val) 0.9252 |*
Epoch 00071 | Loss(train) 0.4247 | Acc(train) 0.8724 | Acc(val) 0.9212 |
Epoch 00072 | Loss(train) 0.4168 | Acc(train) 0.8764 | Acc(val) 0.9186 |
Epoch 00073 | Loss(train) 0.3989 | Acc(train) 0.8677 | Acc(val) 0.9119 |
Epoch 00074 | Loss(train) 0.4062 | Acc(train) 0.8697 | Acc(val) 0.9159 |
Epoch 00075 | Loss(train) 0.4112 | Acc(train) 0.8697 | Acc(val) 0.9252 |
Epoch 00076 | Loss(train) 0.3686 | Acc(train) 0.8898 | Acc(val) 0.9266 |*
Epoch 00077 | Loss(train) 0.3859 | Acc(train) 0.8824 | Acc(val) 0.9266 |
Epoch 00078 | Loss(train) 0.3853 | Acc(train) 0.8891 | Acc(val) 0.9252 |
Epoch 00079 | Loss(train) 0.3845 | Acc(train) 0.8938 | Acc(val) 0.9239 |
Epoch 00080 | Loss(train) 0.3938 | Acc(train) 0.8751 | Acc(val) 0.9186 |
Epoch 00081 | Loss(train) 0.3749 | Acc(train) 0.8778 | Acc(val) 0.9239 |
Epoch 00082 | Loss(train) 0.3836 | Acc(train) 0.8818 | Acc(val) 0.9279 |*
Epoch 00083 | Loss(train) 0.3484 | Acc(train) 0.8931 | Acc(val) 0.9279 |
Epoch 00084 | Loss(train) 0.3886 | Acc(train) 0.8811 | Acc(val) 0.9279 |
Epoch 00085 | Loss(train) 0.3565 | Acc(train) 0.8945 | Acc(val) 0.9279 |
Epoch 00086 | Loss(train) 0.3705 | Acc(train) 0.8851 | Acc(val) 0.9279 |
Epoch 00087 | Loss(train) 0.3619 | Acc(train) 0.8898 | Acc(val) 0.9279 |
Epoch 00088 | Loss(train) 0.3570 | Acc(train) 0.8918 | Acc(val) 0.9226 |
Epoch 00089 | Loss(train) 0.3768 | Acc(train) 0.8871 | Acc(val) 0.9239 |
Epoch 00090 | Loss(train) 0.3791 | Acc(train) 0.8818 | Acc(val) 0.9266 |
Epoch 00091 | Loss(train) 0.3682 | Acc(train) 0.8864 | Acc(val) 0.9319 |*
Epoch 00092 | Loss(train) 0.3529 | Acc(train) 0.8851 | Acc(val) 0.9306 |
Epoch 00093 | Loss(train) 0.3575 | Acc(train) 0.8904 | Acc(val) 0.9279 |
Epoch 00094 | Loss(train) 0.3627 | Acc(train) 0.8911 | Acc(val) 0.9319 |
Epoch 00095 | Loss(train) 0.3556 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00096 | Loss(train) 0.3643 | Acc(train) 0.8864 | Acc(val) 0.9292 |
Epoch 00097 | Loss(train) 0.3620 | Acc(train) 0.8791 | Acc(val) 0.9292 |
Epoch 00098 | Loss(train) 0.3415 | Acc(train) 0.8965 | Acc(val) 0.9292 |
Epoch 00099 | Loss(train) 0.3634 | Acc(train) 0.8884 | Acc(val) 0.9332 |*
Epoch 00100 | Loss(train) 0.3371 | Acc(train) 0.8971 | Acc(val) 0.9346 |*
Epoch 00101 | Loss(train) 0.3273 | Acc(train) 0.8978 | Acc(val) 0.9319 |
Epoch 00102 | Loss(train) 0.3514 | Acc(train) 0.8891 | Acc(val) 0.9292 |
Epoch 00103 | Loss(train) 0.3326 | Acc(train) 0.8978 | Acc(val) 0.9266 |
Epoch 00104 | Loss(train) 0.3420 | Acc(train) 0.8918 | Acc(val) 0.9292 |
Epoch 00105 | Loss(train) 0.3442 | Acc(train) 0.8918 | Acc(val) 0.9306 |
Epoch 00106 | Loss(train) 0.3719 | Acc(train) 0.9005 | Acc(val) 0.9306 |
Epoch 00107 | Loss(train) 0.3236 | Acc(train) 0.8938 | Acc(val) 0.9306 |
Epoch 00108 | Loss(train) 0.3513 | Acc(train) 0.8918 | Acc(val) 0.9319 |
Epoch 00109 | Loss(train) 0.3425 | Acc(train) 0.8904 | Acc(val) 0.9319 |
Epoch 00110 | Loss(train) 0.3577 | Acc(train) 0.8925 | Acc(val) 0.9332 |
Epoch 00111 | Loss(train) 0.3238 | Acc(train) 0.9025 | Acc(val) 0.9306 |
Epoch 00112 | Loss(train) 0.3297 | Acc(train) 0.9031 | Acc(val) 0.9306 |
Epoch 00113 | Loss(train) 0.3413 | Acc(train) 0.8904 | Acc(val) 0.9279 |
Epoch 00114 | Loss(train) 0.3519 | Acc(train) 0.8945 | Acc(val) 0.9266 |
Epoch 00115 | Loss(train) 0.3431 | Acc(train) 0.8898 | Acc(val) 0.9319 |
Epoch 00116 | Loss(train) 0.3241 | Acc(train) 0.9105 | Acc(val) 0.9346 |
Epoch 00117 | Loss(train) 0.3334 | Acc(train) 0.8985 | Acc(val) 0.9306 |
Epoch 00118 | Loss(train) 0.3060 | Acc(train) 0.9138 | Acc(val) 0.9292 |
Epoch 00119 | Loss(train) 0.3084 | Acc(train) 0.9018 | Acc(val) 0.9306 |
Epoch 00120 | Loss(train) 0.3265 | Acc(train) 0.8998 | Acc(val) 0.9279 |
Epoch 00121 | Loss(train) 0.3334 | Acc(train) 0.8925 | Acc(val) 0.9332 |
Epoch 00122 | Loss(train) 0.3138 | Acc(train) 0.9018 | Acc(val) 0.9372 |*
Epoch 00123 | Loss(train) 0.3438 | Acc(train) 0.8991 | Acc(val) 0.9332 |
Epoch 00124 | Loss(train) 0.3323 | Acc(train) 0.8971 | Acc(val) 0.9332 |
Epoch 00125 | Loss(train) 0.3353 | Acc(train) 0.8951 | Acc(val) 0.9372 |
Epoch 00126 | Loss(train) 0.3413 | Acc(train) 0.8925 | Acc(val) 0.9346 |
Epoch 00127 | Loss(train) 0.3173 | Acc(train) 0.9078 | Acc(val) 0.9319 |
Epoch 00128 | Loss(train) 0.3134 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00129 | Loss(train) 0.3081 | Acc(train) 0.9045 | Acc(val) 0.9306 |
Epoch 00130 | Loss(train) 0.3251 | Acc(train) 0.8971 | Acc(val) 0.9319 |
Epoch 00131 | Loss(train) 0.3031 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00132 | Loss(train) 0.3112 | Acc(train) 0.9112 | Acc(val) 0.9386 |*
Epoch 00133 | Loss(train) 0.3280 | Acc(train) 0.8971 | Acc(val) 0.9346 |
Epoch 00134 | Loss(train) 0.3070 | Acc(train) 0.9058 | Acc(val) 0.9319 |
Epoch 00135 | Loss(train) 0.2970 | Acc(train) 0.9025 | Acc(val) 0.9346 |
Epoch 00136 | Loss(train) 0.3080 | Acc(train) 0.9118 | Acc(val) 0.9332 |
Epoch 00137 | Loss(train) 0.2908 | Acc(train) 0.9152 | Acc(val) 0.9346 |
Epoch 00138 | Loss(train) 0.3179 | Acc(train) 0.9065 | Acc(val) 0.9359 |
Epoch 00139 | Loss(train) 0.2882 | Acc(train) 0.9165 | Acc(val) 0.9359 |
Epoch 00140 | Loss(train) 0.3078 | Acc(train) 0.9058 | Acc(val) 0.9292 |
Epoch 00141 | Loss(train) 0.3224 | Acc(train) 0.8918 | Acc(val) 0.9332 |
Epoch 00142 | Loss(train) 0.2985 | Acc(train) 0.9051 | Acc(val) 0.9346 |
Epoch 00143 | Loss(train) 0.3089 | Acc(train) 0.9011 | Acc(val) 0.9332 |
Epoch 00144 | Loss(train) 0.2934 | Acc(train) 0.9098 | Acc(val) 0.9372 |
Epoch 00145 | Loss(train) 0.3016 | Acc(train) 0.9212 | Acc(val) 0.9332 |
Epoch 00146 | Loss(train) 0.2920 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00147 | Loss(train) 0.3153 | Acc(train) 0.9078 | Acc(val) 0.9346 |
Epoch 00148 | Loss(train) 0.2962 | Acc(train) 0.9045 | Acc(val) 0.9359 |
Epoch 00149 | Loss(train) 0.2948 | Acc(train) 0.9145 | Acc(val) 0.9372 |
Epoch 00150 | Loss(train) 0.3037 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00151 | Loss(train) 0.3020 | Acc(train) 0.9085 | Acc(val) 0.9372 |
Epoch 00152 | Loss(train) 0.2977 | Acc(train) 0.9145 | Acc(val) 0.9386 |
Epoch 00153 | Loss(train) 0.2851 | Acc(train) 0.9118 | Acc(val) 0.9372 |
Epoch 00154 | Loss(train) 0.2974 | Acc(train) 0.9105 | Acc(val) 0.9346 |
Epoch 00155 | Loss(train) 0.3024 | Acc(train) 0.9025 | Acc(val) 0.9332 |
Epoch 00156 | Loss(train) 0.2884 | Acc(train) 0.9098 | Acc(val) 0.9386 |
Epoch 00157 | Loss(train) 0.2940 | Acc(train) 0.9132 | Acc(val) 0.9372 |
Epoch 00158 | Loss(train) 0.2922 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00159 | Loss(train) 0.3080 | Acc(train) 0.9051 | Acc(val) 0.9399 |*
Epoch 00160 | Loss(train) 0.3007 | Acc(train) 0.9058 | Acc(val) 0.9372 |
Epoch 00161 | Loss(train) 0.3022 | Acc(train) 0.9085 | Acc(val) 0.9413 |*
Epoch 00162 | Loss(train) 0.2944 | Acc(train) 0.9112 | Acc(val) 0.9399 |
Epoch 00163 | Loss(train) 0.2861 | Acc(train) 0.9165 | Acc(val) 0.9399 |
Epoch 00164 | Loss(train) 0.2680 | Acc(train) 0.9225 | Acc(val) 0.9372 |
Epoch 00165 | Loss(train) 0.2820 | Acc(train) 0.9118 | Acc(val) 0.9346 |
Epoch 00166 | Loss(train) 0.2865 | Acc(train) 0.9158 | Acc(val) 0.9386 |
Epoch 00167 | Loss(train) 0.2734 | Acc(train) 0.9158 | Acc(val) 0.9372 |
Epoch 00168 | Loss(train) 0.2870 | Acc(train) 0.9158 | Acc(val) 0.9372 |
Epoch 00169 | Loss(train) 0.2809 | Acc(train) 0.9152 | Acc(val) 0.9386 |
Epoch 00170 | Loss(train) 0.2712 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00171 | Loss(train) 0.2659 | Acc(train) 0.9245 | Acc(val) 0.9386 |
Epoch 00172 | Loss(train) 0.2756 | Acc(train) 0.9125 | Acc(val) 0.9399 |
Epoch 00173 | Loss(train) 0.2695 | Acc(train) 0.9158 | Acc(val) 0.9332 |
Epoch 00174 | Loss(train) 0.2847 | Acc(train) 0.9071 | Acc(val) 0.9372 |
Epoch 00175 | Loss(train) 0.2792 | Acc(train) 0.9092 | Acc(val) 0.9386 |
Epoch 00176 | Loss(train) 0.2700 | Acc(train) 0.9172 | Acc(val) 0.9399 |
Epoch 00177 | Loss(train) 0.2695 | Acc(train) 0.9252 | Acc(val) 0.9372 |
Epoch 00178 | Loss(train) 0.2704 | Acc(train) 0.9198 | Acc(val) 0.9386 |
Epoch 00179 | Loss(train) 0.2743 | Acc(train) 0.9158 | Acc(val) 0.9399 |
Epoch 00180 | Loss(train) 0.2848 | Acc(train) 0.9118 | Acc(val) 0.9372 |
Epoch 00181 | Loss(train) 0.2871 | Acc(train) 0.9259 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.2746 | Acc(train) 0.9158 | Acc(val) 0.9359 |
Epoch 00183 | Loss(train) 0.2775 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00184 | Loss(train) 0.2831 | Acc(train) 0.9051 | Acc(val) 0.9399 |
Epoch 00185 | Loss(train) 0.2551 | Acc(train) 0.9245 | Acc(val) 0.9386 |
Epoch 00186 | Loss(train) 0.2854 | Acc(train) 0.9158 | Acc(val) 0.9372 |
Epoch 00187 | Loss(train) 0.2788 | Acc(train) 0.9192 | Acc(val) 0.9346 |
Epoch 00188 | Loss(train) 0.2777 | Acc(train) 0.9118 | Acc(val) 0.9332 |
Epoch 00189 | Loss(train) 0.2758 | Acc(train) 0.9112 | Acc(val) 0.9372 |
Epoch 00190 | Loss(train) 0.2803 | Acc(train) 0.9138 | Acc(val) 0.9399 |
Epoch 00191 | Loss(train) 0.2727 | Acc(train) 0.9225 | Acc(val) 0.9386 |
Epoch 00192 | Loss(train) 0.2679 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00193 | Loss(train) 0.2747 | Acc(train) 0.9092 | Acc(val) 0.9346 |
Epoch 00194 | Loss(train) 0.2690 | Acc(train) 0.9158 | Acc(val) 0.9399 |
Epoch 00195 | Loss(train) 0.2837 | Acc(train) 0.9078 | Acc(val) 0.9386 |
Epoch 00196 | Loss(train) 0.2758 | Acc(train) 0.9172 | Acc(val) 0.9399 |
Epoch 00197 | Loss(train) 0.2784 | Acc(train) 0.9138 | Acc(val) 0.9332 |
Epoch 00198 | Loss(train) 0.2563 | Acc(train) 0.9299 | Acc(val) 0.9346 |
Epoch 00199 | Loss(train) 0.2552 | Acc(train) 0.9198 | Acc(val) 0.9386 |
Epoch 00200 | Loss(train) 0.2612 | Acc(train) 0.9238 | Acc(val) 0.9386 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3344 | Acc(train) 0.0828 | Acc(val) 0.2043 |*
Epoch 00002 | Loss(train) 2.8930 | Acc(train) 0.2244 | Acc(val) 0.2550 |*
Epoch 00003 | Loss(train) 3.2649 | Acc(train) 0.2872 | Acc(val) 0.1175 |
Epoch 00004 | Loss(train) 3.4642 | Acc(train) 0.1356 | Acc(val) 0.3952 |*
Epoch 00005 | Loss(train) 2.2561 | Acc(train) 0.2572 | Acc(val) 0.2457 |
Epoch 00006 | Loss(train) 2.3786 | Acc(train) 0.2425 | Acc(val) 0.5274 |*
Epoch 00007 | Loss(train) 1.9602 | Acc(train) 0.4068 | Acc(val) 0.2563 |
Epoch 00008 | Loss(train) 2.1814 | Acc(train) 0.3387 | Acc(val) 0.4166 |
Epoch 00009 | Loss(train) 1.8519 | Acc(train) 0.3948 | Acc(val) 0.6008 |*
Epoch 00010 | Loss(train) 1.6084 | Acc(train) 0.4916 | Acc(val) 0.6756 |*
Epoch 00011 | Loss(train) 1.5143 | Acc(train) 0.5184 | Acc(val) 0.6422 |
Epoch 00012 | Loss(train) 1.4169 | Acc(train) 0.5177 | Acc(val) 0.6756 |
Epoch 00013 | Loss(train) 1.3969 | Acc(train) 0.6219 | Acc(val) 0.6849 |*
Epoch 00014 | Loss(train) 1.4103 | Acc(train) 0.5798 | Acc(val) 0.7023 |*
Epoch 00015 | Loss(train) 1.3211 | Acc(train) 0.6633 | Acc(val) 0.6515 |
Epoch 00016 | Loss(train) 1.2432 | Acc(train) 0.6299 | Acc(val) 0.6662 |
Epoch 00017 | Loss(train) 1.2208 | Acc(train) 0.6339 | Acc(val) 0.6275 |
Epoch 00018 | Loss(train) 1.2404 | Acc(train) 0.5919 | Acc(val) 0.6582 |
Epoch 00019 | Loss(train) 1.1982 | Acc(train) 0.6119 | Acc(val) 0.7076 |*
Epoch 00020 | Loss(train) 1.1482 | Acc(train) 0.6433 | Acc(val) 0.7356 |*
Epoch 00021 | Loss(train) 1.0816 | Acc(train) 0.6820 | Acc(val) 0.7944 |*
Epoch 00022 | Loss(train) 1.0885 | Acc(train) 0.6633 | Acc(val) 0.8318 |*
Epoch 00023 | Loss(train) 1.0350 | Acc(train) 0.7014 | Acc(val) 0.8638 |*
Epoch 00024 | Loss(train) 1.0336 | Acc(train) 0.7134 | Acc(val) 0.8491 |
Epoch 00025 | Loss(train) 0.9732 | Acc(train) 0.7188 | Acc(val) 0.8358 |
Epoch 00026 | Loss(train) 0.9796 | Acc(train) 0.7021 | Acc(val) 0.8478 |
Epoch 00027 | Loss(train) 1.0012 | Acc(train) 0.6907 | Acc(val) 0.8491 |
Epoch 00028 | Loss(train) 0.8782 | Acc(train) 0.7261 | Acc(val) 0.8398 |
Epoch 00029 | Loss(train) 0.8571 | Acc(train) 0.7542 | Acc(val) 0.8411 |
Epoch 00030 | Loss(train) 0.8923 | Acc(train) 0.7288 | Acc(val) 0.8491 |
Epoch 00031 | Loss(train) 0.8222 | Acc(train) 0.7528 | Acc(val) 0.8438 |
Epoch 00032 | Loss(train) 0.7848 | Acc(train) 0.7715 | Acc(val) 0.8491 |
Epoch 00033 | Loss(train) 0.8188 | Acc(train) 0.7281 | Acc(val) 0.8785 |*
Epoch 00034 | Loss(train) 0.7940 | Acc(train) 0.7762 | Acc(val) 0.8879 |*
Epoch 00035 | Loss(train) 0.7139 | Acc(train) 0.8043 | Acc(val) 0.8785 |
Epoch 00036 | Loss(train) 0.7641 | Acc(train) 0.7943 | Acc(val) 0.8785 |
Epoch 00037 | Loss(train) 0.7522 | Acc(train) 0.7782 | Acc(val) 0.8678 |
Epoch 00038 | Loss(train) 0.7547 | Acc(train) 0.7749 | Acc(val) 0.8785 |
Epoch 00039 | Loss(train) 0.6968 | Acc(train) 0.8116 | Acc(val) 0.8879 |
Epoch 00040 | Loss(train) 0.6739 | Acc(train) 0.8196 | Acc(val) 0.9012 |*
Epoch 00041 | Loss(train) 0.6532 | Acc(train) 0.8263 | Acc(val) 0.9025 |*
Epoch 00042 | Loss(train) 0.6428 | Acc(train) 0.8103 | Acc(val) 0.8945 |
Epoch 00043 | Loss(train) 0.6361 | Acc(train) 0.8176 | Acc(val) 0.8852 |
Epoch 00044 | Loss(train) 0.6179 | Acc(train) 0.8277 | Acc(val) 0.8825 |
Epoch 00045 | Loss(train) 0.6184 | Acc(train) 0.8123 | Acc(val) 0.8905 |
Epoch 00046 | Loss(train) 0.5924 | Acc(train) 0.8330 | Acc(val) 0.8919 |
Epoch 00047 | Loss(train) 0.6184 | Acc(train) 0.8110 | Acc(val) 0.8985 |
Epoch 00048 | Loss(train) 0.5856 | Acc(train) 0.8236 | Acc(val) 0.9065 |*
Epoch 00049 | Loss(train) 0.5786 | Acc(train) 0.8397 | Acc(val) 0.9025 |
Epoch 00050 | Loss(train) 0.5600 | Acc(train) 0.8383 | Acc(val) 0.8985 |
Epoch 00051 | Loss(train) 0.5598 | Acc(train) 0.8370 | Acc(val) 0.8999 |
Epoch 00052 | Loss(train) 0.5385 | Acc(train) 0.8343 | Acc(val) 0.9012 |
Epoch 00053 | Loss(train) 0.5226 | Acc(train) 0.8490 | Acc(val) 0.9065 |
Epoch 00054 | Loss(train) 0.5176 | Acc(train) 0.8397 | Acc(val) 0.9159 |*
Epoch 00055 | Loss(train) 0.5076 | Acc(train) 0.8430 | Acc(val) 0.9159 |
Epoch 00056 | Loss(train) 0.5299 | Acc(train) 0.8403 | Acc(val) 0.9119 |
Epoch 00057 | Loss(train) 0.5123 | Acc(train) 0.8417 | Acc(val) 0.9092 |
Epoch 00058 | Loss(train) 0.5093 | Acc(train) 0.8410 | Acc(val) 0.9079 |
Epoch 00059 | Loss(train) 0.4957 | Acc(train) 0.8517 | Acc(val) 0.9079 |
Epoch 00060 | Loss(train) 0.4901 | Acc(train) 0.8417 | Acc(val) 0.9105 |
Epoch 00061 | Loss(train) 0.4929 | Acc(train) 0.8484 | Acc(val) 0.9105 |
Epoch 00062 | Loss(train) 0.4680 | Acc(train) 0.8644 | Acc(val) 0.9119 |
Epoch 00063 | Loss(train) 0.4711 | Acc(train) 0.8564 | Acc(val) 0.9119 |
Epoch 00064 | Loss(train) 0.4623 | Acc(train) 0.8591 | Acc(val) 0.9065 |
Epoch 00065 | Loss(train) 0.4609 | Acc(train) 0.8564 | Acc(val) 0.9132 |
Epoch 00066 | Loss(train) 0.4471 | Acc(train) 0.8671 | Acc(val) 0.9172 |*
Epoch 00067 | Loss(train) 0.4602 | Acc(train) 0.8557 | Acc(val) 0.9199 |*
Epoch 00068 | Loss(train) 0.4353 | Acc(train) 0.8778 | Acc(val) 0.9199 |
Epoch 00069 | Loss(train) 0.4351 | Acc(train) 0.8684 | Acc(val) 0.9186 |
Epoch 00070 | Loss(train) 0.4484 | Acc(train) 0.8637 | Acc(val) 0.9199 |
Epoch 00071 | Loss(train) 0.4274 | Acc(train) 0.8671 | Acc(val) 0.9172 |
Epoch 00072 | Loss(train) 0.4410 | Acc(train) 0.8544 | Acc(val) 0.9119 |
Epoch 00073 | Loss(train) 0.4295 | Acc(train) 0.8697 | Acc(val) 0.9146 |
Epoch 00074 | Loss(train) 0.4257 | Acc(train) 0.8864 | Acc(val) 0.9172 |
Epoch 00075 | Loss(train) 0.4053 | Acc(train) 0.8711 | Acc(val) 0.9212 |*
Epoch 00076 | Loss(train) 0.4238 | Acc(train) 0.8771 | Acc(val) 0.9212 |
Epoch 00077 | Loss(train) 0.4130 | Acc(train) 0.8804 | Acc(val) 0.9172 |
Epoch 00078 | Loss(train) 0.4040 | Acc(train) 0.8824 | Acc(val) 0.9199 |
Epoch 00079 | Loss(train) 0.4039 | Acc(train) 0.8704 | Acc(val) 0.9186 |
Epoch 00080 | Loss(train) 0.4181 | Acc(train) 0.8671 | Acc(val) 0.9239 |*
Epoch 00081 | Loss(train) 0.4192 | Acc(train) 0.8717 | Acc(val) 0.9239 |
Epoch 00082 | Loss(train) 0.4046 | Acc(train) 0.8804 | Acc(val) 0.9172 |
Epoch 00083 | Loss(train) 0.4077 | Acc(train) 0.8764 | Acc(val) 0.9226 |
Epoch 00084 | Loss(train) 0.3978 | Acc(train) 0.8764 | Acc(val) 0.9239 |
Epoch 00085 | Loss(train) 0.4034 | Acc(train) 0.8838 | Acc(val) 0.9239 |
Epoch 00086 | Loss(train) 0.3793 | Acc(train) 0.8804 | Acc(val) 0.9279 |*
Epoch 00087 | Loss(train) 0.3820 | Acc(train) 0.8844 | Acc(val) 0.9292 |*
Epoch 00088 | Loss(train) 0.3981 | Acc(train) 0.8858 | Acc(val) 0.9279 |
Epoch 00089 | Loss(train) 0.3829 | Acc(train) 0.8911 | Acc(val) 0.9279 |
Epoch 00090 | Loss(train) 0.3945 | Acc(train) 0.8804 | Acc(val) 0.9252 |
Epoch 00091 | Loss(train) 0.3663 | Acc(train) 0.8884 | Acc(val) 0.9226 |
Epoch 00092 | Loss(train) 0.3779 | Acc(train) 0.8871 | Acc(val) 0.9266 |
Epoch 00093 | Loss(train) 0.3819 | Acc(train) 0.8778 | Acc(val) 0.9226 |
Epoch 00094 | Loss(train) 0.3716 | Acc(train) 0.8858 | Acc(val) 0.9239 |
Epoch 00095 | Loss(train) 0.3696 | Acc(train) 0.8945 | Acc(val) 0.9279 |
Epoch 00096 | Loss(train) 0.3878 | Acc(train) 0.8844 | Acc(val) 0.9252 |
Epoch 00097 | Loss(train) 0.3508 | Acc(train) 0.8911 | Acc(val) 0.9266 |
Epoch 00098 | Loss(train) 0.3605 | Acc(train) 0.8904 | Acc(val) 0.9292 |
Epoch 00099 | Loss(train) 0.3689 | Acc(train) 0.8931 | Acc(val) 0.9319 |*
Epoch 00100 | Loss(train) 0.3839 | Acc(train) 0.8904 | Acc(val) 0.9292 |
Epoch 00101 | Loss(train) 0.3475 | Acc(train) 0.8938 | Acc(val) 0.9292 |
Epoch 00102 | Loss(train) 0.3510 | Acc(train) 0.9038 | Acc(val) 0.9279 |
Epoch 00103 | Loss(train) 0.3808 | Acc(train) 0.8831 | Acc(val) 0.9279 |
Epoch 00104 | Loss(train) 0.3638 | Acc(train) 0.8858 | Acc(val) 0.9279 |
Epoch 00105 | Loss(train) 0.3531 | Acc(train) 0.8925 | Acc(val) 0.9279 |
Epoch 00106 | Loss(train) 0.3794 | Acc(train) 0.8844 | Acc(val) 0.9252 |
Epoch 00107 | Loss(train) 0.3422 | Acc(train) 0.9031 | Acc(val) 0.9252 |
Epoch 00108 | Loss(train) 0.3635 | Acc(train) 0.8891 | Acc(val) 0.9266 |
Epoch 00109 | Loss(train) 0.3405 | Acc(train) 0.8945 | Acc(val) 0.9279 |
Epoch 00110 | Loss(train) 0.3694 | Acc(train) 0.8878 | Acc(val) 0.9306 |
Epoch 00111 | Loss(train) 0.3501 | Acc(train) 0.8931 | Acc(val) 0.9292 |
Epoch 00112 | Loss(train) 0.3477 | Acc(train) 0.8985 | Acc(val) 0.9279 |
Epoch 00113 | Loss(train) 0.3459 | Acc(train) 0.8938 | Acc(val) 0.9292 |
Epoch 00114 | Loss(train) 0.3435 | Acc(train) 0.8998 | Acc(val) 0.9306 |
Epoch 00115 | Loss(train) 0.3173 | Acc(train) 0.9018 | Acc(val) 0.9319 |
Epoch 00116 | Loss(train) 0.3335 | Acc(train) 0.9071 | Acc(val) 0.9306 |
Epoch 00117 | Loss(train) 0.3397 | Acc(train) 0.8991 | Acc(val) 0.9292 |
Epoch 00118 | Loss(train) 0.3594 | Acc(train) 0.8911 | Acc(val) 0.9306 |
Epoch 00119 | Loss(train) 0.3507 | Acc(train) 0.8945 | Acc(val) 0.9319 |
Epoch 00120 | Loss(train) 0.3276 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00121 | Loss(train) 0.3615 | Acc(train) 0.8884 | Acc(val) 0.9306 |
Epoch 00122 | Loss(train) 0.3516 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00123 | Loss(train) 0.3332 | Acc(train) 0.8898 | Acc(val) 0.9292 |
Epoch 00124 | Loss(train) 0.3453 | Acc(train) 0.8938 | Acc(val) 0.9292 |
Epoch 00125 | Loss(train) 0.3391 | Acc(train) 0.9018 | Acc(val) 0.9319 |
Epoch 00126 | Loss(train) 0.3636 | Acc(train) 0.8824 | Acc(val) 0.9306 |
Epoch 00127 | Loss(train) 0.3199 | Acc(train) 0.9018 | Acc(val) 0.9359 |*
Epoch 00128 | Loss(train) 0.3423 | Acc(train) 0.8971 | Acc(val) 0.9332 |
Epoch 00129 | Loss(train) 0.3380 | Acc(train) 0.8971 | Acc(val) 0.9319 |
Epoch 00130 | Loss(train) 0.3549 | Acc(train) 0.8951 | Acc(val) 0.9292 |
Epoch 00131 | Loss(train) 0.3374 | Acc(train) 0.8931 | Acc(val) 0.9279 |
Epoch 00132 | Loss(train) 0.3516 | Acc(train) 0.8971 | Acc(val) 0.9279 |
Epoch 00133 | Loss(train) 0.3519 | Acc(train) 0.9045 | Acc(val) 0.9292 |
Epoch 00134 | Loss(train) 0.3173 | Acc(train) 0.9105 | Acc(val) 0.9332 |
Epoch 00135 | Loss(train) 0.3379 | Acc(train) 0.9011 | Acc(val) 0.9346 |
Epoch 00136 | Loss(train) 0.3412 | Acc(train) 0.8945 | Acc(val) 0.9319 |
Epoch 00137 | Loss(train) 0.3134 | Acc(train) 0.9118 | Acc(val) 0.9319 |
Epoch 00138 | Loss(train) 0.3219 | Acc(train) 0.9045 | Acc(val) 0.9306 |
Epoch 00139 | Loss(train) 0.3308 | Acc(train) 0.8958 | Acc(val) 0.9319 |
Epoch 00140 | Loss(train) 0.3108 | Acc(train) 0.9071 | Acc(val) 0.9359 |
Epoch 00141 | Loss(train) 0.3229 | Acc(train) 0.8998 | Acc(val) 0.9359 |
Epoch 00142 | Loss(train) 0.3295 | Acc(train) 0.9005 | Acc(val) 0.9332 |
Epoch 00143 | Loss(train) 0.3176 | Acc(train) 0.8951 | Acc(val) 0.9306 |
Epoch 00144 | Loss(train) 0.3183 | Acc(train) 0.8978 | Acc(val) 0.9306 |
Epoch 00145 | Loss(train) 0.3256 | Acc(train) 0.9065 | Acc(val) 0.9332 |
Epoch 00146 | Loss(train) 0.3304 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00147 | Loss(train) 0.3213 | Acc(train) 0.9078 | Acc(val) 0.9346 |
Epoch 00148 | Loss(train) 0.3035 | Acc(train) 0.9145 | Acc(val) 0.9372 |*
Epoch 00149 | Loss(train) 0.3007 | Acc(train) 0.9118 | Acc(val) 0.9319 |
Epoch 00150 | Loss(train) 0.3114 | Acc(train) 0.9158 | Acc(val) 0.9319 |
Epoch 00151 | Loss(train) 0.2997 | Acc(train) 0.9065 | Acc(val) 0.9279 |
Epoch 00152 | Loss(train) 0.3316 | Acc(train) 0.9025 | Acc(val) 0.9292 |
Epoch 00153 | Loss(train) 0.3047 | Acc(train) 0.9011 | Acc(val) 0.9346 |
Epoch 00154 | Loss(train) 0.3205 | Acc(train) 0.9025 | Acc(val) 0.9372 |
Epoch 00155 | Loss(train) 0.3223 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00156 | Loss(train) 0.3006 | Acc(train) 0.9158 | Acc(val) 0.9359 |
Epoch 00157 | Loss(train) 0.3134 | Acc(train) 0.9045 | Acc(val) 0.9346 |
Epoch 00158 | Loss(train) 0.3013 | Acc(train) 0.9125 | Acc(val) 0.9306 |
Epoch 00159 | Loss(train) 0.3155 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Epoch 00160 | Loss(train) 0.3448 | Acc(train) 0.8998 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.3234 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00162 | Loss(train) 0.3222 | Acc(train) 0.9025 | Acc(val) 0.9346 |
Epoch 00163 | Loss(train) 0.2959 | Acc(train) 0.9078 | Acc(val) 0.9359 |
Epoch 00164 | Loss(train) 0.3131 | Acc(train) 0.9031 | Acc(val) 0.9346 |
Epoch 00165 | Loss(train) 0.3216 | Acc(train) 0.9045 | Acc(val) 0.9346 |
Epoch 00166 | Loss(train) 0.3105 | Acc(train) 0.9045 | Acc(val) 0.9332 |
Epoch 00167 | Loss(train) 0.3080 | Acc(train) 0.9098 | Acc(val) 0.9346 |
Epoch 00168 | Loss(train) 0.2982 | Acc(train) 0.9145 | Acc(val) 0.9359 |
Epoch 00169 | Loss(train) 0.3032 | Acc(train) 0.9078 | Acc(val) 0.9332 |
Epoch 00170 | Loss(train) 0.3159 | Acc(train) 0.9058 | Acc(val) 0.9346 |
Epoch 00171 | Loss(train) 0.3149 | Acc(train) 0.9011 | Acc(val) 0.9359 |
Epoch 00172 | Loss(train) 0.2985 | Acc(train) 0.9125 | Acc(val) 0.9372 |
Epoch 00173 | Loss(train) 0.3140 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00174 | Loss(train) 0.3181 | Acc(train) 0.9065 | Acc(val) 0.9346 |
Epoch 00175 | Loss(train) 0.3022 | Acc(train) 0.9125 | Acc(val) 0.9386 |*
Epoch 00176 | Loss(train) 0.3101 | Acc(train) 0.9132 | Acc(val) 0.9359 |
Epoch 00177 | Loss(train) 0.3055 | Acc(train) 0.9092 | Acc(val) 0.9359 |
Epoch 00178 | Loss(train) 0.3014 | Acc(train) 0.9051 | Acc(val) 0.9346 |
Epoch 00179 | Loss(train) 0.2971 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00180 | Loss(train) 0.3069 | Acc(train) 0.9071 | Acc(val) 0.9306 |
Epoch 00181 | Loss(train) 0.2971 | Acc(train) 0.9152 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.3315 | Acc(train) 0.9092 | Acc(val) 0.9386 |
Epoch 00183 | Loss(train) 0.2973 | Acc(train) 0.9145 | Acc(val) 0.9372 |
Epoch 00184 | Loss(train) 0.2946 | Acc(train) 0.9145 | Acc(val) 0.9399 |*
Epoch 00185 | Loss(train) 0.3064 | Acc(train) 0.9138 | Acc(val) 0.9359 |
Epoch 00186 | Loss(train) 0.3079 | Acc(train) 0.9092 | Acc(val) 0.9332 |
Epoch 00187 | Loss(train) 0.3005 | Acc(train) 0.9145 | Acc(val) 0.9292 |
Epoch 00188 | Loss(train) 0.2773 | Acc(train) 0.9125 | Acc(val) 0.9372 |
Epoch 00189 | Loss(train) 0.3149 | Acc(train) 0.9005 | Acc(val) 0.9346 |
Epoch 00190 | Loss(train) 0.3006 | Acc(train) 0.9158 | Acc(val) 0.9372 |
Epoch 00191 | Loss(train) 0.3177 | Acc(train) 0.9085 | Acc(val) 0.9359 |
Epoch 00192 | Loss(train) 0.2976 | Acc(train) 0.9085 | Acc(val) 0.9359 |
Epoch 00193 | Loss(train) 0.3036 | Acc(train) 0.9071 | Acc(val) 0.9319 |
Epoch 00194 | Loss(train) 0.3207 | Acc(train) 0.8978 | Acc(val) 0.9332 |
Epoch 00195 | Loss(train) 0.3224 | Acc(train) 0.8951 | Acc(val) 0.9386 |
Epoch 00196 | Loss(train) 0.2862 | Acc(train) 0.9178 | Acc(val) 0.9372 |
Epoch 00197 | Loss(train) 0.3014 | Acc(train) 0.9132 | Acc(val) 0.9372 |
Epoch 00198 | Loss(train) 0.2902 | Acc(train) 0.9198 | Acc(val) 0.9372 |
Epoch 00199 | Loss(train) 0.2955 | Acc(train) 0.9105 | Acc(val) 0.9372 |
Epoch 00200 | Loss(train) 0.2925 | Acc(train) 0.9098 | Acc(val) 0.9346 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.0966 | Acc(train) 0.1363 | Acc(val) 0.2550 |*
Epoch 00002 | Loss(train) 4.3009 | Acc(train) 0.3173 | Acc(val) 0.1989 |
Epoch 00003 | Loss(train) 3.4946 | Acc(train) 0.1810 | Acc(val) 0.1121 |
Epoch 00004 | Loss(train) 4.7509 | Acc(train) 0.1256 | Acc(val) 0.1883 |
Epoch 00005 | Loss(train) 2.9058 | Acc(train) 0.1797 | Acc(val) 0.1001 |
Epoch 00006 | Loss(train) 2.6727 | Acc(train) 0.1470 | Acc(val) 0.4726 |*
Epoch 00007 | Loss(train) 2.0221 | Acc(train) 0.3400 | Acc(val) 0.2590 |
Epoch 00008 | Loss(train) 2.1688 | Acc(train) 0.3547 | Acc(val) 0.2563 |
Epoch 00009 | Loss(train) 2.3301 | Acc(train) 0.3059 | Acc(val) 0.2630 |
Epoch 00010 | Loss(train) 2.0937 | Acc(train) 0.3908 | Acc(val) 0.4793 |*
Epoch 00011 | Loss(train) 1.8377 | Acc(train) 0.4509 | Acc(val) 0.4833 |*
Epoch 00012 | Loss(train) 1.7086 | Acc(train) 0.4449 | Acc(val) 0.4713 |
Epoch 00013 | Loss(train) 1.7324 | Acc(train) 0.3434 | Acc(val) 0.3338 |
Epoch 00014 | Loss(train) 1.7321 | Acc(train) 0.3106 | Acc(val) 0.3057 |
Epoch 00015 | Loss(train) 1.7173 | Acc(train) 0.3006 | Acc(val) 0.4593 |
Epoch 00016 | Loss(train) 1.6326 | Acc(train) 0.3360 | Acc(val) 0.5514 |*
Epoch 00017 | Loss(train) 1.5199 | Acc(train) 0.4957 | Acc(val) 0.5634 |*
Epoch 00018 | Loss(train) 1.4476 | Acc(train) 0.5585 | Acc(val) 0.5527 |
Epoch 00019 | Loss(train) 1.4496 | Acc(train) 0.5190 | Acc(val) 0.5367 |
Epoch 00020 | Loss(train) 1.3801 | Acc(train) 0.5391 | Acc(val) 0.5220 |
Epoch 00021 | Loss(train) 1.4509 | Acc(train) 0.4656 | Acc(val) 0.5340 |
Epoch 00022 | Loss(train) 1.3829 | Acc(train) 0.5063 | Acc(val) 0.5794 |*
Epoch 00023 | Loss(train) 1.3279 | Acc(train) 0.5397 | Acc(val) 0.6248 |*
Epoch 00024 | Loss(train) 1.2826 | Acc(train) 0.6005 | Acc(val) 0.6769 |*
Epoch 00025 | Loss(train) 1.2997 | Acc(train) 0.5965 | Acc(val) 0.7276 |*
Epoch 00026 | Loss(train) 1.2859 | Acc(train) 0.6426 | Acc(val) 0.7637 |*
Epoch 00027 | Loss(train) 1.2412 | Acc(train) 0.6486 | Acc(val) 0.7570 |
Epoch 00028 | Loss(train) 1.2211 | Acc(train) 0.6640 | Acc(val) 0.7717 |*
Epoch 00029 | Loss(train) 1.1530 | Acc(train) 0.6887 | Acc(val) 0.7757 |*
Epoch 00030 | Loss(train) 1.1367 | Acc(train) 0.6807 | Acc(val) 0.7477 |
Epoch 00031 | Loss(train) 1.0670 | Acc(train) 0.6814 | Acc(val) 0.7463 |
Epoch 00032 | Loss(train) 1.0816 | Acc(train) 0.6760 | Acc(val) 0.7891 |*
Epoch 00033 | Loss(train) 1.0607 | Acc(train) 0.7021 | Acc(val) 0.8077 |*
Epoch 00034 | Loss(train) 0.9971 | Acc(train) 0.7021 | Acc(val) 0.8104 |*
Epoch 00035 | Loss(train) 1.0487 | Acc(train) 0.6894 | Acc(val) 0.8331 |*
Epoch 00036 | Loss(train) 0.9611 | Acc(train) 0.7295 | Acc(val) 0.8331 |
Epoch 00037 | Loss(train) 0.9481 | Acc(train) 0.7341 | Acc(val) 0.8331 |
Epoch 00038 | Loss(train) 0.9123 | Acc(train) 0.7595 | Acc(val) 0.8198 |
Epoch 00039 | Loss(train) 0.9248 | Acc(train) 0.7341 | Acc(val) 0.8224 |
Epoch 00040 | Loss(train) 0.8702 | Acc(train) 0.7568 | Acc(val) 0.8278 |
Epoch 00041 | Loss(train) 0.8424 | Acc(train) 0.7642 | Acc(val) 0.8451 |*
Epoch 00042 | Loss(train) 0.8246 | Acc(train) 0.7635 | Acc(val) 0.8518 |*
Epoch 00043 | Loss(train) 0.8044 | Acc(train) 0.7822 | Acc(val) 0.8585 |*
Epoch 00044 | Loss(train) 0.8201 | Acc(train) 0.7662 | Acc(val) 0.8678 |*
Epoch 00045 | Loss(train) 0.8077 | Acc(train) 0.7729 | Acc(val) 0.8692 |*
Epoch 00046 | Loss(train) 0.7472 | Acc(train) 0.8063 | Acc(val) 0.8758 |*
Epoch 00047 | Loss(train) 0.7369 | Acc(train) 0.7983 | Acc(val) 0.8879 |*
Epoch 00048 | Loss(train) 0.7315 | Acc(train) 0.7976 | Acc(val) 0.8852 |
Epoch 00049 | Loss(train) 0.6979 | Acc(train) 0.8043 | Acc(val) 0.8879 |
Epoch 00050 | Loss(train) 0.6943 | Acc(train) 0.8069 | Acc(val) 0.8905 |*
Epoch 00051 | Loss(train) 0.7069 | Acc(train) 0.7949 | Acc(val) 0.8945 |*
Epoch 00052 | Loss(train) 0.6826 | Acc(train) 0.8076 | Acc(val) 0.9039 |*
Epoch 00053 | Loss(train) 0.6663 | Acc(train) 0.8110 | Acc(val) 0.8959 |
Epoch 00054 | Loss(train) 0.6303 | Acc(train) 0.8263 | Acc(val) 0.8932 |
Epoch 00055 | Loss(train) 0.6128 | Acc(train) 0.8317 | Acc(val) 0.8919 |
Epoch 00056 | Loss(train) 0.6247 | Acc(train) 0.8236 | Acc(val) 0.8985 |
Epoch 00057 | Loss(train) 0.6292 | Acc(train) 0.8110 | Acc(val) 0.9012 |
Epoch 00058 | Loss(train) 0.6203 | Acc(train) 0.8250 | Acc(val) 0.9025 |
Epoch 00059 | Loss(train) 0.5915 | Acc(train) 0.8363 | Acc(val) 0.8999 |
Epoch 00060 | Loss(train) 0.5780 | Acc(train) 0.8350 | Acc(val) 0.9012 |
Epoch 00061 | Loss(train) 0.5704 | Acc(train) 0.8337 | Acc(val) 0.9025 |
Epoch 00062 | Loss(train) 0.5427 | Acc(train) 0.8437 | Acc(val) 0.9025 |
Epoch 00063 | Loss(train) 0.5899 | Acc(train) 0.8230 | Acc(val) 0.9065 |*
Epoch 00064 | Loss(train) 0.5641 | Acc(train) 0.8397 | Acc(val) 0.9039 |
Epoch 00065 | Loss(train) 0.5252 | Acc(train) 0.8510 | Acc(val) 0.9079 |*
Epoch 00066 | Loss(train) 0.5360 | Acc(train) 0.8383 | Acc(val) 0.9092 |*
Epoch 00067 | Loss(train) 0.5452 | Acc(train) 0.8377 | Acc(val) 0.9105 |*
Epoch 00068 | Loss(train) 0.5411 | Acc(train) 0.8403 | Acc(val) 0.9092 |
Epoch 00069 | Loss(train) 0.5186 | Acc(train) 0.8504 | Acc(val) 0.9065 |
Epoch 00070 | Loss(train) 0.5209 | Acc(train) 0.8323 | Acc(val) 0.9039 |
Epoch 00071 | Loss(train) 0.5078 | Acc(train) 0.8490 | Acc(val) 0.9039 |
Epoch 00072 | Loss(train) 0.5126 | Acc(train) 0.8577 | Acc(val) 0.9052 |
Epoch 00073 | Loss(train) 0.4929 | Acc(train) 0.8490 | Acc(val) 0.9065 |
Epoch 00074 | Loss(train) 0.4832 | Acc(train) 0.8550 | Acc(val) 0.9105 |
Epoch 00075 | Loss(train) 0.5027 | Acc(train) 0.8497 | Acc(val) 0.9132 |*
Epoch 00076 | Loss(train) 0.4912 | Acc(train) 0.8437 | Acc(val) 0.9172 |*
Epoch 00077 | Loss(train) 0.4937 | Acc(train) 0.8544 | Acc(val) 0.9199 |*
Epoch 00078 | Loss(train) 0.4557 | Acc(train) 0.8651 | Acc(val) 0.9119 |
Epoch 00079 | Loss(train) 0.4742 | Acc(train) 0.8557 | Acc(val) 0.9105 |
Epoch 00080 | Loss(train) 0.4675 | Acc(train) 0.8524 | Acc(val) 0.9105 |
Epoch 00081 | Loss(train) 0.4425 | Acc(train) 0.8604 | Acc(val) 0.9052 |
Epoch 00082 | Loss(train) 0.4761 | Acc(train) 0.8504 | Acc(val) 0.9039 |
Epoch 00083 | Loss(train) 0.4799 | Acc(train) 0.8504 | Acc(val) 0.9119 |
Epoch 00084 | Loss(train) 0.4443 | Acc(train) 0.8550 | Acc(val) 0.9186 |
Epoch 00085 | Loss(train) 0.4519 | Acc(train) 0.8651 | Acc(val) 0.9226 |*
Epoch 00086 | Loss(train) 0.4845 | Acc(train) 0.8524 | Acc(val) 0.9212 |
Epoch 00087 | Loss(train) 0.4669 | Acc(train) 0.8564 | Acc(val) 0.9212 |
Epoch 00088 | Loss(train) 0.4682 | Acc(train) 0.8604 | Acc(val) 0.9186 |
Epoch 00089 | Loss(train) 0.4497 | Acc(train) 0.8577 | Acc(val) 0.9199 |
Epoch 00090 | Loss(train) 0.4369 | Acc(train) 0.8611 | Acc(val) 0.9212 |
Epoch 00091 | Loss(train) 0.4554 | Acc(train) 0.8564 | Acc(val) 0.9146 |
Epoch 00092 | Loss(train) 0.4336 | Acc(train) 0.8651 | Acc(val) 0.9159 |
Epoch 00093 | Loss(train) 0.4562 | Acc(train) 0.8550 | Acc(val) 0.9146 |
Epoch 00094 | Loss(train) 0.4379 | Acc(train) 0.8651 | Acc(val) 0.9132 |
Epoch 00095 | Loss(train) 0.4217 | Acc(train) 0.8657 | Acc(val) 0.9146 |
Epoch 00096 | Loss(train) 0.4338 | Acc(train) 0.8577 | Acc(val) 0.9146 |
Epoch 00097 | Loss(train) 0.4303 | Acc(train) 0.8617 | Acc(val) 0.9199 |
Epoch 00098 | Loss(train) 0.4150 | Acc(train) 0.8737 | Acc(val) 0.9212 |
Epoch 00099 | Loss(train) 0.4092 | Acc(train) 0.8717 | Acc(val) 0.9186 |
Epoch 00100 | Loss(train) 0.4100 | Acc(train) 0.8664 | Acc(val) 0.9172 |
Epoch 00101 | Loss(train) 0.4190 | Acc(train) 0.8684 | Acc(val) 0.9252 |*
Epoch 00102 | Loss(train) 0.4263 | Acc(train) 0.8691 | Acc(val) 0.9252 |
Epoch 00103 | Loss(train) 0.4058 | Acc(train) 0.8711 | Acc(val) 0.9239 |
Epoch 00104 | Loss(train) 0.4314 | Acc(train) 0.8684 | Acc(val) 0.9212 |
Epoch 00105 | Loss(train) 0.4072 | Acc(train) 0.8691 | Acc(val) 0.9239 |
Epoch 00106 | Loss(train) 0.4175 | Acc(train) 0.8684 | Acc(val) 0.9226 |
Epoch 00107 | Loss(train) 0.3884 | Acc(train) 0.8771 | Acc(val) 0.9252 |
Epoch 00108 | Loss(train) 0.3768 | Acc(train) 0.8851 | Acc(val) 0.9266 |*
Epoch 00109 | Loss(train) 0.3887 | Acc(train) 0.8791 | Acc(val) 0.9199 |
Epoch 00110 | Loss(train) 0.4202 | Acc(train) 0.8657 | Acc(val) 0.9199 |
Epoch 00111 | Loss(train) 0.3963 | Acc(train) 0.8744 | Acc(val) 0.9212 |
Epoch 00112 | Loss(train) 0.3849 | Acc(train) 0.8804 | Acc(val) 0.9199 |
Epoch 00113 | Loss(train) 0.3882 | Acc(train) 0.8758 | Acc(val) 0.9199 |
Epoch 00114 | Loss(train) 0.3879 | Acc(train) 0.8818 | Acc(val) 0.9199 |
Epoch 00115 | Loss(train) 0.3908 | Acc(train) 0.8724 | Acc(val) 0.9266 |
Epoch 00116 | Loss(train) 0.3809 | Acc(train) 0.8764 | Acc(val) 0.9266 |
Epoch 00117 | Loss(train) 0.3951 | Acc(train) 0.8791 | Acc(val) 0.9279 |*
Epoch 00118 | Loss(train) 0.3850 | Acc(train) 0.8758 | Acc(val) 0.9266 |
Epoch 00119 | Loss(train) 0.3737 | Acc(train) 0.8878 | Acc(val) 0.9266 |
Epoch 00120 | Loss(train) 0.3926 | Acc(train) 0.8831 | Acc(val) 0.9252 |
Epoch 00121 | Loss(train) 0.3679 | Acc(train) 0.8804 | Acc(val) 0.9252 |
Epoch 00122 | Loss(train) 0.3688 | Acc(train) 0.8864 | Acc(val) 0.9199 |
Epoch 00123 | Loss(train) 0.3714 | Acc(train) 0.8904 | Acc(val) 0.9239 |
Epoch 00124 | Loss(train) 0.3939 | Acc(train) 0.8818 | Acc(val) 0.9279 |
Epoch 00125 | Loss(train) 0.3612 | Acc(train) 0.8898 | Acc(val) 0.9306 |*
Epoch 00126 | Loss(train) 0.3805 | Acc(train) 0.8838 | Acc(val) 0.9279 |
Epoch 00127 | Loss(train) 0.3907 | Acc(train) 0.8758 | Acc(val) 0.9279 |
Epoch 00128 | Loss(train) 0.3774 | Acc(train) 0.8884 | Acc(val) 0.9279 |
Epoch 00129 | Loss(train) 0.3861 | Acc(train) 0.8804 | Acc(val) 0.9239 |
Epoch 00130 | Loss(train) 0.3661 | Acc(train) 0.8844 | Acc(val) 0.9239 |
Epoch 00131 | Loss(train) 0.3577 | Acc(train) 0.8965 | Acc(val) 0.9266 |
Epoch 00132 | Loss(train) 0.3733 | Acc(train) 0.8864 | Acc(val) 0.9266 |
Epoch 00133 | Loss(train) 0.3566 | Acc(train) 0.8884 | Acc(val) 0.9266 |
Epoch 00134 | Loss(train) 0.3582 | Acc(train) 0.8811 | Acc(val) 0.9266 |
Epoch 00135 | Loss(train) 0.3771 | Acc(train) 0.8758 | Acc(val) 0.9279 |
Epoch 00136 | Loss(train) 0.3501 | Acc(train) 0.8844 | Acc(val) 0.9279 |
Epoch 00137 | Loss(train) 0.3768 | Acc(train) 0.8851 | Acc(val) 0.9279 |
Epoch 00138 | Loss(train) 0.3561 | Acc(train) 0.8838 | Acc(val) 0.9292 |
Epoch 00139 | Loss(train) 0.3661 | Acc(train) 0.8784 | Acc(val) 0.9279 |
Epoch 00140 | Loss(train) 0.3569 | Acc(train) 0.8898 | Acc(val) 0.9266 |
Epoch 00141 | Loss(train) 0.3513 | Acc(train) 0.8965 | Acc(val) 0.9306 |
Epoch 00142 | Loss(train) 0.3671 | Acc(train) 0.8851 | Acc(val) 0.9319 |*
Epoch 00143 | Loss(train) 0.3395 | Acc(train) 0.9025 | Acc(val) 0.9319 |
Epoch 00144 | Loss(train) 0.3553 | Acc(train) 0.8951 | Acc(val) 0.9319 |
Epoch 00145 | Loss(train) 0.3701 | Acc(train) 0.8818 | Acc(val) 0.9279 |
Epoch 00146 | Loss(train) 0.3685 | Acc(train) 0.8737 | Acc(val) 0.9266 |
Epoch 00147 | Loss(train) 0.3373 | Acc(train) 0.8945 | Acc(val) 0.9239 |
Epoch 00148 | Loss(train) 0.3510 | Acc(train) 0.8904 | Acc(val) 0.9252 |
Epoch 00149 | Loss(train) 0.3549 | Acc(train) 0.8844 | Acc(val) 0.9319 |
Epoch 00150 | Loss(train) 0.3712 | Acc(train) 0.8811 | Acc(val) 0.9332 |*
Epoch 00151 | Loss(train) 0.3727 | Acc(train) 0.8851 | Acc(val) 0.9306 |
Epoch 00152 | Loss(train) 0.3364 | Acc(train) 0.9031 | Acc(val) 0.9306 |
Epoch 00153 | Loss(train) 0.3610 | Acc(train) 0.8878 | Acc(val) 0.9292 |
Epoch 00154 | Loss(train) 0.3600 | Acc(train) 0.8798 | Acc(val) 0.9279 |
Epoch 00155 | Loss(train) 0.3539 | Acc(train) 0.8878 | Acc(val) 0.9346 |*
Epoch 00156 | Loss(train) 0.3260 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00157 | Loss(train) 0.3485 | Acc(train) 0.8925 | Acc(val) 0.9306 |
Epoch 00158 | Loss(train) 0.3334 | Acc(train) 0.8918 | Acc(val) 0.9252 |
Epoch 00159 | Loss(train) 0.3497 | Acc(train) 0.8871 | Acc(val) 0.9239 |
Epoch 00160 | Loss(train) 0.3774 | Acc(train) 0.8791 | Acc(val) 0.9319 |
Epoch 00161 | Loss(train) 0.3433 | Acc(train) 0.8911 | Acc(val) 0.9319 |
Epoch 00162 | Loss(train) 0.3442 | Acc(train) 0.8938 | Acc(val) 0.9332 |
Epoch 00163 | Loss(train) 0.3712 | Acc(train) 0.8851 | Acc(val) 0.9306 |
Epoch 00164 | Loss(train) 0.3518 | Acc(train) 0.8945 | Acc(val) 0.9266 |
Epoch 00165 | Loss(train) 0.3419 | Acc(train) 0.8965 | Acc(val) 0.9279 |
Epoch 00166 | Loss(train) 0.3483 | Acc(train) 0.8898 | Acc(val) 0.9252 |
Epoch 00167 | Loss(train) 0.3591 | Acc(train) 0.8898 | Acc(val) 0.9252 |
Epoch 00168 | Loss(train) 0.3290 | Acc(train) 0.8945 | Acc(val) 0.9332 |
Epoch 00169 | Loss(train) 0.3595 | Acc(train) 0.8898 | Acc(val) 0.9332 |
Epoch 00170 | Loss(train) 0.3531 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00171 | Loss(train) 0.3487 | Acc(train) 0.8931 | Acc(val) 0.9306 |
Epoch 00172 | Loss(train) 0.3353 | Acc(train) 0.8938 | Acc(val) 0.9306 |
Epoch 00173 | Loss(train) 0.3450 | Acc(train) 0.8871 | Acc(val) 0.9306 |
Epoch 00174 | Loss(train) 0.3434 | Acc(train) 0.8925 | Acc(val) 0.9306 |
Epoch 00175 | Loss(train) 0.3310 | Acc(train) 0.8931 | Acc(val) 0.9386 |*
Epoch 00176 | Loss(train) 0.3547 | Acc(train) 0.8871 | Acc(val) 0.9306 |
Epoch 00177 | Loss(train) 0.3523 | Acc(train) 0.8925 | Acc(val) 0.9266 |
Epoch 00178 | Loss(train) 0.3470 | Acc(train) 0.8978 | Acc(val) 0.9292 |
Epoch 00179 | Loss(train) 0.3190 | Acc(train) 0.9058 | Acc(val) 0.9306 |
Epoch 00180 | Loss(train) 0.3313 | Acc(train) 0.8965 | Acc(val) 0.9346 |
Epoch 00181 | Loss(train) 0.3157 | Acc(train) 0.8985 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.3123 | Acc(train) 0.9045 | Acc(val) 0.9372 |
Epoch 00183 | Loss(train) 0.3204 | Acc(train) 0.8965 | Acc(val) 0.9279 |
Epoch 00184 | Loss(train) 0.3200 | Acc(train) 0.8911 | Acc(val) 0.9292 |
Epoch 00185 | Loss(train) 0.3431 | Acc(train) 0.8891 | Acc(val) 0.9319 |
Epoch 00186 | Loss(train) 0.3562 | Acc(train) 0.8878 | Acc(val) 0.9266 |
Epoch 00187 | Loss(train) 0.3130 | Acc(train) 0.8965 | Acc(val) 0.9319 |
Epoch 00188 | Loss(train) 0.3274 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00189 | Loss(train) 0.3218 | Acc(train) 0.9092 | Acc(val) 0.9399 |*
Epoch 00190 | Loss(train) 0.3263 | Acc(train) 0.8978 | Acc(val) 0.9359 |
Epoch 00191 | Loss(train) 0.3199 | Acc(train) 0.9018 | Acc(val) 0.9332 |
Epoch 00192 | Loss(train) 0.3112 | Acc(train) 0.8965 | Acc(val) 0.9292 |
Epoch 00193 | Loss(train) 0.3135 | Acc(train) 0.8998 | Acc(val) 0.9306 |
Epoch 00194 | Loss(train) 0.3383 | Acc(train) 0.8878 | Acc(val) 0.9359 |
Epoch 00195 | Loss(train) 0.3355 | Acc(train) 0.8938 | Acc(val) 0.9372 |
Epoch 00196 | Loss(train) 0.3194 | Acc(train) 0.9051 | Acc(val) 0.9372 |
Epoch 00197 | Loss(train) 0.3209 | Acc(train) 0.9005 | Acc(val) 0.9332 |
Epoch 00198 | Loss(train) 0.3228 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00199 | Loss(train) 0.3077 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00200 | Loss(train) 0.3160 | Acc(train) 0.9031 | Acc(val) 0.9346 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.1718 | Acc(train) 0.2485 | Acc(val) 0.1989 |*
Epoch 00002 | Loss(train) 2.8766 | Acc(train) 0.2011 | Acc(val) 0.2563 |*
Epoch 00003 | Loss(train) 2.4372 | Acc(train) 0.1550 | Acc(val) 0.2550 |
Epoch 00004 | Loss(train) 3.3928 | Acc(train) 0.2786 | Acc(val) 0.3004 |*
Epoch 00005 | Loss(train) 2.0447 | Acc(train) 0.3373 | Acc(val) 0.2430 |
Epoch 00006 | Loss(train) 1.8995 | Acc(train) 0.2933 | Acc(val) 0.2537 |
Epoch 00007 | Loss(train) 1.8054 | Acc(train) 0.2826 | Acc(val) 0.7116 |*
Epoch 00008 | Loss(train) 1.7915 | Acc(train) 0.3534 | Acc(val) 0.6422 |
Epoch 00009 | Loss(train) 1.7822 | Acc(train) 0.3821 | Acc(val) 0.4059 |
Epoch 00010 | Loss(train) 1.6731 | Acc(train) 0.4108 | Acc(val) 0.5167 |
Epoch 00011 | Loss(train) 1.6078 | Acc(train) 0.4609 | Acc(val) 0.5381 |
Epoch 00012 | Loss(train) 1.5551 | Acc(train) 0.4322 | Acc(val) 0.4913 |
Epoch 00013 | Loss(train) 1.4816 | Acc(train) 0.5050 | Acc(val) 0.5421 |
Epoch 00014 | Loss(train) 1.3923 | Acc(train) 0.5371 | Acc(val) 0.7744 |*
Epoch 00015 | Loss(train) 1.3025 | Acc(train) 0.6286 | Acc(val) 0.7610 |
Epoch 00016 | Loss(train) 1.2558 | Acc(train) 0.6379 | Acc(val) 0.7196 |
Epoch 00017 | Loss(train) 1.2408 | Acc(train) 0.6339 | Acc(val) 0.7076 |
Epoch 00018 | Loss(train) 1.1852 | Acc(train) 0.6253 | Acc(val) 0.6756 |
Epoch 00019 | Loss(train) 1.1688 | Acc(train) 0.6319 | Acc(val) 0.6622 |
Epoch 00020 | Loss(train) 1.1536 | Acc(train) 0.6159 | Acc(val) 0.6889 |
Epoch 00021 | Loss(train) 1.0840 | Acc(train) 0.6647 | Acc(val) 0.7223 |
Epoch 00022 | Loss(train) 1.0452 | Acc(train) 0.6760 | Acc(val) 0.7490 |
Epoch 00023 | Loss(train) 1.0356 | Acc(train) 0.6914 | Acc(val) 0.7784 |*
Epoch 00024 | Loss(train) 0.9786 | Acc(train) 0.6961 | Acc(val) 0.8011 |*
Epoch 00025 | Loss(train) 0.9373 | Acc(train) 0.7368 | Acc(val) 0.8117 |*
Epoch 00026 | Loss(train) 0.8973 | Acc(train) 0.7261 | Acc(val) 0.8224 |*
Epoch 00027 | Loss(train) 0.9013 | Acc(train) 0.7315 | Acc(val) 0.8224 |
Epoch 00028 | Loss(train) 0.8511 | Acc(train) 0.7442 | Acc(val) 0.8264 |*
Epoch 00029 | Loss(train) 0.8208 | Acc(train) 0.7495 | Acc(val) 0.8344 |*
Epoch 00030 | Loss(train) 0.8061 | Acc(train) 0.7562 | Acc(val) 0.8411 |*
Epoch 00031 | Loss(train) 0.7849 | Acc(train) 0.7715 | Acc(val) 0.8611 |*
Epoch 00032 | Loss(train) 0.7699 | Acc(train) 0.7662 | Acc(val) 0.8772 |*
Epoch 00033 | Loss(train) 0.7768 | Acc(train) 0.7629 | Acc(val) 0.8812 |*
Epoch 00034 | Loss(train) 0.7660 | Acc(train) 0.7929 | Acc(val) 0.8905 |*
Epoch 00035 | Loss(train) 0.7787 | Acc(train) 0.7762 | Acc(val) 0.8959 |*
Epoch 00036 | Loss(train) 0.7471 | Acc(train) 0.7842 | Acc(val) 0.8972 |*
Epoch 00037 | Loss(train) 0.7069 | Acc(train) 0.8043 | Acc(val) 0.8985 |*
Epoch 00038 | Loss(train) 0.7026 | Acc(train) 0.8083 | Acc(val) 0.8932 |
Epoch 00039 | Loss(train) 0.6754 | Acc(train) 0.8263 | Acc(val) 0.8959 |
Epoch 00040 | Loss(train) 0.6770 | Acc(train) 0.8176 | Acc(val) 0.8959 |
Epoch 00041 | Loss(train) 0.6551 | Acc(train) 0.8190 | Acc(val) 0.8945 |
Epoch 00042 | Loss(train) 0.6493 | Acc(train) 0.8116 | Acc(val) 0.8932 |
Epoch 00043 | Loss(train) 0.6545 | Acc(train) 0.8130 | Acc(val) 0.8879 |
Epoch 00044 | Loss(train) 0.6370 | Acc(train) 0.8103 | Acc(val) 0.8879 |
Epoch 00045 | Loss(train) 0.6255 | Acc(train) 0.8297 | Acc(val) 0.8945 |
Epoch 00046 | Loss(train) 0.6039 | Acc(train) 0.8203 | Acc(val) 0.9039 |*
Epoch 00047 | Loss(train) 0.6288 | Acc(train) 0.8163 | Acc(val) 0.9052 |*
Epoch 00048 | Loss(train) 0.5920 | Acc(train) 0.8216 | Acc(val) 0.9039 |
Epoch 00049 | Loss(train) 0.5704 | Acc(train) 0.8310 | Acc(val) 0.9039 |
Epoch 00050 | Loss(train) 0.5640 | Acc(train) 0.8390 | Acc(val) 0.9092 |*
Epoch 00051 | Loss(train) 0.5723 | Acc(train) 0.8230 | Acc(val) 0.9105 |*
Epoch 00052 | Loss(train) 0.5758 | Acc(train) 0.8223 | Acc(val) 0.9146 |*
Epoch 00053 | Loss(train) 0.5473 | Acc(train) 0.8290 | Acc(val) 0.9105 |
Epoch 00054 | Loss(train) 0.5417 | Acc(train) 0.8497 | Acc(val) 0.9146 |
Epoch 00055 | Loss(train) 0.5266 | Acc(train) 0.8370 | Acc(val) 0.9132 |
Epoch 00056 | Loss(train) 0.5155 | Acc(train) 0.8470 | Acc(val) 0.9105 |
Epoch 00057 | Loss(train) 0.5070 | Acc(train) 0.8524 | Acc(val) 0.9079 |
Epoch 00058 | Loss(train) 0.4890 | Acc(train) 0.8530 | Acc(val) 0.9079 |
Epoch 00059 | Loss(train) 0.5034 | Acc(train) 0.8524 | Acc(val) 0.9119 |
Epoch 00060 | Loss(train) 0.5011 | Acc(train) 0.8430 | Acc(val) 0.9159 |*
Epoch 00061 | Loss(train) 0.5003 | Acc(train) 0.8530 | Acc(val) 0.9172 |*
Epoch 00062 | Loss(train) 0.4966 | Acc(train) 0.8624 | Acc(val) 0.9186 |*
Epoch 00063 | Loss(train) 0.4836 | Acc(train) 0.8470 | Acc(val) 0.9159 |
Epoch 00064 | Loss(train) 0.4865 | Acc(train) 0.8604 | Acc(val) 0.9146 |
Epoch 00065 | Loss(train) 0.4898 | Acc(train) 0.8510 | Acc(val) 0.9146 |
Epoch 00066 | Loss(train) 0.4798 | Acc(train) 0.8564 | Acc(val) 0.9146 |
Epoch 00067 | Loss(train) 0.4563 | Acc(train) 0.8591 | Acc(val) 0.9105 |
Epoch 00068 | Loss(train) 0.4427 | Acc(train) 0.8651 | Acc(val) 0.9132 |
Epoch 00069 | Loss(train) 0.4577 | Acc(train) 0.8597 | Acc(val) 0.9132 |
Epoch 00070 | Loss(train) 0.4562 | Acc(train) 0.8510 | Acc(val) 0.9172 |
Epoch 00071 | Loss(train) 0.4396 | Acc(train) 0.8631 | Acc(val) 0.9199 |*
Epoch 00072 | Loss(train) 0.4398 | Acc(train) 0.8657 | Acc(val) 0.9199 |
Epoch 00073 | Loss(train) 0.4527 | Acc(train) 0.8597 | Acc(val) 0.9212 |*
Epoch 00074 | Loss(train) 0.4475 | Acc(train) 0.8697 | Acc(val) 0.9252 |*
Epoch 00075 | Loss(train) 0.4336 | Acc(train) 0.8624 | Acc(val) 0.9252 |
Epoch 00076 | Loss(train) 0.4262 | Acc(train) 0.8651 | Acc(val) 0.9252 |
Epoch 00077 | Loss(train) 0.4266 | Acc(train) 0.8804 | Acc(val) 0.9252 |
Epoch 00078 | Loss(train) 0.4322 | Acc(train) 0.8711 | Acc(val) 0.9252 |
Epoch 00079 | Loss(train) 0.4015 | Acc(train) 0.8731 | Acc(val) 0.9252 |
Epoch 00080 | Loss(train) 0.4265 | Acc(train) 0.8564 | Acc(val) 0.9239 |
Epoch 00081 | Loss(train) 0.4002 | Acc(train) 0.8711 | Acc(val) 0.9239 |
Epoch 00082 | Loss(train) 0.4323 | Acc(train) 0.8617 | Acc(val) 0.9279 |*
Epoch 00083 | Loss(train) 0.4123 | Acc(train) 0.8744 | Acc(val) 0.9279 |
Epoch 00084 | Loss(train) 0.4090 | Acc(train) 0.8831 | Acc(val) 0.9266 |
Epoch 00085 | Loss(train) 0.4067 | Acc(train) 0.8724 | Acc(val) 0.9266 |
Epoch 00086 | Loss(train) 0.4184 | Acc(train) 0.8671 | Acc(val) 0.9239 |
Epoch 00087 | Loss(train) 0.3931 | Acc(train) 0.8824 | Acc(val) 0.9199 |
Epoch 00088 | Loss(train) 0.4162 | Acc(train) 0.8778 | Acc(val) 0.9226 |
Epoch 00089 | Loss(train) 0.3759 | Acc(train) 0.8878 | Acc(val) 0.9226 |
Epoch 00090 | Loss(train) 0.4041 | Acc(train) 0.8778 | Acc(val) 0.9252 |
Epoch 00091 | Loss(train) 0.4077 | Acc(train) 0.8778 | Acc(val) 0.9279 |
Epoch 00092 | Loss(train) 0.3774 | Acc(train) 0.8864 | Acc(val) 0.9252 |
Epoch 00093 | Loss(train) 0.3897 | Acc(train) 0.8804 | Acc(val) 0.9266 |
Epoch 00094 | Loss(train) 0.4097 | Acc(train) 0.8691 | Acc(val) 0.9306 |*
Epoch 00095 | Loss(train) 0.4045 | Acc(train) 0.8798 | Acc(val) 0.9306 |
Epoch 00096 | Loss(train) 0.4002 | Acc(train) 0.8711 | Acc(val) 0.9319 |*
Epoch 00097 | Loss(train) 0.3973 | Acc(train) 0.8717 | Acc(val) 0.9279 |
Epoch 00098 | Loss(train) 0.3510 | Acc(train) 0.9031 | Acc(val) 0.9266 |
Epoch 00099 | Loss(train) 0.3844 | Acc(train) 0.8751 | Acc(val) 0.9279 |
Epoch 00100 | Loss(train) 0.3767 | Acc(train) 0.8771 | Acc(val) 0.9319 |
Epoch 00101 | Loss(train) 0.3613 | Acc(train) 0.8884 | Acc(val) 0.9319 |
Epoch 00102 | Loss(train) 0.3599 | Acc(train) 0.8945 | Acc(val) 0.9319 |
Epoch 00103 | Loss(train) 0.3775 | Acc(train) 0.8945 | Acc(val) 0.9332 |*
Epoch 00104 | Loss(train) 0.3621 | Acc(train) 0.8938 | Acc(val) 0.9346 |*
Epoch 00105 | Loss(train) 0.3697 | Acc(train) 0.8864 | Acc(val) 0.9346 |
Epoch 00106 | Loss(train) 0.3745 | Acc(train) 0.8911 | Acc(val) 0.9332 |
Epoch 00107 | Loss(train) 0.3684 | Acc(train) 0.8891 | Acc(val) 0.9319 |
Epoch 00108 | Loss(train) 0.3663 | Acc(train) 0.8864 | Acc(val) 0.9306 |
Epoch 00109 | Loss(train) 0.3658 | Acc(train) 0.8898 | Acc(val) 0.9306 |
Epoch 00110 | Loss(train) 0.3693 | Acc(train) 0.8864 | Acc(val) 0.9332 |
Epoch 00111 | Loss(train) 0.3608 | Acc(train) 0.8965 | Acc(val) 0.9319 |
Epoch 00112 | Loss(train) 0.3479 | Acc(train) 0.8978 | Acc(val) 0.9306 |
Epoch 00113 | Loss(train) 0.3282 | Acc(train) 0.8918 | Acc(val) 0.9292 |
Epoch 00114 | Loss(train) 0.3466 | Acc(train) 0.8991 | Acc(val) 0.9319 |
Epoch 00115 | Loss(train) 0.3396 | Acc(train) 0.8991 | Acc(val) 0.9332 |
Epoch 00116 | Loss(train) 0.3756 | Acc(train) 0.8918 | Acc(val) 0.9346 |
Epoch 00117 | Loss(train) 0.3389 | Acc(train) 0.8965 | Acc(val) 0.9332 |
Epoch 00118 | Loss(train) 0.3422 | Acc(train) 0.8998 | Acc(val) 0.9319 |
Epoch 00119 | Loss(train) 0.3579 | Acc(train) 0.8938 | Acc(val) 0.9332 |
Epoch 00120 | Loss(train) 0.3364 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00121 | Loss(train) 0.3503 | Acc(train) 0.8838 | Acc(val) 0.9332 |
Epoch 00122 | Loss(train) 0.3627 | Acc(train) 0.8884 | Acc(val) 0.9332 |
Epoch 00123 | Loss(train) 0.3372 | Acc(train) 0.8951 | Acc(val) 0.9319 |
Epoch 00124 | Loss(train) 0.3498 | Acc(train) 0.8925 | Acc(val) 0.9359 |*
Epoch 00125 | Loss(train) 0.3270 | Acc(train) 0.8978 | Acc(val) 0.9346 |
Epoch 00126 | Loss(train) 0.3271 | Acc(train) 0.9018 | Acc(val) 0.9346 |
Epoch 00127 | Loss(train) 0.3322 | Acc(train) 0.8965 | Acc(val) 0.9372 |*
Epoch 00128 | Loss(train) 0.3414 | Acc(train) 0.8951 | Acc(val) 0.9332 |
Epoch 00129 | Loss(train) 0.3452 | Acc(train) 0.9025 | Acc(val) 0.9332 |
Epoch 00130 | Loss(train) 0.3128 | Acc(train) 0.8991 | Acc(val) 0.9346 |
Epoch 00131 | Loss(train) 0.3293 | Acc(train) 0.8871 | Acc(val) 0.9332 |
Epoch 00132 | Loss(train) 0.3348 | Acc(train) 0.8884 | Acc(val) 0.9332 |
Epoch 00133 | Loss(train) 0.3271 | Acc(train) 0.8998 | Acc(val) 0.9346 |
Epoch 00134 | Loss(train) 0.3213 | Acc(train) 0.9092 | Acc(val) 0.9319 |
Epoch 00135 | Loss(train) 0.3191 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00136 | Loss(train) 0.3369 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00137 | Loss(train) 0.3209 | Acc(train) 0.9092 | Acc(val) 0.9319 |
Epoch 00138 | Loss(train) 0.3226 | Acc(train) 0.9045 | Acc(val) 0.9319 |
Epoch 00139 | Loss(train) 0.3410 | Acc(train) 0.8965 | Acc(val) 0.9359 |
Epoch 00140 | Loss(train) 0.3344 | Acc(train) 0.8971 | Acc(val) 0.9359 |
Epoch 00141 | Loss(train) 0.3280 | Acc(train) 0.8985 | Acc(val) 0.9306 |
Epoch 00142 | Loss(train) 0.3172 | Acc(train) 0.8971 | Acc(val) 0.9346 |
Epoch 00143 | Loss(train) 0.3331 | Acc(train) 0.9031 | Acc(val) 0.9372 |
Epoch 00144 | Loss(train) 0.3329 | Acc(train) 0.8891 | Acc(val) 0.9359 |
Epoch 00145 | Loss(train) 0.3143 | Acc(train) 0.9011 | Acc(val) 0.9346 |
Epoch 00146 | Loss(train) 0.3109 | Acc(train) 0.9038 | Acc(val) 0.9346 |
Epoch 00147 | Loss(train) 0.3193 | Acc(train) 0.8991 | Acc(val) 0.9332 |
Epoch 00148 | Loss(train) 0.3206 | Acc(train) 0.8925 | Acc(val) 0.9346 |
Epoch 00149 | Loss(train) 0.3066 | Acc(train) 0.9071 | Acc(val) 0.9346 |
Epoch 00150 | Loss(train) 0.3034 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00151 | Loss(train) 0.3056 | Acc(train) 0.9071 | Acc(val) 0.9332 |
Epoch 00152 | Loss(train) 0.3061 | Acc(train) 0.9118 | Acc(val) 0.9306 |
Epoch 00153 | Loss(train) 0.3118 | Acc(train) 0.9025 | Acc(val) 0.9332 |
Epoch 00154 | Loss(train) 0.3247 | Acc(train) 0.8958 | Acc(val) 0.9359 |
Epoch 00155 | Loss(train) 0.3068 | Acc(train) 0.9031 | Acc(val) 0.9359 |
Epoch 00156 | Loss(train) 0.3202 | Acc(train) 0.8985 | Acc(val) 0.9332 |
Epoch 00157 | Loss(train) 0.3410 | Acc(train) 0.8971 | Acc(val) 0.9306 |
Epoch 00158 | Loss(train) 0.3053 | Acc(train) 0.9058 | Acc(val) 0.9372 |
Epoch 00159 | Loss(train) 0.2985 | Acc(train) 0.9071 | Acc(val) 0.9346 |
Epoch 00160 | Loss(train) 0.3065 | Acc(train) 0.9038 | Acc(val) 0.9332 |
Epoch 00161 | Loss(train) 0.2918 | Acc(train) 0.9145 | Acc(val) 0.9332 |
Epoch 00162 | Loss(train) 0.2910 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00163 | Loss(train) 0.3020 | Acc(train) 0.9085 | Acc(val) 0.9359 |
Epoch 00164 | Loss(train) 0.3068 | Acc(train) 0.9071 | Acc(val) 0.9372 |
Epoch 00165 | Loss(train) 0.2873 | Acc(train) 0.9132 | Acc(val) 0.9426 |*
Epoch 00166 | Loss(train) 0.2945 | Acc(train) 0.9078 | Acc(val) 0.9359 |
Epoch 00167 | Loss(train) 0.3088 | Acc(train) 0.9085 | Acc(val) 0.9346 |
Epoch 00168 | Loss(train) 0.2961 | Acc(train) 0.9152 | Acc(val) 0.9372 |
Epoch 00169 | Loss(train) 0.3071 | Acc(train) 0.9152 | Acc(val) 0.9359 |
Epoch 00170 | Loss(train) 0.3076 | Acc(train) 0.9005 | Acc(val) 0.9332 |
Epoch 00171 | Loss(train) 0.2952 | Acc(train) 0.9058 | Acc(val) 0.9372 |
Epoch 00172 | Loss(train) 0.3210 | Acc(train) 0.9038 | Acc(val) 0.9359 |
Epoch 00173 | Loss(train) 0.3138 | Acc(train) 0.8978 | Acc(val) 0.9346 |
Epoch 00174 | Loss(train) 0.2803 | Acc(train) 0.9085 | Acc(val) 0.9332 |
Epoch 00175 | Loss(train) 0.3148 | Acc(train) 0.9025 | Acc(val) 0.9372 |
Epoch 00176 | Loss(train) 0.3216 | Acc(train) 0.8991 | Acc(val) 0.9386 |
Epoch 00177 | Loss(train) 0.3238 | Acc(train) 0.8971 | Acc(val) 0.9399 |
Epoch 00178 | Loss(train) 0.3003 | Acc(train) 0.9092 | Acc(val) 0.9359 |
Epoch 00179 | Loss(train) 0.3019 | Acc(train) 0.9018 | Acc(val) 0.9346 |
Epoch 00180 | Loss(train) 0.2984 | Acc(train) 0.9005 | Acc(val) 0.9332 |
Epoch 00181 | Loss(train) 0.2944 | Acc(train) 0.9118 | Acc(val) 0.9359 |
Epoch 00182 | Loss(train) 0.2776 | Acc(train) 0.9152 | Acc(val) 0.9372 |
Epoch 00183 | Loss(train) 0.2995 | Acc(train) 0.9112 | Acc(val) 0.9346 |
Epoch 00184 | Loss(train) 0.2823 | Acc(train) 0.9078 | Acc(val) 0.9359 |
Epoch 00185 | Loss(train) 0.2842 | Acc(train) 0.9158 | Acc(val) 0.9372 |
Epoch 00186 | Loss(train) 0.2825 | Acc(train) 0.9138 | Acc(val) 0.9332 |
Epoch 00187 | Loss(train) 0.2841 | Acc(train) 0.9132 | Acc(val) 0.9346 |
Epoch 00188 | Loss(train) 0.3020 | Acc(train) 0.9018 | Acc(val) 0.9319 |
Epoch 00189 | Loss(train) 0.2939 | Acc(train) 0.9051 | Acc(val) 0.9359 |
Epoch 00190 | Loss(train) 0.3045 | Acc(train) 0.9018 | Acc(val) 0.9346 |
Epoch 00191 | Loss(train) 0.2902 | Acc(train) 0.9098 | Acc(val) 0.9359 |
Epoch 00192 | Loss(train) 0.3089 | Acc(train) 0.9045 | Acc(val) 0.9386 |
Epoch 00193 | Loss(train) 0.3093 | Acc(train) 0.9045 | Acc(val) 0.9359 |
Epoch 00194 | Loss(train) 0.2996 | Acc(train) 0.9078 | Acc(val) 0.9372 |
Epoch 00195 | Loss(train) 0.2943 | Acc(train) 0.9105 | Acc(val) 0.9359 |
Epoch 00196 | Loss(train) 0.2807 | Acc(train) 0.9085 | Acc(val) 0.9413 |
Epoch 00197 | Loss(train) 0.3109 | Acc(train) 0.8991 | Acc(val) 0.9386 |
Epoch 00198 | Loss(train) 0.3041 | Acc(train) 0.9058 | Acc(val) 0.9359 |
Epoch 00199 | Loss(train) 0.3131 | Acc(train) 0.9065 | Acc(val) 0.9386 |
Epoch 00200 | Loss(train) 0.2838 | Acc(train) 0.9172 | Acc(val) 0.9359 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 32}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 745, 'out_dim': 8}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 97.97 MB
GPU Memory Reserved: 156.00 MB
All runs:
Uncalibrated Test Accuracy: 93.08 ± 0.28
Uncalibrated Difference: 4.00 ± 0.42
Calibrated Test Accuracy: 93.08 ± 0.28
Calibrated Difference: 1.03 ± 0.18
