/usr/local/lib/python3.11/dist-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning(
Dataset: computers | #Nodes: 13381 | #Edges: 491556 | #Classes: 10 |#Features: 767
Exp 0/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.4178 | Acc(train) 0.0579 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 3.5480 | Acc(train) 0.3587 | Acc(val) 0.1599 |
Epoch 00003 | Loss(train) 4.2127 | Acc(train) 0.1476 | Acc(val) 0.1054 |
Epoch 00004 | Loss(train) 3.4565 | Acc(train) 0.1263 | Acc(val) 0.1622 |
Epoch 00005 | Loss(train) 2.5902 | Acc(train) 0.1775 | Acc(val) 0.3759 |*
Epoch 00006 | Loss(train) 2.3506 | Acc(train) 0.3707 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.2927 | Acc(train) 0.3666 | Acc(val) 0.3714 |
Epoch 00008 | Loss(train) 2.1601 | Acc(train) 0.3703 | Acc(val) 0.3714 |
Epoch 00009 | Loss(train) 2.0859 | Acc(train) 0.3759 | Acc(val) 0.4813 |*
Epoch 00010 | Loss(train) 2.0137 | Acc(train) 0.4185 | Acc(val) 0.4529 |
Epoch 00011 | Loss(train) 2.0140 | Acc(train) 0.4055 | Acc(val) 0.4178 |
Epoch 00012 | Loss(train) 2.0096 | Acc(train) 0.4077 | Acc(val) 0.4335 |
Epoch 00013 | Loss(train) 2.0144 | Acc(train) 0.4290 | Acc(val) 0.4746 |
Epoch 00014 | Loss(train) 1.9375 | Acc(train) 0.4865 | Acc(val) 0.5097 |*
Epoch 00015 | Loss(train) 1.8427 | Acc(train) 0.4907 | Acc(val) 0.4492 |
Epoch 00016 | Loss(train) 1.7824 | Acc(train) 0.4451 | Acc(val) 0.3976 |
Epoch 00017 | Loss(train) 1.7412 | Acc(train) 0.4066 | Acc(val) 0.4163 |
Epoch 00018 | Loss(train) 1.7396 | Acc(train) 0.4387 | Acc(val) 0.4387 |
Epoch 00019 | Loss(train) 1.6867 | Acc(train) 0.4346 | Acc(val) 0.4858 |
Epoch 00020 | Loss(train) 1.6606 | Acc(train) 0.4623 | Acc(val) 0.5187 |*
Epoch 00021 | Loss(train) 1.6416 | Acc(train) 0.5071 | Acc(val) 0.5822 |*
Epoch 00022 | Loss(train) 1.5907 | Acc(train) 0.5146 | Acc(val) 0.6278 |*
Epoch 00023 | Loss(train) 1.5832 | Acc(train) 0.5471 | Acc(val) 0.6390 |*
Epoch 00024 | Loss(train) 1.5270 | Acc(train) 0.5620 | Acc(val) 0.6166 |
Epoch 00025 | Loss(train) 1.4748 | Acc(train) 0.5504 | Acc(val) 0.6315 |
Epoch 00026 | Loss(train) 1.4442 | Acc(train) 0.5886 | Acc(val) 0.6525 |*
Epoch 00027 | Loss(train) 1.4261 | Acc(train) 0.5960 | Acc(val) 0.6532 |*
Epoch 00028 | Loss(train) 1.3790 | Acc(train) 0.6274 | Acc(val) 0.6764 |*
Epoch 00029 | Loss(train) 1.3531 | Acc(train) 0.6394 | Acc(val) 0.6996 |*
Epoch 00030 | Loss(train) 1.3365 | Acc(train) 0.6375 | Acc(val) 0.7093 |*
Epoch 00031 | Loss(train) 1.2870 | Acc(train) 0.6439 | Acc(val) 0.7100 |*
Epoch 00032 | Loss(train) 1.2386 | Acc(train) 0.6685 | Acc(val) 0.7010 |
Epoch 00033 | Loss(train) 1.2263 | Acc(train) 0.6513 | Acc(val) 0.6794 |
Epoch 00034 | Loss(train) 1.2203 | Acc(train) 0.6383 | Acc(val) 0.6652 |
Epoch 00035 | Loss(train) 1.1940 | Acc(train) 0.6263 | Acc(val) 0.6614 |
Epoch 00036 | Loss(train) 1.1637 | Acc(train) 0.6506 | Acc(val) 0.6801 |
Epoch 00037 | Loss(train) 1.1250 | Acc(train) 0.6547 | Acc(val) 0.7040 |
Epoch 00038 | Loss(train) 1.1207 | Acc(train) 0.6573 | Acc(val) 0.7167 |*
Epoch 00039 | Loss(train) 1.0823 | Acc(train) 0.6730 | Acc(val) 0.7265 |*
Epoch 00040 | Loss(train) 1.0872 | Acc(train) 0.6685 | Acc(val) 0.7272 |*
Epoch 00041 | Loss(train) 1.0476 | Acc(train) 0.6779 | Acc(val) 0.7272 |
Epoch 00042 | Loss(train) 1.0206 | Acc(train) 0.6902 | Acc(val) 0.7324 |*
Epoch 00043 | Loss(train) 1.0183 | Acc(train) 0.6913 | Acc(val) 0.7399 |*
Epoch 00044 | Loss(train) 0.9887 | Acc(train) 0.6966 | Acc(val) 0.7549 |*
Epoch 00045 | Loss(train) 0.9666 | Acc(train) 0.7108 | Acc(val) 0.7683 |*
Epoch 00046 | Loss(train) 0.9889 | Acc(train) 0.7141 | Acc(val) 0.7601 |
Epoch 00047 | Loss(train) 0.9475 | Acc(train) 0.7197 | Acc(val) 0.7444 |
Epoch 00048 | Loss(train) 0.9411 | Acc(train) 0.6887 | Acc(val) 0.7481 |
Epoch 00049 | Loss(train) 0.9309 | Acc(train) 0.6969 | Acc(val) 0.7623 |
Epoch 00050 | Loss(train) 0.9013 | Acc(train) 0.7212 | Acc(val) 0.7713 |*
Epoch 00051 | Loss(train) 0.9175 | Acc(train) 0.7130 | Acc(val) 0.7840 |*
Epoch 00052 | Loss(train) 0.9043 | Acc(train) 0.7287 | Acc(val) 0.7840 |
Epoch 00053 | Loss(train) 0.8805 | Acc(train) 0.7347 | Acc(val) 0.7728 |
Epoch 00054 | Loss(train) 0.8606 | Acc(train) 0.7294 | Acc(val) 0.7773 |
Epoch 00055 | Loss(train) 0.8538 | Acc(train) 0.7261 | Acc(val) 0.7877 |*
Epoch 00056 | Loss(train) 0.8823 | Acc(train) 0.7298 | Acc(val) 0.7780 |
Epoch 00057 | Loss(train) 0.8521 | Acc(train) 0.7317 | Acc(val) 0.7952 |*
Epoch 00058 | Loss(train) 0.8601 | Acc(train) 0.7440 | Acc(val) 0.8079 |*
Epoch 00059 | Loss(train) 0.8415 | Acc(train) 0.7317 | Acc(val) 0.8057 |
Epoch 00060 | Loss(train) 0.8042 | Acc(train) 0.7694 | Acc(val) 0.8004 |
Epoch 00061 | Loss(train) 0.8019 | Acc(train) 0.7448 | Acc(val) 0.8087 |*
Epoch 00062 | Loss(train) 0.7952 | Acc(train) 0.7616 | Acc(val) 0.8221 |*
Epoch 00063 | Loss(train) 0.7716 | Acc(train) 0.7638 | Acc(val) 0.8229 |*
Epoch 00064 | Loss(train) 0.7620 | Acc(train) 0.7724 | Acc(val) 0.8244 |*
Epoch 00065 | Loss(train) 0.7837 | Acc(train) 0.7653 | Acc(val) 0.8102 |
Epoch 00066 | Loss(train) 0.7528 | Acc(train) 0.7672 | Acc(val) 0.8176 |
Epoch 00067 | Loss(train) 0.7467 | Acc(train) 0.7664 | Acc(val) 0.8274 |*
Epoch 00068 | Loss(train) 0.7337 | Acc(train) 0.7739 | Acc(val) 0.8341 |*
Epoch 00069 | Loss(train) 0.7285 | Acc(train) 0.7709 | Acc(val) 0.8326 |
Epoch 00070 | Loss(train) 0.7143 | Acc(train) 0.7922 | Acc(val) 0.8348 |*
Epoch 00071 | Loss(train) 0.7130 | Acc(train) 0.7859 | Acc(val) 0.8318 |
Epoch 00072 | Loss(train) 0.7015 | Acc(train) 0.7889 | Acc(val) 0.8393 |*
Epoch 00073 | Loss(train) 0.7101 | Acc(train) 0.7874 | Acc(val) 0.8416 |*
Epoch 00074 | Loss(train) 0.6934 | Acc(train) 0.8034 | Acc(val) 0.8453 |*
Epoch 00075 | Loss(train) 0.6909 | Acc(train) 0.7919 | Acc(val) 0.8430 |
Epoch 00076 | Loss(train) 0.6978 | Acc(train) 0.7855 | Acc(val) 0.8371 |
Epoch 00077 | Loss(train) 0.6670 | Acc(train) 0.8016 | Acc(val) 0.8430 |
Epoch 00078 | Loss(train) 0.6567 | Acc(train) 0.7993 | Acc(val) 0.8490 |*
Epoch 00079 | Loss(train) 0.6486 | Acc(train) 0.8113 | Acc(val) 0.8528 |*
Epoch 00080 | Loss(train) 0.6489 | Acc(train) 0.8146 | Acc(val) 0.8528 |
Epoch 00081 | Loss(train) 0.6356 | Acc(train) 0.8083 | Acc(val) 0.8528 |
Epoch 00082 | Loss(train) 0.6448 | Acc(train) 0.8098 | Acc(val) 0.8401 |
Epoch 00083 | Loss(train) 0.6358 | Acc(train) 0.8132 | Acc(val) 0.8460 |
Epoch 00084 | Loss(train) 0.6197 | Acc(train) 0.8143 | Acc(val) 0.8513 |
Epoch 00085 | Loss(train) 0.6239 | Acc(train) 0.8117 | Acc(val) 0.8430 |
Epoch 00086 | Loss(train) 0.6148 | Acc(train) 0.8075 | Acc(val) 0.8505 |
Epoch 00087 | Loss(train) 0.6024 | Acc(train) 0.8210 | Acc(val) 0.8572 |*
Epoch 00088 | Loss(train) 0.6025 | Acc(train) 0.8102 | Acc(val) 0.8729 |*
Epoch 00089 | Loss(train) 0.6005 | Acc(train) 0.8165 | Acc(val) 0.8700 |
Epoch 00090 | Loss(train) 0.5980 | Acc(train) 0.8270 | Acc(val) 0.8625 |
Epoch 00091 | Loss(train) 0.5923 | Acc(train) 0.8225 | Acc(val) 0.8602 |
Epoch 00092 | Loss(train) 0.5858 | Acc(train) 0.8229 | Acc(val) 0.8580 |
Epoch 00093 | Loss(train) 0.5766 | Acc(train) 0.8292 | Acc(val) 0.8662 |
Epoch 00094 | Loss(train) 0.5934 | Acc(train) 0.8251 | Acc(val) 0.8662 |
Epoch 00095 | Loss(train) 0.5777 | Acc(train) 0.8221 | Acc(val) 0.8587 |
Epoch 00096 | Loss(train) 0.5766 | Acc(train) 0.8188 | Acc(val) 0.8572 |
Epoch 00097 | Loss(train) 0.5876 | Acc(train) 0.8176 | Acc(val) 0.8737 |*
Epoch 00098 | Loss(train) 0.5731 | Acc(train) 0.8281 | Acc(val) 0.8752 |*
Epoch 00099 | Loss(train) 0.5736 | Acc(train) 0.8266 | Acc(val) 0.8543 |
Epoch 00100 | Loss(train) 0.5618 | Acc(train) 0.8345 | Acc(val) 0.8483 |
Epoch 00101 | Loss(train) 0.5510 | Acc(train) 0.8266 | Acc(val) 0.8685 |
Epoch 00102 | Loss(train) 0.5523 | Acc(train) 0.8337 | Acc(val) 0.8692 |
Epoch 00103 | Loss(train) 0.5655 | Acc(train) 0.8274 | Acc(val) 0.8640 |
Epoch 00104 | Loss(train) 0.5734 | Acc(train) 0.8318 | Acc(val) 0.8543 |
Epoch 00105 | Loss(train) 0.5687 | Acc(train) 0.8307 | Acc(val) 0.8692 |
Epoch 00106 | Loss(train) 0.5626 | Acc(train) 0.8255 | Acc(val) 0.8670 |
Epoch 00107 | Loss(train) 0.5482 | Acc(train) 0.8386 | Acc(val) 0.8707 |
Epoch 00108 | Loss(train) 0.5740 | Acc(train) 0.8221 | Acc(val) 0.8782 |*
Epoch 00109 | Loss(train) 0.5739 | Acc(train) 0.8333 | Acc(val) 0.8647 |
Epoch 00110 | Loss(train) 0.5175 | Acc(train) 0.8457 | Acc(val) 0.8572 |/root/WATS/model/calibrator.py:194: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)
  torch.tensor([L.row, L.col]),

Epoch 00111 | Loss(train) 0.5390 | Acc(train) 0.8307 | Acc(val) 0.8647 |
Epoch 00112 | Loss(train) 0.5432 | Acc(train) 0.8285 | Acc(val) 0.8700 |
Epoch 00113 | Loss(train) 0.5490 | Acc(train) 0.8322 | Acc(val) 0.8744 |
Epoch 00114 | Loss(train) 0.5477 | Acc(train) 0.8348 | Acc(val) 0.8737 |
Epoch 00115 | Loss(train) 0.5374 | Acc(train) 0.8337 | Acc(val) 0.8752 |
Epoch 00116 | Loss(train) 0.5316 | Acc(train) 0.8292 | Acc(val) 0.8789 |*
Epoch 00117 | Loss(train) 0.5250 | Acc(train) 0.8404 | Acc(val) 0.8685 |
Epoch 00118 | Loss(train) 0.5208 | Acc(train) 0.8490 | Acc(val) 0.8722 |
Epoch 00119 | Loss(train) 0.5341 | Acc(train) 0.8371 | Acc(val) 0.8722 |
Epoch 00120 | Loss(train) 0.5146 | Acc(train) 0.8382 | Acc(val) 0.8722 |
Epoch 00121 | Loss(train) 0.5409 | Acc(train) 0.8359 | Acc(val) 0.8812 |*
Epoch 00122 | Loss(train) 0.5123 | Acc(train) 0.8487 | Acc(val) 0.8767 |
Epoch 00123 | Loss(train) 0.5115 | Acc(train) 0.8442 | Acc(val) 0.8767 |
Epoch 00124 | Loss(train) 0.5265 | Acc(train) 0.8378 | Acc(val) 0.8662 |
Epoch 00125 | Loss(train) 0.4980 | Acc(train) 0.8513 | Acc(val) 0.8744 |
Epoch 00126 | Loss(train) 0.5221 | Acc(train) 0.8416 | Acc(val) 0.8842 |*
Epoch 00127 | Loss(train) 0.5213 | Acc(train) 0.8416 | Acc(val) 0.8827 |
Epoch 00128 | Loss(train) 0.5170 | Acc(train) 0.8419 | Acc(val) 0.8655 |
Epoch 00129 | Loss(train) 0.5126 | Acc(train) 0.8460 | Acc(val) 0.8655 |
Epoch 00130 | Loss(train) 0.5145 | Acc(train) 0.8457 | Acc(val) 0.8789 |
Epoch 00131 | Loss(train) 0.5036 | Acc(train) 0.8472 | Acc(val) 0.8789 |
Epoch 00132 | Loss(train) 0.5158 | Acc(train) 0.8453 | Acc(val) 0.8789 |
Epoch 00133 | Loss(train) 0.5027 | Acc(train) 0.8498 | Acc(val) 0.8752 |
Epoch 00134 | Loss(train) 0.4985 | Acc(train) 0.8494 | Acc(val) 0.8729 |
Epoch 00135 | Loss(train) 0.4724 | Acc(train) 0.8528 | Acc(val) 0.8722 |
Epoch 00136 | Loss(train) 0.5016 | Acc(train) 0.8427 | Acc(val) 0.8827 |
Epoch 00137 | Loss(train) 0.5009 | Acc(train) 0.8501 | Acc(val) 0.8849 |*
Epoch 00138 | Loss(train) 0.5036 | Acc(train) 0.8487 | Acc(val) 0.8812 |
Epoch 00139 | Loss(train) 0.4986 | Acc(train) 0.8472 | Acc(val) 0.8797 |
Epoch 00140 | Loss(train) 0.4967 | Acc(train) 0.8513 | Acc(val) 0.8804 |
Epoch 00141 | Loss(train) 0.5006 | Acc(train) 0.8423 | Acc(val) 0.8789 |
Epoch 00142 | Loss(train) 0.5059 | Acc(train) 0.8416 | Acc(val) 0.8752 |
Epoch 00143 | Loss(train) 0.4973 | Acc(train) 0.8442 | Acc(val) 0.8834 |
Epoch 00144 | Loss(train) 0.4905 | Acc(train) 0.8524 | Acc(val) 0.8849 |
Epoch 00145 | Loss(train) 0.5024 | Acc(train) 0.8453 | Acc(val) 0.8789 |
Epoch 00146 | Loss(train) 0.4910 | Acc(train) 0.8539 | Acc(val) 0.8819 |
Epoch 00147 | Loss(train) 0.4760 | Acc(train) 0.8561 | Acc(val) 0.8767 |
Epoch 00148 | Loss(train) 0.4894 | Acc(train) 0.8419 | Acc(val) 0.8819 |
Epoch 00149 | Loss(train) 0.4744 | Acc(train) 0.8554 | Acc(val) 0.8752 |
Epoch 00150 | Loss(train) 0.5035 | Acc(train) 0.8430 | Acc(val) 0.8797 |
Epoch 00151 | Loss(train) 0.4780 | Acc(train) 0.8501 | Acc(val) 0.8834 |
Epoch 00152 | Loss(train) 0.4857 | Acc(train) 0.8554 | Acc(val) 0.8707 |
Epoch 00153 | Loss(train) 0.5015 | Acc(train) 0.8419 | Acc(val) 0.8789 |
Epoch 00154 | Loss(train) 0.4900 | Acc(train) 0.8453 | Acc(val) 0.8827 |
Epoch 00155 | Loss(train) 0.4981 | Acc(train) 0.8464 | Acc(val) 0.8864 |*
Epoch 00156 | Loss(train) 0.4820 | Acc(train) 0.8554 | Acc(val) 0.8729 |
Epoch 00157 | Loss(train) 0.4828 | Acc(train) 0.8513 | Acc(val) 0.8819 |
Epoch 00158 | Loss(train) 0.4949 | Acc(train) 0.8430 | Acc(val) 0.8886 |*
Epoch 00159 | Loss(train) 0.4828 | Acc(train) 0.8490 | Acc(val) 0.8774 |
Epoch 00160 | Loss(train) 0.4828 | Acc(train) 0.8505 | Acc(val) 0.8774 |
Epoch 00161 | Loss(train) 0.4794 | Acc(train) 0.8494 | Acc(val) 0.8797 |
Epoch 00162 | Loss(train) 0.4698 | Acc(train) 0.8602 | Acc(val) 0.8879 |
Epoch 00163 | Loss(train) 0.4703 | Acc(train) 0.8561 | Acc(val) 0.8886 |
Epoch 00164 | Loss(train) 0.4655 | Acc(train) 0.8531 | Acc(val) 0.8849 |
Epoch 00165 | Loss(train) 0.4754 | Acc(train) 0.8550 | Acc(val) 0.8804 |
Epoch 00166 | Loss(train) 0.4736 | Acc(train) 0.8561 | Acc(val) 0.8804 |
Epoch 00167 | Loss(train) 0.4778 | Acc(train) 0.8494 | Acc(val) 0.8849 |
Epoch 00168 | Loss(train) 0.4710 | Acc(train) 0.8528 | Acc(val) 0.8871 |
Epoch 00169 | Loss(train) 0.4574 | Acc(train) 0.8602 | Acc(val) 0.8901 |*
Epoch 00170 | Loss(train) 0.4791 | Acc(train) 0.8509 | Acc(val) 0.8812 |
Epoch 00171 | Loss(train) 0.4650 | Acc(train) 0.8531 | Acc(val) 0.8819 |
Epoch 00172 | Loss(train) 0.4812 | Acc(train) 0.8565 | Acc(val) 0.8946 |*
Epoch 00173 | Loss(train) 0.4604 | Acc(train) 0.8673 | Acc(val) 0.8909 |
Epoch 00174 | Loss(train) 0.4804 | Acc(train) 0.8531 | Acc(val) 0.8916 |
Epoch 00175 | Loss(train) 0.4640 | Acc(train) 0.8580 | Acc(val) 0.8871 |
Epoch 00176 | Loss(train) 0.4512 | Acc(train) 0.8543 | Acc(val) 0.8864 |
Epoch 00177 | Loss(train) 0.4590 | Acc(train) 0.8617 | Acc(val) 0.8879 |
Epoch 00178 | Loss(train) 0.4713 | Acc(train) 0.8479 | Acc(val) 0.8916 |
Epoch 00179 | Loss(train) 0.4474 | Acc(train) 0.8632 | Acc(val) 0.8879 |
Epoch 00180 | Loss(train) 0.4711 | Acc(train) 0.8614 | Acc(val) 0.8894 |
Epoch 00181 | Loss(train) 0.4536 | Acc(train) 0.8561 | Acc(val) 0.8871 |
Epoch 00182 | Loss(train) 0.4607 | Acc(train) 0.8610 | Acc(val) 0.8931 |
Epoch 00183 | Loss(train) 0.4530 | Acc(train) 0.8572 | Acc(val) 0.8931 |
Epoch 00184 | Loss(train) 0.4543 | Acc(train) 0.8614 | Acc(val) 0.8849 |
Epoch 00185 | Loss(train) 0.4655 | Acc(train) 0.8513 | Acc(val) 0.8879 |
Epoch 00186 | Loss(train) 0.4551 | Acc(train) 0.8554 | Acc(val) 0.8894 |
Epoch 00187 | Loss(train) 0.4415 | Acc(train) 0.8655 | Acc(val) 0.8909 |
Epoch 00188 | Loss(train) 0.4398 | Acc(train) 0.8688 | Acc(val) 0.8879 |
Epoch 00189 | Loss(train) 0.4466 | Acc(train) 0.8640 | Acc(val) 0.8916 |
Epoch 00190 | Loss(train) 0.4445 | Acc(train) 0.8636 | Acc(val) 0.8939 |
Epoch 00191 | Loss(train) 0.4454 | Acc(train) 0.8572 | Acc(val) 0.8909 |
Epoch 00192 | Loss(train) 0.4402 | Acc(train) 0.8595 | Acc(val) 0.8901 |
Epoch 00193 | Loss(train) 0.4447 | Acc(train) 0.8632 | Acc(val) 0.8894 |
Epoch 00194 | Loss(train) 0.4554 | Acc(train) 0.8643 | Acc(val) 0.8916 |
Epoch 00195 | Loss(train) 0.4431 | Acc(train) 0.8587 | Acc(val) 0.8827 |
Epoch 00196 | Loss(train) 0.4636 | Acc(train) 0.8558 | Acc(val) 0.8827 |
Epoch 00197 | Loss(train) 0.4680 | Acc(train) 0.8513 | Acc(val) 0.8871 |
Epoch 00198 | Loss(train) 0.4559 | Acc(train) 0.8531 | Acc(val) 0.8707 |
Epoch 00199 | Loss(train) 0.4768 | Acc(train) 0.8475 | Acc(val) 0.8886 |
Epoch 00200 | Loss(train) 0.4516 | Acc(train) 0.8587 | Acc(val) 0.8954 |*
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 212.00 MB
Exp 1/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.1524 | Acc(train) 0.3434 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 3.5204 | Acc(train) 0.3610 | Acc(val) 0.1622 |
Epoch 00003 | Loss(train) 5.4458 | Acc(train) 0.1484 | Acc(val) 0.2556 |
Epoch 00004 | Loss(train) 3.4575 | Acc(train) 0.1820 | Acc(val) 0.1046 |
Epoch 00005 | Loss(train) 3.6785 | Acc(train) 0.1132 | Acc(val) 0.4604 |*
Epoch 00006 | Loss(train) 2.6350 | Acc(train) 0.3662 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.6376 | Acc(train) 0.3546 | Acc(val) 0.4679 |*
Epoch 00008 | Loss(train) 2.5531 | Acc(train) 0.3412 | Acc(val) 0.3460 |
Epoch 00009 | Loss(train) 2.3209 | Acc(train) 0.3004 | Acc(val) 0.3879 |
Epoch 00010 | Loss(train) 2.0827 | Acc(train) 0.3842 | Acc(val) 0.4574 |
Epoch 00011 | Loss(train) 2.0904 | Acc(train) 0.3711 | Acc(val) 0.4013 |
Epoch 00012 | Loss(train) 2.0744 | Acc(train) 0.3479 | Acc(val) 0.5052 |*
Epoch 00013 | Loss(train) 2.0765 | Acc(train) 0.3954 | Acc(val) 0.5374 |*
Epoch 00014 | Loss(train) 2.0002 | Acc(train) 0.3961 | Acc(val) 0.5022 |
Epoch 00015 | Loss(train) 1.8609 | Acc(train) 0.4518 | Acc(val) 0.4163 |
Epoch 00016 | Loss(train) 1.7832 | Acc(train) 0.4496 | Acc(val) 0.4783 |
Epoch 00017 | Loss(train) 1.7674 | Acc(train) 0.4563 | Acc(val) 0.4731 |
Epoch 00018 | Loss(train) 1.8299 | Acc(train) 0.4581 | Acc(val) 0.4746 |
Epoch 00019 | Loss(train) 1.7761 | Acc(train) 0.4697 | Acc(val) 0.5575 |*
Epoch 00020 | Loss(train) 1.6879 | Acc(train) 0.5273 | Acc(val) 0.6428 |*
Epoch 00021 | Loss(train) 1.6048 | Acc(train) 0.5807 | Acc(val) 0.6480 |*
Epoch 00022 | Loss(train) 1.5776 | Acc(train) 0.5736 | Acc(val) 0.6054 |
Epoch 00023 | Loss(train) 1.5672 | Acc(train) 0.5411 | Acc(val) 0.6353 |
Epoch 00024 | Loss(train) 1.5239 | Acc(train) 0.5538 | Acc(val) 0.6951 |*
Epoch 00025 | Loss(train) 1.4923 | Acc(train) 0.5878 | Acc(val) 0.7055 |*
Epoch 00026 | Loss(train) 1.4486 | Acc(train) 0.5964 | Acc(val) 0.6629 |
Epoch 00027 | Loss(train) 1.4483 | Acc(train) 0.5878 | Acc(val) 0.6480 |
Epoch 00028 | Loss(train) 1.4285 | Acc(train) 0.5583 | Acc(val) 0.6465 |
Epoch 00029 | Loss(train) 1.3999 | Acc(train) 0.5807 | Acc(val) 0.6779 |
Epoch 00030 | Loss(train) 1.3897 | Acc(train) 0.5930 | Acc(val) 0.6988 |
Epoch 00031 | Loss(train) 1.3217 | Acc(train) 0.6312 | Acc(val) 0.7078 |*
Epoch 00032 | Loss(train) 1.3090 | Acc(train) 0.6428 | Acc(val) 0.7190 |*
Epoch 00033 | Loss(train) 1.2964 | Acc(train) 0.6390 | Acc(val) 0.7108 |
Epoch 00034 | Loss(train) 1.2372 | Acc(train) 0.6629 | Acc(val) 0.7003 |
Epoch 00035 | Loss(train) 1.2378 | Acc(train) 0.6540 | Acc(val) 0.7025 |
Epoch 00036 | Loss(train) 1.2226 | Acc(train) 0.6663 | Acc(val) 0.7227 |*
Epoch 00037 | Loss(train) 1.1825 | Acc(train) 0.6771 | Acc(val) 0.7257 |*
Epoch 00038 | Loss(train) 1.1922 | Acc(train) 0.6760 | Acc(val) 0.7197 |
Epoch 00039 | Loss(train) 1.1321 | Acc(train) 0.6921 | Acc(val) 0.7302 |*
Epoch 00040 | Loss(train) 1.1170 | Acc(train) 0.6887 | Acc(val) 0.7317 |*
Epoch 00041 | Loss(train) 1.1089 | Acc(train) 0.6764 | Acc(val) 0.7309 |
Epoch 00042 | Loss(train) 1.1036 | Acc(train) 0.6719 | Acc(val) 0.7317 |
Epoch 00043 | Loss(train) 1.0843 | Acc(train) 0.6786 | Acc(val) 0.7362 |*
Epoch 00044 | Loss(train) 1.0447 | Acc(train) 0.6749 | Acc(val) 0.7362 |
Epoch 00045 | Loss(train) 1.0300 | Acc(train) 0.6925 | Acc(val) 0.7339 |
Epoch 00046 | Loss(train) 1.0037 | Acc(train) 0.6958 | Acc(val) 0.7324 |
Epoch 00047 | Loss(train) 1.0133 | Acc(train) 0.6996 | Acc(val) 0.7332 |
Epoch 00048 | Loss(train) 1.0241 | Acc(train) 0.6996 | Acc(val) 0.7377 |*
Epoch 00049 | Loss(train) 0.9802 | Acc(train) 0.7093 | Acc(val) 0.7444 |*
Epoch 00050 | Loss(train) 0.9628 | Acc(train) 0.7126 | Acc(val) 0.7481 |*
Epoch 00051 | Loss(train) 0.9829 | Acc(train) 0.7014 | Acc(val) 0.7541 |*
Epoch 00052 | Loss(train) 0.9395 | Acc(train) 0.7227 | Acc(val) 0.7631 |*
Epoch 00053 | Loss(train) 0.9440 | Acc(train) 0.7044 | Acc(val) 0.7683 |*
Epoch 00054 | Loss(train) 0.9338 | Acc(train) 0.7186 | Acc(val) 0.7631 |
Epoch 00055 | Loss(train) 0.9053 | Acc(train) 0.7194 | Acc(val) 0.7556 |
Epoch 00056 | Loss(train) 0.9062 | Acc(train) 0.7130 | Acc(val) 0.7623 |
Epoch 00057 | Loss(train) 0.8752 | Acc(train) 0.7268 | Acc(val) 0.7706 |*
Epoch 00058 | Loss(train) 0.8637 | Acc(train) 0.7336 | Acc(val) 0.7788 |*
Epoch 00059 | Loss(train) 0.8709 | Acc(train) 0.7403 | Acc(val) 0.7870 |*
Epoch 00060 | Loss(train) 0.8327 | Acc(train) 0.7567 | Acc(val) 0.7765 |
Epoch 00061 | Loss(train) 0.8409 | Acc(train) 0.7369 | Acc(val) 0.7848 |
Epoch 00062 | Loss(train) 0.8018 | Acc(train) 0.7605 | Acc(val) 0.7952 |*
Epoch 00063 | Loss(train) 0.8189 | Acc(train) 0.7578 | Acc(val) 0.8004 |*
Epoch 00064 | Loss(train) 0.8075 | Acc(train) 0.7605 | Acc(val) 0.8027 |*
Epoch 00065 | Loss(train) 0.7944 | Acc(train) 0.7515 | Acc(val) 0.7990 |
Epoch 00066 | Loss(train) 0.8058 | Acc(train) 0.7496 | Acc(val) 0.7982 |
Epoch 00067 | Loss(train) 0.7926 | Acc(train) 0.7530 | Acc(val) 0.8057 |*
Epoch 00068 | Loss(train) 0.7687 | Acc(train) 0.7769 | Acc(val) 0.8132 |*
Epoch 00069 | Loss(train) 0.7555 | Acc(train) 0.7649 | Acc(val) 0.8169 |*
Epoch 00070 | Loss(train) 0.7517 | Acc(train) 0.7844 | Acc(val) 0.8259 |*
Epoch 00071 | Loss(train) 0.7503 | Acc(train) 0.7896 | Acc(val) 0.8259 |
Epoch 00072 | Loss(train) 0.7271 | Acc(train) 0.7896 | Acc(val) 0.8244 |
Epoch 00073 | Loss(train) 0.7248 | Acc(train) 0.7874 | Acc(val) 0.8229 |
Epoch 00074 | Loss(train) 0.7136 | Acc(train) 0.7904 | Acc(val) 0.8348 |*
Epoch 00075 | Loss(train) 0.7212 | Acc(train) 0.7784 | Acc(val) 0.8266 |
Epoch 00076 | Loss(train) 0.7115 | Acc(train) 0.7866 | Acc(val) 0.8288 |
Epoch 00077 | Loss(train) 0.6927 | Acc(train) 0.7900 | Acc(val) 0.8371 |*
Epoch 00078 | Loss(train) 0.6694 | Acc(train) 0.8083 | Acc(val) 0.8333 |
Epoch 00079 | Loss(train) 0.6926 | Acc(train) 0.7844 | Acc(val) 0.8341 |
Epoch 00080 | Loss(train) 0.6697 | Acc(train) 0.7982 | Acc(val) 0.8475 |*
Epoch 00081 | Loss(train) 0.6778 | Acc(train) 0.7911 | Acc(val) 0.8423 |
Epoch 00082 | Loss(train) 0.6672 | Acc(train) 0.7859 | Acc(val) 0.8468 |
Epoch 00083 | Loss(train) 0.6422 | Acc(train) 0.8016 | Acc(val) 0.8505 |*
Epoch 00084 | Loss(train) 0.6615 | Acc(train) 0.8098 | Acc(val) 0.8430 |
Epoch 00085 | Loss(train) 0.6451 | Acc(train) 0.8087 | Acc(val) 0.8356 |
Epoch 00086 | Loss(train) 0.6559 | Acc(train) 0.8034 | Acc(val) 0.8498 |
Epoch 00087 | Loss(train) 0.6254 | Acc(train) 0.8132 | Acc(val) 0.8543 |*
Epoch 00088 | Loss(train) 0.6371 | Acc(train) 0.8053 | Acc(val) 0.8505 |
Epoch 00089 | Loss(train) 0.6087 | Acc(train) 0.8120 | Acc(val) 0.8528 |
Epoch 00090 | Loss(train) 0.6194 | Acc(train) 0.8169 | Acc(val) 0.8625 |*
Epoch 00091 | Loss(train) 0.6169 | Acc(train) 0.8139 | Acc(val) 0.8528 |
Epoch 00092 | Loss(train) 0.5997 | Acc(train) 0.8188 | Acc(val) 0.8423 |
Epoch 00093 | Loss(train) 0.6070 | Acc(train) 0.8098 | Acc(val) 0.8670 |*
Epoch 00094 | Loss(train) 0.6257 | Acc(train) 0.8034 | Acc(val) 0.8632 |
Epoch 00095 | Loss(train) 0.6022 | Acc(train) 0.8176 | Acc(val) 0.8625 |
Epoch 00096 | Loss(train) 0.5757 | Acc(train) 0.8326 | Acc(val) 0.8416 |
Epoch 00097 | Loss(train) 0.6079 | Acc(train) 0.8042 | Acc(val) 0.8670 |
Epoch 00098 | Loss(train) 0.5890 | Acc(train) 0.8113 | Acc(val) 0.8632 |
Epoch 00099 | Loss(train) 0.5979 | Acc(train) 0.8154 | Acc(val) 0.8752 |*
Epoch 00100 | Loss(train) 0.6030 | Acc(train) 0.8180 | Acc(val) 0.8655 |
Epoch 00101 | Loss(train) 0.5819 | Acc(train) 0.8259 | Acc(val) 0.8438 |
Epoch 00102 | Loss(train) 0.5963 | Acc(train) 0.8128 | Acc(val) 0.8580 |
Epoch 00103 | Loss(train) 0.5934 | Acc(train) 0.8259 | Acc(val) 0.8677 |
Epoch 00104 | Loss(train) 0.5964 | Acc(train) 0.8225 | Acc(val) 0.8647 |
Epoch 00105 | Loss(train) 0.5692 | Acc(train) 0.8173 | Acc(val) 0.8602 |
Epoch 00106 | Loss(train) 0.5684 | Acc(train) 0.8277 | Acc(val) 0.8729 |
Epoch 00107 | Loss(train) 0.5685 | Acc(train) 0.8262 | Acc(val) 0.8714 |
Epoch 00108 | Loss(train) 0.5610 | Acc(train) 0.8318 | Acc(val) 0.8767 |*
Epoch 00109 | Loss(train) 0.5564 | Acc(train) 0.8371 | Acc(val) 0.8797 |*
Epoch 00110 | Loss(train) 0.5473 | Acc(train) 0.8389 | Acc(val) 0.8640 |
Epoch 00111 | Loss(train) 0.5531 | Acc(train) 0.8285 | Acc(val) 0.8528 |
Epoch 00112 | Loss(train) 0.5640 | Acc(train) 0.8296 | Acc(val) 0.8707 |
Epoch 00113 | Loss(train) 0.5338 | Acc(train) 0.8307 | Acc(val) 0.8707 |
Epoch 00114 | Loss(train) 0.5522 | Acc(train) 0.8307 | Acc(val) 0.8685 |
Epoch 00115 | Loss(train) 0.5526 | Acc(train) 0.8285 | Acc(val) 0.8729 |
Epoch 00116 | Loss(train) 0.5431 | Acc(train) 0.8311 | Acc(val) 0.8692 |
Epoch 00117 | Loss(train) 0.5170 | Acc(train) 0.8449 | Acc(val) 0.8707 |
Epoch 00118 | Loss(train) 0.5567 | Acc(train) 0.8210 | Acc(val) 0.8759 |
Epoch 00119 | Loss(train) 0.5541 | Acc(train) 0.8296 | Acc(val) 0.8767 |
Epoch 00120 | Loss(train) 0.5382 | Acc(train) 0.8277 | Acc(val) 0.8602 |
Epoch 00121 | Loss(train) 0.5217 | Acc(train) 0.8404 | Acc(val) 0.8558 |
Epoch 00122 | Loss(train) 0.5087 | Acc(train) 0.8483 | Acc(val) 0.8685 |
Epoch 00123 | Loss(train) 0.5084 | Acc(train) 0.8487 | Acc(val) 0.8700 |
Epoch 00124 | Loss(train) 0.5470 | Acc(train) 0.8221 | Acc(val) 0.8849 |*
Epoch 00125 | Loss(train) 0.5265 | Acc(train) 0.8427 | Acc(val) 0.8737 |
Epoch 00126 | Loss(train) 0.5356 | Acc(train) 0.8352 | Acc(val) 0.8662 |
Epoch 00127 | Loss(train) 0.5203 | Acc(train) 0.8348 | Acc(val) 0.8729 |
Epoch 00128 | Loss(train) 0.5170 | Acc(train) 0.8318 | Acc(val) 0.8714 |
Epoch 00129 | Loss(train) 0.5127 | Acc(train) 0.8382 | Acc(val) 0.8752 |
Epoch 00130 | Loss(train) 0.5093 | Acc(train) 0.8359 | Acc(val) 0.8662 |
Epoch 00131 | Loss(train) 0.5127 | Acc(train) 0.8427 | Acc(val) 0.8752 |
Epoch 00132 | Loss(train) 0.5031 | Acc(train) 0.8472 | Acc(val) 0.8744 |
Epoch 00133 | Loss(train) 0.5150 | Acc(train) 0.8341 | Acc(val) 0.8722 |
Epoch 00134 | Loss(train) 0.5016 | Acc(train) 0.8419 | Acc(val) 0.8722 |
Epoch 00135 | Loss(train) 0.5058 | Acc(train) 0.8464 | Acc(val) 0.8767 |
Epoch 00136 | Loss(train) 0.5176 | Acc(train) 0.8397 | Acc(val) 0.8744 |
Epoch 00137 | Loss(train) 0.5168 | Acc(train) 0.8445 | Acc(val) 0.8744 |
Epoch 00138 | Loss(train) 0.5170 | Acc(train) 0.8300 | Acc(val) 0.8744 |
Epoch 00139 | Loss(train) 0.5006 | Acc(train) 0.8483 | Acc(val) 0.8729 |
Epoch 00140 | Loss(train) 0.4983 | Acc(train) 0.8438 | Acc(val) 0.8842 |
Epoch 00141 | Loss(train) 0.5089 | Acc(train) 0.8442 | Acc(val) 0.8677 |
Epoch 00142 | Loss(train) 0.4972 | Acc(train) 0.8468 | Acc(val) 0.8714 |
Epoch 00143 | Loss(train) 0.4977 | Acc(train) 0.8401 | Acc(val) 0.8767 |
Epoch 00144 | Loss(train) 0.4944 | Acc(train) 0.8389 | Acc(val) 0.8774 |
Epoch 00145 | Loss(train) 0.4950 | Acc(train) 0.8479 | Acc(val) 0.8744 |
Epoch 00146 | Loss(train) 0.4877 | Acc(train) 0.8509 | Acc(val) 0.8714 |
Epoch 00147 | Loss(train) 0.4802 | Acc(train) 0.8516 | Acc(val) 0.8789 |
Epoch 00148 | Loss(train) 0.4782 | Acc(train) 0.8572 | Acc(val) 0.8827 |
Epoch 00149 | Loss(train) 0.4792 | Acc(train) 0.8509 | Acc(val) 0.8729 |
Epoch 00150 | Loss(train) 0.4998 | Acc(train) 0.8363 | Acc(val) 0.8752 |
Epoch 00151 | Loss(train) 0.4751 | Acc(train) 0.8487 | Acc(val) 0.8871 |*
Epoch 00152 | Loss(train) 0.4815 | Acc(train) 0.8535 | Acc(val) 0.8842 |
Epoch 00153 | Loss(train) 0.4911 | Acc(train) 0.8464 | Acc(val) 0.8842 |
Epoch 00154 | Loss(train) 0.4740 | Acc(train) 0.8520 | Acc(val) 0.8707 |
Epoch 00155 | Loss(train) 0.4833 | Acc(train) 0.8475 | Acc(val) 0.8767 |
Epoch 00156 | Loss(train) 0.4801 | Acc(train) 0.8498 | Acc(val) 0.8827 |
Epoch 00157 | Loss(train) 0.4803 | Acc(train) 0.8501 | Acc(val) 0.8812 |
Epoch 00158 | Loss(train) 0.4861 | Acc(train) 0.8464 | Acc(val) 0.8700 |
Epoch 00159 | Loss(train) 0.4780 | Acc(train) 0.8490 | Acc(val) 0.8767 |
Epoch 00160 | Loss(train) 0.4870 | Acc(train) 0.8487 | Acc(val) 0.8886 |*
Epoch 00161 | Loss(train) 0.4734 | Acc(train) 0.8584 | Acc(val) 0.8894 |*
Epoch 00162 | Loss(train) 0.4619 | Acc(train) 0.8561 | Acc(val) 0.8797 |
Epoch 00163 | Loss(train) 0.4769 | Acc(train) 0.8610 | Acc(val) 0.8737 |
Epoch 00164 | Loss(train) 0.4688 | Acc(train) 0.8479 | Acc(val) 0.8774 |
Epoch 00165 | Loss(train) 0.4749 | Acc(train) 0.8427 | Acc(val) 0.8827 |
Epoch 00166 | Loss(train) 0.4799 | Acc(train) 0.8550 | Acc(val) 0.8849 |
Epoch 00167 | Loss(train) 0.4793 | Acc(train) 0.8520 | Acc(val) 0.8752 |
Epoch 00168 | Loss(train) 0.4619 | Acc(train) 0.8490 | Acc(val) 0.8804 |
Epoch 00169 | Loss(train) 0.4636 | Acc(train) 0.8505 | Acc(val) 0.8842 |
Epoch 00170 | Loss(train) 0.4686 | Acc(train) 0.8550 | Acc(val) 0.8819 |
Epoch 00171 | Loss(train) 0.4700 | Acc(train) 0.8543 | Acc(val) 0.8707 |
Epoch 00172 | Loss(train) 0.4749 | Acc(train) 0.8472 | Acc(val) 0.8864 |
Epoch 00173 | Loss(train) 0.4629 | Acc(train) 0.8528 | Acc(val) 0.8842 |
Epoch 00174 | Loss(train) 0.5000 | Acc(train) 0.8479 | Acc(val) 0.8842 |
Epoch 00175 | Loss(train) 0.4736 | Acc(train) 0.8561 | Acc(val) 0.8625 |
Epoch 00176 | Loss(train) 0.4767 | Acc(train) 0.8401 | Acc(val) 0.8789 |
Epoch 00177 | Loss(train) 0.4562 | Acc(train) 0.8617 | Acc(val) 0.8864 |
Epoch 00178 | Loss(train) 0.4819 | Acc(train) 0.8546 | Acc(val) 0.8857 |
Epoch 00179 | Loss(train) 0.4756 | Acc(train) 0.8509 | Acc(val) 0.8812 |
Epoch 00180 | Loss(train) 0.4695 | Acc(train) 0.8472 | Acc(val) 0.8759 |
Epoch 00181 | Loss(train) 0.4667 | Acc(train) 0.8468 | Acc(val) 0.8827 |
Epoch 00182 | Loss(train) 0.4764 | Acc(train) 0.8535 | Acc(val) 0.8894 |
Epoch 00183 | Loss(train) 0.4598 | Acc(train) 0.8625 | Acc(val) 0.8864 |
Epoch 00184 | Loss(train) 0.4574 | Acc(train) 0.8595 | Acc(val) 0.8767 |
Epoch 00185 | Loss(train) 0.4561 | Acc(train) 0.8524 | Acc(val) 0.8842 |
Epoch 00186 | Loss(train) 0.4795 | Acc(train) 0.8464 | Acc(val) 0.8812 |
Epoch 00187 | Loss(train) 0.4607 | Acc(train) 0.8591 | Acc(val) 0.8886 |
Epoch 00188 | Loss(train) 0.4453 | Acc(train) 0.8666 | Acc(val) 0.8849 |
Epoch 00189 | Loss(train) 0.4718 | Acc(train) 0.8505 | Acc(val) 0.8827 |
Epoch 00190 | Loss(train) 0.4576 | Acc(train) 0.8479 | Acc(val) 0.8842 |
Epoch 00191 | Loss(train) 0.4683 | Acc(train) 0.8516 | Acc(val) 0.8871 |
Epoch 00192 | Loss(train) 0.4561 | Acc(train) 0.8599 | Acc(val) 0.8804 |
Epoch 00193 | Loss(train) 0.4440 | Acc(train) 0.8606 | Acc(val) 0.8804 |
Epoch 00194 | Loss(train) 0.4566 | Acc(train) 0.8516 | Acc(val) 0.8857 |
Epoch 00195 | Loss(train) 0.4456 | Acc(train) 0.8610 | Acc(val) 0.8909 |*
Epoch 00196 | Loss(train) 0.4589 | Acc(train) 0.8554 | Acc(val) 0.8901 |
Epoch 00197 | Loss(train) 0.4483 | Acc(train) 0.8572 | Acc(val) 0.8901 |
Epoch 00198 | Loss(train) 0.4458 | Acc(train) 0.8599 | Acc(val) 0.8909 |
Epoch 00199 | Loss(train) 0.4552 | Acc(train) 0.8670 | Acc(val) 0.8931 |*
Epoch 00200 | Loss(train) 0.4434 | Acc(train) 0.8666 | Acc(val) 0.8767 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 2/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.1713 | Acc(train) 0.3472 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 4.7430 | Acc(train) 0.3681 | Acc(val) 0.2399 |
Epoch 00003 | Loss(train) 4.8859 | Acc(train) 0.1618 | Acc(val) 0.1046 |
Epoch 00004 | Loss(train) 5.2890 | Acc(train) 0.1420 | Acc(val) 0.1390 |
Epoch 00005 | Loss(train) 3.4470 | Acc(train) 0.1592 | Acc(val) 0.1330 |
Epoch 00006 | Loss(train) 2.6665 | Acc(train) 0.1166 | Acc(val) 0.4028 |*
Epoch 00007 | Loss(train) 2.2247 | Acc(train) 0.3621 | Acc(val) 0.3714 |
Epoch 00008 | Loss(train) 2.7859 | Acc(train) 0.3658 | Acc(val) 0.3714 |
Epoch 00009 | Loss(train) 2.7569 | Acc(train) 0.3685 | Acc(val) 0.3924 |
Epoch 00010 | Loss(train) 2.1860 | Acc(train) 0.4017 | Acc(val) 0.6151 |*
Epoch 00011 | Loss(train) 1.9621 | Acc(train) 0.4574 | Acc(val) 0.5673 |
Epoch 00012 | Loss(train) 1.9926 | Acc(train) 0.4107 | Acc(val) 0.5120 |
Epoch 00013 | Loss(train) 1.8769 | Acc(train) 0.4193 | Acc(val) 0.6868 |*
Epoch 00014 | Loss(train) 1.7241 | Acc(train) 0.5523 | Acc(val) 0.6480 |
Epoch 00015 | Loss(train) 1.6191 | Acc(train) 0.5830 | Acc(val) 0.5299 |
Epoch 00016 | Loss(train) 1.6392 | Acc(train) 0.5198 | Acc(val) 0.4865 |
Epoch 00017 | Loss(train) 1.6689 | Acc(train) 0.4914 | Acc(val) 0.4813 |
Epoch 00018 | Loss(train) 1.6540 | Acc(train) 0.4746 | Acc(val) 0.4880 |
Epoch 00019 | Loss(train) 1.6144 | Acc(train) 0.4993 | Acc(val) 0.5224 |
Epoch 00020 | Loss(train) 1.5452 | Acc(train) 0.5318 | Acc(val) 0.6106 |
Epoch 00021 | Loss(train) 1.4775 | Acc(train) 0.5725 | Acc(val) 0.6562 |
Epoch 00022 | Loss(train) 1.4405 | Acc(train) 0.6181 | Acc(val) 0.6697 |
Epoch 00023 | Loss(train) 1.3985 | Acc(train) 0.6267 | Acc(val) 0.6689 |
Epoch 00024 | Loss(train) 1.3768 | Acc(train) 0.6398 | Acc(val) 0.6562 |
Epoch 00025 | Loss(train) 1.3789 | Acc(train) 0.6140 | Acc(val) 0.6734 |
Epoch 00026 | Loss(train) 1.3610 | Acc(train) 0.6345 | Acc(val) 0.7078 |*
Epoch 00027 | Loss(train) 1.3386 | Acc(train) 0.6129 | Acc(val) 0.7197 |*
Epoch 00028 | Loss(train) 1.3241 | Acc(train) 0.6248 | Acc(val) 0.7108 |
Epoch 00029 | Loss(train) 1.3070 | Acc(train) 0.6241 | Acc(val) 0.7055 |
Epoch 00030 | Loss(train) 1.2692 | Acc(train) 0.6259 | Acc(val) 0.7033 |
Epoch 00031 | Loss(train) 1.2475 | Acc(train) 0.6383 | Acc(val) 0.7190 |
Epoch 00032 | Loss(train) 1.2005 | Acc(train) 0.6499 | Acc(val) 0.7265 |*
Epoch 00033 | Loss(train) 1.2065 | Acc(train) 0.6685 | Acc(val) 0.7287 |*
Epoch 00034 | Loss(train) 1.1823 | Acc(train) 0.6797 | Acc(val) 0.7257 |
Epoch 00035 | Loss(train) 1.1812 | Acc(train) 0.6659 | Acc(val) 0.7272 |
Epoch 00036 | Loss(train) 1.1276 | Acc(train) 0.6906 | Acc(val) 0.7145 |
Epoch 00037 | Loss(train) 1.1415 | Acc(train) 0.6790 | Acc(val) 0.6966 |
Epoch 00038 | Loss(train) 1.1209 | Acc(train) 0.6663 | Acc(val) 0.6981 |
Epoch 00039 | Loss(train) 1.1246 | Acc(train) 0.6614 | Acc(val) 0.7085 |
Epoch 00040 | Loss(train) 1.1137 | Acc(train) 0.6592 | Acc(val) 0.7235 |
Epoch 00041 | Loss(train) 1.0753 | Acc(train) 0.6809 | Acc(val) 0.7287 |
Epoch 00042 | Loss(train) 1.0838 | Acc(train) 0.6775 | Acc(val) 0.7339 |*
Epoch 00043 | Loss(train) 1.0504 | Acc(train) 0.6977 | Acc(val) 0.7347 |*
Epoch 00044 | Loss(train) 1.0506 | Acc(train) 0.6883 | Acc(val) 0.7317 |
Epoch 00045 | Loss(train) 1.0218 | Acc(train) 0.6925 | Acc(val) 0.7317 |
Epoch 00046 | Loss(train) 1.0189 | Acc(train) 0.6756 | Acc(val) 0.7317 |
Epoch 00047 | Loss(train) 0.9908 | Acc(train) 0.6812 | Acc(val) 0.7369 |*
Epoch 00048 | Loss(train) 0.9940 | Acc(train) 0.6951 | Acc(val) 0.7496 |*
Epoch 00049 | Loss(train) 0.9735 | Acc(train) 0.7059 | Acc(val) 0.7534 |*
Epoch 00050 | Loss(train) 0.9681 | Acc(train) 0.7055 | Acc(val) 0.7676 |*
Epoch 00051 | Loss(train) 0.9446 | Acc(train) 0.7179 | Acc(val) 0.7571 |
Epoch 00052 | Loss(train) 0.9451 | Acc(train) 0.7145 | Acc(val) 0.7541 |
Epoch 00053 | Loss(train) 0.9365 | Acc(train) 0.7074 | Acc(val) 0.7608 |
Epoch 00054 | Loss(train) 0.8815 | Acc(train) 0.7324 | Acc(val) 0.7728 |*
Epoch 00055 | Loss(train) 0.9060 | Acc(train) 0.7231 | Acc(val) 0.7840 |*
Epoch 00056 | Loss(train) 0.8949 | Acc(train) 0.7339 | Acc(val) 0.7795 |
Epoch 00057 | Loss(train) 0.8881 | Acc(train) 0.7384 | Acc(val) 0.7683 |
Epoch 00058 | Loss(train) 0.8536 | Acc(train) 0.7377 | Acc(val) 0.7758 |
Epoch 00059 | Loss(train) 0.8479 | Acc(train) 0.7302 | Acc(val) 0.7907 |*
Epoch 00060 | Loss(train) 0.8427 | Acc(train) 0.7283 | Acc(val) 0.7997 |*
Epoch 00061 | Loss(train) 0.8054 | Acc(train) 0.7549 | Acc(val) 0.7960 |
Epoch 00062 | Loss(train) 0.7978 | Acc(train) 0.7567 | Acc(val) 0.8012 |*
Epoch 00063 | Loss(train) 0.7971 | Acc(train) 0.7623 | Acc(val) 0.8004 |
Epoch 00064 | Loss(train) 0.7888 | Acc(train) 0.7485 | Acc(val) 0.7975 |
Epoch 00065 | Loss(train) 0.7854 | Acc(train) 0.7627 | Acc(val) 0.8064 |*
Epoch 00066 | Loss(train) 0.7621 | Acc(train) 0.7676 | Acc(val) 0.8154 |*
Epoch 00067 | Loss(train) 0.7458 | Acc(train) 0.7691 | Acc(val) 0.8102 |
Epoch 00068 | Loss(train) 0.7416 | Acc(train) 0.7657 | Acc(val) 0.8064 |
Epoch 00069 | Loss(train) 0.7526 | Acc(train) 0.7750 | Acc(val) 0.8191 |*
Epoch 00070 | Loss(train) 0.7298 | Acc(train) 0.7806 | Acc(val) 0.8356 |*
Epoch 00071 | Loss(train) 0.7157 | Acc(train) 0.7732 | Acc(val) 0.8303 |
Epoch 00072 | Loss(train) 0.7030 | Acc(train) 0.7795 | Acc(val) 0.8236 |
Epoch 00073 | Loss(train) 0.7020 | Acc(train) 0.7803 | Acc(val) 0.8236 |
Epoch 00074 | Loss(train) 0.6734 | Acc(train) 0.7948 | Acc(val) 0.8251 |
Epoch 00075 | Loss(train) 0.7063 | Acc(train) 0.7784 | Acc(val) 0.8229 |
Epoch 00076 | Loss(train) 0.6953 | Acc(train) 0.7810 | Acc(val) 0.8274 |
Epoch 00077 | Loss(train) 0.6899 | Acc(train) 0.7930 | Acc(val) 0.8423 |*
Epoch 00078 | Loss(train) 0.6826 | Acc(train) 0.7877 | Acc(val) 0.8356 |
Epoch 00079 | Loss(train) 0.6528 | Acc(train) 0.8109 | Acc(val) 0.8296 |
Epoch 00080 | Loss(train) 0.6679 | Acc(train) 0.8087 | Acc(val) 0.8408 |
Epoch 00081 | Loss(train) 0.6526 | Acc(train) 0.8042 | Acc(val) 0.8408 |
Epoch 00082 | Loss(train) 0.6539 | Acc(train) 0.8004 | Acc(val) 0.8348 |
Epoch 00083 | Loss(train) 0.6658 | Acc(train) 0.8001 | Acc(val) 0.8318 |
Epoch 00084 | Loss(train) 0.6347 | Acc(train) 0.7933 | Acc(val) 0.8408 |
Epoch 00085 | Loss(train) 0.6253 | Acc(train) 0.8124 | Acc(val) 0.8423 |
Epoch 00086 | Loss(train) 0.6397 | Acc(train) 0.8090 | Acc(val) 0.8303 |
Epoch 00087 | Loss(train) 0.6238 | Acc(train) 0.8090 | Acc(val) 0.8416 |
Epoch 00088 | Loss(train) 0.5844 | Acc(train) 0.8180 | Acc(val) 0.8490 |*
Epoch 00089 | Loss(train) 0.6116 | Acc(train) 0.7990 | Acc(val) 0.8468 |
Epoch 00090 | Loss(train) 0.6216 | Acc(train) 0.8068 | Acc(val) 0.8513 |*
Epoch 00091 | Loss(train) 0.5950 | Acc(train) 0.8251 | Acc(val) 0.8558 |*
Epoch 00092 | Loss(train) 0.5956 | Acc(train) 0.8232 | Acc(val) 0.8610 |*
Epoch 00093 | Loss(train) 0.5885 | Acc(train) 0.8169 | Acc(val) 0.8602 |
Epoch 00094 | Loss(train) 0.5891 | Acc(train) 0.8165 | Acc(val) 0.8475 |
Epoch 00095 | Loss(train) 0.5795 | Acc(train) 0.8236 | Acc(val) 0.8528 |
Epoch 00096 | Loss(train) 0.5851 | Acc(train) 0.8165 | Acc(val) 0.8685 |*
Epoch 00097 | Loss(train) 0.5816 | Acc(train) 0.8303 | Acc(val) 0.8647 |
Epoch 00098 | Loss(train) 0.5749 | Acc(train) 0.8307 | Acc(val) 0.8595 |
Epoch 00099 | Loss(train) 0.5740 | Acc(train) 0.8236 | Acc(val) 0.8662 |
Epoch 00100 | Loss(train) 0.5609 | Acc(train) 0.8337 | Acc(val) 0.8700 |*
Epoch 00101 | Loss(train) 0.5811 | Acc(train) 0.8169 | Acc(val) 0.8729 |*
Epoch 00102 | Loss(train) 0.5696 | Acc(train) 0.8311 | Acc(val) 0.8617 |
Epoch 00103 | Loss(train) 0.5766 | Acc(train) 0.8221 | Acc(val) 0.8670 |
Epoch 00104 | Loss(train) 0.5699 | Acc(train) 0.8363 | Acc(val) 0.8729 |
Epoch 00105 | Loss(train) 0.5642 | Acc(train) 0.8247 | Acc(val) 0.8550 |
Epoch 00106 | Loss(train) 0.5387 | Acc(train) 0.8363 | Acc(val) 0.8602 |
Epoch 00107 | Loss(train) 0.5805 | Acc(train) 0.8176 | Acc(val) 0.8692 |
Epoch 00108 | Loss(train) 0.5630 | Acc(train) 0.8333 | Acc(val) 0.8744 |*
Epoch 00109 | Loss(train) 0.5524 | Acc(train) 0.8386 | Acc(val) 0.8587 |
Epoch 00110 | Loss(train) 0.5516 | Acc(train) 0.8374 | Acc(val) 0.8610 |
Epoch 00111 | Loss(train) 0.5810 | Acc(train) 0.8113 | Acc(val) 0.8685 |
Epoch 00112 | Loss(train) 0.5709 | Acc(train) 0.8225 | Acc(val) 0.8744 |
Epoch 00113 | Loss(train) 0.5518 | Acc(train) 0.8345 | Acc(val) 0.8543 |
Epoch 00114 | Loss(train) 0.5398 | Acc(train) 0.8367 | Acc(val) 0.8640 |
Epoch 00115 | Loss(train) 0.5652 | Acc(train) 0.8300 | Acc(val) 0.8692 |
Epoch 00116 | Loss(train) 0.5375 | Acc(train) 0.8307 | Acc(val) 0.8819 |*
Epoch 00117 | Loss(train) 0.5192 | Acc(train) 0.8453 | Acc(val) 0.8804 |
Epoch 00118 | Loss(train) 0.5261 | Acc(train) 0.8468 | Acc(val) 0.8632 |
Epoch 00119 | Loss(train) 0.5547 | Acc(train) 0.8288 | Acc(val) 0.8729 |
Epoch 00120 | Loss(train) 0.5217 | Acc(train) 0.8453 | Acc(val) 0.8789 |
Epoch 00121 | Loss(train) 0.5202 | Acc(train) 0.8453 | Acc(val) 0.8812 |
Epoch 00122 | Loss(train) 0.5068 | Acc(train) 0.8543 | Acc(val) 0.8759 |
Epoch 00123 | Loss(train) 0.5120 | Acc(train) 0.8460 | Acc(val) 0.8707 |
Epoch 00124 | Loss(train) 0.5183 | Acc(train) 0.8464 | Acc(val) 0.8677 |
Epoch 00125 | Loss(train) 0.5203 | Acc(train) 0.8322 | Acc(val) 0.8812 |
Epoch 00126 | Loss(train) 0.5166 | Acc(train) 0.8367 | Acc(val) 0.8842 |*
Epoch 00127 | Loss(train) 0.5250 | Acc(train) 0.8367 | Acc(val) 0.8789 |
Epoch 00128 | Loss(train) 0.5200 | Acc(train) 0.8341 | Acc(val) 0.8655 |
Epoch 00129 | Loss(train) 0.5126 | Acc(train) 0.8416 | Acc(val) 0.8714 |
Epoch 00130 | Loss(train) 0.5328 | Acc(train) 0.8318 | Acc(val) 0.8774 |
Epoch 00131 | Loss(train) 0.5012 | Acc(train) 0.8546 | Acc(val) 0.8819 |
Epoch 00132 | Loss(train) 0.5328 | Acc(train) 0.8445 | Acc(val) 0.8819 |
Epoch 00133 | Loss(train) 0.5032 | Acc(train) 0.8419 | Acc(val) 0.8744 |
Epoch 00134 | Loss(train) 0.5030 | Acc(train) 0.8460 | Acc(val) 0.8767 |
Epoch 00135 | Loss(train) 0.4886 | Acc(train) 0.8479 | Acc(val) 0.8797 |
Epoch 00136 | Loss(train) 0.5215 | Acc(train) 0.8423 | Acc(val) 0.8804 |
Epoch 00137 | Loss(train) 0.5143 | Acc(train) 0.8442 | Acc(val) 0.8625 |
Epoch 00138 | Loss(train) 0.4992 | Acc(train) 0.8487 | Acc(val) 0.8737 |
Epoch 00139 | Loss(train) 0.5131 | Acc(train) 0.8457 | Acc(val) 0.8819 |
Epoch 00140 | Loss(train) 0.5062 | Acc(train) 0.8464 | Acc(val) 0.8842 |
Epoch 00141 | Loss(train) 0.5221 | Acc(train) 0.8401 | Acc(val) 0.8744 |
Epoch 00142 | Loss(train) 0.5072 | Acc(train) 0.8374 | Acc(val) 0.8797 |
Epoch 00143 | Loss(train) 0.4969 | Acc(train) 0.8453 | Acc(val) 0.8834 |
Epoch 00144 | Loss(train) 0.5086 | Acc(train) 0.8472 | Acc(val) 0.8857 |*
Epoch 00145 | Loss(train) 0.4960 | Acc(train) 0.8513 | Acc(val) 0.8774 |
Epoch 00146 | Loss(train) 0.5150 | Acc(train) 0.8389 | Acc(val) 0.8707 |
Epoch 00147 | Loss(train) 0.5168 | Acc(train) 0.8430 | Acc(val) 0.8782 |
Epoch 00148 | Loss(train) 0.4837 | Acc(train) 0.8520 | Acc(val) 0.8871 |*
Epoch 00149 | Loss(train) 0.4951 | Acc(train) 0.8554 | Acc(val) 0.8782 |
Epoch 00150 | Loss(train) 0.4959 | Acc(train) 0.8520 | Acc(val) 0.8789 |
Epoch 00151 | Loss(train) 0.4941 | Acc(train) 0.8416 | Acc(val) 0.8864 |
Epoch 00152 | Loss(train) 0.4799 | Acc(train) 0.8490 | Acc(val) 0.8819 |
Epoch 00153 | Loss(train) 0.4753 | Acc(train) 0.8584 | Acc(val) 0.8767 |
Epoch 00154 | Loss(train) 0.4877 | Acc(train) 0.8490 | Acc(val) 0.8864 |
Epoch 00155 | Loss(train) 0.4861 | Acc(train) 0.8505 | Acc(val) 0.8879 |*
Epoch 00156 | Loss(train) 0.4720 | Acc(train) 0.8434 | Acc(val) 0.8834 |
Epoch 00157 | Loss(train) 0.4930 | Acc(train) 0.8513 | Acc(val) 0.8842 |
Epoch 00158 | Loss(train) 0.4949 | Acc(train) 0.8445 | Acc(val) 0.8842 |
Epoch 00159 | Loss(train) 0.4689 | Acc(train) 0.8475 | Acc(val) 0.8827 |
Epoch 00160 | Loss(train) 0.4897 | Acc(train) 0.8505 | Acc(val) 0.8827 |
Epoch 00161 | Loss(train) 0.4759 | Acc(train) 0.8572 | Acc(val) 0.8842 |
Epoch 00162 | Loss(train) 0.4857 | Acc(train) 0.8445 | Acc(val) 0.8894 |*
Epoch 00163 | Loss(train) 0.4845 | Acc(train) 0.8487 | Acc(val) 0.8804 |
Epoch 00164 | Loss(train) 0.4838 | Acc(train) 0.8494 | Acc(val) 0.8871 |
Epoch 00165 | Loss(train) 0.4946 | Acc(train) 0.8524 | Acc(val) 0.8834 |
Epoch 00166 | Loss(train) 0.4660 | Acc(train) 0.8561 | Acc(val) 0.8864 |
Epoch 00167 | Loss(train) 0.4787 | Acc(train) 0.8520 | Acc(val) 0.8849 |
Epoch 00168 | Loss(train) 0.4689 | Acc(train) 0.8576 | Acc(val) 0.8857 |
Epoch 00169 | Loss(train) 0.4902 | Acc(train) 0.8524 | Acc(val) 0.8857 |
Epoch 00170 | Loss(train) 0.4644 | Acc(train) 0.8584 | Acc(val) 0.8857 |
Epoch 00171 | Loss(train) 0.4898 | Acc(train) 0.8449 | Acc(val) 0.8857 |
Epoch 00172 | Loss(train) 0.4797 | Acc(train) 0.8569 | Acc(val) 0.8879 |
Epoch 00173 | Loss(train) 0.4897 | Acc(train) 0.8498 | Acc(val) 0.8864 |
Epoch 00174 | Loss(train) 0.4719 | Acc(train) 0.8524 | Acc(val) 0.8834 |
Epoch 00175 | Loss(train) 0.4707 | Acc(train) 0.8561 | Acc(val) 0.8767 |
Epoch 00176 | Loss(train) 0.4696 | Acc(train) 0.8569 | Acc(val) 0.8886 |
Epoch 00177 | Loss(train) 0.4633 | Acc(train) 0.8651 | Acc(val) 0.8879 |
Epoch 00178 | Loss(train) 0.4762 | Acc(train) 0.8490 | Acc(val) 0.8871 |
Epoch 00179 | Loss(train) 0.4597 | Acc(train) 0.8647 | Acc(val) 0.8782 |
Epoch 00180 | Loss(train) 0.4655 | Acc(train) 0.8554 | Acc(val) 0.8879 |
Epoch 00181 | Loss(train) 0.4785 | Acc(train) 0.8427 | Acc(val) 0.8834 |
Epoch 00182 | Loss(train) 0.4709 | Acc(train) 0.8505 | Acc(val) 0.8759 |
Epoch 00183 | Loss(train) 0.4618 | Acc(train) 0.8528 | Acc(val) 0.8744 |
Epoch 00184 | Loss(train) 0.4772 | Acc(train) 0.8438 | Acc(val) 0.8901 |*
Epoch 00185 | Loss(train) 0.4695 | Acc(train) 0.8543 | Acc(val) 0.8894 |
Epoch 00186 | Loss(train) 0.4687 | Acc(train) 0.8599 | Acc(val) 0.8707 |
Epoch 00187 | Loss(train) 0.4628 | Acc(train) 0.8543 | Acc(val) 0.8871 |
Epoch 00188 | Loss(train) 0.4667 | Acc(train) 0.8670 | Acc(val) 0.8834 |
Epoch 00189 | Loss(train) 0.4805 | Acc(train) 0.8599 | Acc(val) 0.8879 |
Epoch 00190 | Loss(train) 0.4798 | Acc(train) 0.8494 | Acc(val) 0.8729 |
Epoch 00191 | Loss(train) 0.4658 | Acc(train) 0.8505 | Acc(val) 0.8789 |
Epoch 00192 | Loss(train) 0.4670 | Acc(train) 0.8449 | Acc(val) 0.8871 |
Epoch 00193 | Loss(train) 0.4589 | Acc(train) 0.8666 | Acc(val) 0.8864 |
Epoch 00194 | Loss(train) 0.4596 | Acc(train) 0.8561 | Acc(val) 0.8864 |
Epoch 00195 | Loss(train) 0.4638 | Acc(train) 0.8550 | Acc(val) 0.8939 |*
Epoch 00196 | Loss(train) 0.4601 | Acc(train) 0.8617 | Acc(val) 0.8961 |*
Epoch 00197 | Loss(train) 0.4562 | Acc(train) 0.8621 | Acc(val) 0.8834 |
Epoch 00198 | Loss(train) 0.4562 | Acc(train) 0.8572 | Acc(val) 0.8864 |
Epoch 00199 | Loss(train) 0.4573 | Acc(train) 0.8629 | Acc(val) 0.8879 |
Epoch 00200 | Loss(train) 0.4517 | Acc(train) 0.8591 | Acc(val) 0.8849 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 3/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.5289 | Acc(train) 0.0392 | Acc(val) 0.3722 |*
Epoch 00002 | Loss(train) 2.9015 | Acc(train) 0.3363 | Acc(val) 0.1046 |
Epoch 00003 | Loss(train) 3.0141 | Acc(train) 0.1413 | Acc(val) 0.4275 |*
Epoch 00004 | Loss(train) 2.4638 | Acc(train) 0.2926 | Acc(val) 0.2489 |
Epoch 00005 | Loss(train) 2.2756 | Acc(train) 0.2635 | Acc(val) 0.2152 |
Epoch 00006 | Loss(train) 2.3002 | Acc(train) 0.2608 | Acc(val) 0.4611 |*
Epoch 00007 | Loss(train) 1.9818 | Acc(train) 0.4182 | Acc(val) 0.3789 |
Epoch 00008 | Loss(train) 1.8131 | Acc(train) 0.4241 | Acc(val) 0.4686 |*
Epoch 00009 | Loss(train) 1.8698 | Acc(train) 0.4144 | Acc(val) 0.4701 |*
Epoch 00010 | Loss(train) 1.8486 | Acc(train) 0.4544 | Acc(val) 0.4649 |
Epoch 00011 | Loss(train) 1.7467 | Acc(train) 0.4496 | Acc(val) 0.4910 |*
Epoch 00012 | Loss(train) 1.6606 | Acc(train) 0.4649 | Acc(val) 0.5710 |*
Epoch 00013 | Loss(train) 1.6478 | Acc(train) 0.5448 | Acc(val) 0.5994 |*
Epoch 00014 | Loss(train) 1.6461 | Acc(train) 0.5639 | Acc(val) 0.5463 |
Epoch 00015 | Loss(train) 1.6031 | Acc(train) 0.5265 | Acc(val) 0.5957 |
Epoch 00016 | Loss(train) 1.5504 | Acc(train) 0.5206 | Acc(val) 0.6442 |*
Epoch 00017 | Loss(train) 1.4926 | Acc(train) 0.5766 | Acc(val) 0.6286 |
Epoch 00018 | Loss(train) 1.4483 | Acc(train) 0.5602 | Acc(val) 0.6256 |
Epoch 00019 | Loss(train) 1.4111 | Acc(train) 0.5889 | Acc(val) 0.5867 |
Epoch 00020 | Loss(train) 1.3912 | Acc(train) 0.5654 | Acc(val) 0.6196 |
Epoch 00021 | Loss(train) 1.3252 | Acc(train) 0.5863 | Acc(val) 0.6502 |*
Epoch 00022 | Loss(train) 1.2876 | Acc(train) 0.6076 | Acc(val) 0.6652 |*
Epoch 00023 | Loss(train) 1.3077 | Acc(train) 0.6125 | Acc(val) 0.6891 |*
Epoch 00024 | Loss(train) 1.2403 | Acc(train) 0.6319 | Acc(val) 0.6756 |
Epoch 00025 | Loss(train) 1.2001 | Acc(train) 0.6454 | Acc(val) 0.6689 |
Epoch 00026 | Loss(train) 1.1863 | Acc(train) 0.6390 | Acc(val) 0.6704 |
Epoch 00027 | Loss(train) 1.1631 | Acc(train) 0.6203 | Acc(val) 0.6659 |
Epoch 00028 | Loss(train) 1.0961 | Acc(train) 0.6566 | Acc(val) 0.6786 |
Epoch 00029 | Loss(train) 1.1153 | Acc(train) 0.6424 | Acc(val) 0.7205 |*
Epoch 00030 | Loss(train) 1.0719 | Acc(train) 0.6801 | Acc(val) 0.7294 |*
Epoch 00031 | Loss(train) 1.0457 | Acc(train) 0.6913 | Acc(val) 0.7407 |*
Epoch 00032 | Loss(train) 1.0384 | Acc(train) 0.6936 | Acc(val) 0.7504 |*
Epoch 00033 | Loss(train) 1.0072 | Acc(train) 0.7160 | Acc(val) 0.7593 |*
Epoch 00034 | Loss(train) 0.9894 | Acc(train) 0.7164 | Acc(val) 0.7549 |
Epoch 00035 | Loss(train) 0.9650 | Acc(train) 0.6992 | Acc(val) 0.7504 |
Epoch 00036 | Loss(train) 0.9373 | Acc(train) 0.7160 | Acc(val) 0.7601 |*
Epoch 00037 | Loss(train) 0.9185 | Acc(train) 0.7250 | Acc(val) 0.7616 |*
Epoch 00038 | Loss(train) 0.9101 | Acc(train) 0.7190 | Acc(val) 0.7638 |*
Epoch 00039 | Loss(train) 0.9019 | Acc(train) 0.7152 | Acc(val) 0.7706 |*
Epoch 00040 | Loss(train) 0.8516 | Acc(train) 0.7283 | Acc(val) 0.7810 |*
Epoch 00041 | Loss(train) 0.8634 | Acc(train) 0.7227 | Acc(val) 0.7825 |*
Epoch 00042 | Loss(train) 0.8288 | Acc(train) 0.7362 | Acc(val) 0.7930 |*
Epoch 00043 | Loss(train) 0.8277 | Acc(train) 0.7399 | Acc(val) 0.8019 |*
Epoch 00044 | Loss(train) 0.8284 | Acc(train) 0.7500 | Acc(val) 0.8087 |*
Epoch 00045 | Loss(train) 0.7964 | Acc(train) 0.7549 | Acc(val) 0.8132 |*
Epoch 00046 | Loss(train) 0.7964 | Acc(train) 0.7653 | Acc(val) 0.8184 |*
Epoch 00047 | Loss(train) 0.7640 | Acc(train) 0.7560 | Acc(val) 0.8169 |
Epoch 00048 | Loss(train) 0.7693 | Acc(train) 0.7556 | Acc(val) 0.8274 |*
Epoch 00049 | Loss(train) 0.7405 | Acc(train) 0.7806 | Acc(val) 0.8341 |*
Epoch 00050 | Loss(train) 0.7552 | Acc(train) 0.7720 | Acc(val) 0.8333 |
Epoch 00051 | Loss(train) 0.7389 | Acc(train) 0.7754 | Acc(val) 0.8333 |
Epoch 00052 | Loss(train) 0.7146 | Acc(train) 0.7866 | Acc(val) 0.8326 |
Epoch 00053 | Loss(train) 0.6958 | Acc(train) 0.7806 | Acc(val) 0.8296 |
Epoch 00054 | Loss(train) 0.7109 | Acc(train) 0.7683 | Acc(val) 0.8288 |
Epoch 00055 | Loss(train) 0.6837 | Acc(train) 0.7874 | Acc(val) 0.8386 |*
Epoch 00056 | Loss(train) 0.7053 | Acc(train) 0.7777 | Acc(val) 0.8430 |*
Epoch 00057 | Loss(train) 0.6558 | Acc(train) 0.7978 | Acc(val) 0.8438 |*
Epoch 00058 | Loss(train) 0.6795 | Acc(train) 0.7777 | Acc(val) 0.8483 |*
Epoch 00059 | Loss(train) 0.6787 | Acc(train) 0.7870 | Acc(val) 0.8393 |
Epoch 00060 | Loss(train) 0.6596 | Acc(train) 0.7993 | Acc(val) 0.8416 |
Epoch 00061 | Loss(train) 0.6585 | Acc(train) 0.7952 | Acc(val) 0.8535 |*
Epoch 00062 | Loss(train) 0.6720 | Acc(train) 0.7919 | Acc(val) 0.8498 |
Epoch 00063 | Loss(train) 0.6518 | Acc(train) 0.7926 | Acc(val) 0.8610 |*
Epoch 00064 | Loss(train) 0.6592 | Acc(train) 0.7945 | Acc(val) 0.8580 |
Epoch 00065 | Loss(train) 0.6386 | Acc(train) 0.7960 | Acc(val) 0.8498 |
Epoch 00066 | Loss(train) 0.6428 | Acc(train) 0.8027 | Acc(val) 0.8423 |
Epoch 00067 | Loss(train) 0.6512 | Acc(train) 0.7911 | Acc(val) 0.8550 |
Epoch 00068 | Loss(train) 0.6405 | Acc(train) 0.8143 | Acc(val) 0.8677 |*
Epoch 00069 | Loss(train) 0.6325 | Acc(train) 0.8087 | Acc(val) 0.8602 |
Epoch 00070 | Loss(train) 0.6186 | Acc(train) 0.8090 | Acc(val) 0.8453 |
Epoch 00071 | Loss(train) 0.6198 | Acc(train) 0.8117 | Acc(val) 0.8460 |
Epoch 00072 | Loss(train) 0.5967 | Acc(train) 0.8188 | Acc(val) 0.8572 |
Epoch 00073 | Loss(train) 0.6088 | Acc(train) 0.8120 | Acc(val) 0.8625 |
Epoch 00074 | Loss(train) 0.6316 | Acc(train) 0.7945 | Acc(val) 0.8572 |
Epoch 00075 | Loss(train) 0.5775 | Acc(train) 0.8195 | Acc(val) 0.8438 |
Epoch 00076 | Loss(train) 0.5932 | Acc(train) 0.8146 | Acc(val) 0.8483 |
Epoch 00077 | Loss(train) 0.5805 | Acc(train) 0.8184 | Acc(val) 0.8632 |
Epoch 00078 | Loss(train) 0.5894 | Acc(train) 0.8214 | Acc(val) 0.8700 |*
Epoch 00079 | Loss(train) 0.5911 | Acc(train) 0.8232 | Acc(val) 0.8700 |
Epoch 00080 | Loss(train) 0.5917 | Acc(train) 0.8255 | Acc(val) 0.8602 |
Epoch 00081 | Loss(train) 0.5748 | Acc(train) 0.8210 | Acc(val) 0.8587 |
Epoch 00082 | Loss(train) 0.5894 | Acc(train) 0.8135 | Acc(val) 0.8670 |
Epoch 00083 | Loss(train) 0.5756 | Acc(train) 0.8165 | Acc(val) 0.8737 |*
Epoch 00084 | Loss(train) 0.5633 | Acc(train) 0.8307 | Acc(val) 0.8640 |
Epoch 00085 | Loss(train) 0.5771 | Acc(train) 0.8203 | Acc(val) 0.8565 |
Epoch 00086 | Loss(train) 0.5499 | Acc(train) 0.8300 | Acc(val) 0.8647 |
Epoch 00087 | Loss(train) 0.5527 | Acc(train) 0.8262 | Acc(val) 0.8722 |
Epoch 00088 | Loss(train) 0.5728 | Acc(train) 0.8266 | Acc(val) 0.8729 |
Epoch 00089 | Loss(train) 0.5586 | Acc(train) 0.8244 | Acc(val) 0.8767 |*
Epoch 00090 | Loss(train) 0.5513 | Acc(train) 0.8303 | Acc(val) 0.8685 |
Epoch 00091 | Loss(train) 0.5443 | Acc(train) 0.8315 | Acc(val) 0.8610 |
Epoch 00092 | Loss(train) 0.5575 | Acc(train) 0.8292 | Acc(val) 0.8707 |
Epoch 00093 | Loss(train) 0.5205 | Acc(train) 0.8453 | Acc(val) 0.8752 |
Epoch 00094 | Loss(train) 0.5329 | Acc(train) 0.8393 | Acc(val) 0.8752 |
Epoch 00095 | Loss(train) 0.5346 | Acc(train) 0.8371 | Acc(val) 0.8722 |
Epoch 00096 | Loss(train) 0.5222 | Acc(train) 0.8303 | Acc(val) 0.8632 |
Epoch 00097 | Loss(train) 0.5354 | Acc(train) 0.8333 | Acc(val) 0.8662 |
Epoch 00098 | Loss(train) 0.5475 | Acc(train) 0.8285 | Acc(val) 0.8744 |
Epoch 00099 | Loss(train) 0.5337 | Acc(train) 0.8367 | Acc(val) 0.8812 |*
Epoch 00100 | Loss(train) 0.5432 | Acc(train) 0.8307 | Acc(val) 0.8767 |
Epoch 00101 | Loss(train) 0.5406 | Acc(train) 0.8259 | Acc(val) 0.8714 |
Epoch 00102 | Loss(train) 0.5282 | Acc(train) 0.8311 | Acc(val) 0.8722 |
Epoch 00103 | Loss(train) 0.5245 | Acc(train) 0.8378 | Acc(val) 0.8782 |
Epoch 00104 | Loss(train) 0.5206 | Acc(train) 0.8416 | Acc(val) 0.8767 |
Epoch 00105 | Loss(train) 0.4973 | Acc(train) 0.8520 | Acc(val) 0.8662 |
Epoch 00106 | Loss(train) 0.5099 | Acc(train) 0.8453 | Acc(val) 0.8700 |
Epoch 00107 | Loss(train) 0.5146 | Acc(train) 0.8359 | Acc(val) 0.8782 |
Epoch 00108 | Loss(train) 0.5203 | Acc(train) 0.8404 | Acc(val) 0.8812 |
Epoch 00109 | Loss(train) 0.5072 | Acc(train) 0.8460 | Acc(val) 0.8782 |
Epoch 00110 | Loss(train) 0.5088 | Acc(train) 0.8389 | Acc(val) 0.8767 |
Epoch 00111 | Loss(train) 0.5015 | Acc(train) 0.8393 | Acc(val) 0.8782 |
Epoch 00112 | Loss(train) 0.4977 | Acc(train) 0.8490 | Acc(val) 0.8804 |
Epoch 00113 | Loss(train) 0.5062 | Acc(train) 0.8475 | Acc(val) 0.8744 |
Epoch 00114 | Loss(train) 0.4976 | Acc(train) 0.8498 | Acc(val) 0.8744 |
Epoch 00115 | Loss(train) 0.5252 | Acc(train) 0.8318 | Acc(val) 0.8789 |
Epoch 00116 | Loss(train) 0.5132 | Acc(train) 0.8430 | Acc(val) 0.8737 |
Epoch 00117 | Loss(train) 0.4986 | Acc(train) 0.8430 | Acc(val) 0.8737 |
Epoch 00118 | Loss(train) 0.4991 | Acc(train) 0.8374 | Acc(val) 0.8685 |
Epoch 00119 | Loss(train) 0.5025 | Acc(train) 0.8382 | Acc(val) 0.8744 |
Epoch 00120 | Loss(train) 0.4939 | Acc(train) 0.8505 | Acc(val) 0.8827 |*
Epoch 00121 | Loss(train) 0.4918 | Acc(train) 0.8617 | Acc(val) 0.8767 |
Epoch 00122 | Loss(train) 0.5032 | Acc(train) 0.8401 | Acc(val) 0.8789 |
Epoch 00123 | Loss(train) 0.4900 | Acc(train) 0.8419 | Acc(val) 0.8864 |*
Epoch 00124 | Loss(train) 0.4947 | Acc(train) 0.8498 | Acc(val) 0.8804 |
Epoch 00125 | Loss(train) 0.4770 | Acc(train) 0.8531 | Acc(val) 0.8774 |
Epoch 00126 | Loss(train) 0.4974 | Acc(train) 0.8397 | Acc(val) 0.8744 |
Epoch 00127 | Loss(train) 0.4790 | Acc(train) 0.8524 | Acc(val) 0.8797 |
Epoch 00128 | Loss(train) 0.4774 | Acc(train) 0.8505 | Acc(val) 0.8789 |
Epoch 00129 | Loss(train) 0.4671 | Acc(train) 0.8449 | Acc(val) 0.8789 |
Epoch 00130 | Loss(train) 0.4796 | Acc(train) 0.8501 | Acc(val) 0.8812 |
Epoch 00131 | Loss(train) 0.4809 | Acc(train) 0.8501 | Acc(val) 0.8864 |
Epoch 00132 | Loss(train) 0.4682 | Acc(train) 0.8587 | Acc(val) 0.8812 |
Epoch 00133 | Loss(train) 0.4988 | Acc(train) 0.8475 | Acc(val) 0.8827 |
Epoch 00134 | Loss(train) 0.4807 | Acc(train) 0.8591 | Acc(val) 0.8759 |
Epoch 00135 | Loss(train) 0.4884 | Acc(train) 0.8412 | Acc(val) 0.8834 |
Epoch 00136 | Loss(train) 0.4699 | Acc(train) 0.8505 | Acc(val) 0.8886 |*
Epoch 00137 | Loss(train) 0.4679 | Acc(train) 0.8535 | Acc(val) 0.8924 |*
Epoch 00138 | Loss(train) 0.4626 | Acc(train) 0.8621 | Acc(val) 0.8857 |
Epoch 00139 | Loss(train) 0.4695 | Acc(train) 0.8531 | Acc(val) 0.8789 |
Epoch 00140 | Loss(train) 0.4656 | Acc(train) 0.8554 | Acc(val) 0.8819 |
Epoch 00141 | Loss(train) 0.4570 | Acc(train) 0.8475 | Acc(val) 0.8834 |
Epoch 00142 | Loss(train) 0.4757 | Acc(train) 0.8513 | Acc(val) 0.8834 |
Epoch 00143 | Loss(train) 0.4643 | Acc(train) 0.8565 | Acc(val) 0.8707 |
Epoch 00144 | Loss(train) 0.4743 | Acc(train) 0.8438 | Acc(val) 0.8834 |
Epoch 00145 | Loss(train) 0.4725 | Acc(train) 0.8516 | Acc(val) 0.8827 |
Epoch 00146 | Loss(train) 0.4789 | Acc(train) 0.8546 | Acc(val) 0.8886 |
Epoch 00147 | Loss(train) 0.4609 | Acc(train) 0.8617 | Acc(val) 0.8782 |
Epoch 00148 | Loss(train) 0.4769 | Acc(train) 0.8453 | Acc(val) 0.8759 |
Epoch 00149 | Loss(train) 0.4601 | Acc(train) 0.8531 | Acc(val) 0.8849 |
Epoch 00150 | Loss(train) 0.4830 | Acc(train) 0.8509 | Acc(val) 0.8857 |
Epoch 00151 | Loss(train) 0.4449 | Acc(train) 0.8606 | Acc(val) 0.8752 |
Epoch 00152 | Loss(train) 0.4706 | Acc(train) 0.8393 | Acc(val) 0.8849 |
Epoch 00153 | Loss(train) 0.4631 | Acc(train) 0.8509 | Acc(val) 0.8886 |
Epoch 00154 | Loss(train) 0.4584 | Acc(train) 0.8546 | Acc(val) 0.8871 |
Epoch 00155 | Loss(train) 0.4716 | Acc(train) 0.8595 | Acc(val) 0.8737 |
Epoch 00156 | Loss(train) 0.4470 | Acc(train) 0.8602 | Acc(val) 0.8894 |
Epoch 00157 | Loss(train) 0.4614 | Acc(train) 0.8520 | Acc(val) 0.8871 |
Epoch 00158 | Loss(train) 0.4676 | Acc(train) 0.8587 | Acc(val) 0.8842 |
Epoch 00159 | Loss(train) 0.4524 | Acc(train) 0.8554 | Acc(val) 0.8797 |
Epoch 00160 | Loss(train) 0.4383 | Acc(train) 0.8610 | Acc(val) 0.8901 |
Epoch 00161 | Loss(train) 0.4539 | Acc(train) 0.8509 | Acc(val) 0.8901 |
Epoch 00162 | Loss(train) 0.4550 | Acc(train) 0.8655 | Acc(val) 0.8849 |
Epoch 00163 | Loss(train) 0.4587 | Acc(train) 0.8606 | Acc(val) 0.8871 |
Epoch 00164 | Loss(train) 0.4691 | Acc(train) 0.8516 | Acc(val) 0.8909 |
Epoch 00165 | Loss(train) 0.4467 | Acc(train) 0.8606 | Acc(val) 0.8879 |
Epoch 00166 | Loss(train) 0.4723 | Acc(train) 0.8561 | Acc(val) 0.8901 |
Epoch 00167 | Loss(train) 0.4371 | Acc(train) 0.8531 | Acc(val) 0.8886 |
Epoch 00168 | Loss(train) 0.4396 | Acc(train) 0.8599 | Acc(val) 0.8886 |
Epoch 00169 | Loss(train) 0.4241 | Acc(train) 0.8756 | Acc(val) 0.8789 |
Epoch 00170 | Loss(train) 0.4512 | Acc(train) 0.8516 | Acc(val) 0.8931 |*
Epoch 00171 | Loss(train) 0.4388 | Acc(train) 0.8606 | Acc(val) 0.8946 |*
Epoch 00172 | Loss(train) 0.4561 | Acc(train) 0.8591 | Acc(val) 0.8946 |
Epoch 00173 | Loss(train) 0.4344 | Acc(train) 0.8655 | Acc(val) 0.8797 |
Epoch 00174 | Loss(train) 0.4422 | Acc(train) 0.8543 | Acc(val) 0.8864 |
Epoch 00175 | Loss(train) 0.4419 | Acc(train) 0.8651 | Acc(val) 0.8931 |
Epoch 00176 | Loss(train) 0.4265 | Acc(train) 0.8718 | Acc(val) 0.8931 |
Epoch 00177 | Loss(train) 0.4321 | Acc(train) 0.8606 | Acc(val) 0.8954 |*
Epoch 00178 | Loss(train) 0.4361 | Acc(train) 0.8599 | Acc(val) 0.8916 |
Epoch 00179 | Loss(train) 0.4264 | Acc(train) 0.8662 | Acc(val) 0.8871 |
Epoch 00180 | Loss(train) 0.4444 | Acc(train) 0.8554 | Acc(val) 0.8827 |
Epoch 00181 | Loss(train) 0.4407 | Acc(train) 0.8606 | Acc(val) 0.8879 |
Epoch 00182 | Loss(train) 0.4292 | Acc(train) 0.8655 | Acc(val) 0.8939 |
Epoch 00183 | Loss(train) 0.4296 | Acc(train) 0.8673 | Acc(val) 0.8961 |*
Epoch 00184 | Loss(train) 0.4384 | Acc(train) 0.8666 | Acc(val) 0.8931 |
Epoch 00185 | Loss(train) 0.4056 | Acc(train) 0.8800 | Acc(val) 0.8842 |
Epoch 00186 | Loss(train) 0.4362 | Acc(train) 0.8591 | Acc(val) 0.8954 |
Epoch 00187 | Loss(train) 0.4430 | Acc(train) 0.8658 | Acc(val) 0.8939 |
Epoch 00188 | Loss(train) 0.4357 | Acc(train) 0.8636 | Acc(val) 0.8909 |
Epoch 00189 | Loss(train) 0.4277 | Acc(train) 0.8655 | Acc(val) 0.8939 |
Epoch 00190 | Loss(train) 0.4201 | Acc(train) 0.8621 | Acc(val) 0.8916 |
Epoch 00191 | Loss(train) 0.4448 | Acc(train) 0.8595 | Acc(val) 0.8924 |
Epoch 00192 | Loss(train) 0.4133 | Acc(train) 0.8703 | Acc(val) 0.8931 |
Epoch 00193 | Loss(train) 0.4434 | Acc(train) 0.8643 | Acc(val) 0.8946 |
Epoch 00194 | Loss(train) 0.4189 | Acc(train) 0.8685 | Acc(val) 0.8961 |
Epoch 00195 | Loss(train) 0.4291 | Acc(train) 0.8700 | Acc(val) 0.8924 |
Epoch 00196 | Loss(train) 0.4253 | Acc(train) 0.8632 | Acc(val) 0.8909 |
Epoch 00197 | Loss(train) 0.4309 | Acc(train) 0.8617 | Acc(val) 0.8939 |
Epoch 00198 | Loss(train) 0.4217 | Acc(train) 0.8625 | Acc(val) 0.8909 |
Epoch 00199 | Loss(train) 0.4180 | Acc(train) 0.8703 | Acc(val) 0.8961 |
Epoch 00200 | Loss(train) 0.4182 | Acc(train) 0.8670 | Acc(val) 0.8946 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 4/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.2631 | Acc(train) 0.1966 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 3.7980 | Acc(train) 0.3632 | Acc(val) 0.3303 |
Epoch 00003 | Loss(train) 5.0392 | Acc(train) 0.1719 | Acc(val) 0.1861 |
Epoch 00004 | Loss(train) 4.1479 | Acc(train) 0.1349 | Acc(val) 0.4006 |*
Epoch 00005 | Loss(train) 2.2898 | Acc(train) 0.2511 | Acc(val) 0.3714 |
Epoch 00006 | Loss(train) 2.8330 | Acc(train) 0.3606 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.4400 | Acc(train) 0.3711 | Acc(val) 0.3572 |
Epoch 00008 | Loss(train) 2.4349 | Acc(train) 0.2971 | Acc(val) 0.5217 |*
Epoch 00009 | Loss(train) 2.0198 | Acc(train) 0.4492 | Acc(val) 0.4155 |
Epoch 00010 | Loss(train) 2.0142 | Acc(train) 0.4182 | Acc(val) 0.4656 |
Epoch 00011 | Loss(train) 1.8368 | Acc(train) 0.4608 | Acc(val) 0.4552 |
Epoch 00012 | Loss(train) 1.6881 | Acc(train) 0.4540 | Acc(val) 0.5897 |*
Epoch 00013 | Loss(train) 1.5712 | Acc(train) 0.5549 | Acc(val) 0.5344 |
Epoch 00014 | Loss(train) 1.6868 | Acc(train) 0.4910 | Acc(val) 0.5531 |
Epoch 00015 | Loss(train) 1.6749 | Acc(train) 0.4794 | Acc(val) 0.5979 |*
Epoch 00016 | Loss(train) 1.5846 | Acc(train) 0.5288 | Acc(val) 0.6114 |*
Epoch 00017 | Loss(train) 1.5073 | Acc(train) 0.5534 | Acc(val) 0.5650 |
Epoch 00018 | Loss(train) 1.4843 | Acc(train) 0.5370 | Acc(val) 0.6786 |*
Epoch 00019 | Loss(train) 1.4381 | Acc(train) 0.5830 | Acc(val) 0.6891 |*
Epoch 00020 | Loss(train) 1.4006 | Acc(train) 0.6241 | Acc(val) 0.6913 |*
Epoch 00021 | Loss(train) 1.3747 | Acc(train) 0.6364 | Acc(val) 0.6928 |*
Epoch 00022 | Loss(train) 1.3447 | Acc(train) 0.6196 | Acc(val) 0.6921 |
Epoch 00023 | Loss(train) 1.3125 | Acc(train) 0.6095 | Acc(val) 0.6936 |*
Epoch 00024 | Loss(train) 1.2906 | Acc(train) 0.6200 | Acc(val) 0.7123 |*
Epoch 00025 | Loss(train) 1.2648 | Acc(train) 0.6162 | Acc(val) 0.7100 |
Epoch 00026 | Loss(train) 1.2439 | Acc(train) 0.6241 | Acc(val) 0.7138 |*
Epoch 00027 | Loss(train) 1.2039 | Acc(train) 0.6465 | Acc(val) 0.7130 |
Epoch 00028 | Loss(train) 1.1946 | Acc(train) 0.6413 | Acc(val) 0.7272 |*
Epoch 00029 | Loss(train) 1.1430 | Acc(train) 0.6551 | Acc(val) 0.7309 |*
Epoch 00030 | Loss(train) 1.1272 | Acc(train) 0.6670 | Acc(val) 0.7257 |
Epoch 00031 | Loss(train) 1.1123 | Acc(train) 0.6827 | Acc(val) 0.7190 |
Epoch 00032 | Loss(train) 1.0959 | Acc(train) 0.6730 | Acc(val) 0.7212 |
Epoch 00033 | Loss(train) 1.1004 | Acc(train) 0.6753 | Acc(val) 0.7324 |*
Epoch 00034 | Loss(train) 1.0514 | Acc(train) 0.6984 | Acc(val) 0.7347 |*
Epoch 00035 | Loss(train) 1.0301 | Acc(train) 0.7040 | Acc(val) 0.7347 |
Epoch 00036 | Loss(train) 1.0363 | Acc(train) 0.6895 | Acc(val) 0.7354 |*
Epoch 00037 | Loss(train) 1.0127 | Acc(train) 0.6768 | Acc(val) 0.7422 |*
Epoch 00038 | Loss(train) 0.9789 | Acc(train) 0.7010 | Acc(val) 0.7422 |
Epoch 00039 | Loss(train) 0.9591 | Acc(train) 0.7040 | Acc(val) 0.7474 |*
Epoch 00040 | Loss(train) 0.9401 | Acc(train) 0.7104 | Acc(val) 0.7556 |*
Epoch 00041 | Loss(train) 0.9409 | Acc(train) 0.7235 | Acc(val) 0.7631 |*
Epoch 00042 | Loss(train) 0.8985 | Acc(train) 0.7246 | Acc(val) 0.7608 |
Epoch 00043 | Loss(train) 0.8789 | Acc(train) 0.7242 | Acc(val) 0.7638 |*
Epoch 00044 | Loss(train) 0.8919 | Acc(train) 0.7306 | Acc(val) 0.7698 |*
Epoch 00045 | Loss(train) 0.8541 | Acc(train) 0.7429 | Acc(val) 0.7765 |*
Epoch 00046 | Loss(train) 0.8610 | Acc(train) 0.7313 | Acc(val) 0.7818 |*
Epoch 00047 | Loss(train) 0.8259 | Acc(train) 0.7478 | Acc(val) 0.7773 |
Epoch 00048 | Loss(train) 0.8016 | Acc(train) 0.7526 | Acc(val) 0.7900 |*
Epoch 00049 | Loss(train) 0.8260 | Acc(train) 0.7500 | Acc(val) 0.7900 |
Epoch 00050 | Loss(train) 0.8037 | Acc(train) 0.7575 | Acc(val) 0.7892 |
Epoch 00051 | Loss(train) 0.7882 | Acc(train) 0.7515 | Acc(val) 0.7892 |
Epoch 00052 | Loss(train) 0.7891 | Acc(train) 0.7496 | Acc(val) 0.7945 |*
Epoch 00053 | Loss(train) 0.7845 | Acc(train) 0.7691 | Acc(val) 0.8019 |*
Epoch 00054 | Loss(train) 0.7598 | Acc(train) 0.7642 | Acc(val) 0.8087 |*
Epoch 00055 | Loss(train) 0.7596 | Acc(train) 0.7616 | Acc(val) 0.8079 |
Epoch 00056 | Loss(train) 0.7455 | Acc(train) 0.7717 | Acc(val) 0.8102 |*
Epoch 00057 | Loss(train) 0.7353 | Acc(train) 0.7747 | Acc(val) 0.8117 |*
Epoch 00058 | Loss(train) 0.7146 | Acc(train) 0.7900 | Acc(val) 0.8132 |*
Epoch 00059 | Loss(train) 0.7212 | Acc(train) 0.7896 | Acc(val) 0.8296 |*
Epoch 00060 | Loss(train) 0.7022 | Acc(train) 0.7829 | Acc(val) 0.8318 |*
Epoch 00061 | Loss(train) 0.7083 | Acc(train) 0.7814 | Acc(val) 0.8184 |
Epoch 00062 | Loss(train) 0.6995 | Acc(train) 0.7833 | Acc(val) 0.8169 |
Epoch 00063 | Loss(train) 0.6660 | Acc(train) 0.8038 | Acc(val) 0.8318 |
Epoch 00064 | Loss(train) 0.6815 | Acc(train) 0.7978 | Acc(val) 0.8356 |*
Epoch 00065 | Loss(train) 0.6568 | Acc(train) 0.8034 | Acc(val) 0.8251 |
Epoch 00066 | Loss(train) 0.6656 | Acc(train) 0.7978 | Acc(val) 0.8251 |
Epoch 00067 | Loss(train) 0.6549 | Acc(train) 0.8038 | Acc(val) 0.8363 |*
Epoch 00068 | Loss(train) 0.6575 | Acc(train) 0.7941 | Acc(val) 0.8468 |*
Epoch 00069 | Loss(train) 0.6586 | Acc(train) 0.7960 | Acc(val) 0.8483 |*
Epoch 00070 | Loss(train) 0.6404 | Acc(train) 0.8027 | Acc(val) 0.8363 |
Epoch 00071 | Loss(train) 0.6385 | Acc(train) 0.8087 | Acc(val) 0.8363 |
Epoch 00072 | Loss(train) 0.6402 | Acc(train) 0.8102 | Acc(val) 0.8460 |
Epoch 00073 | Loss(train) 0.6304 | Acc(train) 0.8128 | Acc(val) 0.8460 |
Epoch 00074 | Loss(train) 0.6180 | Acc(train) 0.8102 | Acc(val) 0.8445 |
Epoch 00075 | Loss(train) 0.6265 | Acc(train) 0.8113 | Acc(val) 0.8423 |
Epoch 00076 | Loss(train) 0.6071 | Acc(train) 0.8247 | Acc(val) 0.8535 |*
Epoch 00077 | Loss(train) 0.6148 | Acc(train) 0.8210 | Acc(val) 0.8587 |*
Epoch 00078 | Loss(train) 0.6018 | Acc(train) 0.8169 | Acc(val) 0.8558 |
Epoch 00079 | Loss(train) 0.6007 | Acc(train) 0.8184 | Acc(val) 0.8543 |
Epoch 00080 | Loss(train) 0.5953 | Acc(train) 0.8214 | Acc(val) 0.8528 |
Epoch 00081 | Loss(train) 0.5983 | Acc(train) 0.8203 | Acc(val) 0.8558 |
Epoch 00082 | Loss(train) 0.5920 | Acc(train) 0.8244 | Acc(val) 0.8595 |*
Epoch 00083 | Loss(train) 0.6008 | Acc(train) 0.8132 | Acc(val) 0.8602 |*
Epoch 00084 | Loss(train) 0.5988 | Acc(train) 0.8277 | Acc(val) 0.8625 |*
Epoch 00085 | Loss(train) 0.5903 | Acc(train) 0.8318 | Acc(val) 0.8647 |*
Epoch 00086 | Loss(train) 0.5596 | Acc(train) 0.8333 | Acc(val) 0.8670 |*
Epoch 00087 | Loss(train) 0.5618 | Acc(train) 0.8423 | Acc(val) 0.8602 |
Epoch 00088 | Loss(train) 0.5695 | Acc(train) 0.8288 | Acc(val) 0.8632 |
Epoch 00089 | Loss(train) 0.5617 | Acc(train) 0.8277 | Acc(val) 0.8670 |
Epoch 00090 | Loss(train) 0.5632 | Acc(train) 0.8247 | Acc(val) 0.8662 |
Epoch 00091 | Loss(train) 0.5572 | Acc(train) 0.8397 | Acc(val) 0.8632 |
Epoch 00092 | Loss(train) 0.5592 | Acc(train) 0.8285 | Acc(val) 0.8700 |*
Epoch 00093 | Loss(train) 0.5473 | Acc(train) 0.8389 | Acc(val) 0.8685 |
Epoch 00094 | Loss(train) 0.5545 | Acc(train) 0.8423 | Acc(val) 0.8610 |
Epoch 00095 | Loss(train) 0.5425 | Acc(train) 0.8371 | Acc(val) 0.8587 |
Epoch 00096 | Loss(train) 0.5520 | Acc(train) 0.8434 | Acc(val) 0.8700 |
Epoch 00097 | Loss(train) 0.5376 | Acc(train) 0.8341 | Acc(val) 0.8729 |*
Epoch 00098 | Loss(train) 0.5395 | Acc(train) 0.8419 | Acc(val) 0.8625 |
Epoch 00099 | Loss(train) 0.5414 | Acc(train) 0.8412 | Acc(val) 0.8632 |
Epoch 00100 | Loss(train) 0.5450 | Acc(train) 0.8318 | Acc(val) 0.8752 |*
Epoch 00101 | Loss(train) 0.5405 | Acc(train) 0.8427 | Acc(val) 0.8744 |
Epoch 00102 | Loss(train) 0.5374 | Acc(train) 0.8352 | Acc(val) 0.8647 |
Epoch 00103 | Loss(train) 0.5322 | Acc(train) 0.8378 | Acc(val) 0.8670 |
Epoch 00104 | Loss(train) 0.5288 | Acc(train) 0.8386 | Acc(val) 0.8774 |*
Epoch 00105 | Loss(train) 0.5227 | Acc(train) 0.8430 | Acc(val) 0.8759 |
Epoch 00106 | Loss(train) 0.5158 | Acc(train) 0.8483 | Acc(val) 0.8737 |
Epoch 00107 | Loss(train) 0.5212 | Acc(train) 0.8457 | Acc(val) 0.8655 |
Epoch 00108 | Loss(train) 0.5294 | Acc(train) 0.8419 | Acc(val) 0.8729 |
Epoch 00109 | Loss(train) 0.5161 | Acc(train) 0.8472 | Acc(val) 0.8789 |*
Epoch 00110 | Loss(train) 0.5218 | Acc(train) 0.8464 | Acc(val) 0.8714 |
Epoch 00111 | Loss(train) 0.5006 | Acc(train) 0.8483 | Acc(val) 0.8789 |
Epoch 00112 | Loss(train) 0.5213 | Acc(train) 0.8348 | Acc(val) 0.8774 |
Epoch 00113 | Loss(train) 0.5217 | Acc(train) 0.8356 | Acc(val) 0.8767 |
Epoch 00114 | Loss(train) 0.5116 | Acc(train) 0.8457 | Acc(val) 0.8662 |
Epoch 00115 | Loss(train) 0.4939 | Acc(train) 0.8438 | Acc(val) 0.8632 |
Epoch 00116 | Loss(train) 0.5058 | Acc(train) 0.8460 | Acc(val) 0.8804 |*
Epoch 00117 | Loss(train) 0.4974 | Acc(train) 0.8565 | Acc(val) 0.8767 |
Epoch 00118 | Loss(train) 0.5102 | Acc(train) 0.8487 | Acc(val) 0.8819 |*
Epoch 00119 | Loss(train) 0.4964 | Acc(train) 0.8505 | Acc(val) 0.8729 |
Epoch 00120 | Loss(train) 0.4990 | Acc(train) 0.8513 | Acc(val) 0.8737 |
Epoch 00121 | Loss(train) 0.4928 | Acc(train) 0.8494 | Acc(val) 0.8797 |
Epoch 00122 | Loss(train) 0.5031 | Acc(train) 0.8569 | Acc(val) 0.8864 |*
Epoch 00123 | Loss(train) 0.5066 | Acc(train) 0.8576 | Acc(val) 0.8827 |
Epoch 00124 | Loss(train) 0.4895 | Acc(train) 0.8528 | Acc(val) 0.8759 |
Epoch 00125 | Loss(train) 0.5008 | Acc(train) 0.8539 | Acc(val) 0.8812 |
Epoch 00126 | Loss(train) 0.4823 | Acc(train) 0.8580 | Acc(val) 0.8812 |
Epoch 00127 | Loss(train) 0.4859 | Acc(train) 0.8554 | Acc(val) 0.8797 |
Epoch 00128 | Loss(train) 0.4829 | Acc(train) 0.8561 | Acc(val) 0.8729 |
Epoch 00129 | Loss(train) 0.4738 | Acc(train) 0.8524 | Acc(val) 0.8812 |
Epoch 00130 | Loss(train) 0.4804 | Acc(train) 0.8505 | Acc(val) 0.8871 |*
Epoch 00131 | Loss(train) 0.4816 | Acc(train) 0.8636 | Acc(val) 0.8857 |
Epoch 00132 | Loss(train) 0.4955 | Acc(train) 0.8468 | Acc(val) 0.8842 |
Epoch 00133 | Loss(train) 0.4865 | Acc(train) 0.8554 | Acc(val) 0.8707 |
Epoch 00134 | Loss(train) 0.4748 | Acc(train) 0.8472 | Acc(val) 0.8759 |
Epoch 00135 | Loss(train) 0.4812 | Acc(train) 0.8475 | Acc(val) 0.8834 |
Epoch 00136 | Loss(train) 0.4681 | Acc(train) 0.8610 | Acc(val) 0.8879 |*
Epoch 00137 | Loss(train) 0.4649 | Acc(train) 0.8647 | Acc(val) 0.8857 |
Epoch 00138 | Loss(train) 0.4651 | Acc(train) 0.8576 | Acc(val) 0.8834 |
Epoch 00139 | Loss(train) 0.4699 | Acc(train) 0.8550 | Acc(val) 0.8804 |
Epoch 00140 | Loss(train) 0.4648 | Acc(train) 0.8602 | Acc(val) 0.8819 |
Epoch 00141 | Loss(train) 0.4708 | Acc(train) 0.8546 | Acc(val) 0.8737 |
Epoch 00142 | Loss(train) 0.4821 | Acc(train) 0.8524 | Acc(val) 0.8685 |
Epoch 00143 | Loss(train) 0.4682 | Acc(train) 0.8587 | Acc(val) 0.8812 |
Epoch 00144 | Loss(train) 0.4494 | Acc(train) 0.8569 | Acc(val) 0.8864 |
Epoch 00145 | Loss(train) 0.4945 | Acc(train) 0.8468 | Acc(val) 0.8857 |
Epoch 00146 | Loss(train) 0.4622 | Acc(train) 0.8655 | Acc(val) 0.8752 |
Epoch 00147 | Loss(train) 0.4713 | Acc(train) 0.8632 | Acc(val) 0.8864 |
Epoch 00148 | Loss(train) 0.4599 | Acc(train) 0.8640 | Acc(val) 0.8894 |*
Epoch 00149 | Loss(train) 0.4525 | Acc(train) 0.8584 | Acc(val) 0.8849 |
Epoch 00150 | Loss(train) 0.4681 | Acc(train) 0.8528 | Acc(val) 0.8864 |
Epoch 00151 | Loss(train) 0.4557 | Acc(train) 0.8621 | Acc(val) 0.8834 |
Epoch 00152 | Loss(train) 0.4663 | Acc(train) 0.8494 | Acc(val) 0.8894 |
Epoch 00153 | Loss(train) 0.4452 | Acc(train) 0.8666 | Acc(val) 0.8797 |
Epoch 00154 | Loss(train) 0.4564 | Acc(train) 0.8610 | Acc(val) 0.8849 |
Epoch 00155 | Loss(train) 0.4549 | Acc(train) 0.8625 | Acc(val) 0.8894 |
Epoch 00156 | Loss(train) 0.4585 | Acc(train) 0.8587 | Acc(val) 0.8849 |
Epoch 00157 | Loss(train) 0.4370 | Acc(train) 0.8673 | Acc(val) 0.8819 |
Epoch 00158 | Loss(train) 0.4318 | Acc(train) 0.8711 | Acc(val) 0.8857 |
Epoch 00159 | Loss(train) 0.4265 | Acc(train) 0.8685 | Acc(val) 0.8931 |*
Epoch 00160 | Loss(train) 0.4358 | Acc(train) 0.8688 | Acc(val) 0.8894 |
Epoch 00161 | Loss(train) 0.4406 | Acc(train) 0.8640 | Acc(val) 0.8901 |
Epoch 00162 | Loss(train) 0.4412 | Acc(train) 0.8647 | Acc(val) 0.8909 |
Epoch 00163 | Loss(train) 0.4338 | Acc(train) 0.8662 | Acc(val) 0.8871 |
Epoch 00164 | Loss(train) 0.4355 | Acc(train) 0.8643 | Acc(val) 0.8804 |
Epoch 00165 | Loss(train) 0.4483 | Acc(train) 0.8640 | Acc(val) 0.8819 |
Epoch 00166 | Loss(train) 0.4424 | Acc(train) 0.8662 | Acc(val) 0.8939 |*
Epoch 00167 | Loss(train) 0.4342 | Acc(train) 0.8741 | Acc(val) 0.8924 |
Epoch 00168 | Loss(train) 0.4332 | Acc(train) 0.8696 | Acc(val) 0.8864 |
Epoch 00169 | Loss(train) 0.4392 | Acc(train) 0.8580 | Acc(val) 0.8864 |
Epoch 00170 | Loss(train) 0.4189 | Acc(train) 0.8688 | Acc(val) 0.8909 |
Epoch 00171 | Loss(train) 0.4445 | Acc(train) 0.8625 | Acc(val) 0.8984 |*
Epoch 00172 | Loss(train) 0.4370 | Acc(train) 0.8617 | Acc(val) 0.8864 |
Epoch 00173 | Loss(train) 0.4335 | Acc(train) 0.8677 | Acc(val) 0.8939 |
Epoch 00174 | Loss(train) 0.4352 | Acc(train) 0.8681 | Acc(val) 0.8916 |
Epoch 00175 | Loss(train) 0.4363 | Acc(train) 0.8700 | Acc(val) 0.8894 |
Epoch 00176 | Loss(train) 0.4512 | Acc(train) 0.8662 | Acc(val) 0.8931 |
Epoch 00177 | Loss(train) 0.4227 | Acc(train) 0.8722 | Acc(val) 0.8939 |
Epoch 00178 | Loss(train) 0.4354 | Acc(train) 0.8677 | Acc(val) 0.8879 |
Epoch 00179 | Loss(train) 0.4306 | Acc(train) 0.8647 | Acc(val) 0.8842 |
Epoch 00180 | Loss(train) 0.4189 | Acc(train) 0.8662 | Acc(val) 0.8864 |
Epoch 00181 | Loss(train) 0.4401 | Acc(train) 0.8647 | Acc(val) 0.8976 |
Epoch 00182 | Loss(train) 0.4376 | Acc(train) 0.8632 | Acc(val) 0.8886 |
Epoch 00183 | Loss(train) 0.4323 | Acc(train) 0.8666 | Acc(val) 0.8857 |
Epoch 00184 | Loss(train) 0.4404 | Acc(train) 0.8591 | Acc(val) 0.8842 |
Epoch 00185 | Loss(train) 0.4424 | Acc(train) 0.8546 | Acc(val) 0.8916 |
Epoch 00186 | Loss(train) 0.4129 | Acc(train) 0.8774 | Acc(val) 0.8954 |
Epoch 00187 | Loss(train) 0.4349 | Acc(train) 0.8741 | Acc(val) 0.8961 |
Epoch 00188 | Loss(train) 0.4374 | Acc(train) 0.8655 | Acc(val) 0.8946 |
Epoch 00189 | Loss(train) 0.4443 | Acc(train) 0.8640 | Acc(val) 0.8954 |
Epoch 00190 | Loss(train) 0.4232 | Acc(train) 0.8748 | Acc(val) 0.8939 |
Epoch 00191 | Loss(train) 0.4369 | Acc(train) 0.8707 | Acc(val) 0.8976 |
Epoch 00192 | Loss(train) 0.4085 | Acc(train) 0.8756 | Acc(val) 0.8871 |
Epoch 00193 | Loss(train) 0.4119 | Acc(train) 0.8662 | Acc(val) 0.8842 |
Epoch 00194 | Loss(train) 0.4465 | Acc(train) 0.8554 | Acc(val) 0.8946 |
Epoch 00195 | Loss(train) 0.4200 | Acc(train) 0.8718 | Acc(val) 0.8879 |
Epoch 00196 | Loss(train) 0.4393 | Acc(train) 0.8636 | Acc(val) 0.8901 |
Epoch 00197 | Loss(train) 0.4274 | Acc(train) 0.8662 | Acc(val) 0.8879 |
Epoch 00198 | Loss(train) 0.4036 | Acc(train) 0.8800 | Acc(val) 0.8864 |
Epoch 00199 | Loss(train) 0.4300 | Acc(train) 0.8640 | Acc(val) 0.8984 |
Epoch 00200 | Loss(train) 0.4194 | Acc(train) 0.8718 | Acc(val) 0.8984 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 5/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.2803 | Acc(train) 0.1981 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 3.1089 | Acc(train) 0.3703 | Acc(val) 0.1599 |
Epoch 00003 | Loss(train) 5.4863 | Acc(train) 0.1536 | Acc(val) 0.1592 |
Epoch 00004 | Loss(train) 3.5188 | Acc(train) 0.1626 | Acc(val) 0.2040 |
Epoch 00005 | Loss(train) 2.3421 | Acc(train) 0.2713 | Acc(val) 0.3714 |
Epoch 00006 | Loss(train) 3.2308 | Acc(train) 0.3718 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 3.1587 | Acc(train) 0.3681 | Acc(val) 0.3707 |
Epoch 00008 | Loss(train) 2.4125 | Acc(train) 0.3714 | Acc(val) 0.3894 |*
Epoch 00009 | Loss(train) 2.3520 | Acc(train) 0.3064 | Acc(val) 0.2945 |
Epoch 00010 | Loss(train) 2.2888 | Acc(train) 0.2235 | Acc(val) 0.4895 |*
Epoch 00011 | Loss(train) 2.2406 | Acc(train) 0.2324 | Acc(val) 0.4148 |
Epoch 00012 | Loss(train) 2.0606 | Acc(train) 0.3535 | Acc(val) 0.4574 |
Epoch 00013 | Loss(train) 1.8663 | Acc(train) 0.4283 | Acc(val) 0.3984 |
Epoch 00014 | Loss(train) 1.8066 | Acc(train) 0.4070 | Acc(val) 0.4454 |
Epoch 00015 | Loss(train) 1.7989 | Acc(train) 0.4327 | Acc(val) 0.4141 |
Epoch 00016 | Loss(train) 1.8114 | Acc(train) 0.4107 | Acc(val) 0.4028 |
Epoch 00017 | Loss(train) 1.7450 | Acc(train) 0.4268 | Acc(val) 0.4238 |
Epoch 00018 | Loss(train) 1.6956 | Acc(train) 0.4559 | Acc(val) 0.5822 |*
Epoch 00019 | Loss(train) 1.6586 | Acc(train) 0.5224 | Acc(val) 0.5867 |*
Epoch 00020 | Loss(train) 1.6420 | Acc(train) 0.5280 | Acc(val) 0.5830 |
Epoch 00021 | Loss(train) 1.6414 | Acc(train) 0.5419 | Acc(val) 0.6226 |*
Epoch 00022 | Loss(train) 1.6107 | Acc(train) 0.5561 | Acc(val) 0.6622 |*
Epoch 00023 | Loss(train) 1.5897 | Acc(train) 0.5628 | Acc(val) 0.6442 |
Epoch 00024 | Loss(train) 1.5067 | Acc(train) 0.5762 | Acc(val) 0.6166 |
Epoch 00025 | Loss(train) 1.4987 | Acc(train) 0.5441 | Acc(val) 0.6151 |
Epoch 00026 | Loss(train) 1.4753 | Acc(train) 0.5605 | Acc(val) 0.6300 |
Epoch 00027 | Loss(train) 1.4385 | Acc(train) 0.5691 | Acc(val) 0.6487 |
Epoch 00028 | Loss(train) 1.4217 | Acc(train) 0.6043 | Acc(val) 0.6525 |
Epoch 00029 | Loss(train) 1.3742 | Acc(train) 0.6185 | Acc(val) 0.6472 |
Epoch 00030 | Loss(train) 1.3608 | Acc(train) 0.6226 | Acc(val) 0.6375 |
Epoch 00031 | Loss(train) 1.3374 | Acc(train) 0.6091 | Acc(val) 0.6420 |
Epoch 00032 | Loss(train) 1.3053 | Acc(train) 0.6117 | Acc(val) 0.6472 |
Epoch 00033 | Loss(train) 1.3063 | Acc(train) 0.6028 | Acc(val) 0.6599 |
Epoch 00034 | Loss(train) 1.2751 | Acc(train) 0.6114 | Acc(val) 0.6622 |
Epoch 00035 | Loss(train) 1.2403 | Acc(train) 0.6293 | Acc(val) 0.6756 |*
Epoch 00036 | Loss(train) 1.2066 | Acc(train) 0.6536 | Acc(val) 0.6913 |*
Epoch 00037 | Loss(train) 1.1893 | Acc(train) 0.6607 | Acc(val) 0.7033 |*
Epoch 00038 | Loss(train) 1.1745 | Acc(train) 0.6342 | Acc(val) 0.7070 |*
Epoch 00039 | Loss(train) 1.1522 | Acc(train) 0.6540 | Acc(val) 0.7040 |
Epoch 00040 | Loss(train) 1.1431 | Acc(train) 0.6431 | Acc(val) 0.7123 |*
Epoch 00041 | Loss(train) 1.1056 | Acc(train) 0.6670 | Acc(val) 0.7033 |
Epoch 00042 | Loss(train) 1.0868 | Acc(train) 0.6532 | Acc(val) 0.6966 |
Epoch 00043 | Loss(train) 1.1087 | Acc(train) 0.6614 | Acc(val) 0.6981 |
Epoch 00044 | Loss(train) 1.0791 | Acc(train) 0.6457 | Acc(val) 0.7115 |
Epoch 00045 | Loss(train) 1.0426 | Acc(train) 0.6603 | Acc(val) 0.7354 |*
Epoch 00046 | Loss(train) 1.0392 | Acc(train) 0.6891 | Acc(val) 0.7534 |*
Epoch 00047 | Loss(train) 1.0205 | Acc(train) 0.6891 | Acc(val) 0.7549 |*
Epoch 00048 | Loss(train) 1.0082 | Acc(train) 0.6868 | Acc(val) 0.7541 |
Epoch 00049 | Loss(train) 0.9952 | Acc(train) 0.6932 | Acc(val) 0.7608 |*
Epoch 00050 | Loss(train) 0.9675 | Acc(train) 0.7093 | Acc(val) 0.7676 |*
Epoch 00051 | Loss(train) 0.9518 | Acc(train) 0.7048 | Acc(val) 0.7631 |
Epoch 00052 | Loss(train) 0.9565 | Acc(train) 0.6996 | Acc(val) 0.7504 |
Epoch 00053 | Loss(train) 0.9368 | Acc(train) 0.6992 | Acc(val) 0.7676 |
Epoch 00054 | Loss(train) 0.9198 | Acc(train) 0.7108 | Acc(val) 0.7848 |*
Epoch 00055 | Loss(train) 0.9237 | Acc(train) 0.7123 | Acc(val) 0.7728 |
Epoch 00056 | Loss(train) 0.9177 | Acc(train) 0.7160 | Acc(val) 0.7683 |
Epoch 00057 | Loss(train) 0.8916 | Acc(train) 0.7194 | Acc(val) 0.7743 |
Epoch 00058 | Loss(train) 0.8986 | Acc(train) 0.7220 | Acc(val) 0.7877 |*
Epoch 00059 | Loss(train) 0.8977 | Acc(train) 0.7164 | Acc(val) 0.8042 |*
Epoch 00060 | Loss(train) 0.8742 | Acc(train) 0.7451 | Acc(val) 0.8027 |
Epoch 00061 | Loss(train) 0.8461 | Acc(train) 0.7380 | Acc(val) 0.7855 |
Epoch 00062 | Loss(train) 0.8537 | Acc(train) 0.7235 | Acc(val) 0.7848 |
Epoch 00063 | Loss(train) 0.8362 | Acc(train) 0.7351 | Acc(val) 0.8012 |
Epoch 00064 | Loss(train) 0.8309 | Acc(train) 0.7399 | Acc(val) 0.8109 |*
Epoch 00065 | Loss(train) 0.8271 | Acc(train) 0.7429 | Acc(val) 0.8124 |*
Epoch 00066 | Loss(train) 0.7878 | Acc(train) 0.7507 | Acc(val) 0.8079 |
Epoch 00067 | Loss(train) 0.7917 | Acc(train) 0.7638 | Acc(val) 0.8102 |
Epoch 00068 | Loss(train) 0.7729 | Acc(train) 0.7545 | Acc(val) 0.8176 |*
Epoch 00069 | Loss(train) 0.7572 | Acc(train) 0.7668 | Acc(val) 0.8169 |
Epoch 00070 | Loss(train) 0.7753 | Acc(train) 0.7623 | Acc(val) 0.8161 |
Epoch 00071 | Loss(train) 0.7786 | Acc(train) 0.7425 | Acc(val) 0.8191 |*
Epoch 00072 | Loss(train) 0.7363 | Acc(train) 0.7649 | Acc(val) 0.8214 |*
Epoch 00073 | Loss(train) 0.7722 | Acc(train) 0.7519 | Acc(val) 0.8206 |
Epoch 00074 | Loss(train) 0.7656 | Acc(train) 0.7653 | Acc(val) 0.8221 |*
Epoch 00075 | Loss(train) 0.7277 | Acc(train) 0.7706 | Acc(val) 0.8296 |*
Epoch 00076 | Loss(train) 0.7237 | Acc(train) 0.7833 | Acc(val) 0.8393 |*
Epoch 00077 | Loss(train) 0.7137 | Acc(train) 0.7754 | Acc(val) 0.8430 |*
Epoch 00078 | Loss(train) 0.7269 | Acc(train) 0.7799 | Acc(val) 0.8333 |
Epoch 00079 | Loss(train) 0.7090 | Acc(train) 0.7833 | Acc(val) 0.8296 |
Epoch 00080 | Loss(train) 0.7027 | Acc(train) 0.7672 | Acc(val) 0.8326 |
Epoch 00081 | Loss(train) 0.6973 | Acc(train) 0.7773 | Acc(val) 0.8371 |
Epoch 00082 | Loss(train) 0.7022 | Acc(train) 0.7859 | Acc(val) 0.8423 |
Epoch 00083 | Loss(train) 0.7070 | Acc(train) 0.7814 | Acc(val) 0.8543 |*
Epoch 00084 | Loss(train) 0.6746 | Acc(train) 0.7971 | Acc(val) 0.8401 |
Epoch 00085 | Loss(train) 0.6545 | Acc(train) 0.8046 | Acc(val) 0.8408 |
Epoch 00086 | Loss(train) 0.6602 | Acc(train) 0.7866 | Acc(val) 0.8453 |
Epoch 00087 | Loss(train) 0.6575 | Acc(train) 0.7885 | Acc(val) 0.8460 |
Epoch 00088 | Loss(train) 0.6568 | Acc(train) 0.7948 | Acc(val) 0.8445 |
Epoch 00089 | Loss(train) 0.6589 | Acc(train) 0.8016 | Acc(val) 0.8528 |
Epoch 00090 | Loss(train) 0.6640 | Acc(train) 0.7952 | Acc(val) 0.8498 |
Epoch 00091 | Loss(train) 0.6568 | Acc(train) 0.7885 | Acc(val) 0.8401 |
Epoch 00092 | Loss(train) 0.6616 | Acc(train) 0.7919 | Acc(val) 0.8490 |
Epoch 00093 | Loss(train) 0.6644 | Acc(train) 0.7945 | Acc(val) 0.8543 |
Epoch 00094 | Loss(train) 0.6524 | Acc(train) 0.7963 | Acc(val) 0.8647 |*
Epoch 00095 | Loss(train) 0.6380 | Acc(train) 0.8031 | Acc(val) 0.8640 |
Epoch 00096 | Loss(train) 0.6324 | Acc(train) 0.8042 | Acc(val) 0.8580 |
Epoch 00097 | Loss(train) 0.6150 | Acc(train) 0.8120 | Acc(val) 0.8550 |
Epoch 00098 | Loss(train) 0.6350 | Acc(train) 0.7986 | Acc(val) 0.8610 |
Epoch 00099 | Loss(train) 0.6672 | Acc(train) 0.7956 | Acc(val) 0.8438 |
Epoch 00100 | Loss(train) 0.6125 | Acc(train) 0.8113 | Acc(val) 0.8438 |
Epoch 00101 | Loss(train) 0.6464 | Acc(train) 0.8004 | Acc(val) 0.8655 |*
Epoch 00102 | Loss(train) 0.6261 | Acc(train) 0.8090 | Acc(val) 0.8692 |*
Epoch 00103 | Loss(train) 0.6039 | Acc(train) 0.8146 | Acc(val) 0.8565 |
Epoch 00104 | Loss(train) 0.6145 | Acc(train) 0.8102 | Acc(val) 0.8535 |
Epoch 00105 | Loss(train) 0.5941 | Acc(train) 0.8090 | Acc(val) 0.8520 |
Epoch 00106 | Loss(train) 0.6169 | Acc(train) 0.8098 | Acc(val) 0.8580 |
Epoch 00107 | Loss(train) 0.6044 | Acc(train) 0.8128 | Acc(val) 0.8759 |*
Epoch 00108 | Loss(train) 0.6015 | Acc(train) 0.8090 | Acc(val) 0.8722 |
Epoch 00109 | Loss(train) 0.5963 | Acc(train) 0.8105 | Acc(val) 0.8692 |
Epoch 00110 | Loss(train) 0.5808 | Acc(train) 0.8210 | Acc(val) 0.8550 |
Epoch 00111 | Loss(train) 0.5839 | Acc(train) 0.8150 | Acc(val) 0.8587 |
Epoch 00112 | Loss(train) 0.5885 | Acc(train) 0.8087 | Acc(val) 0.8640 |
Epoch 00113 | Loss(train) 0.5763 | Acc(train) 0.8221 | Acc(val) 0.8744 |
Epoch 00114 | Loss(train) 0.5877 | Acc(train) 0.8191 | Acc(val) 0.8617 |
Epoch 00115 | Loss(train) 0.5669 | Acc(train) 0.8341 | Acc(val) 0.8572 |
Epoch 00116 | Loss(train) 0.5903 | Acc(train) 0.8117 | Acc(val) 0.8677 |
Epoch 00117 | Loss(train) 0.5791 | Acc(train) 0.8255 | Acc(val) 0.8685 |
Epoch 00118 | Loss(train) 0.5753 | Acc(train) 0.8195 | Acc(val) 0.8565 |
Epoch 00119 | Loss(train) 0.5872 | Acc(train) 0.8165 | Acc(val) 0.8483 |
Epoch 00120 | Loss(train) 0.5829 | Acc(train) 0.8158 | Acc(val) 0.8595 |
Epoch 00121 | Loss(train) 0.5531 | Acc(train) 0.8296 | Acc(val) 0.8662 |
Epoch 00122 | Loss(train) 0.5685 | Acc(train) 0.8262 | Acc(val) 0.8595 |
Epoch 00123 | Loss(train) 0.5601 | Acc(train) 0.8259 | Acc(val) 0.8640 |
Epoch 00124 | Loss(train) 0.5667 | Acc(train) 0.8217 | Acc(val) 0.8737 |
Epoch 00125 | Loss(train) 0.5624 | Acc(train) 0.8333 | Acc(val) 0.8632 |
Epoch 00126 | Loss(train) 0.5639 | Acc(train) 0.8199 | Acc(val) 0.8677 |
Epoch 00127 | Loss(train) 0.5497 | Acc(train) 0.8288 | Acc(val) 0.8677 |
Epoch 00128 | Loss(train) 0.5637 | Acc(train) 0.8281 | Acc(val) 0.8752 |
Epoch 00129 | Loss(train) 0.5569 | Acc(train) 0.8240 | Acc(val) 0.8722 |
Epoch 00130 | Loss(train) 0.5453 | Acc(train) 0.8337 | Acc(val) 0.8752 |
Epoch 00131 | Loss(train) 0.5489 | Acc(train) 0.8266 | Acc(val) 0.8707 |
Epoch 00132 | Loss(train) 0.5556 | Acc(train) 0.8348 | Acc(val) 0.8774 |*
Epoch 00133 | Loss(train) 0.5566 | Acc(train) 0.8333 | Acc(val) 0.8737 |
Epoch 00134 | Loss(train) 0.5418 | Acc(train) 0.8389 | Acc(val) 0.8737 |
Epoch 00135 | Loss(train) 0.5452 | Acc(train) 0.8356 | Acc(val) 0.8670 |
Epoch 00136 | Loss(train) 0.5455 | Acc(train) 0.8236 | Acc(val) 0.8640 |
Epoch 00137 | Loss(train) 0.5410 | Acc(train) 0.8259 | Acc(val) 0.8640 |
Epoch 00138 | Loss(train) 0.5224 | Acc(train) 0.8341 | Acc(val) 0.8714 |
Epoch 00139 | Loss(train) 0.5405 | Acc(train) 0.8303 | Acc(val) 0.8752 |
Epoch 00140 | Loss(train) 0.5433 | Acc(train) 0.8311 | Acc(val) 0.8834 |*
Epoch 00141 | Loss(train) 0.5402 | Acc(train) 0.8337 | Acc(val) 0.8685 |
Epoch 00142 | Loss(train) 0.5399 | Acc(train) 0.8333 | Acc(val) 0.8647 |
Epoch 00143 | Loss(train) 0.5321 | Acc(train) 0.8288 | Acc(val) 0.8722 |
Epoch 00144 | Loss(train) 0.5308 | Acc(train) 0.8274 | Acc(val) 0.8782 |
Epoch 00145 | Loss(train) 0.5158 | Acc(train) 0.8423 | Acc(val) 0.8759 |
Epoch 00146 | Loss(train) 0.5294 | Acc(train) 0.8307 | Acc(val) 0.8812 |
Epoch 00147 | Loss(train) 0.5170 | Acc(train) 0.8442 | Acc(val) 0.8729 |
Epoch 00148 | Loss(train) 0.5100 | Acc(train) 0.8419 | Acc(val) 0.8722 |
Epoch 00149 | Loss(train) 0.5290 | Acc(train) 0.8401 | Acc(val) 0.8714 |
Epoch 00150 | Loss(train) 0.5180 | Acc(train) 0.8430 | Acc(val) 0.8827 |
Epoch 00151 | Loss(train) 0.5114 | Acc(train) 0.8416 | Acc(val) 0.8759 |
Epoch 00152 | Loss(train) 0.5253 | Acc(train) 0.8270 | Acc(val) 0.8782 |
Epoch 00153 | Loss(train) 0.5003 | Acc(train) 0.8397 | Acc(val) 0.8729 |
Epoch 00154 | Loss(train) 0.5333 | Acc(train) 0.8330 | Acc(val) 0.8722 |
Epoch 00155 | Loss(train) 0.5320 | Acc(train) 0.8259 | Acc(val) 0.8842 |*
Epoch 00156 | Loss(train) 0.5169 | Acc(train) 0.8442 | Acc(val) 0.8804 |
Epoch 00157 | Loss(train) 0.5185 | Acc(train) 0.8378 | Acc(val) 0.8707 |
Epoch 00158 | Loss(train) 0.5124 | Acc(train) 0.8352 | Acc(val) 0.8864 |*
Epoch 00159 | Loss(train) 0.5135 | Acc(train) 0.8404 | Acc(val) 0.8849 |
Epoch 00160 | Loss(train) 0.5171 | Acc(train) 0.8348 | Acc(val) 0.8774 |
Epoch 00161 | Loss(train) 0.5069 | Acc(train) 0.8416 | Acc(val) 0.8729 |
Epoch 00162 | Loss(train) 0.5006 | Acc(train) 0.8464 | Acc(val) 0.8804 |
Epoch 00163 | Loss(train) 0.4836 | Acc(train) 0.8539 | Acc(val) 0.8797 |
Epoch 00164 | Loss(train) 0.5056 | Acc(train) 0.8393 | Acc(val) 0.8804 |
Epoch 00165 | Loss(train) 0.4916 | Acc(train) 0.8483 | Acc(val) 0.8774 |
Epoch 00166 | Loss(train) 0.5117 | Acc(train) 0.8378 | Acc(val) 0.8707 |
Epoch 00167 | Loss(train) 0.5062 | Acc(train) 0.8401 | Acc(val) 0.8707 |
Epoch 00168 | Loss(train) 0.4987 | Acc(train) 0.8363 | Acc(val) 0.8842 |
Epoch 00169 | Loss(train) 0.4972 | Acc(train) 0.8460 | Acc(val) 0.8827 |
Epoch 00170 | Loss(train) 0.5085 | Acc(train) 0.8539 | Acc(val) 0.8610 |
Epoch 00171 | Loss(train) 0.4981 | Acc(train) 0.8442 | Acc(val) 0.8714 |
Epoch 00172 | Loss(train) 0.4975 | Acc(train) 0.8475 | Acc(val) 0.8879 |*
Epoch 00173 | Loss(train) 0.4909 | Acc(train) 0.8494 | Acc(val) 0.8879 |
Epoch 00174 | Loss(train) 0.5012 | Acc(train) 0.8434 | Acc(val) 0.8767 |
Epoch 00175 | Loss(train) 0.4987 | Acc(train) 0.8423 | Acc(val) 0.8759 |
Epoch 00176 | Loss(train) 0.5011 | Acc(train) 0.8401 | Acc(val) 0.8909 |*
Epoch 00177 | Loss(train) 0.4814 | Acc(train) 0.8599 | Acc(val) 0.8849 |
Epoch 00178 | Loss(train) 0.5053 | Acc(train) 0.8550 | Acc(val) 0.8685 |
Epoch 00179 | Loss(train) 0.4893 | Acc(train) 0.8524 | Acc(val) 0.8707 |
Epoch 00180 | Loss(train) 0.4964 | Acc(train) 0.8457 | Acc(val) 0.8901 |
Epoch 00181 | Loss(train) 0.4767 | Acc(train) 0.8501 | Acc(val) 0.8879 |
Epoch 00182 | Loss(train) 0.4878 | Acc(train) 0.8520 | Acc(val) 0.8797 |
Epoch 00183 | Loss(train) 0.4804 | Acc(train) 0.8442 | Acc(val) 0.8804 |
Epoch 00184 | Loss(train) 0.4809 | Acc(train) 0.8464 | Acc(val) 0.8871 |
Epoch 00185 | Loss(train) 0.4834 | Acc(train) 0.8558 | Acc(val) 0.8879 |
Epoch 00186 | Loss(train) 0.4799 | Acc(train) 0.8587 | Acc(val) 0.8879 |
Epoch 00187 | Loss(train) 0.4742 | Acc(train) 0.8516 | Acc(val) 0.8842 |
Epoch 00188 | Loss(train) 0.4926 | Acc(train) 0.8509 | Acc(val) 0.8804 |
Epoch 00189 | Loss(train) 0.4817 | Acc(train) 0.8513 | Acc(val) 0.8849 |
Epoch 00190 | Loss(train) 0.4829 | Acc(train) 0.8442 | Acc(val) 0.8871 |
Epoch 00191 | Loss(train) 0.4839 | Acc(train) 0.8550 | Acc(val) 0.8827 |
Epoch 00192 | Loss(train) 0.4840 | Acc(train) 0.8498 | Acc(val) 0.8864 |
Epoch 00193 | Loss(train) 0.4727 | Acc(train) 0.8501 | Acc(val) 0.8909 |
Epoch 00194 | Loss(train) 0.4709 | Acc(train) 0.8565 | Acc(val) 0.8894 |
Epoch 00195 | Loss(train) 0.4715 | Acc(train) 0.8632 | Acc(val) 0.8707 |
Epoch 00196 | Loss(train) 0.4867 | Acc(train) 0.8475 | Acc(val) 0.8871 |
Epoch 00197 | Loss(train) 0.4688 | Acc(train) 0.8531 | Acc(val) 0.8894 |
Epoch 00198 | Loss(train) 0.4698 | Acc(train) 0.8546 | Acc(val) 0.8871 |
Epoch 00199 | Loss(train) 0.4518 | Acc(train) 0.8617 | Acc(val) 0.8834 |
Epoch 00200 | Loss(train) 0.4920 | Acc(train) 0.8494 | Acc(val) 0.8834 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 6/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.5498 | Acc(train) 0.0239 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 5.2098 | Acc(train) 0.3692 | Acc(val) 0.3714 |
Epoch 00003 | Loss(train) 2.6404 | Acc(train) 0.2735 | Acc(val) 0.0314 |
Epoch 00004 | Loss(train) 2.5027 | Acc(train) 0.0762 | Acc(val) 0.1726 |
Epoch 00005 | Loss(train) 2.2034 | Acc(train) 0.1805 | Acc(val) 0.3759 |*
Epoch 00006 | Loss(train) 2.0021 | Acc(train) 0.3763 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.1175 | Acc(train) 0.3629 | Acc(val) 0.3714 |
Epoch 00008 | Loss(train) 2.0838 | Acc(train) 0.3625 | Acc(val) 0.3714 |
Epoch 00009 | Loss(train) 2.0152 | Acc(train) 0.3703 | Acc(val) 0.3714 |
Epoch 00010 | Loss(train) 1.9634 | Acc(train) 0.3711 | Acc(val) 0.4806 |*
Epoch 00011 | Loss(train) 1.9659 | Acc(train) 0.4133 | Acc(val) 0.5807 |*
Epoch 00012 | Loss(train) 1.8683 | Acc(train) 0.4458 | Acc(val) 0.5381 |
Epoch 00013 | Loss(train) 1.8550 | Acc(train) 0.4630 | Acc(val) 0.5433 |
Epoch 00014 | Loss(train) 1.8269 | Acc(train) 0.4552 | Acc(val) 0.4873 |
Epoch 00015 | Loss(train) 1.7530 | Acc(train) 0.4354 | Acc(val) 0.4783 |
Epoch 00016 | Loss(train) 1.7690 | Acc(train) 0.4398 | Acc(val) 0.4671 |
Epoch 00017 | Loss(train) 1.7419 | Acc(train) 0.4671 | Acc(val) 0.4709 |
Epoch 00018 | Loss(train) 1.7028 | Acc(train) 0.4324 | Acc(val) 0.5202 |
Epoch 00019 | Loss(train) 1.6326 | Acc(train) 0.4884 | Acc(val) 0.5247 |
Epoch 00020 | Loss(train) 1.5995 | Acc(train) 0.5071 | Acc(val) 0.5389 |
Epoch 00021 | Loss(train) 1.6006 | Acc(train) 0.4993 | Acc(val) 0.5912 |*
Epoch 00022 | Loss(train) 1.5633 | Acc(train) 0.5355 | Acc(val) 0.6256 |*
Epoch 00023 | Loss(train) 1.5153 | Acc(train) 0.5460 | Acc(val) 0.6353 |*
Epoch 00024 | Loss(train) 1.4746 | Acc(train) 0.5605 | Acc(val) 0.6682 |*
Epoch 00025 | Loss(train) 1.4548 | Acc(train) 0.5841 | Acc(val) 0.6779 |*
Epoch 00026 | Loss(train) 1.3999 | Acc(train) 0.5994 | Acc(val) 0.6719 |
Epoch 00027 | Loss(train) 1.3686 | Acc(train) 0.5972 | Acc(val) 0.6577 |
Epoch 00028 | Loss(train) 1.3530 | Acc(train) 0.6140 | Acc(val) 0.6966 |*
Epoch 00029 | Loss(train) 1.3058 | Acc(train) 0.6207 | Acc(val) 0.7175 |*
Epoch 00030 | Loss(train) 1.2882 | Acc(train) 0.6491 | Acc(val) 0.7294 |*
Epoch 00031 | Loss(train) 1.2597 | Acc(train) 0.6599 | Acc(val) 0.7407 |*
Epoch 00032 | Loss(train) 1.2147 | Acc(train) 0.6775 | Acc(val) 0.7436 |*
Epoch 00033 | Loss(train) 1.2062 | Acc(train) 0.6685 | Acc(val) 0.7429 |
Epoch 00034 | Loss(train) 1.1420 | Acc(train) 0.6925 | Acc(val) 0.7422 |
Epoch 00035 | Loss(train) 1.1160 | Acc(train) 0.6835 | Acc(val) 0.7474 |*
Epoch 00036 | Loss(train) 1.0810 | Acc(train) 0.7003 | Acc(val) 0.7541 |*
Epoch 00037 | Loss(train) 1.0642 | Acc(train) 0.6872 | Acc(val) 0.7549 |*
Epoch 00038 | Loss(train) 1.0684 | Acc(train) 0.6850 | Acc(val) 0.7571 |*
Epoch 00039 | Loss(train) 1.0236 | Acc(train) 0.6996 | Acc(val) 0.7571 |
Epoch 00040 | Loss(train) 1.0011 | Acc(train) 0.6951 | Acc(val) 0.7743 |*
Epoch 00041 | Loss(train) 0.9761 | Acc(train) 0.7063 | Acc(val) 0.7795 |*
Epoch 00042 | Loss(train) 0.9334 | Acc(train) 0.7294 | Acc(val) 0.7907 |*
Epoch 00043 | Loss(train) 0.9533 | Acc(train) 0.7268 | Acc(val) 0.7892 |
Epoch 00044 | Loss(train) 0.9185 | Acc(train) 0.7283 | Acc(val) 0.7825 |
Epoch 00045 | Loss(train) 0.8925 | Acc(train) 0.7276 | Acc(val) 0.7855 |
Epoch 00046 | Loss(train) 0.8825 | Acc(train) 0.7332 | Acc(val) 0.7975 |*
Epoch 00047 | Loss(train) 0.8709 | Acc(train) 0.7339 | Acc(val) 0.8012 |*
Epoch 00048 | Loss(train) 0.8807 | Acc(train) 0.7324 | Acc(val) 0.7915 |
Epoch 00049 | Loss(train) 0.8312 | Acc(train) 0.7392 | Acc(val) 0.7945 |
Epoch 00050 | Loss(train) 0.8237 | Acc(train) 0.7455 | Acc(val) 0.8027 |*
Epoch 00051 | Loss(train) 0.8247 | Acc(train) 0.7399 | Acc(val) 0.8176 |*
Epoch 00052 | Loss(train) 0.7895 | Acc(train) 0.7638 | Acc(val) 0.8169 |
Epoch 00053 | Loss(train) 0.8109 | Acc(train) 0.7459 | Acc(val) 0.8042 |
Epoch 00054 | Loss(train) 0.7893 | Acc(train) 0.7608 | Acc(val) 0.8169 |
Epoch 00055 | Loss(train) 0.7917 | Acc(train) 0.7545 | Acc(val) 0.8274 |*
Epoch 00056 | Loss(train) 0.7514 | Acc(train) 0.7709 | Acc(val) 0.8356 |*
Epoch 00057 | Loss(train) 0.7565 | Acc(train) 0.7668 | Acc(val) 0.8199 |
Epoch 00058 | Loss(train) 0.7696 | Acc(train) 0.7735 | Acc(val) 0.8146 |
Epoch 00059 | Loss(train) 0.7639 | Acc(train) 0.7635 | Acc(val) 0.8296 |
Epoch 00060 | Loss(train) 0.7239 | Acc(train) 0.7754 | Acc(val) 0.8326 |
Epoch 00061 | Loss(train) 0.7305 | Acc(train) 0.7735 | Acc(val) 0.8363 |*
Epoch 00062 | Loss(train) 0.7327 | Acc(train) 0.7803 | Acc(val) 0.8363 |
Epoch 00063 | Loss(train) 0.7195 | Acc(train) 0.7780 | Acc(val) 0.8371 |*
Epoch 00064 | Loss(train) 0.7087 | Acc(train) 0.7862 | Acc(val) 0.8460 |*
Epoch 00065 | Loss(train) 0.7129 | Acc(train) 0.7810 | Acc(val) 0.8416 |
Epoch 00066 | Loss(train) 0.7138 | Acc(train) 0.7694 | Acc(val) 0.8475 |*
Epoch 00067 | Loss(train) 0.6831 | Acc(train) 0.8008 | Acc(val) 0.8453 |
Epoch 00068 | Loss(train) 0.6955 | Acc(train) 0.7821 | Acc(val) 0.8550 |*
Epoch 00069 | Loss(train) 0.6741 | Acc(train) 0.8034 | Acc(val) 0.8580 |*
Epoch 00070 | Loss(train) 0.6612 | Acc(train) 0.7956 | Acc(val) 0.8558 |
Epoch 00071 | Loss(train) 0.6890 | Acc(train) 0.7848 | Acc(val) 0.8543 |
Epoch 00072 | Loss(train) 0.6518 | Acc(train) 0.8016 | Acc(val) 0.8468 |
Epoch 00073 | Loss(train) 0.6673 | Acc(train) 0.7892 | Acc(val) 0.8520 |
Epoch 00074 | Loss(train) 0.6605 | Acc(train) 0.7975 | Acc(val) 0.8543 |
Epoch 00075 | Loss(train) 0.6716 | Acc(train) 0.7997 | Acc(val) 0.8550 |
Epoch 00076 | Loss(train) 0.6719 | Acc(train) 0.7990 | Acc(val) 0.8475 |
Epoch 00077 | Loss(train) 0.6482 | Acc(train) 0.8008 | Acc(val) 0.8513 |
Epoch 00078 | Loss(train) 0.6436 | Acc(train) 0.8016 | Acc(val) 0.8655 |*
Epoch 00079 | Loss(train) 0.6355 | Acc(train) 0.8016 | Acc(val) 0.8677 |*
Epoch 00080 | Loss(train) 0.6427 | Acc(train) 0.8049 | Acc(val) 0.8640 |
Epoch 00081 | Loss(train) 0.6333 | Acc(train) 0.8049 | Acc(val) 0.8453 |
Epoch 00082 | Loss(train) 0.6353 | Acc(train) 0.8075 | Acc(val) 0.8535 |
Epoch 00083 | Loss(train) 0.6167 | Acc(train) 0.8169 | Acc(val) 0.8595 |
Epoch 00084 | Loss(train) 0.6388 | Acc(train) 0.8061 | Acc(val) 0.8617 |
Epoch 00085 | Loss(train) 0.6186 | Acc(train) 0.8031 | Acc(val) 0.8558 |
Epoch 00086 | Loss(train) 0.6274 | Acc(train) 0.8068 | Acc(val) 0.8580 |
Epoch 00087 | Loss(train) 0.6111 | Acc(train) 0.8012 | Acc(val) 0.8670 |
Epoch 00088 | Loss(train) 0.6175 | Acc(train) 0.8120 | Acc(val) 0.8647 |
Epoch 00089 | Loss(train) 0.6020 | Acc(train) 0.8109 | Acc(val) 0.8617 |
Epoch 00090 | Loss(train) 0.6160 | Acc(train) 0.8098 | Acc(val) 0.8632 |
Epoch 00091 | Loss(train) 0.6154 | Acc(train) 0.8150 | Acc(val) 0.8647 |
Epoch 00092 | Loss(train) 0.6154 | Acc(train) 0.8016 | Acc(val) 0.8692 |*
Epoch 00093 | Loss(train) 0.6198 | Acc(train) 0.7971 | Acc(val) 0.8617 |
Epoch 00094 | Loss(train) 0.5958 | Acc(train) 0.8139 | Acc(val) 0.8528 |
Epoch 00095 | Loss(train) 0.6209 | Acc(train) 0.8042 | Acc(val) 0.8640 |
Epoch 00096 | Loss(train) 0.5975 | Acc(train) 0.8188 | Acc(val) 0.8789 |*
Epoch 00097 | Loss(train) 0.6095 | Acc(train) 0.8158 | Acc(val) 0.8685 |
Epoch 00098 | Loss(train) 0.5916 | Acc(train) 0.8176 | Acc(val) 0.8550 |
Epoch 00099 | Loss(train) 0.6014 | Acc(train) 0.8124 | Acc(val) 0.8543 |
Epoch 00100 | Loss(train) 0.5925 | Acc(train) 0.8143 | Acc(val) 0.8707 |
Epoch 00101 | Loss(train) 0.5835 | Acc(train) 0.8150 | Acc(val) 0.8707 |
Epoch 00102 | Loss(train) 0.6120 | Acc(train) 0.8083 | Acc(val) 0.8625 |
Epoch 00103 | Loss(train) 0.5778 | Acc(train) 0.8203 | Acc(val) 0.8610 |
Epoch 00104 | Loss(train) 0.5815 | Acc(train) 0.8139 | Acc(val) 0.8685 |
Epoch 00105 | Loss(train) 0.5722 | Acc(train) 0.8300 | Acc(val) 0.8759 |
Epoch 00106 | Loss(train) 0.5813 | Acc(train) 0.8206 | Acc(val) 0.8700 |
Epoch 00107 | Loss(train) 0.5839 | Acc(train) 0.8221 | Acc(val) 0.8647 |
Epoch 00108 | Loss(train) 0.5777 | Acc(train) 0.8150 | Acc(val) 0.8752 |
Epoch 00109 | Loss(train) 0.5714 | Acc(train) 0.8214 | Acc(val) 0.8759 |
Epoch 00110 | Loss(train) 0.5802 | Acc(train) 0.8150 | Acc(val) 0.8722 |
Epoch 00111 | Loss(train) 0.5832 | Acc(train) 0.8169 | Acc(val) 0.8670 |
Epoch 00112 | Loss(train) 0.5797 | Acc(train) 0.8154 | Acc(val) 0.8707 |
Epoch 00113 | Loss(train) 0.5568 | Acc(train) 0.8359 | Acc(val) 0.8797 |*
Epoch 00114 | Loss(train) 0.5654 | Acc(train) 0.8262 | Acc(val) 0.8714 |
Epoch 00115 | Loss(train) 0.5566 | Acc(train) 0.8300 | Acc(val) 0.8640 |
Epoch 00116 | Loss(train) 0.5712 | Acc(train) 0.8195 | Acc(val) 0.8685 |
Epoch 00117 | Loss(train) 0.5457 | Acc(train) 0.8307 | Acc(val) 0.8759 |
Epoch 00118 | Loss(train) 0.5822 | Acc(train) 0.8247 | Acc(val) 0.8782 |
Epoch 00119 | Loss(train) 0.5881 | Acc(train) 0.8210 | Acc(val) 0.8707 |
Epoch 00120 | Loss(train) 0.5567 | Acc(train) 0.8262 | Acc(val) 0.8655 |
Epoch 00121 | Loss(train) 0.5820 | Acc(train) 0.8203 | Acc(val) 0.8677 |
Epoch 00122 | Loss(train) 0.5603 | Acc(train) 0.8356 | Acc(val) 0.8827 |*
Epoch 00123 | Loss(train) 0.5642 | Acc(train) 0.8266 | Acc(val) 0.8834 |*
Epoch 00124 | Loss(train) 0.5692 | Acc(train) 0.8165 | Acc(val) 0.8655 |
Epoch 00125 | Loss(train) 0.5818 | Acc(train) 0.8143 | Acc(val) 0.8707 |
Epoch 00126 | Loss(train) 0.5810 | Acc(train) 0.8214 | Acc(val) 0.8849 |*
Epoch 00127 | Loss(train) 0.5458 | Acc(train) 0.8255 | Acc(val) 0.8812 |
Epoch 00128 | Loss(train) 0.5371 | Acc(train) 0.8393 | Acc(val) 0.8759 |
Epoch 00129 | Loss(train) 0.5324 | Acc(train) 0.8337 | Acc(val) 0.8685 |
Epoch 00130 | Loss(train) 0.5405 | Acc(train) 0.8274 | Acc(val) 0.8774 |
Epoch 00131 | Loss(train) 0.5430 | Acc(train) 0.8274 | Acc(val) 0.8834 |
Epoch 00132 | Loss(train) 0.5409 | Acc(train) 0.8277 | Acc(val) 0.8737 |
Epoch 00133 | Loss(train) 0.5548 | Acc(train) 0.8232 | Acc(val) 0.8819 |
Epoch 00134 | Loss(train) 0.5458 | Acc(train) 0.8274 | Acc(val) 0.8737 |
Epoch 00135 | Loss(train) 0.5451 | Acc(train) 0.8229 | Acc(val) 0.8729 |
Epoch 00136 | Loss(train) 0.5355 | Acc(train) 0.8356 | Acc(val) 0.8767 |
Epoch 00137 | Loss(train) 0.5302 | Acc(train) 0.8345 | Acc(val) 0.8767 |
Epoch 00138 | Loss(train) 0.5197 | Acc(train) 0.8475 | Acc(val) 0.8774 |
Epoch 00139 | Loss(train) 0.5388 | Acc(train) 0.8311 | Acc(val) 0.8714 |
Epoch 00140 | Loss(train) 0.5392 | Acc(train) 0.8296 | Acc(val) 0.8789 |
Epoch 00141 | Loss(train) 0.5286 | Acc(train) 0.8322 | Acc(val) 0.8789 |
Epoch 00142 | Loss(train) 0.5417 | Acc(train) 0.8345 | Acc(val) 0.8812 |
Epoch 00143 | Loss(train) 0.5266 | Acc(train) 0.8374 | Acc(val) 0.8857 |*
Epoch 00144 | Loss(train) 0.5345 | Acc(train) 0.8288 | Acc(val) 0.8737 |
Epoch 00145 | Loss(train) 0.5369 | Acc(train) 0.8337 | Acc(val) 0.8700 |
Epoch 00146 | Loss(train) 0.5190 | Acc(train) 0.8430 | Acc(val) 0.8789 |
Epoch 00147 | Loss(train) 0.5281 | Acc(train) 0.8341 | Acc(val) 0.8827 |
Epoch 00148 | Loss(train) 0.5032 | Acc(train) 0.8378 | Acc(val) 0.8812 |
Epoch 00149 | Loss(train) 0.5278 | Acc(train) 0.8318 | Acc(val) 0.8834 |
Epoch 00150 | Loss(train) 0.5232 | Acc(train) 0.8345 | Acc(val) 0.8737 |
Epoch 00151 | Loss(train) 0.5285 | Acc(train) 0.8326 | Acc(val) 0.8782 |
Epoch 00152 | Loss(train) 0.5146 | Acc(train) 0.8367 | Acc(val) 0.8827 |
Epoch 00153 | Loss(train) 0.5085 | Acc(train) 0.8423 | Acc(val) 0.8894 |*
Epoch 00154 | Loss(train) 0.5291 | Acc(train) 0.8303 | Acc(val) 0.8842 |
Epoch 00155 | Loss(train) 0.5079 | Acc(train) 0.8401 | Acc(val) 0.8767 |
Epoch 00156 | Loss(train) 0.5175 | Acc(train) 0.8333 | Acc(val) 0.8864 |
Epoch 00157 | Loss(train) 0.4932 | Acc(train) 0.8509 | Acc(val) 0.8804 |
Epoch 00158 | Loss(train) 0.5223 | Acc(train) 0.8367 | Acc(val) 0.8774 |
Epoch 00159 | Loss(train) 0.5282 | Acc(train) 0.8281 | Acc(val) 0.8797 |
Epoch 00160 | Loss(train) 0.5090 | Acc(train) 0.8345 | Acc(val) 0.8842 |
Epoch 00161 | Loss(train) 0.4932 | Acc(train) 0.8408 | Acc(val) 0.8864 |
Epoch 00162 | Loss(train) 0.5198 | Acc(train) 0.8389 | Acc(val) 0.8737 |
Epoch 00163 | Loss(train) 0.5186 | Acc(train) 0.8374 | Acc(val) 0.8812 |
Epoch 00164 | Loss(train) 0.5082 | Acc(train) 0.8442 | Acc(val) 0.8857 |
Epoch 00165 | Loss(train) 0.5024 | Acc(train) 0.8427 | Acc(val) 0.8744 |
Epoch 00166 | Loss(train) 0.5074 | Acc(train) 0.8434 | Acc(val) 0.8759 |
Epoch 00167 | Loss(train) 0.5000 | Acc(train) 0.8449 | Acc(val) 0.8864 |
Epoch 00168 | Loss(train) 0.4986 | Acc(train) 0.8423 | Acc(val) 0.8879 |
Epoch 00169 | Loss(train) 0.4827 | Acc(train) 0.8457 | Acc(val) 0.8662 |
Epoch 00170 | Loss(train) 0.4973 | Acc(train) 0.8445 | Acc(val) 0.8714 |
Epoch 00171 | Loss(train) 0.4994 | Acc(train) 0.8430 | Acc(val) 0.8857 |
Epoch 00172 | Loss(train) 0.4966 | Acc(train) 0.8389 | Acc(val) 0.8782 |
Epoch 00173 | Loss(train) 0.5233 | Acc(train) 0.8318 | Acc(val) 0.8789 |
Epoch 00174 | Loss(train) 0.5000 | Acc(train) 0.8438 | Acc(val) 0.8797 |
Epoch 00175 | Loss(train) 0.5184 | Acc(train) 0.8270 | Acc(val) 0.8871 |
Epoch 00176 | Loss(train) 0.4893 | Acc(train) 0.8501 | Acc(val) 0.8789 |
Epoch 00177 | Loss(train) 0.5050 | Acc(train) 0.8378 | Acc(val) 0.8744 |
Epoch 00178 | Loss(train) 0.4953 | Acc(train) 0.8423 | Acc(val) 0.8849 |
Epoch 00179 | Loss(train) 0.4772 | Acc(train) 0.8520 | Acc(val) 0.8894 |
Epoch 00180 | Loss(train) 0.4937 | Acc(train) 0.8453 | Acc(val) 0.8797 |
Epoch 00181 | Loss(train) 0.4994 | Acc(train) 0.8333 | Acc(val) 0.8804 |
Epoch 00182 | Loss(train) 0.4920 | Acc(train) 0.8341 | Acc(val) 0.8879 |
Epoch 00183 | Loss(train) 0.4870 | Acc(train) 0.8438 | Acc(val) 0.8804 |
Epoch 00184 | Loss(train) 0.4918 | Acc(train) 0.8359 | Acc(val) 0.8759 |
Epoch 00185 | Loss(train) 0.5021 | Acc(train) 0.8341 | Acc(val) 0.8879 |
Epoch 00186 | Loss(train) 0.4560 | Acc(train) 0.8584 | Acc(val) 0.8879 |
Epoch 00187 | Loss(train) 0.4818 | Acc(train) 0.8487 | Acc(val) 0.8812 |
Epoch 00188 | Loss(train) 0.4834 | Acc(train) 0.8535 | Acc(val) 0.8834 |
Epoch 00189 | Loss(train) 0.4726 | Acc(train) 0.8501 | Acc(val) 0.8894 |
Epoch 00190 | Loss(train) 0.4754 | Acc(train) 0.8513 | Acc(val) 0.8894 |
Epoch 00191 | Loss(train) 0.4592 | Acc(train) 0.8535 | Acc(val) 0.8782 |
Epoch 00192 | Loss(train) 0.4876 | Acc(train) 0.8490 | Acc(val) 0.8774 |
Epoch 00193 | Loss(train) 0.4940 | Acc(train) 0.8457 | Acc(val) 0.8894 |
Epoch 00194 | Loss(train) 0.4766 | Acc(train) 0.8505 | Acc(val) 0.8931 |*
Epoch 00195 | Loss(train) 0.4928 | Acc(train) 0.8479 | Acc(val) 0.8632 |
Epoch 00196 | Loss(train) 0.5049 | Acc(train) 0.8374 | Acc(val) 0.8789 |
Epoch 00197 | Loss(train) 0.4802 | Acc(train) 0.8449 | Acc(val) 0.8834 |
Epoch 00198 | Loss(train) 0.5074 | Acc(train) 0.8341 | Acc(val) 0.8886 |
Epoch 00199 | Loss(train) 0.4781 | Acc(train) 0.8509 | Acc(val) 0.8797 |
Epoch 00200 | Loss(train) 0.4781 | Acc(train) 0.8520 | Acc(val) 0.8819 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 7/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.6066 | Acc(train) 0.0389 | Acc(val) 0.1629 |*
Epoch 00002 | Loss(train) 2.4453 | Acc(train) 0.2276 | Acc(val) 0.3714 |*
Epoch 00003 | Loss(train) 2.9591 | Acc(train) 0.3587 | Acc(val) 0.3430 |
Epoch 00004 | Loss(train) 2.3333 | Acc(train) 0.2522 | Acc(val) 0.1988 |
Epoch 00005 | Loss(train) 2.3061 | Acc(train) 0.2093 | Acc(val) 0.1203 |
Epoch 00006 | Loss(train) 2.1445 | Acc(train) 0.2014 | Acc(val) 0.4268 |*
Epoch 00007 | Loss(train) 2.0077 | Acc(train) 0.3830 | Acc(val) 0.3714 |
Epoch 00008 | Loss(train) 1.9580 | Acc(train) 0.3797 | Acc(val) 0.4365 |*
Epoch 00009 | Loss(train) 1.8801 | Acc(train) 0.4286 | Acc(val) 0.4664 |*
Epoch 00010 | Loss(train) 1.8360 | Acc(train) 0.4458 | Acc(val) 0.4858 |*
Epoch 00011 | Loss(train) 1.8244 | Acc(train) 0.4776 | Acc(val) 0.5561 |*
Epoch 00012 | Loss(train) 1.7715 | Acc(train) 0.5194 | Acc(val) 0.5299 |
Epoch 00013 | Loss(train) 1.7954 | Acc(train) 0.4993 | Acc(val) 0.5717 |*
Epoch 00014 | Loss(train) 1.6744 | Acc(train) 0.5381 | Acc(val) 0.5807 |*
Epoch 00015 | Loss(train) 1.6845 | Acc(train) 0.5086 | Acc(val) 0.5359 |
Epoch 00016 | Loss(train) 1.6663 | Acc(train) 0.4993 | Acc(val) 0.5590 |
Epoch 00017 | Loss(train) 1.6502 | Acc(train) 0.4884 | Acc(val) 0.6031 |*
Epoch 00018 | Loss(train) 1.6112 | Acc(train) 0.5209 | Acc(val) 0.5516 |
Epoch 00019 | Loss(train) 1.5711 | Acc(train) 0.5355 | Acc(val) 0.5919 |
Epoch 00020 | Loss(train) 1.5166 | Acc(train) 0.5575 | Acc(val) 0.6540 |*
Epoch 00021 | Loss(train) 1.4973 | Acc(train) 0.5703 | Acc(val) 0.6570 |*
Epoch 00022 | Loss(train) 1.4616 | Acc(train) 0.5826 | Acc(val) 0.6360 |
Epoch 00023 | Loss(train) 1.4480 | Acc(train) 0.5998 | Acc(val) 0.6413 |
Epoch 00024 | Loss(train) 1.4096 | Acc(train) 0.6016 | Acc(val) 0.6599 |*
Epoch 00025 | Loss(train) 1.3947 | Acc(train) 0.6069 | Acc(val) 0.6906 |*
Epoch 00026 | Loss(train) 1.3404 | Acc(train) 0.6143 | Acc(val) 0.7108 |*
Epoch 00027 | Loss(train) 1.3090 | Acc(train) 0.6222 | Acc(val) 0.7197 |*
Epoch 00028 | Loss(train) 1.2710 | Acc(train) 0.6525 | Acc(val) 0.7280 |*
Epoch 00029 | Loss(train) 1.2587 | Acc(train) 0.6570 | Acc(val) 0.7250 |
Epoch 00030 | Loss(train) 1.1988 | Acc(train) 0.6618 | Acc(val) 0.7265 |
Epoch 00031 | Loss(train) 1.1970 | Acc(train) 0.6551 | Acc(val) 0.7422 |*
Epoch 00032 | Loss(train) 1.1659 | Acc(train) 0.6693 | Acc(val) 0.7504 |*
Epoch 00033 | Loss(train) 1.1087 | Acc(train) 0.6921 | Acc(val) 0.7496 |
Epoch 00034 | Loss(train) 1.0881 | Acc(train) 0.6835 | Acc(val) 0.7504 |
Epoch 00035 | Loss(train) 1.0619 | Acc(train) 0.6969 | Acc(val) 0.7556 |*
Epoch 00036 | Loss(train) 1.0314 | Acc(train) 0.7070 | Acc(val) 0.7534 |
Epoch 00037 | Loss(train) 1.0119 | Acc(train) 0.7134 | Acc(val) 0.7519 |
Epoch 00038 | Loss(train) 0.9861 | Acc(train) 0.7037 | Acc(val) 0.7646 |*
Epoch 00039 | Loss(train) 0.9379 | Acc(train) 0.7190 | Acc(val) 0.7773 |*
Epoch 00040 | Loss(train) 0.9306 | Acc(train) 0.7261 | Acc(val) 0.7795 |*
Epoch 00041 | Loss(train) 0.9053 | Acc(train) 0.7298 | Acc(val) 0.7818 |*
Epoch 00042 | Loss(train) 0.9213 | Acc(train) 0.7205 | Acc(val) 0.7773 |
Epoch 00043 | Loss(train) 0.9001 | Acc(train) 0.7081 | Acc(val) 0.7967 |*
Epoch 00044 | Loss(train) 0.8952 | Acc(train) 0.7265 | Acc(val) 0.7840 |
Epoch 00045 | Loss(train) 0.8978 | Acc(train) 0.7313 | Acc(val) 0.7960 |
Epoch 00046 | Loss(train) 0.8270 | Acc(train) 0.7493 | Acc(val) 0.8012 |*
Epoch 00047 | Loss(train) 0.8279 | Acc(train) 0.7328 | Acc(val) 0.8004 |
Epoch 00048 | Loss(train) 0.8431 | Acc(train) 0.7324 | Acc(val) 0.7975 |
Epoch 00049 | Loss(train) 0.7834 | Acc(train) 0.7590 | Acc(val) 0.8049 |*
Epoch 00050 | Loss(train) 0.8082 | Acc(train) 0.7448 | Acc(val) 0.8161 |*
Epoch 00051 | Loss(train) 0.8047 | Acc(train) 0.7507 | Acc(val) 0.8259 |*
Epoch 00052 | Loss(train) 0.7406 | Acc(train) 0.7806 | Acc(val) 0.8184 |
Epoch 00053 | Loss(train) 0.7660 | Acc(train) 0.7754 | Acc(val) 0.8318 |*
Epoch 00054 | Loss(train) 0.7345 | Acc(train) 0.7855 | Acc(val) 0.8288 |
Epoch 00055 | Loss(train) 0.7408 | Acc(train) 0.7638 | Acc(val) 0.8109 |
Epoch 00056 | Loss(train) 0.7363 | Acc(train) 0.7657 | Acc(val) 0.8326 |*
Epoch 00057 | Loss(train) 0.7173 | Acc(train) 0.7877 | Acc(val) 0.8416 |*
Epoch 00058 | Loss(train) 0.6979 | Acc(train) 0.7874 | Acc(val) 0.8408 |
Epoch 00059 | Loss(train) 0.7193 | Acc(train) 0.7706 | Acc(val) 0.8408 |
Epoch 00060 | Loss(train) 0.6916 | Acc(train) 0.7948 | Acc(val) 0.8438 |*
Epoch 00061 | Loss(train) 0.6770 | Acc(train) 0.7982 | Acc(val) 0.8303 |
Epoch 00062 | Loss(train) 0.6795 | Acc(train) 0.7956 | Acc(val) 0.8311 |
Epoch 00063 | Loss(train) 0.6752 | Acc(train) 0.7930 | Acc(val) 0.8505 |*
Epoch 00064 | Loss(train) 0.6643 | Acc(train) 0.7941 | Acc(val) 0.8550 |*
Epoch 00065 | Loss(train) 0.6446 | Acc(train) 0.8049 | Acc(val) 0.8490 |
Epoch 00066 | Loss(train) 0.6443 | Acc(train) 0.8139 | Acc(val) 0.8602 |*
Epoch 00067 | Loss(train) 0.6379 | Acc(train) 0.8109 | Acc(val) 0.8617 |*
Epoch 00068 | Loss(train) 0.6571 | Acc(train) 0.7993 | Acc(val) 0.8326 |
Epoch 00069 | Loss(train) 0.6653 | Acc(train) 0.8001 | Acc(val) 0.8468 |
Epoch 00070 | Loss(train) 0.6308 | Acc(train) 0.8180 | Acc(val) 0.8625 |*
Epoch 00071 | Loss(train) 0.6422 | Acc(train) 0.8053 | Acc(val) 0.8528 |
Epoch 00072 | Loss(train) 0.6328 | Acc(train) 0.8109 | Acc(val) 0.8535 |
Epoch 00073 | Loss(train) 0.6228 | Acc(train) 0.8120 | Acc(val) 0.8677 |*
Epoch 00074 | Loss(train) 0.6195 | Acc(train) 0.8135 | Acc(val) 0.8700 |*
Epoch 00075 | Loss(train) 0.6190 | Acc(train) 0.8128 | Acc(val) 0.8610 |
Epoch 00076 | Loss(train) 0.5774 | Acc(train) 0.8307 | Acc(val) 0.8513 |
Epoch 00077 | Loss(train) 0.6113 | Acc(train) 0.8083 | Acc(val) 0.8610 |
Epoch 00078 | Loss(train) 0.6036 | Acc(train) 0.8221 | Acc(val) 0.8714 |*
Epoch 00079 | Loss(train) 0.5845 | Acc(train) 0.8266 | Acc(val) 0.8707 |
Epoch 00080 | Loss(train) 0.5943 | Acc(train) 0.8132 | Acc(val) 0.8700 |
Epoch 00081 | Loss(train) 0.5941 | Acc(train) 0.8210 | Acc(val) 0.8700 |
Epoch 00082 | Loss(train) 0.5726 | Acc(train) 0.8288 | Acc(val) 0.8625 |
Epoch 00083 | Loss(train) 0.5808 | Acc(train) 0.8307 | Acc(val) 0.8602 |
Epoch 00084 | Loss(train) 0.5964 | Acc(train) 0.8173 | Acc(val) 0.8737 |*
Epoch 00085 | Loss(train) 0.5725 | Acc(train) 0.8337 | Acc(val) 0.8700 |
Epoch 00086 | Loss(train) 0.5582 | Acc(train) 0.8326 | Acc(val) 0.8707 |
Epoch 00087 | Loss(train) 0.5588 | Acc(train) 0.8232 | Acc(val) 0.8737 |
Epoch 00088 | Loss(train) 0.5593 | Acc(train) 0.8363 | Acc(val) 0.8662 |
Epoch 00089 | Loss(train) 0.5575 | Acc(train) 0.8277 | Acc(val) 0.8707 |
Epoch 00090 | Loss(train) 0.5743 | Acc(train) 0.8363 | Acc(val) 0.8744 |*
Epoch 00091 | Loss(train) 0.5381 | Acc(train) 0.8318 | Acc(val) 0.8752 |*
Epoch 00092 | Loss(train) 0.5469 | Acc(train) 0.8285 | Acc(val) 0.8752 |
Epoch 00093 | Loss(train) 0.5432 | Acc(train) 0.8311 | Acc(val) 0.8737 |
Epoch 00094 | Loss(train) 0.5492 | Acc(train) 0.8303 | Acc(val) 0.8737 |
Epoch 00095 | Loss(train) 0.5306 | Acc(train) 0.8419 | Acc(val) 0.8737 |
Epoch 00096 | Loss(train) 0.5523 | Acc(train) 0.8326 | Acc(val) 0.8759 |*
Epoch 00097 | Loss(train) 0.5294 | Acc(train) 0.8315 | Acc(val) 0.8744 |
Epoch 00098 | Loss(train) 0.5249 | Acc(train) 0.8412 | Acc(val) 0.8767 |*
Epoch 00099 | Loss(train) 0.5268 | Acc(train) 0.8445 | Acc(val) 0.8752 |
Epoch 00100 | Loss(train) 0.5561 | Acc(train) 0.8285 | Acc(val) 0.8707 |
Epoch 00101 | Loss(train) 0.5272 | Acc(train) 0.8330 | Acc(val) 0.8662 |
Epoch 00102 | Loss(train) 0.5394 | Acc(train) 0.8322 | Acc(val) 0.8759 |
Epoch 00103 | Loss(train) 0.5398 | Acc(train) 0.8416 | Acc(val) 0.8737 |
Epoch 00104 | Loss(train) 0.5353 | Acc(train) 0.8472 | Acc(val) 0.8729 |
Epoch 00105 | Loss(train) 0.5308 | Acc(train) 0.8386 | Acc(val) 0.8722 |
Epoch 00106 | Loss(train) 0.5388 | Acc(train) 0.8371 | Acc(val) 0.8759 |
Epoch 00107 | Loss(train) 0.5247 | Acc(train) 0.8359 | Acc(val) 0.8774 |*
Epoch 00108 | Loss(train) 0.5081 | Acc(train) 0.8408 | Acc(val) 0.8774 |
Epoch 00109 | Loss(train) 0.5064 | Acc(train) 0.8419 | Acc(val) 0.8744 |
Epoch 00110 | Loss(train) 0.5218 | Acc(train) 0.8371 | Acc(val) 0.8752 |
Epoch 00111 | Loss(train) 0.4948 | Acc(train) 0.8472 | Acc(val) 0.8767 |
Epoch 00112 | Loss(train) 0.5025 | Acc(train) 0.8389 | Acc(val) 0.8774 |
Epoch 00113 | Loss(train) 0.5036 | Acc(train) 0.8472 | Acc(val) 0.8737 |
Epoch 00114 | Loss(train) 0.5176 | Acc(train) 0.8430 | Acc(val) 0.8827 |*
Epoch 00115 | Loss(train) 0.4883 | Acc(train) 0.8505 | Acc(val) 0.8767 |
Epoch 00116 | Loss(train) 0.5107 | Acc(train) 0.8389 | Acc(val) 0.8729 |
Epoch 00117 | Loss(train) 0.5101 | Acc(train) 0.8401 | Acc(val) 0.8729 |
Epoch 00118 | Loss(train) 0.5077 | Acc(train) 0.8404 | Acc(val) 0.8827 |
Epoch 00119 | Loss(train) 0.4974 | Acc(train) 0.8509 | Acc(val) 0.8774 |
Epoch 00120 | Loss(train) 0.5023 | Acc(train) 0.8561 | Acc(val) 0.8819 |
Epoch 00121 | Loss(train) 0.5148 | Acc(train) 0.8382 | Acc(val) 0.8774 |
Epoch 00122 | Loss(train) 0.5031 | Acc(train) 0.8419 | Acc(val) 0.8797 |
Epoch 00123 | Loss(train) 0.5028 | Acc(train) 0.8416 | Acc(val) 0.8812 |
Epoch 00124 | Loss(train) 0.4894 | Acc(train) 0.8505 | Acc(val) 0.8864 |*
Epoch 00125 | Loss(train) 0.4966 | Acc(train) 0.8453 | Acc(val) 0.8819 |
Epoch 00126 | Loss(train) 0.5060 | Acc(train) 0.8363 | Acc(val) 0.8886 |*
Epoch 00127 | Loss(train) 0.4955 | Acc(train) 0.8464 | Acc(val) 0.8834 |
Epoch 00128 | Loss(train) 0.4883 | Acc(train) 0.8457 | Acc(val) 0.8752 |
Epoch 00129 | Loss(train) 0.5001 | Acc(train) 0.8389 | Acc(val) 0.8819 |
Epoch 00130 | Loss(train) 0.4838 | Acc(train) 0.8430 | Acc(val) 0.8879 |
Epoch 00131 | Loss(train) 0.4910 | Acc(train) 0.8531 | Acc(val) 0.8857 |
Epoch 00132 | Loss(train) 0.4759 | Acc(train) 0.8546 | Acc(val) 0.8752 |
Epoch 00133 | Loss(train) 0.4954 | Acc(train) 0.8419 | Acc(val) 0.8819 |
Epoch 00134 | Loss(train) 0.4892 | Acc(train) 0.8479 | Acc(val) 0.8834 |
Epoch 00135 | Loss(train) 0.4898 | Acc(train) 0.8505 | Acc(val) 0.8819 |
Epoch 00136 | Loss(train) 0.4884 | Acc(train) 0.8516 | Acc(val) 0.8782 |
Epoch 00137 | Loss(train) 0.4916 | Acc(train) 0.8404 | Acc(val) 0.8879 |
Epoch 00138 | Loss(train) 0.4972 | Acc(train) 0.8442 | Acc(val) 0.8819 |
Epoch 00139 | Loss(train) 0.5187 | Acc(train) 0.8483 | Acc(val) 0.8692 |
Epoch 00140 | Loss(train) 0.4829 | Acc(train) 0.8468 | Acc(val) 0.8632 |
Epoch 00141 | Loss(train) 0.5165 | Acc(train) 0.8378 | Acc(val) 0.8834 |
Epoch 00142 | Loss(train) 0.4955 | Acc(train) 0.8438 | Acc(val) 0.8879 |
Epoch 00143 | Loss(train) 0.5010 | Acc(train) 0.8543 | Acc(val) 0.8804 |
Epoch 00144 | Loss(train) 0.4938 | Acc(train) 0.8378 | Acc(val) 0.8827 |
Epoch 00145 | Loss(train) 0.4828 | Acc(train) 0.8543 | Acc(val) 0.8767 |
Epoch 00146 | Loss(train) 0.4837 | Acc(train) 0.8442 | Acc(val) 0.8737 |
Epoch 00147 | Loss(train) 0.4943 | Acc(train) 0.8509 | Acc(val) 0.8871 |
Epoch 00148 | Loss(train) 0.4799 | Acc(train) 0.8576 | Acc(val) 0.8849 |
Epoch 00149 | Loss(train) 0.4814 | Acc(train) 0.8614 | Acc(val) 0.8812 |
Epoch 00150 | Loss(train) 0.4694 | Acc(train) 0.8487 | Acc(val) 0.8797 |
Epoch 00151 | Loss(train) 0.4864 | Acc(train) 0.8445 | Acc(val) 0.8722 |
Epoch 00152 | Loss(train) 0.4764 | Acc(train) 0.8509 | Acc(val) 0.8827 |
Epoch 00153 | Loss(train) 0.4781 | Acc(train) 0.8520 | Acc(val) 0.8849 |
Epoch 00154 | Loss(train) 0.4927 | Acc(train) 0.8546 | Acc(val) 0.8842 |
Epoch 00155 | Loss(train) 0.4754 | Acc(train) 0.8464 | Acc(val) 0.8909 |*
Epoch 00156 | Loss(train) 0.4633 | Acc(train) 0.8599 | Acc(val) 0.8946 |*
Epoch 00157 | Loss(train) 0.4879 | Acc(train) 0.8539 | Acc(val) 0.8842 |
Epoch 00158 | Loss(train) 0.4720 | Acc(train) 0.8513 | Acc(val) 0.8864 |
Epoch 00159 | Loss(train) 0.4701 | Acc(train) 0.8524 | Acc(val) 0.8879 |
Epoch 00160 | Loss(train) 0.4717 | Acc(train) 0.8572 | Acc(val) 0.8931 |
Epoch 00161 | Loss(train) 0.4424 | Acc(train) 0.8685 | Acc(val) 0.8916 |
Epoch 00162 | Loss(train) 0.4668 | Acc(train) 0.8520 | Acc(val) 0.8954 |*
Epoch 00163 | Loss(train) 0.4651 | Acc(train) 0.8595 | Acc(val) 0.8946 |
Epoch 00164 | Loss(train) 0.4626 | Acc(train) 0.8576 | Acc(val) 0.8946 |
Epoch 00165 | Loss(train) 0.4621 | Acc(train) 0.8621 | Acc(val) 0.8931 |
Epoch 00166 | Loss(train) 0.4596 | Acc(train) 0.8584 | Acc(val) 0.8894 |
Epoch 00167 | Loss(train) 0.4727 | Acc(train) 0.8572 | Acc(val) 0.8871 |
Epoch 00168 | Loss(train) 0.4488 | Acc(train) 0.8621 | Acc(val) 0.8916 |
Epoch 00169 | Loss(train) 0.4658 | Acc(train) 0.8561 | Acc(val) 0.8969 |*
Epoch 00170 | Loss(train) 0.4551 | Acc(train) 0.8666 | Acc(val) 0.8901 |
Epoch 00171 | Loss(train) 0.4383 | Acc(train) 0.8696 | Acc(val) 0.8879 |
Epoch 00172 | Loss(train) 0.4332 | Acc(train) 0.8595 | Acc(val) 0.8939 |
Epoch 00173 | Loss(train) 0.4366 | Acc(train) 0.8587 | Acc(val) 0.8871 |
Epoch 00174 | Loss(train) 0.4573 | Acc(train) 0.8599 | Acc(val) 0.8931 |
Epoch 00175 | Loss(train) 0.4351 | Acc(train) 0.8621 | Acc(val) 0.8894 |
Epoch 00176 | Loss(train) 0.4548 | Acc(train) 0.8614 | Acc(val) 0.8931 |
Epoch 00177 | Loss(train) 0.4443 | Acc(train) 0.8591 | Acc(val) 0.8886 |
Epoch 00178 | Loss(train) 0.4633 | Acc(train) 0.8516 | Acc(val) 0.8961 |
Epoch 00179 | Loss(train) 0.4537 | Acc(train) 0.8587 | Acc(val) 0.8842 |
Epoch 00180 | Loss(train) 0.4404 | Acc(train) 0.8599 | Acc(val) 0.8909 |
Epoch 00181 | Loss(train) 0.4361 | Acc(train) 0.8625 | Acc(val) 0.8976 |*
Epoch 00182 | Loss(train) 0.4507 | Acc(train) 0.8595 | Acc(val) 0.8857 |
Epoch 00183 | Loss(train) 0.4552 | Acc(train) 0.8531 | Acc(val) 0.8909 |
Epoch 00184 | Loss(train) 0.4505 | Acc(train) 0.8535 | Acc(val) 0.8939 |
Epoch 00185 | Loss(train) 0.4432 | Acc(train) 0.8546 | Acc(val) 0.8999 |*
Epoch 00186 | Loss(train) 0.4450 | Acc(train) 0.8655 | Acc(val) 0.8931 |
Epoch 00187 | Loss(train) 0.4574 | Acc(train) 0.8625 | Acc(val) 0.8901 |
Epoch 00188 | Loss(train) 0.4381 | Acc(train) 0.8565 | Acc(val) 0.8894 |
Epoch 00189 | Loss(train) 0.4349 | Acc(train) 0.8599 | Acc(val) 0.8939 |
Epoch 00190 | Loss(train) 0.4427 | Acc(train) 0.8617 | Acc(val) 0.8954 |
Epoch 00191 | Loss(train) 0.4493 | Acc(train) 0.8658 | Acc(val) 0.8976 |
Epoch 00192 | Loss(train) 0.4445 | Acc(train) 0.8572 | Acc(val) 0.8894 |
Epoch 00193 | Loss(train) 0.4513 | Acc(train) 0.8524 | Acc(val) 0.8916 |
Epoch 00194 | Loss(train) 0.4313 | Acc(train) 0.8636 | Acc(val) 0.8931 |
Epoch 00195 | Loss(train) 0.4364 | Acc(train) 0.8640 | Acc(val) 0.8991 |
Epoch 00196 | Loss(train) 0.4273 | Acc(train) 0.8733 | Acc(val) 0.8969 |
Epoch 00197 | Loss(train) 0.4345 | Acc(train) 0.8632 | Acc(val) 0.8894 |
Epoch 00198 | Loss(train) 0.4305 | Acc(train) 0.8543 | Acc(val) 0.8991 |
Epoch 00199 | Loss(train) 0.4291 | Acc(train) 0.8707 | Acc(val) 0.8931 |
Epoch 00200 | Loss(train) 0.4291 | Acc(train) 0.8759 | Acc(val) 0.8931 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 8/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3059 | Acc(train) 0.2590 | Acc(val) 0.3714 |*
Epoch 00002 | Loss(train) 3.9248 | Acc(train) 0.3528 | Acc(val) 0.1599 |
Epoch 00003 | Loss(train) 4.7309 | Acc(train) 0.1491 | Acc(val) 0.1046 |
Epoch 00004 | Loss(train) 4.1068 | Acc(train) 0.1338 | Acc(val) 0.1629 |
Epoch 00005 | Loss(train) 3.0272 | Acc(train) 0.1386 | Acc(val) 0.0680 |
Epoch 00006 | Loss(train) 2.6913 | Acc(train) 0.1001 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.3876 | Acc(train) 0.3636 | Acc(val) 0.3714 |
Epoch 00008 | Loss(train) 2.5213 | Acc(train) 0.3576 | Acc(val) 0.3714 |
Epoch 00009 | Loss(train) 2.3015 | Acc(train) 0.3572 | Acc(val) 0.3707 |
Epoch 00010 | Loss(train) 2.1218 | Acc(train) 0.3572 | Acc(val) 0.3819 |*
Epoch 00011 | Loss(train) 2.0415 | Acc(train) 0.3595 | Acc(val) 0.4320 |*
Epoch 00012 | Loss(train) 1.9195 | Acc(train) 0.4152 | Acc(val) 0.5396 |*
Epoch 00013 | Loss(train) 1.8934 | Acc(train) 0.4914 | Acc(val) 0.5396 |
Epoch 00014 | Loss(train) 1.8465 | Acc(train) 0.5075 | Acc(val) 0.5247 |
Epoch 00015 | Loss(train) 1.7630 | Acc(train) 0.4892 | Acc(val) 0.4469 |
Epoch 00016 | Loss(train) 1.7574 | Acc(train) 0.4402 | Acc(val) 0.3797 |
Epoch 00017 | Loss(train) 1.7352 | Acc(train) 0.4159 | Acc(val) 0.3774 |
Epoch 00018 | Loss(train) 1.7710 | Acc(train) 0.4133 | Acc(val) 0.3954 |
Epoch 00019 | Loss(train) 1.7334 | Acc(train) 0.4383 | Acc(val) 0.5972 |*
Epoch 00020 | Loss(train) 1.6822 | Acc(train) 0.5217 | Acc(val) 0.6390 |*
Epoch 00021 | Loss(train) 1.6694 | Acc(train) 0.5422 | Acc(val) 0.6323 |
Epoch 00022 | Loss(train) 1.6233 | Acc(train) 0.5572 | Acc(val) 0.6300 |
Epoch 00023 | Loss(train) 1.5983 | Acc(train) 0.5587 | Acc(val) 0.5919 |
Epoch 00024 | Loss(train) 1.5762 | Acc(train) 0.5493 | Acc(val) 0.5673 |
Epoch 00025 | Loss(train) 1.5400 | Acc(train) 0.5448 | Acc(val) 0.5717 |
Epoch 00026 | Loss(train) 1.4972 | Acc(train) 0.5475 | Acc(val) 0.6480 |*
Epoch 00027 | Loss(train) 1.4473 | Acc(train) 0.5818 | Acc(val) 0.6891 |*
Epoch 00028 | Loss(train) 1.4551 | Acc(train) 0.6132 | Acc(val) 0.6831 |
Epoch 00029 | Loss(train) 1.4154 | Acc(train) 0.5987 | Acc(val) 0.6562 |
Epoch 00030 | Loss(train) 1.3807 | Acc(train) 0.6087 | Acc(val) 0.6375 |
Epoch 00031 | Loss(train) 1.3670 | Acc(train) 0.5908 | Acc(val) 0.6435 |
Epoch 00032 | Loss(train) 1.3478 | Acc(train) 0.6020 | Acc(val) 0.6779 |
Epoch 00033 | Loss(train) 1.3029 | Acc(train) 0.6207 | Acc(val) 0.7048 |*
Epoch 00034 | Loss(train) 1.2897 | Acc(train) 0.6446 | Acc(val) 0.7070 |*
Epoch 00035 | Loss(train) 1.2458 | Acc(train) 0.6648 | Acc(val) 0.7085 |*
Epoch 00036 | Loss(train) 1.2355 | Acc(train) 0.6670 | Acc(val) 0.7130 |*
Epoch 00037 | Loss(train) 1.1934 | Acc(train) 0.6644 | Acc(val) 0.7175 |*
Epoch 00038 | Loss(train) 1.1809 | Acc(train) 0.6633 | Acc(val) 0.7197 |*
Epoch 00039 | Loss(train) 1.1881 | Acc(train) 0.6502 | Acc(val) 0.7160 |
Epoch 00040 | Loss(train) 1.1505 | Acc(train) 0.6663 | Acc(val) 0.7227 |*
Epoch 00041 | Loss(train) 1.1313 | Acc(train) 0.6704 | Acc(val) 0.7235 |*
Epoch 00042 | Loss(train) 1.1044 | Acc(train) 0.6783 | Acc(val) 0.7272 |*
Epoch 00043 | Loss(train) 1.0742 | Acc(train) 0.6854 | Acc(val) 0.7280 |*
Epoch 00044 | Loss(train) 1.0700 | Acc(train) 0.6801 | Acc(val) 0.7272 |
Epoch 00045 | Loss(train) 1.0556 | Acc(train) 0.6939 | Acc(val) 0.7287 |*
Epoch 00046 | Loss(train) 1.0604 | Acc(train) 0.6854 | Acc(val) 0.7294 |*
Epoch 00047 | Loss(train) 0.9909 | Acc(train) 0.6906 | Acc(val) 0.7272 |
Epoch 00048 | Loss(train) 0.9994 | Acc(train) 0.7014 | Acc(val) 0.7272 |
Epoch 00049 | Loss(train) 0.9943 | Acc(train) 0.6917 | Acc(val) 0.7302 |*
Epoch 00050 | Loss(train) 1.0035 | Acc(train) 0.6977 | Acc(val) 0.7339 |*
Epoch 00051 | Loss(train) 0.9846 | Acc(train) 0.6816 | Acc(val) 0.7384 |*
Epoch 00052 | Loss(train) 0.9602 | Acc(train) 0.6999 | Acc(val) 0.7459 |*
Epoch 00053 | Loss(train) 0.9519 | Acc(train) 0.7040 | Acc(val) 0.7459 |
Epoch 00054 | Loss(train) 0.9163 | Acc(train) 0.7115 | Acc(val) 0.7526 |*
Epoch 00055 | Loss(train) 0.9369 | Acc(train) 0.6872 | Acc(val) 0.7407 |
Epoch 00056 | Loss(train) 0.9329 | Acc(train) 0.6984 | Acc(val) 0.7713 |*
Epoch 00057 | Loss(train) 0.8831 | Acc(train) 0.7186 | Acc(val) 0.7735 |*
Epoch 00058 | Loss(train) 0.9094 | Acc(train) 0.7115 | Acc(val) 0.7773 |*
Epoch 00059 | Loss(train) 0.8490 | Acc(train) 0.7283 | Acc(val) 0.7862 |*
Epoch 00060 | Loss(train) 0.8769 | Acc(train) 0.7149 | Acc(val) 0.7877 |*
Epoch 00061 | Loss(train) 0.8485 | Acc(train) 0.7209 | Acc(val) 0.7982 |*
Epoch 00062 | Loss(train) 0.8225 | Acc(train) 0.7470 | Acc(val) 0.8072 |*
Epoch 00063 | Loss(train) 0.8091 | Acc(train) 0.7507 | Acc(val) 0.8161 |*
Epoch 00064 | Loss(train) 0.8013 | Acc(train) 0.7601 | Acc(val) 0.8094 |
Epoch 00065 | Loss(train) 0.7821 | Acc(train) 0.7564 | Acc(val) 0.8042 |
Epoch 00066 | Loss(train) 0.7966 | Acc(train) 0.7504 | Acc(val) 0.8049 |
Epoch 00067 | Loss(train) 0.7952 | Acc(train) 0.7504 | Acc(val) 0.8169 |*
Epoch 00068 | Loss(train) 0.7634 | Acc(train) 0.7620 | Acc(val) 0.8199 |*
Epoch 00069 | Loss(train) 0.7510 | Acc(train) 0.7720 | Acc(val) 0.8214 |*
Epoch 00070 | Loss(train) 0.7679 | Acc(train) 0.7706 | Acc(val) 0.8296 |*
Epoch 00071 | Loss(train) 0.7452 | Acc(train) 0.7664 | Acc(val) 0.8236 |
Epoch 00072 | Loss(train) 0.7445 | Acc(train) 0.7739 | Acc(val) 0.8191 |
Epoch 00073 | Loss(train) 0.7775 | Acc(train) 0.7578 | Acc(val) 0.8274 |
Epoch 00074 | Loss(train) 0.7347 | Acc(train) 0.7616 | Acc(val) 0.8363 |*
Epoch 00075 | Loss(train) 0.7332 | Acc(train) 0.7728 | Acc(val) 0.8318 |
Epoch 00076 | Loss(train) 0.7216 | Acc(train) 0.7694 | Acc(val) 0.8296 |
Epoch 00077 | Loss(train) 0.6918 | Acc(train) 0.7877 | Acc(val) 0.8363 |
Epoch 00078 | Loss(train) 0.6987 | Acc(train) 0.7877 | Acc(val) 0.8363 |
Epoch 00079 | Loss(train) 0.6812 | Acc(train) 0.7836 | Acc(val) 0.8348 |
Epoch 00080 | Loss(train) 0.6820 | Acc(train) 0.7915 | Acc(val) 0.8348 |
Epoch 00081 | Loss(train) 0.6769 | Acc(train) 0.7933 | Acc(val) 0.8416 |*
Epoch 00082 | Loss(train) 0.6725 | Acc(train) 0.7941 | Acc(val) 0.8416 |
Epoch 00083 | Loss(train) 0.6728 | Acc(train) 0.7904 | Acc(val) 0.8430 |*
Epoch 00084 | Loss(train) 0.6588 | Acc(train) 0.7982 | Acc(val) 0.8356 |
Epoch 00085 | Loss(train) 0.6746 | Acc(train) 0.7922 | Acc(val) 0.8423 |
Epoch 00086 | Loss(train) 0.6589 | Acc(train) 0.8150 | Acc(val) 0.8543 |*
Epoch 00087 | Loss(train) 0.6493 | Acc(train) 0.8023 | Acc(val) 0.8468 |
Epoch 00088 | Loss(train) 0.6274 | Acc(train) 0.8049 | Acc(val) 0.8408 |
Epoch 00089 | Loss(train) 0.6392 | Acc(train) 0.7952 | Acc(val) 0.8430 |
Epoch 00090 | Loss(train) 0.6441 | Acc(train) 0.8001 | Acc(val) 0.8460 |
Epoch 00091 | Loss(train) 0.6295 | Acc(train) 0.8053 | Acc(val) 0.8520 |
Epoch 00092 | Loss(train) 0.6426 | Acc(train) 0.7971 | Acc(val) 0.8505 |
Epoch 00093 | Loss(train) 0.6620 | Acc(train) 0.7978 | Acc(val) 0.8490 |
Epoch 00094 | Loss(train) 0.6274 | Acc(train) 0.8057 | Acc(val) 0.8543 |
Epoch 00095 | Loss(train) 0.6256 | Acc(train) 0.8046 | Acc(val) 0.8520 |
Epoch 00096 | Loss(train) 0.6164 | Acc(train) 0.7978 | Acc(val) 0.8520 |
Epoch 00097 | Loss(train) 0.6073 | Acc(train) 0.8161 | Acc(val) 0.8520 |
Epoch 00098 | Loss(train) 0.6152 | Acc(train) 0.8064 | Acc(val) 0.8565 |*
Epoch 00099 | Loss(train) 0.6145 | Acc(train) 0.8061 | Acc(val) 0.8550 |
Epoch 00100 | Loss(train) 0.6220 | Acc(train) 0.8031 | Acc(val) 0.8558 |
Epoch 00101 | Loss(train) 0.6081 | Acc(train) 0.8150 | Acc(val) 0.8520 |
Epoch 00102 | Loss(train) 0.6038 | Acc(train) 0.8124 | Acc(val) 0.8535 |
Epoch 00103 | Loss(train) 0.6164 | Acc(train) 0.8004 | Acc(val) 0.8587 |*
Epoch 00104 | Loss(train) 0.6030 | Acc(train) 0.8083 | Acc(val) 0.8580 |
Epoch 00105 | Loss(train) 0.5877 | Acc(train) 0.8135 | Acc(val) 0.8543 |
Epoch 00106 | Loss(train) 0.6174 | Acc(train) 0.8124 | Acc(val) 0.8595 |*
Epoch 00107 | Loss(train) 0.5858 | Acc(train) 0.8251 | Acc(val) 0.8677 |*
Epoch 00108 | Loss(train) 0.6007 | Acc(train) 0.8158 | Acc(val) 0.8640 |
Epoch 00109 | Loss(train) 0.5908 | Acc(train) 0.8221 | Acc(val) 0.8640 |
Epoch 00110 | Loss(train) 0.5691 | Acc(train) 0.8288 | Acc(val) 0.8580 |
Epoch 00111 | Loss(train) 0.5823 | Acc(train) 0.8214 | Acc(val) 0.8617 |
Epoch 00112 | Loss(train) 0.5811 | Acc(train) 0.8315 | Acc(val) 0.8655 |
Epoch 00113 | Loss(train) 0.6049 | Acc(train) 0.8203 | Acc(val) 0.8572 |
Epoch 00114 | Loss(train) 0.5897 | Acc(train) 0.8169 | Acc(val) 0.8565 |
Epoch 00115 | Loss(train) 0.5724 | Acc(train) 0.8277 | Acc(val) 0.8625 |
Epoch 00116 | Loss(train) 0.5850 | Acc(train) 0.8150 | Acc(val) 0.8655 |
Epoch 00117 | Loss(train) 0.5973 | Acc(train) 0.8083 | Acc(val) 0.8647 |
Epoch 00118 | Loss(train) 0.5865 | Acc(train) 0.8061 | Acc(val) 0.8662 |
Epoch 00119 | Loss(train) 0.5659 | Acc(train) 0.8217 | Acc(val) 0.8625 |
Epoch 00120 | Loss(train) 0.5720 | Acc(train) 0.8274 | Acc(val) 0.8692 |*
Epoch 00121 | Loss(train) 0.5734 | Acc(train) 0.8251 | Acc(val) 0.8700 |*
Epoch 00122 | Loss(train) 0.5481 | Acc(train) 0.8247 | Acc(val) 0.8692 |
Epoch 00123 | Loss(train) 0.5613 | Acc(train) 0.8214 | Acc(val) 0.8655 |
Epoch 00124 | Loss(train) 0.5516 | Acc(train) 0.8277 | Acc(val) 0.8685 |
Epoch 00125 | Loss(train) 0.5729 | Acc(train) 0.8270 | Acc(val) 0.8625 |
Epoch 00126 | Loss(train) 0.5467 | Acc(train) 0.8296 | Acc(val) 0.8655 |
Epoch 00127 | Loss(train) 0.5472 | Acc(train) 0.8296 | Acc(val) 0.8744 |*
Epoch 00128 | Loss(train) 0.5718 | Acc(train) 0.8225 | Acc(val) 0.8759 |*
Epoch 00129 | Loss(train) 0.5451 | Acc(train) 0.8315 | Acc(val) 0.8617 |
Epoch 00130 | Loss(train) 0.5920 | Acc(train) 0.8176 | Acc(val) 0.8722 |
Epoch 00131 | Loss(train) 0.5604 | Acc(train) 0.8274 | Acc(val) 0.8752 |
Epoch 00132 | Loss(train) 0.5799 | Acc(train) 0.8199 | Acc(val) 0.8744 |
Epoch 00133 | Loss(train) 0.5738 | Acc(train) 0.8255 | Acc(val) 0.8625 |
Epoch 00134 | Loss(train) 0.5559 | Acc(train) 0.8333 | Acc(val) 0.8587 |
Epoch 00135 | Loss(train) 0.5571 | Acc(train) 0.8262 | Acc(val) 0.8737 |
Epoch 00136 | Loss(train) 0.5449 | Acc(train) 0.8337 | Acc(val) 0.8752 |
Epoch 00137 | Loss(train) 0.5452 | Acc(train) 0.8307 | Acc(val) 0.8700 |
Epoch 00138 | Loss(train) 0.5608 | Acc(train) 0.8285 | Acc(val) 0.8685 |
Epoch 00139 | Loss(train) 0.5410 | Acc(train) 0.8288 | Acc(val) 0.8685 |
Epoch 00140 | Loss(train) 0.5191 | Acc(train) 0.8348 | Acc(val) 0.8767 |*
Epoch 00141 | Loss(train) 0.5482 | Acc(train) 0.8303 | Acc(val) 0.8797 |*
Epoch 00142 | Loss(train) 0.5443 | Acc(train) 0.8300 | Acc(val) 0.8677 |
Epoch 00143 | Loss(train) 0.5492 | Acc(train) 0.8244 | Acc(val) 0.8692 |
Epoch 00144 | Loss(train) 0.5477 | Acc(train) 0.8210 | Acc(val) 0.8797 |
Epoch 00145 | Loss(train) 0.5324 | Acc(train) 0.8262 | Acc(val) 0.8744 |
Epoch 00146 | Loss(train) 0.5440 | Acc(train) 0.8259 | Acc(val) 0.8767 |
Epoch 00147 | Loss(train) 0.5344 | Acc(train) 0.8408 | Acc(val) 0.8707 |
Epoch 00148 | Loss(train) 0.5452 | Acc(train) 0.8322 | Acc(val) 0.8714 |
Epoch 00149 | Loss(train) 0.5473 | Acc(train) 0.8307 | Acc(val) 0.8782 |
Epoch 00150 | Loss(train) 0.5265 | Acc(train) 0.8330 | Acc(val) 0.8789 |
Epoch 00151 | Loss(train) 0.5307 | Acc(train) 0.8359 | Acc(val) 0.8655 |
Epoch 00152 | Loss(train) 0.5480 | Acc(train) 0.8288 | Acc(val) 0.8707 |
Epoch 00153 | Loss(train) 0.5335 | Acc(train) 0.8303 | Acc(val) 0.8729 |
Epoch 00154 | Loss(train) 0.5365 | Acc(train) 0.8285 | Acc(val) 0.8842 |*
Epoch 00155 | Loss(train) 0.5308 | Acc(train) 0.8412 | Acc(val) 0.8789 |
Epoch 00156 | Loss(train) 0.5450 | Acc(train) 0.8277 | Acc(val) 0.8692 |
Epoch 00157 | Loss(train) 0.5277 | Acc(train) 0.8434 | Acc(val) 0.8774 |
Epoch 00158 | Loss(train) 0.5238 | Acc(train) 0.8345 | Acc(val) 0.8812 |
Epoch 00159 | Loss(train) 0.5034 | Acc(train) 0.8430 | Acc(val) 0.8834 |
Epoch 00160 | Loss(train) 0.5333 | Acc(train) 0.8348 | Acc(val) 0.8752 |
Epoch 00161 | Loss(train) 0.5173 | Acc(train) 0.8348 | Acc(val) 0.8752 |
Epoch 00162 | Loss(train) 0.5205 | Acc(train) 0.8345 | Acc(val) 0.8782 |
Epoch 00163 | Loss(train) 0.5076 | Acc(train) 0.8438 | Acc(val) 0.8834 |
Epoch 00164 | Loss(train) 0.5252 | Acc(train) 0.8419 | Acc(val) 0.8834 |
Epoch 00165 | Loss(train) 0.5049 | Acc(train) 0.8490 | Acc(val) 0.8782 |
Epoch 00166 | Loss(train) 0.5351 | Acc(train) 0.8333 | Acc(val) 0.8782 |
Epoch 00167 | Loss(train) 0.4909 | Acc(train) 0.8494 | Acc(val) 0.8767 |
Epoch 00168 | Loss(train) 0.5187 | Acc(train) 0.8359 | Acc(val) 0.8842 |
Epoch 00169 | Loss(train) 0.4971 | Acc(train) 0.8531 | Acc(val) 0.8849 |*
Epoch 00170 | Loss(train) 0.5033 | Acc(train) 0.8550 | Acc(val) 0.8759 |
Epoch 00171 | Loss(train) 0.5192 | Acc(train) 0.8367 | Acc(val) 0.8797 |
Epoch 00172 | Loss(train) 0.5148 | Acc(train) 0.8363 | Acc(val) 0.8857 |*
Epoch 00173 | Loss(train) 0.5165 | Acc(train) 0.8472 | Acc(val) 0.8797 |
Epoch 00174 | Loss(train) 0.5275 | Acc(train) 0.8345 | Acc(val) 0.8767 |
Epoch 00175 | Loss(train) 0.5101 | Acc(train) 0.8401 | Acc(val) 0.8789 |
Epoch 00176 | Loss(train) 0.5363 | Acc(train) 0.8262 | Acc(val) 0.8842 |
Epoch 00177 | Loss(train) 0.5082 | Acc(train) 0.8393 | Acc(val) 0.8827 |
Epoch 00178 | Loss(train) 0.5071 | Acc(train) 0.8408 | Acc(val) 0.8737 |
Epoch 00179 | Loss(train) 0.5096 | Acc(train) 0.8341 | Acc(val) 0.8812 |
Epoch 00180 | Loss(train) 0.5028 | Acc(train) 0.8442 | Acc(val) 0.8857 |
Epoch 00181 | Loss(train) 0.5008 | Acc(train) 0.8427 | Acc(val) 0.8797 |
Epoch 00182 | Loss(train) 0.5001 | Acc(train) 0.8438 | Acc(val) 0.8782 |
Epoch 00183 | Loss(train) 0.4950 | Acc(train) 0.8483 | Acc(val) 0.8871 |*
Epoch 00184 | Loss(train) 0.4968 | Acc(train) 0.8449 | Acc(val) 0.8797 |
Epoch 00185 | Loss(train) 0.4930 | Acc(train) 0.8419 | Acc(val) 0.8722 |
Epoch 00186 | Loss(train) 0.5061 | Acc(train) 0.8359 | Acc(val) 0.8842 |
Epoch 00187 | Loss(train) 0.4901 | Acc(train) 0.8472 | Acc(val) 0.8857 |
Epoch 00188 | Loss(train) 0.4925 | Acc(train) 0.8468 | Acc(val) 0.8804 |
Epoch 00189 | Loss(train) 0.4958 | Acc(train) 0.8501 | Acc(val) 0.8797 |
Epoch 00190 | Loss(train) 0.4944 | Acc(train) 0.8416 | Acc(val) 0.8789 |
Epoch 00191 | Loss(train) 0.5165 | Acc(train) 0.8311 | Acc(val) 0.8849 |
Epoch 00192 | Loss(train) 0.5016 | Acc(train) 0.8397 | Acc(val) 0.8804 |
Epoch 00193 | Loss(train) 0.5033 | Acc(train) 0.8464 | Acc(val) 0.8729 |
Epoch 00194 | Loss(train) 0.4817 | Acc(train) 0.8483 | Acc(val) 0.8804 |
Epoch 00195 | Loss(train) 0.5010 | Acc(train) 0.8363 | Acc(val) 0.8886 |*
Epoch 00196 | Loss(train) 0.5000 | Acc(train) 0.8483 | Acc(val) 0.8789 |
Epoch 00197 | Loss(train) 0.4872 | Acc(train) 0.8468 | Acc(val) 0.8774 |
Epoch 00198 | Loss(train) 0.4764 | Acc(train) 0.8513 | Acc(val) 0.8759 |
Epoch 00199 | Loss(train) 0.4899 | Acc(train) 0.8475 | Acc(val) 0.8871 |
Epoch 00200 | Loss(train) 0.4840 | Acc(train) 0.8509 | Acc(val) 0.8879 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
Exp 9/10
************************************
Start fitting model
************************************
Epoch 00001 | Loss(train) 2.3685 | Acc(train) 0.1214 | Acc(val) 0.3722 |*
Epoch 00002 | Loss(train) 4.0797 | Acc(train) 0.3546 | Acc(val) 0.1158 |
Epoch 00003 | Loss(train) 4.3952 | Acc(train) 0.1480 | Acc(val) 0.1622 |
Epoch 00004 | Loss(train) 3.7191 | Acc(train) 0.1465 | Acc(val) 0.4477 |*
Epoch 00005 | Loss(train) 2.3866 | Acc(train) 0.2971 | Acc(val) 0.3714 |
Epoch 00006 | Loss(train) 3.1743 | Acc(train) 0.3591 | Acc(val) 0.3714 |
Epoch 00007 | Loss(train) 2.7928 | Acc(train) 0.3643 | Acc(val) 0.4073 |
Epoch 00008 | Loss(train) 2.3354 | Acc(train) 0.3666 | Acc(val) 0.5478 |*
Epoch 00009 | Loss(train) 2.2608 | Acc(train) 0.3318 | Acc(val) 0.3550 |
Epoch 00010 | Loss(train) 2.1912 | Acc(train) 0.3102 | Acc(val) 0.4858 |
Epoch 00011 | Loss(train) 1.9667 | Acc(train) 0.3991 | Acc(val) 0.6248 |*
Epoch 00012 | Loss(train) 1.8055 | Acc(train) 0.5273 | Acc(val) 0.4791 |
Epoch 00013 | Loss(train) 1.7722 | Acc(train) 0.4858 | Acc(val) 0.4081 |
Epoch 00014 | Loss(train) 1.8766 | Acc(train) 0.4170 | Acc(val) 0.3924 |
Epoch 00015 | Loss(train) 1.8343 | Acc(train) 0.4339 | Acc(val) 0.5389 |
Epoch 00016 | Loss(train) 1.7707 | Acc(train) 0.4929 | Acc(val) 0.6046 |
Epoch 00017 | Loss(train) 1.7402 | Acc(train) 0.5299 | Acc(val) 0.5949 |
Epoch 00018 | Loss(train) 1.6657 | Acc(train) 0.5366 | Acc(val) 0.6405 |*
Epoch 00019 | Loss(train) 1.6065 | Acc(train) 0.5602 | Acc(val) 0.7138 |*
Epoch 00020 | Loss(train) 1.5497 | Acc(train) 0.6009 | Acc(val) 0.7070 |
Epoch 00021 | Loss(train) 1.5374 | Acc(train) 0.5919 | Acc(val) 0.6966 |
Epoch 00022 | Loss(train) 1.4912 | Acc(train) 0.6024 | Acc(val) 0.7018 |
Epoch 00023 | Loss(train) 1.4721 | Acc(train) 0.6050 | Acc(val) 0.6966 |
Epoch 00024 | Loss(train) 1.4509 | Acc(train) 0.6043 | Acc(val) 0.6943 |
Epoch 00025 | Loss(train) 1.4370 | Acc(train) 0.6248 | Acc(val) 0.6988 |
Epoch 00026 | Loss(train) 1.3827 | Acc(train) 0.6345 | Acc(val) 0.7040 |
Epoch 00027 | Loss(train) 1.3727 | Acc(train) 0.6289 | Acc(val) 0.7100 |
Epoch 00028 | Loss(train) 1.3354 | Acc(train) 0.6286 | Acc(val) 0.7130 |
Epoch 00029 | Loss(train) 1.3158 | Acc(train) 0.6405 | Acc(val) 0.7175 |*
Epoch 00030 | Loss(train) 1.2489 | Acc(train) 0.6577 | Acc(val) 0.7175 |
Epoch 00031 | Loss(train) 1.2603 | Acc(train) 0.6573 | Acc(val) 0.7145 |
Epoch 00032 | Loss(train) 1.2496 | Acc(train) 0.6607 | Acc(val) 0.7138 |
Epoch 00033 | Loss(train) 1.2201 | Acc(train) 0.6614 | Acc(val) 0.7108 |
Epoch 00034 | Loss(train) 1.1790 | Acc(train) 0.6760 | Acc(val) 0.7108 |
Epoch 00035 | Loss(train) 1.1713 | Acc(train) 0.6708 | Acc(val) 0.7190 |*
Epoch 00036 | Loss(train) 1.1678 | Acc(train) 0.6812 | Acc(val) 0.7182 |
Epoch 00037 | Loss(train) 1.1275 | Acc(train) 0.6839 | Acc(val) 0.7175 |
Epoch 00038 | Loss(train) 1.0840 | Acc(train) 0.6850 | Acc(val) 0.7280 |*
Epoch 00039 | Loss(train) 1.0690 | Acc(train) 0.6913 | Acc(val) 0.7347 |*
Epoch 00040 | Loss(train) 1.0449 | Acc(train) 0.6887 | Acc(val) 0.7362 |*
Epoch 00041 | Loss(train) 1.0404 | Acc(train) 0.7067 | Acc(val) 0.7354 |
Epoch 00042 | Loss(train) 1.0140 | Acc(train) 0.7096 | Acc(val) 0.7407 |*
Epoch 00043 | Loss(train) 1.0103 | Acc(train) 0.7096 | Acc(val) 0.7519 |*
Epoch 00044 | Loss(train) 0.9691 | Acc(train) 0.7194 | Acc(val) 0.7466 |
Epoch 00045 | Loss(train) 0.9743 | Acc(train) 0.7093 | Acc(val) 0.7496 |
Epoch 00046 | Loss(train) 0.9488 | Acc(train) 0.7231 | Acc(val) 0.7556 |*
Epoch 00047 | Loss(train) 0.9292 | Acc(train) 0.7302 | Acc(val) 0.7706 |*
Epoch 00048 | Loss(train) 0.9317 | Acc(train) 0.7194 | Acc(val) 0.7720 |*
Epoch 00049 | Loss(train) 0.8890 | Acc(train) 0.7410 | Acc(val) 0.7735 |*
Epoch 00050 | Loss(train) 0.8673 | Acc(train) 0.7384 | Acc(val) 0.7728 |
Epoch 00051 | Loss(train) 0.8651 | Acc(train) 0.7470 | Acc(val) 0.7780 |*
Epoch 00052 | Loss(train) 0.8634 | Acc(train) 0.7474 | Acc(val) 0.7788 |*
Epoch 00053 | Loss(train) 0.8632 | Acc(train) 0.7343 | Acc(val) 0.7765 |
Epoch 00054 | Loss(train) 0.8296 | Acc(train) 0.7429 | Acc(val) 0.7892 |*
Epoch 00055 | Loss(train) 0.8255 | Acc(train) 0.7526 | Acc(val) 0.7990 |*
Epoch 00056 | Loss(train) 0.8182 | Acc(train) 0.7496 | Acc(val) 0.7825 |
Epoch 00057 | Loss(train) 0.7743 | Acc(train) 0.7620 | Acc(val) 0.7915 |
Epoch 00058 | Loss(train) 0.8049 | Acc(train) 0.7500 | Acc(val) 0.8004 |*
Epoch 00059 | Loss(train) 0.7771 | Acc(train) 0.7526 | Acc(val) 0.8184 |*
Epoch 00060 | Loss(train) 0.7612 | Acc(train) 0.7698 | Acc(val) 0.8087 |
Epoch 00061 | Loss(train) 0.7624 | Acc(train) 0.7717 | Acc(val) 0.8004 |
Epoch 00062 | Loss(train) 0.7649 | Acc(train) 0.7601 | Acc(val) 0.7960 |
Epoch 00063 | Loss(train) 0.7526 | Acc(train) 0.7679 | Acc(val) 0.8064 |
Epoch 00064 | Loss(train) 0.7325 | Acc(train) 0.7709 | Acc(val) 0.8221 |*
Epoch 00065 | Loss(train) 0.7382 | Acc(train) 0.7694 | Acc(val) 0.8236 |*
Epoch 00066 | Loss(train) 0.7357 | Acc(train) 0.7758 | Acc(val) 0.8132 |
Epoch 00067 | Loss(train) 0.7216 | Acc(train) 0.7791 | Acc(val) 0.8109 |
Epoch 00068 | Loss(train) 0.6981 | Acc(train) 0.7848 | Acc(val) 0.8236 |
Epoch 00069 | Loss(train) 0.7004 | Acc(train) 0.7844 | Acc(val) 0.8356 |*
Epoch 00070 | Loss(train) 0.7027 | Acc(train) 0.7806 | Acc(val) 0.8326 |
Epoch 00071 | Loss(train) 0.7045 | Acc(train) 0.7904 | Acc(val) 0.8356 |
Epoch 00072 | Loss(train) 0.6993 | Acc(train) 0.7862 | Acc(val) 0.8386 |*
Epoch 00073 | Loss(train) 0.6842 | Acc(train) 0.7956 | Acc(val) 0.8393 |*
Epoch 00074 | Loss(train) 0.6647 | Acc(train) 0.7967 | Acc(val) 0.8386 |
Epoch 00075 | Loss(train) 0.6547 | Acc(train) 0.7978 | Acc(val) 0.8341 |
Epoch 00076 | Loss(train) 0.6442 | Acc(train) 0.7963 | Acc(val) 0.8348 |
Epoch 00077 | Loss(train) 0.6810 | Acc(train) 0.7892 | Acc(val) 0.8378 |
Epoch 00078 | Loss(train) 0.6639 | Acc(train) 0.8023 | Acc(val) 0.8460 |*
Epoch 00079 | Loss(train) 0.6397 | Acc(train) 0.8046 | Acc(val) 0.8453 |
Epoch 00080 | Loss(train) 0.6302 | Acc(train) 0.8057 | Acc(val) 0.8386 |
Epoch 00081 | Loss(train) 0.6593 | Acc(train) 0.7941 | Acc(val) 0.8378 |
Epoch 00082 | Loss(train) 0.6378 | Acc(train) 0.8090 | Acc(val) 0.8438 |
Epoch 00083 | Loss(train) 0.6470 | Acc(train) 0.7975 | Acc(val) 0.8483 |*
Epoch 00084 | Loss(train) 0.6289 | Acc(train) 0.8109 | Acc(val) 0.8520 |*
Epoch 00085 | Loss(train) 0.6236 | Acc(train) 0.8019 | Acc(val) 0.8505 |
Epoch 00086 | Loss(train) 0.6261 | Acc(train) 0.8102 | Acc(val) 0.8468 |
Epoch 00087 | Loss(train) 0.6169 | Acc(train) 0.8139 | Acc(val) 0.8513 |
Epoch 00088 | Loss(train) 0.6302 | Acc(train) 0.8083 | Acc(val) 0.8558 |*
Epoch 00089 | Loss(train) 0.6218 | Acc(train) 0.8154 | Acc(val) 0.8595 |*
Epoch 00090 | Loss(train) 0.6160 | Acc(train) 0.8161 | Acc(val) 0.8580 |
Epoch 00091 | Loss(train) 0.6134 | Acc(train) 0.8180 | Acc(val) 0.8558 |
Epoch 00092 | Loss(train) 0.5948 | Acc(train) 0.8154 | Acc(val) 0.8587 |
Epoch 00093 | Loss(train) 0.6059 | Acc(train) 0.8158 | Acc(val) 0.8610 |*
Epoch 00094 | Loss(train) 0.6131 | Acc(train) 0.8203 | Acc(val) 0.8617 |*
Epoch 00095 | Loss(train) 0.5947 | Acc(train) 0.8191 | Acc(val) 0.8610 |
Epoch 00096 | Loss(train) 0.6016 | Acc(train) 0.8244 | Acc(val) 0.8655 |*
Epoch 00097 | Loss(train) 0.5840 | Acc(train) 0.8274 | Acc(val) 0.8587 |
Epoch 00098 | Loss(train) 0.5797 | Acc(train) 0.8270 | Acc(val) 0.8550 |
Epoch 00099 | Loss(train) 0.6130 | Acc(train) 0.8113 | Acc(val) 0.8692 |*
Epoch 00100 | Loss(train) 0.5989 | Acc(train) 0.8225 | Acc(val) 0.8655 |
Epoch 00101 | Loss(train) 0.5997 | Acc(train) 0.8113 | Acc(val) 0.8662 |
Epoch 00102 | Loss(train) 0.5845 | Acc(train) 0.8277 | Acc(val) 0.8595 |
Epoch 00103 | Loss(train) 0.6063 | Acc(train) 0.8105 | Acc(val) 0.8610 |
Epoch 00104 | Loss(train) 0.5855 | Acc(train) 0.8221 | Acc(val) 0.8655 |
Epoch 00105 | Loss(train) 0.5789 | Acc(train) 0.8311 | Acc(val) 0.8729 |*
Epoch 00106 | Loss(train) 0.5955 | Acc(train) 0.8288 | Acc(val) 0.8700 |
Epoch 00107 | Loss(train) 0.5680 | Acc(train) 0.8311 | Acc(val) 0.8498 |
Epoch 00108 | Loss(train) 0.5830 | Acc(train) 0.8158 | Acc(val) 0.8610 |
Epoch 00109 | Loss(train) 0.5865 | Acc(train) 0.8210 | Acc(val) 0.8677 |
Epoch 00110 | Loss(train) 0.5687 | Acc(train) 0.8296 | Acc(val) 0.8670 |
Epoch 00111 | Loss(train) 0.5894 | Acc(train) 0.8206 | Acc(val) 0.8625 |
Epoch 00112 | Loss(train) 0.5653 | Acc(train) 0.8311 | Acc(val) 0.8632 |
Epoch 00113 | Loss(train) 0.5856 | Acc(train) 0.8176 | Acc(val) 0.8670 |
Epoch 00114 | Loss(train) 0.5712 | Acc(train) 0.8195 | Acc(val) 0.8707 |
Epoch 00115 | Loss(train) 0.5878 | Acc(train) 0.8203 | Acc(val) 0.8744 |*
Epoch 00116 | Loss(train) 0.5682 | Acc(train) 0.8359 | Acc(val) 0.8722 |
Epoch 00117 | Loss(train) 0.5754 | Acc(train) 0.8322 | Acc(val) 0.8692 |
Epoch 00118 | Loss(train) 0.5712 | Acc(train) 0.8296 | Acc(val) 0.8670 |
Epoch 00119 | Loss(train) 0.5673 | Acc(train) 0.8259 | Acc(val) 0.8744 |
Epoch 00120 | Loss(train) 0.5481 | Acc(train) 0.8300 | Acc(val) 0.8722 |
Epoch 00121 | Loss(train) 0.5498 | Acc(train) 0.8412 | Acc(val) 0.8722 |
Epoch 00122 | Loss(train) 0.5607 | Acc(train) 0.8281 | Acc(val) 0.8685 |
Epoch 00123 | Loss(train) 0.5315 | Acc(train) 0.8386 | Acc(val) 0.8729 |
Epoch 00124 | Loss(train) 0.5567 | Acc(train) 0.8251 | Acc(val) 0.8729 |
Epoch 00125 | Loss(train) 0.5391 | Acc(train) 0.8363 | Acc(val) 0.8692 |
Epoch 00126 | Loss(train) 0.5519 | Acc(train) 0.8337 | Acc(val) 0.8677 |
Epoch 00127 | Loss(train) 0.5407 | Acc(train) 0.8326 | Acc(val) 0.8737 |
Epoch 00128 | Loss(train) 0.5494 | Acc(train) 0.8341 | Acc(val) 0.8759 |*
Epoch 00129 | Loss(train) 0.5425 | Acc(train) 0.8367 | Acc(val) 0.8759 |
Epoch 00130 | Loss(train) 0.5420 | Acc(train) 0.8345 | Acc(val) 0.8759 |
Epoch 00131 | Loss(train) 0.5424 | Acc(train) 0.8352 | Acc(val) 0.8767 |*
Epoch 00132 | Loss(train) 0.5220 | Acc(train) 0.8419 | Acc(val) 0.8700 |
Epoch 00133 | Loss(train) 0.5256 | Acc(train) 0.8397 | Acc(val) 0.8707 |
Epoch 00134 | Loss(train) 0.5179 | Acc(train) 0.8404 | Acc(val) 0.8722 |
Epoch 00135 | Loss(train) 0.5348 | Acc(train) 0.8382 | Acc(val) 0.8692 |
Epoch 00136 | Loss(train) 0.5245 | Acc(train) 0.8427 | Acc(val) 0.8744 |
Epoch 00137 | Loss(train) 0.5266 | Acc(train) 0.8427 | Acc(val) 0.8729 |
Epoch 00138 | Loss(train) 0.5234 | Acc(train) 0.8404 | Acc(val) 0.8782 |*
Epoch 00139 | Loss(train) 0.5401 | Acc(train) 0.8378 | Acc(val) 0.8759 |
Epoch 00140 | Loss(train) 0.5337 | Acc(train) 0.8318 | Acc(val) 0.8767 |
Epoch 00141 | Loss(train) 0.5139 | Acc(train) 0.8404 | Acc(val) 0.8767 |
Epoch 00142 | Loss(train) 0.5329 | Acc(train) 0.8382 | Acc(val) 0.8737 |
Epoch 00143 | Loss(train) 0.5265 | Acc(train) 0.8393 | Acc(val) 0.8655 |
Epoch 00144 | Loss(train) 0.5506 | Acc(train) 0.8337 | Acc(val) 0.8722 |
Epoch 00145 | Loss(train) 0.5265 | Acc(train) 0.8408 | Acc(val) 0.8789 |*
Epoch 00146 | Loss(train) 0.5020 | Acc(train) 0.8464 | Acc(val) 0.8759 |
Epoch 00147 | Loss(train) 0.5138 | Acc(train) 0.8352 | Acc(val) 0.8804 |*
Epoch 00148 | Loss(train) 0.5111 | Acc(train) 0.8393 | Acc(val) 0.8692 |
Epoch 00149 | Loss(train) 0.5082 | Acc(train) 0.8483 | Acc(val) 0.8759 |
Epoch 00150 | Loss(train) 0.5092 | Acc(train) 0.8501 | Acc(val) 0.8819 |*
Epoch 00151 | Loss(train) 0.5260 | Acc(train) 0.8333 | Acc(val) 0.8782 |
Epoch 00152 | Loss(train) 0.5153 | Acc(train) 0.8438 | Acc(val) 0.8700 |
Epoch 00153 | Loss(train) 0.4988 | Acc(train) 0.8453 | Acc(val) 0.8700 |
Epoch 00154 | Loss(train) 0.5152 | Acc(train) 0.8374 | Acc(val) 0.8812 |
Epoch 00155 | Loss(train) 0.5102 | Acc(train) 0.8449 | Acc(val) 0.8789 |
Epoch 00156 | Loss(train) 0.5085 | Acc(train) 0.8401 | Acc(val) 0.8744 |
Epoch 00157 | Loss(train) 0.4945 | Acc(train) 0.8558 | Acc(val) 0.8662 |
Epoch 00158 | Loss(train) 0.5105 | Acc(train) 0.8404 | Acc(val) 0.8767 |
Epoch 00159 | Loss(train) 0.4938 | Acc(train) 0.8475 | Acc(val) 0.8774 |
Epoch 00160 | Loss(train) 0.5021 | Acc(train) 0.8572 | Acc(val) 0.8759 |
Epoch 00161 | Loss(train) 0.5112 | Acc(train) 0.8419 | Acc(val) 0.8752 |
Epoch 00162 | Loss(train) 0.5134 | Acc(train) 0.8367 | Acc(val) 0.8722 |
Epoch 00163 | Loss(train) 0.5170 | Acc(train) 0.8430 | Acc(val) 0.8812 |
Epoch 00164 | Loss(train) 0.5039 | Acc(train) 0.8487 | Acc(val) 0.8819 |
Epoch 00165 | Loss(train) 0.5125 | Acc(train) 0.8438 | Acc(val) 0.8804 |
Epoch 00166 | Loss(train) 0.4885 | Acc(train) 0.8505 | Acc(val) 0.8700 |
Epoch 00167 | Loss(train) 0.5040 | Acc(train) 0.8371 | Acc(val) 0.8700 |
Epoch 00168 | Loss(train) 0.5031 | Acc(train) 0.8468 | Acc(val) 0.8864 |*
Epoch 00169 | Loss(train) 0.4971 | Acc(train) 0.8546 | Acc(val) 0.8879 |*
Epoch 00170 | Loss(train) 0.5075 | Acc(train) 0.8505 | Acc(val) 0.8782 |
Epoch 00171 | Loss(train) 0.4994 | Acc(train) 0.8445 | Acc(val) 0.8722 |
Epoch 00172 | Loss(train) 0.5119 | Acc(train) 0.8416 | Acc(val) 0.8759 |
Epoch 00173 | Loss(train) 0.5065 | Acc(train) 0.8457 | Acc(val) 0.8812 |
Epoch 00174 | Loss(train) 0.5054 | Acc(train) 0.8460 | Acc(val) 0.8834 |
Epoch 00175 | Loss(train) 0.4815 | Acc(train) 0.8584 | Acc(val) 0.8759 |
Epoch 00176 | Loss(train) 0.5072 | Acc(train) 0.8371 | Acc(val) 0.8752 |
Epoch 00177 | Loss(train) 0.5070 | Acc(train) 0.8397 | Acc(val) 0.8797 |
Epoch 00178 | Loss(train) 0.4834 | Acc(train) 0.8509 | Acc(val) 0.8834 |
Epoch 00179 | Loss(train) 0.4908 | Acc(train) 0.8580 | Acc(val) 0.8819 |
Epoch 00180 | Loss(train) 0.4970 | Acc(train) 0.8472 | Acc(val) 0.8804 |
Epoch 00181 | Loss(train) 0.5112 | Acc(train) 0.8378 | Acc(val) 0.8752 |
Epoch 00182 | Loss(train) 0.4824 | Acc(train) 0.8528 | Acc(val) 0.8797 |
Epoch 00183 | Loss(train) 0.4791 | Acc(train) 0.8535 | Acc(val) 0.8804 |
Epoch 00184 | Loss(train) 0.4787 | Acc(train) 0.8550 | Acc(val) 0.8864 |
Epoch 00185 | Loss(train) 0.4847 | Acc(train) 0.8505 | Acc(val) 0.8857 |
Epoch 00186 | Loss(train) 0.4827 | Acc(train) 0.8576 | Acc(val) 0.8782 |
Epoch 00187 | Loss(train) 0.4866 | Acc(train) 0.8513 | Acc(val) 0.8767 |
Epoch 00188 | Loss(train) 0.4954 | Acc(train) 0.8430 | Acc(val) 0.8842 |
Epoch 00189 | Loss(train) 0.4758 | Acc(train) 0.8498 | Acc(val) 0.8901 |*
Epoch 00190 | Loss(train) 0.4875 | Acc(train) 0.8498 | Acc(val) 0.8797 |
Epoch 00191 | Loss(train) 0.4913 | Acc(train) 0.8449 | Acc(val) 0.8774 |
Epoch 00192 | Loss(train) 0.4953 | Acc(train) 0.8371 | Acc(val) 0.8789 |
Epoch 00193 | Loss(train) 0.4800 | Acc(train) 0.8543 | Acc(val) 0.8879 |
Epoch 00194 | Loss(train) 0.4719 | Acc(train) 0.8591 | Acc(val) 0.8834 |
Epoch 00195 | Loss(train) 0.4772 | Acc(train) 0.8494 | Acc(val) 0.8812 |
Epoch 00196 | Loss(train) 0.4812 | Acc(train) 0.8487 | Acc(val) 0.8834 |
Epoch 00197 | Loss(train) 0.4812 | Acc(train) 0.8464 | Acc(val) 0.8857 |
Epoch 00198 | Loss(train) 0.4687 | Acc(train) 0.8554 | Acc(val) 0.8886 |
Epoch 00199 | Loss(train) 0.4943 | Acc(train) 0.8513 | Acc(val) 0.8782 |
Epoch 00200 | Loss(train) 0.4727 | Acc(train) 0.8513 | Acc(val) 0.8767 |
************************************
Start fitting calibration
************************************
Calibration model configuration
Namespace(calibration={'epochs': 1000, 'patience': 50, 'cal_lr': 0.01, 'cal_weight_decay': 0, 'num_bin': 10, 'calibrator_name': 'WATS', 'dist_to_train': None, 'heads': 2, 'bias': 1, 'cal_dropout': 0.4, 'cal_hidden_dim': 64}, gnn={'type': 'gcn', 'num_layer': 2, 'hid_dim': 64, 'dropout': 0.8, 'norm': None, 'in_dim': 767, 'out_dim': 10}, train={'epochs': 200, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 50})
************************************
************************************
GPU memory allowcation
GPU Memory Allocated: 127.74 MB
GPU Memory Reserved: 214.00 MB
All runs:
Uncalibrated Test Accuracy: 88.38  0.65
Uncalibrated Difference: 5.63  0.56
Calibrated Test Accuracy: 88.38  0.65
Calibrated Difference: 1.31  0.29
